{"source-free": {"Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation": "|**2025-7-28**|**Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation**|Yihong Cao et.al|[paper](https://arxiv.org/abs/2506.21198)|[code](https://github.com/yihong-97/UNLOCK.)|<details><summary>detail</summary>ICCV 2025</details>|\n", "GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning": "|**2025-7-26**|**GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning**|Sanqing Qu et.al|[paper](https://arxiv.org/abs/2403.14410)|[code](https://github.com/ispc-lab/GLC-plus.)|<details><summary>detail</summary>A substantial extension of the CVPR paper \"Upcycling Models under Domain and Category Shift\"</details>|\n", "SFUOD: Source-Free Unknown Object Detection": "|**2025-7-23**|**SFUOD: Source-Free Unknown Object Detection**|Keon-Hee Park et.al|[paper](https://arxiv.org/abs/2507.17373)|-|<details><summary>detail</summary>This paper has been accepted by ICCV 2025</details>|\n", "Model-Free and Real-Time Bioinspired Unicycle-Based Source Seeking: Differential Wheeled Robotic Experiments": "|**2025-7-21**|**Model-Free and Real-Time Bioinspired Unicycle-Based Source Seeking: Differential Wheeled Robotic Experiments**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2501.02184)|-|-|\n", "Text-Driven Causal Representation Learning for Source-Free Domain Generalization": "|**2025-7-14**|**Text-Driven Causal Representation Learning for Source-Free Domain Generalization**|Lihua Zhou et.al|[paper](https://arxiv.org/abs/2507.09961)|-|<details><summary>detail</summary>Under Review</details>|\n", "Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting": "|**2025-7-12**|**Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting**|Zheang Huai et.al|[paper](https://arxiv.org/abs/2505.08527)|[code](https://github.com/xmed-lab/DFG.)|<details><summary>detail</summary>Accepted in TMI 2025</details>|\n", "Source-Free Domain Adaptation via Multi-view Contrastive Learning": "|**2025-7-4**|**Source-Free Domain Adaptation via Multi-view Contrastive Learning**|Amirfarhad Farhadi et.al|[paper](https://arxiv.org/abs/2507.03321)|-|-|\n", "Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework": "|**2025-6-26**|**Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework**|Ismail Nejjar et.al|[paper](https://arxiv.org/abs/2411.12558)|-|<details><summary>detail</summary>TMLR 2025</details>|\n", "Context Aware Grounded Teacher for Source Free Object Detection": "|**2025-6-25**|**Context Aware Grounded Teacher for Source Free Object Detection**|Tajamul Ashraf et.al|[paper](https://arxiv.org/abs/2504.15404)|[code](https://github.com/Tajamul21/Grounded_Teacher.)|-|\n", "SFDLA: Source-Free Document Layout Analysis": "|**2025-6-18**|**SFDLA: Source-Free Document Layout Analysis**|Sebastian Tewes et.al|[paper](https://arxiv.org/abs/2503.18742)|[code](https://github.com/s3setewe/sfdla-DLAdapter.)|<details><summary>detail</summary>Accepted by ICDAR 2025</details>|\n", "Unified Source-Free Domain Adaptation": "|**2025-6-17**|**Unified Source-Free Domain Adaptation**|Song Tang et.al|[paper](https://arxiv.org/abs/2403.07601)|-|-|\n", "SRPL-SFDA: SAM-Guided Reliable Pseudo-Labels for Source-Free Domain Adaptation in Medical Image Segmentation": "|**2025-6-11**|**SRPL-SFDA: SAM-Guided Reliable Pseudo-Labels for Source-Free Domain Adaptation in Medical Image Segmentation**|Xinya Liu et.al|[paper](https://arxiv.org/abs/2506.09403)|[code](https://github.com/HiLab-git/SRPL-SFDA.)|-|\n", "DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization": "|**2025-6-5**|**DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization**|Geonyoung Lee et.al|[paper](https://arxiv.org/abs/2506.02858)|[code](https://wltschmrz.github.io/DGMO/)|<details><summary>detail</summary>Interspeech 2025</details>|\n", "Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data": "|**2025-5-30**|**Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2503.20771)|-|-|\n", "Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation": "|**2025-5-30**|**Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation**|Pascal Schlachter et.al|[paper](https://arxiv.org/abs/2504.11992)|[code](https://github.com/pascalschlachter/PLAnalysis.)|<details><summary>detail</summary>the 33rd European Signal Processing Conference (EUSIPCO 2025)</details>|\n"}, "object detection": {"Rethinking Multi-Modal Object Detection from the Perspective of Mono-Modality Feature Learning": "|**2025-7-28**|**Rethinking Multi-Modal Object Detection from the Perspective of Mono-Modality Feature Learning**|Tianyi Zhao et.al|[paper](https://arxiv.org/abs/2503.11780)|[code](https://github.com/Zhao-Tian-yi/M2D-LIF.)|-|\n", "Hoi2Threat: An Interpretable Threat Detection Method for Human Violence Scenarios Guided by Human-Object Interaction": "|**2025-7-28**|**Hoi2Threat: An Interpretable Threat Detection Method for Human Violence Scenarios Guided by Human-Object Interaction**|Yuhan Wang et.al|[paper](https://arxiv.org/abs/2503.10508)|-|-|\n", "Synthetic-to-Real Camouflaged Object Detection": "|**2025-7-28**|**Synthetic-to-Real Camouflaged Object Detection**|Zhihao Luo et.al|[paper](https://arxiv.org/abs/2507.18911)|[code](https://github.com/Muscape/S2R-COD.)|-|\n", "YOLO-PRO: Enhancing Instance-Specific Object Detection with Full-Channel Global Self-Attention": "|**2025-7-28**|**YOLO-PRO: Enhancing Instance-Specific Object Detection with Full-Channel Global Self-Attention**|Lin Huang et.al|[paper](https://arxiv.org/abs/2503.02348)|-|-|\n", "Wavelet-guided Misalignment-aware Network for Visible-Infrared Object Detection": "|**2025-7-27**|**Wavelet-guided Misalignment-aware Network for Visible-Infrared Object Detection**|Haote Zhang et.al|[paper](https://arxiv.org/abs/2507.20146)|-|-|\n", "DriveIndia: An Object Detection Dataset for Diverse Indian Traffic Scenes": "|**2025-7-26**|**DriveIndia: An Object Detection Dataset for Diverse Indian Traffic Scenes**|Rishav Kumar et.al|[paper](https://arxiv.org/abs/2507.19912)|[code](https://tihan.iith.ac.in/tiand-datasets/).)|<details><summary>detail</summary>ITSC 2025 Conference</details>|\n", "Interpretable Open-Vocabulary Referring Object Detection with Reverse Contrast Attention": "|**2025-7-26**|**Interpretable Open-Vocabulary Referring Object Detection with Reverse Contrast Attention**|Drandreb Earl O. Juanico et.al|[paper](https://arxiv.org/abs/2507.19891)|-|-|\n", "OW-CLIP: Data-Efficient Visual Supervision for Open-World Object Detection via Human-AI Collaboration": "|**2025-7-26**|**OW-CLIP: Data-Efficient Visual Supervision for Open-World Object Detection via Human-AI Collaboration**|Junwen Duan et.al|[paper](https://arxiv.org/abs/2507.19870)|-|-|\n", "RaGS: Unleashing 3D Gaussian Splatting from 4D Radar and Monocular Cues for 3D Object Detection": "|**2025-7-26**|**RaGS: Unleashing 3D Gaussian Splatting from 4D Radar and Monocular Cues for 3D Object Detection**|Xiaokai Bai et.al|[paper](https://arxiv.org/abs/2507.19856)|-|-|\n", "DS-Det: Single-Query Paradigm and Attention Disentangled Learning for Flexible Object Detection": "|**2025-7-26**|**DS-Det: Single-Query Paradigm and Attention Disentangled Learning for Flexible Object Detection**|Guiping Cao et.al|[paper](https://arxiv.org/abs/2507.19807)|[code](https://github.com/Med-Process/DS-Det/.)|<details><summary>detail</summary>Journal ref:The 33rd ACM International Conference on Multimedia 2025</details>|\n", "TransFlow: Motion Knowledge Transfer from Video Diffusion Models to Video Salient Object Detection": "|**2025-7-26**|**TransFlow: Motion Knowledge Transfer from Video Diffusion Models to Video Salient Object Detection**|Suhwan Cho et.al|[paper](https://arxiv.org/abs/2507.19789)|-|<details><summary>detail</summary>ICCVW 2025</details>|\n", "Co-Win: Joint Object Detection and Instance Segmentation in LiDAR Point Clouds via Collaborative Window Processing": "|**2025-7-25**|**Co-Win: Joint Object Detection and Instance Segmentation in LiDAR Point Clouds via Collaborative Window Processing**|Haichuan Li et.al|[paper](https://arxiv.org/abs/2507.19691)|-|-|\n", "Multistream Network for LiDAR and Camera-based 3D Object Detection in Outdoor Scenes": "|**2025-7-25**|**Multistream Network for LiDAR and Camera-based 3D Object Detection in Outdoor Scenes**|Muhammad Ibrahim et.al|[paper](https://arxiv.org/abs/2507.19304)|[code](https://www.cvlibs.net/datasets/kitti/eval_object_detail.php?&result=d162ec699d6992040e34314d19ab7f5c217075e0)|<details><summary>detail</summary>This paper has been accepted by IEEE/RSJ IROS 2025 for oral presentation on 19 Oct</details>|\n", "Cross Spatial Temporal Fusion Attention for Remote Sensing Object Detection via Image Feature Matching": "|**2025-7-25**|**Cross Spatial Temporal Fusion Attention for Remote Sensing Object Detection via Image Feature Matching**|Abu Sadat Mohammad Salehin Amit et.al|[paper](https://arxiv.org/abs/2507.19118)|-|-|\n", "Revisiting DETR for Small Object Detection via Noise-Resilient Query Optimization": "|**2025-7-25**|**Revisiting DETR for Small Object Detection via Noise-Resilient Query Optimization**|Xiaocheng Fang et.al|[paper](https://arxiv.org/abs/2507.19059)|-|<details><summary>detail</summary>2025 IEEE International Conference on Multimedia and Expo (ICME)</details>|\n"}, "domain adaptation": {"Adapting Vehicle Detectors for Aerial Imagery to Unseen Domains with Weak Supervision": "|**2025-7-28**|**Adapting Vehicle Detectors for Aerial Imagery to Unseen Domains with Weak Supervision**|Xiao Fang et.al|[paper](https://arxiv.org/abs/2507.20976)|[code](https://humansensinglab.github.io/AGenDA)|<details><summary>detail</summary>ICCV 2025</details>|\n", "From Entanglement to Alignment: Representation Space Decomposition for Unsupervised Time Series Domain Adaptation": "|**2025-7-28**|**From Entanglement to Alignment: Representation Space Decomposition for Unsupervised Time Series Domain Adaptation**|Rongyao Cai et.al|[paper](https://arxiv.org/abs/2507.20968)|-|-|\n", "Partial Domain Adaptation via Importance Sampling-based Shift Correction": "|**2025-7-27**|**Partial Domain Adaptation via Importance Sampling-based Shift Correction**|Cheng-Jun Guo et.al|[paper](https://arxiv.org/abs/2507.20191)|-|-|\n", "GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning": "|**2025-7-26**|**GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning**|Sanqing Qu et.al|[paper](https://arxiv.org/abs/2403.14410)|[code](https://github.com/ispc-lab/GLC-plus.)|<details><summary>detail</summary>A substantial extension of the CVPR paper \"Upcycling Models under Domain and Category Shift\"</details>|\n", "Deep Unsupervised Domain Adaptation for Time Series Classification: a Benchmark": "|**2025-7-25**|**Deep Unsupervised Domain Adaptation for Time Series Classification: a Benchmark**|Hassan Ismail Fawaz et.al|[paper](https://arxiv.org/abs/2312.09857)|[code](https://github.com/EricssonResearch/UDA-4-TSC.)|<details><summary>detail</summary>Published in Data Mining and Knowledge Discovery</details>|\n", "Style-Adaptive Detection Transformer for Single-Source Domain Generalized Object Detection": "|**2025-7-25**|**Style-Adaptive Detection Transformer for Single-Source Domain Generalized Object Detection**|Jianhong Han et.al|[paper](https://arxiv.org/abs/2504.20498)|-|<details><summary>detail</summary>Manuscript submitted to IEEE Transactions on Circuits and Systems for Video Technology</details>|\n", "SIDA: Synthetic Image Driven Zero-shot Domain Adaptation": "|**2025-7-24**|**SIDA: Synthetic Image Driven Zero-shot Domain Adaptation**|Ye-Chan Kim et.al|[paper](https://arxiv.org/abs/2507.18632)|-|<details><summary>detail</summary>ACM MM 2025</details>|\n", "crossMoDA Challenge: Evolution of Cross-Modality Domain Adaptation Techniques for Vestibular Schwannoma and Cochlea Segmentation from 2021 to 2023": "|**2025-7-24**|**crossMoDA Challenge: Evolution of Cross-Modality Domain Adaptation Techniques for Vestibular Schwannoma and Cochlea Segmentation from 2021 to 2023**|Navodini Wijethilake et.al|[paper](https://arxiv.org/abs/2506.12006)|-|-|\n", "Att-Adapter: A Robust and Precise Domain-Specific Multi-Attributes T2I Diffusion Adapter via Conditional Variational Autoencoder": "|**2025-7-24**|**Att-Adapter: A Robust and Precise Domain-Specific Multi-Attributes T2I Diffusion Adapter via Conditional Variational Autoencoder**|Wonwoong Cho et.al|[paper](https://arxiv.org/abs/2503.11937)|[code](https://tri-mac.github.io/att-adapter/)|<details><summary>detail</summary>ICCV'25 (Highlight)</details>|\n", "Unsupervised Domain Adaptation for 3D LiDAR Semantic Segmentation Using Contrastive Learning and Multi-Model Pseudo Labeling": "|**2025-7-24**|**Unsupervised Domain Adaptation for 3D LiDAR Semantic Segmentation Using Contrastive Learning and Multi-Model Pseudo Labeling**|Abhishek Kaushik et.al|[paper](https://arxiv.org/abs/2507.18176)|-|-|\n", "AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation": "|**2025-7-23**|**AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation**|Md. Al-Masrur Khan et.al|[paper](https://arxiv.org/abs/2507.17957)|[code](https://github.com/Masrur02/AFRDA)|-|\n", "ODES: Domain Adaptation with Expert Guidance for Online Medical Image Segmentation": "|**2025-7-23**|**ODES: Domain Adaptation with Expert Guidance for Online Medical Image Segmentation**|Md Shazid Islam et.al|[paper](https://arxiv.org/abs/2312.05407)|-|-|\n", "SDC-Net: A Domain Adaptation Framework with Semantic-Dynamic Consistency for Cross-Subject EEG Emotion Recognition": "|**2025-7-23**|**SDC-Net: A Domain Adaptation Framework with Semantic-Dynamic Consistency for Cross-Subject EEG Emotion Recognition**|Jiahao Tang et.al|[paper](https://arxiv.org/abs/2507.17524)|[code](https://github.com/XuanSuTrum/SDC-Net.)|-|\n", "Towards Railway Domain Adaptation for LiDAR-based 3D Detection: Road-to-Rail and Sim-to-Real via SynDRA-BBox": "|**2025-7-22**|**Towards Railway Domain Adaptation for LiDAR-based 3D Detection: Road-to-Rail and Sim-to-Real via SynDRA-BBox**|Xavier Diaz et.al|[paper](https://arxiv.org/abs/2507.16413)|[code](https://syndra.retis.santannapisa.it.)|<details><summary>detail</summary>IEEE International Conference on Intelligent Rail Transportation (ICIRT) 2025</details>|\n", "UPRE: Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement": "|**2025-7-21**|**UPRE: Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement**|Xiao Zhang et.al|[paper](https://arxiv.org/abs/2507.00721)|[code](https://github.com/AMAP-ML/UPRE.)|<details><summary>detail</summary>ICCV2025</details>|\n"}, "domain generalization": {"FedS2R: One-Shot Federated Domain Generalization for Synthetic-to-Real Semantic Segmentation in Autonomous Driving": "|**2025-7-26**|**FedS2R: One-Shot Federated Domain Generalization for Synthetic-to-Real Semantic Segmentation in Autonomous Driving**|Tao Lian et.al|[paper](https://arxiv.org/abs/2507.19881)|-|-|\n", "PennyCoder: Efficient Domain-Specific LLMs for PennyLane-Based Quantum Code Generation": "|**2025-7-25**|**PennyCoder: Efficient Domain-Specific LLMs for PennyLane-Based Quantum Code Generation**|Abdul Basit et.al|[paper](https://arxiv.org/abs/2507.19562)|-|-|\n", "From Continuous to Discrete: Cross-Domain Collaborative General Speech Enhancement via Hierarchical Language Models": "|**2025-7-25**|**From Continuous to Discrete: Cross-Domain Collaborative General Speech Enhancement via Hierarchical Language Models**|Zhaoxi Mu et.al|[paper](https://arxiv.org/abs/2507.19062)|-|<details><summary>detail</summary>ACMMM 2025</details>|\n", "Style-Adaptive Detection Transformer for Single-Source Domain Generalized Object Detection": "|**2025-7-25**|**Style-Adaptive Detection Transformer for Single-Source Domain Generalized Object Detection**|Jianhong Han et.al|[paper](https://arxiv.org/abs/2504.20498)|-|<details><summary>detail</summary>Manuscript submitted to IEEE Transactions on Circuits and Systems for Video Technology</details>|\n", "Omni-Thinker: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards": "|**2025-7-24**|**Omni-Thinker: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards**|Derek Li et.al|[paper](https://arxiv.org/abs/2507.14783)|-|-|\n", "VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks": "|**2025-7-24**|**VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks**|Juhwan Choi et.al|[paper](https://arxiv.org/abs/2407.19795)|-|<details><summary>detail</summary>ICCV 2025 Workshop on Curated Data for Efficient Learning (CDEL)</details>|\n", "Fully Automated SAM for Single-source Domain Generalization in Medical Image Segmentation": "|**2025-7-23**|**Fully Automated SAM for Single-source Domain Generalization in Medical Image Segmentation**|Huanli Zhuo et.al|[paper](https://arxiv.org/abs/2507.17281)|-|<details><summary>detail</summary>This manuscript has been accepted for presentation at the IEEE International Conference on Systems</details>|\n", "Gradient-Guided Annealing for Domain Generalization": "|**2025-7-21**|**Gradient-Guided Annealing for Domain Generalization**|Aristotelis Ballas et.al|[paper](https://arxiv.org/abs/2502.20162)|-|<details><summary>detail</summary>Paper accepted in CVPR2025</details>|\n", "DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation": "|**2025-7-20**|**DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation**|Bo Liu et.al|[paper](https://arxiv.org/abs/2501.03466)|-|-|\n", "Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification": "|**2025-7-19**|**Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification**|Subhendu Khatuya et.al|[paper](https://arxiv.org/abs/2506.06806)|-|<details><summary>detail</summary>This work has been accepted to appear at the Association for Computational Linguistics (ACL)</details>|\n", "Generative Multi-Target Cross-Domain Recommendation": "|**2025-7-17**|**Generative Multi-Target Cross-Domain Recommendation**|Jinqiu Jin et.al|[paper](https://arxiv.org/abs/2507.12871)|-|<details><summary>detail</summary>fix author information</details>|\n", "Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning": "|**2025-7-17**|**Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning**|Simon Ouellette et.al|[paper](https://arxiv.org/abs/2507.15877)|-|-|\n", "Addressing the ML Domain Adaptation Problem for Networking: Realistic and Controllable Training Data Generation with NetReplica": "|**2025-7-17**|**Addressing the ML Domain Adaptation Problem for Networking: Realistic and Controllable Training Data Generation with NetReplica**|Jaber Daneshamooz et.al|[paper](https://arxiv.org/abs/2507.13476)|-|-|\n", "CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings": "|**2025-7-17**|**CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings**|Daniil Orel et.al|[paper](https://arxiv.org/abs/2503.13733)|-|-|\n", "Generative AI Models for Learning Flow Maps of Stochastic Dynamical Systems in Bounded Domains": "|**2025-7-17**|**Generative AI Models for Learning Flow Maps of Stochastic Dynamical Systems in Bounded Domains**|Minglei Yang et.al|[paper](https://arxiv.org/abs/2507.15990)|-|-|\n"}, "vision language": {"The Importance of Facial Features in Vision-based Sign Language Recognition: Eyes, Mouth or Full Face?": "|**2025-7-28**|**The Importance of Facial Features in Vision-based Sign Language Recognition: Eyes, Mouth or Full Face?**|Dinh Nam Pham et.al|[paper](https://arxiv.org/abs/2507.20884)|-|<details><summary>detail</summary>9th International Workshop on Sign Language Translation and Avatar Technologies @ ACM IVA'25</details>|\n", "METEOR: Multi-Encoder Collaborative Token Pruning for Efficient Vision Language Models": "|**2025-7-28**|**METEOR: Multi-Encoder Collaborative Token Pruning for Efficient Vision Language Models**|Yuchen Liu et.al|[paper](https://arxiv.org/abs/2507.20842)|[code](https://github.com/YuchenLiu98/METEOR.)|<details><summary>detail</summary>Accepted by ICCV 2025</details>|\n", "MMGraphRAG: Bridging Vision and Language with Interpretable Multimodal Knowledge Graphs": "|**2025-7-28**|**MMGraphRAG: Bridging Vision and Language with Interpretable Multimodal Knowledge Graphs**|Xueyao Wan et.al|[paper](https://arxiv.org/abs/2507.20804)|-|-|\n", "InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing": "|**2025-7-28**|**InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing**|Kun-Hsiang Lin et.al|[paper](https://arxiv.org/abs/2507.12060)|[code](https://kunkunlin1221.github.io/InstructFLIP.)|<details><summary>detail</summary>Accepted by MM'25</details>|\n", "TransPrune: Token Transition Pruning for Efficient Large Vision-Language Model": "|**2025-7-28**|**TransPrune: Token Transition Pruning for Efficient Large Vision-Language Model**|Ao Li et.al|[paper](https://arxiv.org/abs/2507.20630)|[code](https://github.com/liaolea/TransPrune.)|-|\n", "AgroBench: Vision-Language Model Benchmark in Agriculture": "|**2025-7-28**|**AgroBench: Vision-Language Model Benchmark in Agriculture**|Risa Shinoda et.al|[paper](https://arxiv.org/abs/2507.20519)|[code](https://dahlian00.github.io/AgroBenchPage/)|<details><summary>detail</summary>ICCV 2025</details>|\n", "One Last Attention for Your Vision-Language Model": "|**2025-7-28**|**One Last Attention for Your Vision-Language Model**|Liang Chen et.al|[paper](https://arxiv.org/abs/2507.15480)|[code](https://github.com/khufia/RAda/tree/main)|<details><summary>detail</summary>Accepted by ICCV 2025</details>|\n", "VLM-CPL: Consensus Pseudo Labels from Vision-Language Models for Human Annotation-Free Pathological Image Classification": "|**2025-7-27**|**VLM-CPL: Consensus Pseudo Labels from Vision-Language Models for Human Annotation-Free Pathological Image Classification**|Lanfeng Zhong et.al|[paper](https://arxiv.org/abs/2403.15836)|[code](https://github.com/HiLab-git/VLM-CPL.)|<details><summary>detail</summary>TMI</details>|\n", "Token Reduction Should Go Beyond Efficiency in Generative Models -- From Vision, Language to Multimodality": "|**2025-7-27**|**Token Reduction Should Go Beyond Efficiency in Generative Models -- From Vision, Language to Multimodality**|Zhenglun Kong et.al|[paper](https://arxiv.org/abs/2505.18227)|[code](https://github.com/ZLKong/Awesome-Collection-Token-Reduction)|<details><summary>detail</summary>Project page: https://github</details>|\n", "SAViL-Det: Semantic-Aware Vision-Language Model for Multi-Script Text Detection": "|**2025-7-27**|**SAViL-Det: Semantic-Aware Vision-Language Model for Multi-Script Text Detection**|Mohammed-En-Nadhir Zighem et.al|[paper](https://arxiv.org/abs/2507.20188)|-|-|\n", "LRR-Bench: Left, Right or Rotate? Vision-Language models Still Struggle With Spatial Understanding Tasks": "|**2025-7-27**|**LRR-Bench: Left, Right or Rotate? Vision-Language models Still Struggle With Spatial Understanding Tasks**|Fei Kong et.al|[paper](https://arxiv.org/abs/2507.20174)|[code](https://github.com/kong13661/LRR-Bench.)|-|\n", "Egocentric Action-aware Inertial Localization in Point Clouds with Vision-Language Guidance": "|**2025-7-26**|**Egocentric Action-aware Inertial Localization in Point Clouds with Vision-Language Guidance**|Mingfang Zhang et.al|[paper](https://arxiv.org/abs/2505.14346)|-|<details><summary>detail</summary>ICCV 2025</details>|\n", "ATCTrack: Aligning Target-Context Cues with Dynamic Target States for Robust Vision-Language Tracking": "|**2025-7-26**|**ATCTrack: Aligning Target-Context Cues with Dynamic Target States for Robust Vision-Language Tracking**|X. Feng et.al|[paper](https://arxiv.org/abs/2507.19875)|[code](https://github.com/XiaokunFeng/ATCTrack.)|<details><summary>detail</summary>Accepted by ICCV2025 Highlight ~</details>|\n", "Knowledge Regularized Negative Feature Tuning for Out-of-Distribution Detection with Vision-Language Models": "|**2025-7-26**|**Knowledge Regularized Negative Feature Tuning for Out-of-Distribution Detection with Vision-Language Models**|Wenjie Zhu et.al|[paper](https://arxiv.org/abs/2507.19847)|[code](https://github.com/ZhuWenjie98/KRNFT)|<details><summary>detail</summary>accepted by ACMMM 2025</details>|\n", "SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models": "|**2025-7-25**|**SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models**|Xiangyu Dong et.al|[paper](https://arxiv.org/abs/2507.13152)|-|-|\n"}}