{"source-free": {"Transcending Domains through Text-to-Image Diffusion: A Source-Free Approach to Domain Adaptation": "|**2023-10-2**|**Transcending Domains through Text-to-Image Diffusion: A Source-Free Approach to Domain Adaptation**|Shivang Chopraet.al|[paper](https://arxiv.org/abs/2310.01701)|-|-|\n", "Source-free Depth for Object Pop-out": "|**2023-9-25**|**Source-free Depth for Object Pop-out**|Zongwei Wuet.al|[paper](https://arxiv.org/abs/2212.05370)|-|<details><summary>detail</summary>ICCV 2023</details>|\n", "Dual-Reference Source-Free Active Domain Adaptation for Nasopharyngeal Carcinoma Tumor Segmentation across Multiple Hospitals": "|**2023-9-23**|**Dual-Reference Source-Free Active Domain Adaptation for Nasopharyngeal Carcinoma Tumor Segmentation across Multiple Hospitals**|Hongqiu Wanget.al|[paper](https://arxiv.org/abs/2309.13401)|-|-|\n", "Source-free Active Domain Adaptation for Diabetic Retinopathy Grading Based on Ultra-wide-field Fundus Image": "|**2023-9-19**|**Source-free Active Domain Adaptation for Diabetic Retinopathy Grading Based on Ultra-wide-field Fundus Image**|Jinye Ranet.al|[paper](https://arxiv.org/abs/2309.10619)|-|-|\n", "UPL-SFDA: Uncertainty-aware Pseudo Label Guided Source-Free Domain Adaptation for Medical Image Segmentation": "|**2023-9-18**|**UPL-SFDA: Uncertainty-aware Pseudo Label Guided Source-Free Domain Adaptation for Medical Image Segmentation**|Jianghao Wuet.al|[paper](https://arxiv.org/abs/2309.10244)|-|-|\n", "Trust your Good Friends: Source-free Domain Adaptation by Reciprocal Neighborhood Clustering": "|**2023-9-1**|**Trust your Good Friends: Source-free Domain Adaptation by Reciprocal Neighborhood Clustering**|Shiqi Yanget.al|[paper](https://arxiv.org/abs/2309.00528)|-|<details><summary>detail</summary>Accepted by IEEE TPAMI</details>|\n", "Uncertainty-Aware Source-Free Adaptive Image Super-Resolution with Wavelet Augmentation Transformer": "|**2023-8-30**|**Uncertainty-Aware Source-Free Adaptive Image Super-Resolution with Wavelet Augmentation Transformer**|Yuang Aiet.al|[paper](https://arxiv.org/abs/2303.17783)|-|-|\n", "Local-Global Pseudo-label Correction for Source-free Domain Adaptive Medical Image Segmentation": "|**2023-8-28**|**Local-Global Pseudo-label Correction for Source-free Domain Adaptive Medical Image Segmentation**|Yanyu Yeet.al|[paper](https://arxiv.org/abs/2308.14312)|-|-|\n", "Domain-Specificity Inducing Transformers for Source-Free Domain Adaptation": "|**2023-8-27**|**Domain-Specificity Inducing Transformers for Source-Free Domain Adaptation**|Sunandini Sanyalet.al|[paper](https://arxiv.org/abs/2308.14023)|[code](http://val.cds.iisc.ac.in/DSiT-SFDA)|<details><summary>detail</summary>ICCV 2023</details>|\n", "Prior-guided Source-free Domain Adaptation for Human Pose Estimation": "|**2023-8-26**|**Prior-guided Source-free Domain Adaptation for Human Pose Estimation**|Dripta S. Raychaudhuriet.al|[paper](https://arxiv.org/abs/2308.13954)|-|<details><summary>detail</summary>ICCV 2023</details>|\n", "Rethinking the Role of Pre-Trained Networks in Source-Free Domain Adaptation": "|**2023-8-25**|**Rethinking the Role of Pre-Trained Networks in Source-Free Domain Adaptation**|Wenyu Zhanget.al|[paper](https://arxiv.org/abs/2212.07585)|-|<details><summary>detail</summary>ICCV 2023</details>|\n", "Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis": "|**2023-8-23**|**Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis**|Yuqi Fanget.al|[paper](https://arxiv.org/abs/2308.12495)|-|-|\n", "Black-box Source-free Domain Adaptation via Two-stage Knowledge Distillation": "|**2023-8-23**|**Black-box Source-free Domain Adaptation via Two-stage Knowledge Distillation**|Shuai Wanget.al|[paper](https://arxiv.org/abs/2305.07881)|-|<details><summary>detail</summary>The short version is accepted by IJCAI 1st International Workshop on Generalizing from Limited Resources in the Open World</details>|\n", "SUMMIT: Source-Free Adaptation of Uni-Modal Models to Multi-Modal Targets": "|**2023-8-22**|**SUMMIT: Source-Free Adaptation of Uni-Modal Models to Multi-Modal Targets**|Cody Simonset.al|[paper](https://arxiv.org/abs/2308.11880)|[code](https://github.com/csimo005/SUMMIT.)|-|\n", "The Unreasonable Effectiveness of Large Language-Vision Models for Source-free Video Domain Adaptation": "|**2023-8-22**|**The Unreasonable Effectiveness of Large Language-Vision Models for Source-free Video Domain Adaptation**|Giacomo Zaraet.al|[paper](https://arxiv.org/abs/2308.09139)|[code](https://github.com/giaczara/dallv)|<details><summary>detail</summary>ICCV2023</details>|\n", "In Search for a Generalizable Method for Source Free Domain Adaptation": "|**2023-9-30**|**In Search for a Generalizable Method for Source Free Domain Adaptation**|M Boudiaf et.al|[paper](https://arxiv.org/abs/2302.06658)|[code](https://paperswithcode.com/paper/in-search-for-a-generalizable-method-for)|-|\n", "MAPS: A Noise-Robust Progressive Learning Approach for Source-Free Domain Adaptive Keypoint Detection": "|**2023-9-27**|**MAPS: A Noise-Robust Progressive Learning Approach for Source-Free Domain Adaptive Keypoint Detection**|Y Ding et.al|[paper](https://arxiv.org/abs/2302.04589)|[code](https://github.com/yuhed/maps)|-|\n", "Universal source-free domain adaptation method for cross-domain fault diagnosis of machines": "|**2023-9-20**|**Universal source-free domain adaptation method for cross-domain fault diagnosis of machines**|Y Zhang et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0888327023000663)|-|<details><summary>detail</summary>Mechanical Systems and\u00a0\u2026, 2023 Elsevier</details>|\n", "Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation": "|**2023-9-18**|**Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation**|Y Chen et.al|[paper](https://arxiv.org/abs/2301.13428)|[code](https://github.com/yukilulu/cac)|-|\n", "TIDo: Source-free Task Incremental Learning in Non-stationary Environments": "|**2023-9-14**|**TIDo: Source-free Task Incremental Learning in Non-stationary Environments**|AK Ambastha et.al|[paper](https://arxiv.org/abs/2301.12055)|[code](https://paperswithcode.com/paper/tido-source-free-task-incremental-learning-in)|-|\n", "Adversarial Learning Networks: Source-free Unsupervised Domain Incremental Learning": "|**2023-9-14**|**Adversarial Learning Networks: Source-free Unsupervised Domain Incremental Learning**|AK Ambastha et.al|[paper](https://arxiv.org/abs/2301.12054)|[code](https://paperswithcode.com/paper/adversarial-learning-networks-source-free)|-|\n", "Cross-platform privacy-preserving CT image COVID-19 diagnosis based on source-free domain adaptation": "|**2023-9-9**|**Cross-platform privacy-preserving CT image COVID-19 diagnosis based on source-free domain adaptation**|Y Feng et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0950705123000746)|-|<details><summary>detail</summary>Knowledge Based Systems, 2023 Elsevier</details>|\n", "Source-free Subject Adaptation for EEG-based Visual Recognition": "|**2023-9-6**|**Source-free Subject Adaptation for EEG-based Visual Recognition**|P Lee et.al|[paper](https://arxiv.org/abs/2301.08448)|[code](https://github.com/DeepBCI/Deep-BCI)|-|\n", "When Source-Free Domain Adaptation Meets Label Propagation": "|**2023-9-6**|**When Source-Free Domain Adaptation Meets Label Propagation**|C Wu et.al|[paper](https://arxiv.org/abs/2301.08413)|-|-|\n", "Source-Free Domain Adaptive Detection of Concealed Objects in Passive Millimeter-Wave Images": "|**2023-9-4**|**Source-Free Domain Adaptive Detection of Concealed Objects in Passive Millimeter-Wave Images**|H Yang et.al|[paper](https://ieeexplore.ieee.org/abstract/document/10019315/)|-|<details><summary>detail</summary>IEEE Transactions on\u00a0\u2026, 2023 ieeexplore.ieee.org</details>|\n"}, "object detection": {"Building Flyweight FLIM-based CNNs with Adaptive Decoding for Object Detection": "|**2023-10-5**|**Building Flyweight FLIM-based CNNs with Adaptive Decoding for Object Detection**|Leonardo de Melo Joaoet.al|[paper](https://arxiv.org/abs/2306.14840)|-|-|\n", "SMURF: Spatial Multi-Representation Fusion for 3D Object Detection with 4D Imaging Radar": "|**2023-10-5**|**SMURF: Spatial Multi-Representation Fusion for 3D Object Detection with 4D Imaging Radar**|Jianan Liuet.al|[paper](https://arxiv.org/abs/2307.10784)|-|<details><summary>detail</summary>Accepted by IEEE Transactions on Intelligent Vehicles</details>|\n", "Towards Robust 3D Object Detection In Rainy Conditions": "|**2023-10-5**|**Towards Robust 3D Object Detection In Rainy Conditions**|Aldi Piroliet.al|[paper](https://arxiv.org/abs/2310.00944)|-|<details><summary>detail</summary>Published at IEEE International Conference on Intelligent Transportation Systems ITSC 2023</details>|\n", "Real-time Multi-modal Object Detection and Tracking on Edge for Regulatory Compliance Monitoring": "|**2023-10-5**|**Real-time Multi-modal Object Detection and Tracking on Edge for Regulatory Compliance Monitoring**|Jia Syuen Limet.al|[paper](https://arxiv.org/abs/2310.03333)|-|-|\n", "CoDA: Collaborative Novel Box Discovery and Cross-modal Alignment for Open-vocabulary 3D Object Detection": "|**2023-10-4**|**CoDA: Collaborative Novel Box Discovery and Cross-modal Alignment for Open-vocabulary 3D Object Detection**|Yang Caoet.al|[paper](https://arxiv.org/abs/2310.02960)|[code](https://yangcaoai.github.io/publications/CoDA.html)|<details><summary>detail</summary>Accepted by NeurIPS 2023</details>|\n", "CoBEV: Elevating Roadside 3D Object Detection with Depth and Height Complementarity": "|**2023-10-4**|**CoBEV: Elevating Roadside 3D Object Detection with Depth and Height Complementarity**|Hao Shiet.al|[paper](https://arxiv.org/abs/2310.02815)|[code](https://github.com/MasterHow/CoBEV.)|<details><summary>detail</summary>The source code will be made publicly available at https://github</details>|\n", "Land-cover change detection using paired OpenStreetMap data and optical high-resolution imagery via object-guided Transformer": "|**2023-10-4**|**Land-cover change detection using paired OpenStreetMap data and optical high-resolution imagery via object-guided Transformer**|Hongruixuan Chenet.al|[paper](https://arxiv.org/abs/2310.02674)|-|-|\n", "RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection": "|**2023-10-3**|**RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection**|Ming Kanget.al|[paper](https://arxiv.org/abs/2307.16412)|[code](https://github.com/mkang315/RCS-YOLO.)|<details><summary>detail</summary>MSC Class:68U10 (Primary) 68T10</details>|\n", "MarineDet: Towards Open-Marine Object Detection": "|**2023-10-3**|**MarineDet: Towards Open-Marine Object Detection**|Liang Haixinet.al|[paper](https://arxiv.org/abs/2310.01931)|-|-|\n", "LXL: LiDAR Excluded Lean 3D Object Detection with 4D Imaging Radar and Camera Fusion": "|**2023-10-3**|**LXL: LiDAR Excluded Lean 3D Object Detection with 4D Imaging Radar and Camera Fusion**|Weiyi Xionget.al|[paper](https://arxiv.org/abs/2307.00724)|-|<details><summary>detail</summary>Accepted by IEEE Transactions on Intelligent Vehicles</details>|\n", "Pixel-Aligned Recurrent Queries for Multi-View 3D Object Detection": "|**2023-10-2**|**Pixel-Aligned Recurrent Queries for Multi-View 3D Object Detection**|Yiming Xieet.al|[paper](https://arxiv.org/abs/2310.01401)|[code](https://ymingxie.github.io/parq)|<details><summary>detail</summary>ICCV 2023</details>|\n", "DST-Det: Simple Dynamic Self-Training for Open-Vocabulary Object Detection": "|**2023-10-2**|**DST-Det: Simple Dynamic Self-Training for Open-Vocabulary Object Detection**|Shilin Xuet.al|[paper](https://arxiv.org/abs/2310.01393)|[code](https://github.com/xushilin1/dst-det.)|-|\n", "LS-VOS: Identifying Outliers in 3D Object Detections Using Latent Space Virtual Outlier Synthesis": "|**2023-10-2**|**LS-VOS: Identifying Outliers in 3D Object Detections Using Latent Space Virtual Outlier Synthesis**|Aldi Piroliet.al|[paper](https://arxiv.org/abs/2310.00952)|-|<details><summary>detail</summary>Published at IEEE International Conference on Intelligent Transportation Systems ITSC 2023</details>|\n", "Every Dataset Counts: Scaling up Monocular 3D Object Detection with Joint Datasets Training": "|**2023-10-2**|**Every Dataset Counts: Scaling up Monocular 3D Object Detection with Joint Datasets Training**|Fulong Maet.al|[paper](https://arxiv.org/abs/2310.00920)|-|-|\n", "You Do Not Need Additional Priors in Camouflage Object Detection": "|**2023-10-1**|**You Do Not Need Additional Priors in Camouflage Object Detection**|Yuchen Donget.al|[paper](https://arxiv.org/abs/2310.00702)|-|-|\n", "E-detector: Asynchronous Spatio-temporal for Event-based Object Detection in Intelligent Transportation System": "|**2023-10-5**|**E-detector: Asynchronous Spatio-temporal for Event-based Object Detection in Intelligent Transportation System**|S Zhang et.al|[paper](https://dl.acm.org/doi/abs/10.1145/3584361)|-|<details><summary>detail</summary>ACM Transactions on Multimedia\u00a0\u2026, 2023 dl.acm.org</details>|\n", "\u2026\u00a0Simultaneous Defects Visualizing Algorithm for Both Macro and Micro Defects Based on Nonlinear Lamb Wave with an Application of Faster R-Cnn Object Detection": "|**2023-10-4**|**\u2026\u00a0Simultaneous Defects Visualizing Algorithm for Both Macro and Micro Defects Based on Nonlinear Lamb Wave with an Application of Faster R-Cnn Object Detection**|Y Lee et.al|[paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4362451)|-|<details><summary>detail</summary>Available at SSRN 4362451 papers.ssrn.com</details>|\n", "YOGA: Deep Object Detection in the Wild with Lightweight Feature Learning and Multiscale Attention": "|**2023-10-4**|**YOGA: Deep Object Detection in the Wild with Lightweight Feature Learning and Multiscale Attention**|R Sunkara et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0031320323001516)|[code](https://paperswithcode.com/paper/yoga-deep-object-detection-in-the-wild-with)|<details><summary>detail</summary>Pattern Recognition, 2023 Elsevier</details>|\n", "Spectral-Spatial Feature Enhancement Algorithm for Nighttime Object Detection and Tracking": "|**2023-10-4**|**Spectral-Spatial Feature Enhancement Algorithm for Nighttime Object Detection and Tracking**|Y Lv et.al|[paper](https://www.mdpi.com/2073-8994/15/2/546)|-|<details><summary>detail</summary>Symmetry, 2023 mdpi.com</details>|\n", "CRRNet: Channel Relation Reasoning Network for Salient Object Detection": "|**2023-10-4**|**CRRNet: Channel Relation Reasoning Network for Salient Object Detection**|S Gao et.al|[paper](https://link.springer.com/chapter/10.1007/978-981-99-0301-6_2)|-|<details><summary>detail</summary>\u2026\u00a0Conference, CCF CIRAC 2022, Xi'an\u00a0\u2026, 2023 Springer</details>|\n", "Iterative Fusion and Dual Enhancement for Accurate and Efficient Object Detection": "|**2023-10-4**|**Iterative Fusion and Dual Enhancement for Accurate and Efficient Object Detection**|Z Duan et.al|[paper](https://www.worldscientific.com/doi/abs/10.1142/S0218126623502328)|-|<details><summary>detail</summary>Journal of Circuits\u00a0\u2026, 2023 World Scientific</details>|\n", "CTA-FPN: Channel-Target Attention Feature Pyramid Network for Prohibited Object Detection in X-ray Images": "|**2023-10-4**|**CTA-FPN: Channel-Target Attention Feature Pyramid Network for Prohibited Object Detection in X-ray Images**|Y Zhang et.al|[paper](https://www.researchsquare.com/article/rs-2584406/latest.pdf)|-|<details><summary>detail</summary>2023 researchsquare.com</details>|\n", "Hierarchical Cross-modal Transformer for RGB-D Salient Object Detection": "|**2023-10-4**|**Hierarchical Cross-modal Transformer for RGB-D Salient Object Detection**|H Chen et.al|[paper](https://arxiv.org/abs/2302.08052)|[code](https://github.com/liuzywen/swinnet)|-|\n", "3M3D: Multi-view, Multi-path, Multi-representation for 3D Object Detection": "|**2023-10-4**|**3M3D: Multi-view, Multi-path, Multi-representation for 3D Object Detection**|J Park et.al|[paper](https://arxiv.org/abs/2302.08231)|[code](https://paperswithcode.com/paper/3m3d-multi-view-multi-path-multi)|-|\n", "Research on road object detection algorithm based on improved YOLOX": "|**2023-10-4**|**Research on road object detection algorithm based on improved YOLOX**|T Yang et.al|[paper](https://arxiv.org/abs/2302.08156)|[code](https://paperswithcode.com/paper/research-on-road-object-detection-algorithm)|-|\n"}, "domain adaptation": {"Mitigating the Influence of Domain Shift in Skin Lesion Classification: A Benchmark Study of Unsupervised Domain Adaptation Methods on Dermoscopic Images": "|**2023-10-5**|**Mitigating the Influence of Domain Shift in Skin Lesion Classification: A Benchmark Study of Unsupervised Domain Adaptation Methods on Dermoscopic Images**|Sireesha Chamarthiet.al|[paper](https://arxiv.org/abs/2310.03432)|-|-|\n", "Multi-label Image Classification using Adaptive Graph Convolutional Networks: from a Single Domain to Multiple Domains": "|**2023-10-5**|**Multi-label Image Classification using Adaptive Graph Convolutional Networks: from a Single Domain to Multiple Domains**|Indel Pal Singhet.al|[paper](https://arxiv.org/abs/2301.04494)|-|-|\n", "Continual Test-time Domain Adaptation via Dynamic Sample Selection": "|**2023-10-5**|**Continual Test-time Domain Adaptation via Dynamic Sample Selection**|Yanshuo Wanget.al|[paper](https://arxiv.org/abs/2310.03335)|-|-|\n", "Reformulating Domain Adaptation of Large Language Models as Adapt-Retrieve-Revise": "|**2023-10-5**|**Reformulating Domain Adaptation of Large Language Models as Adapt-Retrieve-Revise**|Zhen wanet.al|[paper](https://arxiv.org/abs/2310.03328)|-|<details><summary>detail</summary>Under submission to ICLR 2024</details>|\n", "Gradual Domain Adaptation via Normalizing Flows": "|**2023-10-4**|**Gradual Domain Adaptation via Normalizing Flows**|Shogo Sagawaet.al|[paper](https://arxiv.org/abs/2206.11492)|-|-|\n", "Learnable Data Augmentation for One-Shot Unsupervised Domain Adaptation": "|**2023-10-3**|**Learnable Data Augmentation for One-Shot Unsupervised Domain Adaptation**|Julio Ivan Davila Carrazcoet.al|[paper](https://arxiv.org/abs/2310.02201)|[code](https://github.com/IIT-PAVIS/LearnAug-UDA)|<details><summary>detail</summary>The 34th British Machine Vision Conference (BMVC 2023)</details>|\n", "Cross-City Matters: A Multimodal Remote Sensing Benchmark Dataset for Cross-City Semantic Segmentation using High-Resolution Domain Adaptation Networks": "|**2023-10-3**|**Cross-City Matters: A Multimodal Remote Sensing Benchmark Dataset for Cross-City Semantic Segmentation using High-Resolution Domain Adaptation Networks**|Danfeng Honget.al|[paper](https://arxiv.org/abs/2309.16499)|[code](https://github.com/danfenghong.)|-|\n", "Transcending Domains through Text-to-Image Diffusion: A Source-Free Approach to Domain Adaptation": "|**2023-10-2**|**Transcending Domains through Text-to-Image Diffusion: A Source-Free Approach to Domain Adaptation**|Shivang Chopraet.al|[paper](https://arxiv.org/abs/2310.01701)|-|-|\n", "The CHiME-7 UDASE task: Unsupervised domain adaptation for conversational speech enhancement": "|**2023-10-2**|**The CHiME-7 UDASE task: Unsupervised domain adaptation for conversational speech enhancement**|Simon Leglaiveet.al|[paper](https://arxiv.org/abs/2307.03533)|-|<details><summary>detail</summary>Journal ref:The 7th International Workshop on Speech Processing in Everyday Environments (CHiME)</details>|\n", "Exploring Sparse Visual Prompt for Domain Adaptive Dense Prediction": "|**2023-10-1**|**Exploring Sparse Visual Prompt for Domain Adaptive Dense Prediction**|Senqiao Yanget.al|[paper](https://arxiv.org/abs/2303.09792)|-|-|\n", "ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation": "|**2023-9-30**|**ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation**|Jiaming Liuet.al|[paper](https://arxiv.org/abs/2306.04344)|-|<details><summary>detail</summary>Neurips2023 final Rating: Weak Accept</details>|\n", "Confidence-based Visual Dispersal for Few-shot Unsupervised Domain Adaptation": "|**2023-9-29**|**Confidence-based Visual Dispersal for Few-shot Unsupervised Domain Adaptation**|Yizhe Xionget.al|[paper](https://arxiv.org/abs/2309.15575)|[code](https://github.com/Bostoncake/C-VisDiT.)|<details><summary>detail</summary>Accepted as ICCV 2023 poster (https://openaccess</details>|\n", "Few-Shot Domain Adaptation for Charge Prediction on Unprofessional Descriptions": "|**2023-9-29**|**Few-Shot Domain Adaptation for Charge Prediction on Unprofessional Descriptions**|Jie Zhaoet.al|[paper](https://arxiv.org/abs/2309.17313)|-|-|\n", "Domain-Adaptive Learning: Unsupervised Adaptation for Histology Images with Improved Loss Function Combination": "|**2023-9-29**|**Domain-Adaptive Learning: Unsupervised Adaptation for Histology Images with Improved Loss Function Combination**|Ravi Kant Guptaet.al|[paper](https://arxiv.org/abs/2309.17172)|-|-|\n", "PC-Adapter: Topology-Aware Adapter for Efficient Domain Adaption on Point Clouds with Rectified Pseudo-label": "|**2023-9-28**|**PC-Adapter: Topology-Aware Adapter for Efficient Domain Adaption on Point Clouds with Rectified Pseudo-label**|Joonhyung Parket.al|[paper](https://arxiv.org/abs/2309.16936)|-|-|\n", "Kurcuma: a kitchen utensil recognition collection for unsupervised domain adaptation": "|**2023-10-4**|**Kurcuma: a kitchen utensil recognition collection for unsupervised domain adaptation**|A Rosello et.al|[paper](https://link.springer.com/article/10.1007/s10044-023-01147-x)|-|<details><summary>detail</summary>Mas, AJ Gallego\u2026 Pattern Analysis and\u00a0\u2026, 2023 Springer</details>|\n", "An improved multi-source domain adaptation network for inter-subject mental fatigue detection based on DANN": "|**2023-10-4**|**An improved multi-source domain adaptation network for inter-subject mental fatigue detection based on DANN**|K Chen et.al|[paper](https://www.degruyter.com/document/doi/10.1515/bmt-2022-0354/html)|-|<details><summary>detail</summary>Biomedical Engineering\u00a0\u2026, 2023 degruyter.com</details>|\n", "A multi-source transfer learning model based on LSTM and domain adaptation for building energy prediction": "|**2023-10-4**|**A multi-source transfer learning model based on LSTM and domain adaptation for building energy prediction**|H Lu et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0142061523000819)|-|<details><summary>detail</summary>International Journal of\u00a0\u2026, 2023 Elsevier</details>|\n", "Open Set Domain Adaptation with Latent Structure Discovery and Kernelized Classifier Learning": "|**2023-10-4**|**Open Set Domain Adaptation with Latent Structure Discovery and Kernelized Classifier Learning**|Y Tang et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0925231223001509)|-|<details><summary>detail</summary>Neurocomputing, 2023 Elsevier</details>|\n", "Towards Real-Time Online Unsupervised Domain Adaptation for Real-World Person Re-identification": "|**2023-10-4**|**Towards Real-Time Online Unsupervised Domain Adaptation for Real-World Person Re-identification**|C Neff et.al|[paper](https://www.researchsquare.com/article/rs-2588554/latest.pdf)|-|<details><summary>detail</summary>2023 researchsquare.com</details>|\n", "Unsupervised Domain Adaptation for MRI Volume Segmentation and Classification Using Image-to-Image Translation": "|**2023-10-4**|**Unsupervised Domain Adaptation for MRI Volume Segmentation and Classification Using Image-to-Image Translation**|S Kondo et.al|[paper](https://arxiv.org/abs/2302.08016)|[code](https://paperswithcode.com/paper/unsupervised-domain-adaptation-for-mri-volume)|-|\n", "High-Intensified Resemblance and Statistic-Restructured Alignment in Few-Shot Domain Adaptation for Industrial-Specialized Employment": "|**2023-10-3**|**High-Intensified Resemblance and Statistic-Restructured Alignment in Few-Shot Domain Adaptation for Industrial-Specialized Employment**|J Petchhan et.al|[paper](https://ieeexplore.ieee.org/abstract/document/10045719/)|-|<details><summary>detail</summary>IEEE Transactions on Consumer\u00a0\u2026, 2023 ieeexplore.ieee.org</details>|\n", "KRADA: Known-region-aware Domain Alignment for Open-set Domain Adaptation in Semantic Segmentation": "|**2023-10-3**|**KRADA: Known-region-aware Domain Alignment for Open-set Domain Adaptation in Semantic Segmentation**|C Zhou et.al|[paper](https://europepmc.org/article/ppr/ppr617459)|[code](https://github.com/chenhong-zhou/krada)|<details><summary>detail</summary>2023 europepmc.org</details>|\n", "Blade crack detection based on domain adaptation and autoencoder of multidimensional vibro-acoustic feature fusion": "|**2023-10-3**|**Blade crack detection based on domain adaptation and autoencoder of multidimensional vibro-acoustic feature fusion**|J Shen et.al|[paper](https://journals.sagepub.com/doi/abs/10.1177/14759217221139134)|-|<details><summary>detail</summary>Structural Health Monitoring, 2023 journals.sagepub.com</details>|\n", "Infrared ship target segmentation based on Adversarial Domain Adaptation": "|**2023-10-2**|**Infrared ship target segmentation based on Adversarial Domain Adaptation**|T Zhang et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0950705123000941)|-|<details><summary>detail</summary>Knowledge Based\u00a0\u2026, 2023 Elsevier</details>|\n"}, "domain generalization": {"Assessment of the Reliablity of a Model's Decision by Generalizing Attribution to the Wavelet Domain": "|**2023-10-5**|**Assessment of the Reliablity of a Model's Decision by Generalizing Attribution to the Wavelet Domain**|Gabriel Kasmiet.al|[paper](https://arxiv.org/abs/2305.14979)|-|-|\n", "Towards Domain-Specific Features Disentanglement for Domain Generalization": "|**2023-10-4**|**Towards Domain-Specific Features Disentanglement for Domain Generalization**|Hao Chenet.al|[paper](https://arxiv.org/abs/2310.03007)|-|-|\n", "Prompting-based Efficient Temporal Domain Generalization": "|**2023-10-3**|**Prompting-based Efficient Temporal Domain Generalization**|Sepidehsadat Hosseiniet.al|[paper](https://arxiv.org/abs/2310.02473)|-|-|\n", "Adversarial Bayesian Augmentation for Single-Source Domain Generalization": "|**2023-10-2**|**Adversarial Bayesian Augmentation for Single-Source Domain Generalization**|Sheng Chenget.al|[paper](https://arxiv.org/abs/2307.09520)|-|<details><summary>detail</summary>ICCV 2023</details>|\n", "CODA: Temporal Domain Generalization via Concept Drift Simulator": "|**2023-10-2**|**CODA: Temporal Domain Generalization via Concept Drift Simulator**|Chia-Yuan Changet.al|[paper](https://arxiv.org/abs/2310.01508)|-|-|\n", "Domain-Agnostic Molecular Generation with Self-feedback": "|**2023-10-2**|**Domain-Agnostic Molecular Generation with Self-feedback**|Yin Fanget.al|[paper](https://arxiv.org/abs/2301.11259)|[code](https://github.com/zjunlp/MolGen.)|<details><summary>detail</summary>Work in progress</details>|\n", "Incorporating Supervised Domain Generalization into Data Augmentation": "|**2023-10-2**|**Incorporating Supervised Domain Generalization into Data Augmentation**|Shohei Enomotoet.al|[paper](https://arxiv.org/abs/2310.01029)|-|-|\n", "Mind the Gap: Federated Learning Broadens Domain Generalization in Diagnostic AI Models": "|**2023-10-1**|**Mind the Gap: Federated Learning Broadens Domain Generalization in Diagnostic AI Models**|Soroosh Tayebi Arastehet.al|[paper](https://arxiv.org/abs/2310.00757)|-|-|\n", "AfriSpeech-200: Pan-African Accented Speech Dataset for Clinical and General Domain ASR": "|**2023-9-30**|**AfriSpeech-200: Pan-African Accented Speech Dataset for Clinical and General Domain ASR**|Tobi Olatunjiet.al|[paper](https://arxiv.org/abs/2310.00274)|-|<details><summary>detail</summary>TACL 2023</details>|\n", "Unlabeled Out-Of-Domain Data Improves Generalization": "|**2023-9-28**|**Unlabeled Out-Of-Domain Data Improves Generalization**|Amir Hossein Saberiet.al|[paper](https://arxiv.org/abs/2310.00027)|-|-|\n", "Rethinking Domain Generalization: Discriminability and Generalizability": "|**2023-9-28**|**Rethinking Domain Generalization: Discriminability and Generalizability**|Shaocong Longet.al|[paper](https://arxiv.org/abs/2309.16483)|-|-|\n", "Diverse Target and Contribution Scheduling for Domain Generalization": "|**2023-9-28**|**Diverse Target and Contribution Scheduling for Domain Generalization**|Shaocong Longet.al|[paper](https://arxiv.org/abs/2309.16460)|-|-|\n", "Domain generalization across tumor types, laboratories, and species -- insights from the 2022 edition of the Mitosis Domain Generalization Challenge": "|**2023-9-27**|**Domain generalization across tumor types, laboratories, and species -- insights from the 2022 edition of the Mitosis Domain Generalization Challenge**|Marc Aubrevilleet.al|[paper](https://arxiv.org/abs/2309.15589)|-|-|\n", "Robust Internal Representations for Domain Generalization": "|**2023-9-27**|**Robust Internal Representations for Domain Generalization**|Mohammad Rostamiet.al|[paper](https://arxiv.org/abs/2309.15522)|-|<details><summary>detail</summary>to appear in AI Magazine Winter 2023 Issue</details>|\n", "CauDR: A Causality-inspired Domain Generalization Framework for Fundus-based Diabetic Retinopathy Grading": "|**2023-9-27**|**CauDR: A Causality-inspired Domain Generalization Framework for Fundus-based Diabetic Retinopathy Grading**|Hao Weiet.al|[paper](https://arxiv.org/abs/2309.15493)|-|-|\n", "Domain Generalization with Global Sample Mixup": "|**2023-10-5**|**Domain Generalization with Global Sample Mixup**|Y Lu et.al|[paper](https://link.springer.com/chapter/10.1007/978-3-031-25075-0_35)|-|<details><summary>detail</summary>European Conference on Computer\u00a0\u2026, 2023 Springer</details>|\n", "Cross-Domain Augmentation Diagnosis: An Adversarial Domain-Augmented Generalization Method for Fault Diagnosis under Unseen Working Conditions": "|**2023-10-5**|**Cross-Domain Augmentation Diagnosis: An Adversarial Domain-Augmented Generalization Method for Fault Diagnosis under Unseen Working Conditions**|Q Li et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0951832023000868)|-|<details><summary>detail</summary>Reliability Engineering &\u00a0\u2026, 2023 Elsevier</details>|\n", "On the Hyperparameters influencing a PINN's generalization beyond the training domain": "|**2023-10-3**|**On the Hyperparameters influencing a PINN's generalization beyond the training domain**|A Bonfanti et.al|[paper](https://arxiv.org/abs/2302.07557)|-|-|\n", "Robust Representation Learning with Self-Distillation for Domain Generalization": "|**2023-10-2**|**Robust Representation Learning with Self-Distillation for Domain Generalization**|A Singh et.al|[paper](https://arxiv.org/abs/2302.06874)|[code](https://github.com/tongkunguan/ccd)|-|\n", "Cross-corpora spoken language identification with domain diversification and generalization": "|**2023-9-30**|**Cross-corpora spoken language identification with domain diversification and generalization**|S Dey et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0885230823000086)|[code](https://paperswithcode.com/paper/cross-corpora-spoken-language-identification)|<details><summary>detail</summary>Computer Speech & Language, 2023 Elsevier</details>|\n", "Domain-Conditioned Normalization for Test-Time Domain Generalization": "|**2023-9-28**|**Domain-Conditioned Normalization for Test-Time Domain Generalization**|Y Jiang et.al|[paper](https://link.springer.com/chapter/10.1007/978-3-031-25085-9_17)|-|<details><summary>detail</summary>Computer Vision\u2013ECCV\u00a0\u2026, 2023 Springer</details>|\n", "Domain Generalization by Functional Regression": "|**2023-9-27**|**Domain Generalization by Functional Regression**|M Holzleitner et.al|[paper](https://arxiv.org/abs/2302.04724)|[code](https://github.com/mlr-org/mlr)|-|\n", "Leveraging Domain Relations for Domain Generalization": "|**2023-9-24**|**Leveraging Domain Relations for Domain Generalization**|H Yao et.al|[paper](https://arxiv.org/abs/2302.02609)|[code](https://github.com/rusty1s/pytorch_geometric)|-|\n", "Aggregation of Disentanglement: Reconsidering Domain Variations in Domain Generalization": "|**2023-9-22**|**Aggregation of Disentanglement: Reconsidering Domain Variations in Domain Generalization**|D Zhang et.al|[paper](https://arxiv.org/abs/2302.02350)|[code](https://paperswithcode.com/paper/aggregation-of-disentanglement-reconsidering)|-|\n", "Domain Generalization Emerges from Dreaming": "|**2023-9-20**|**Domain Generalization Emerges from Dreaming**|H Heo et.al|[paper](https://arxiv.org/abs/2302.00980)|[code](https://paperswithcode.com/paper/domain-generalization-emerges-from-dreaming)|-|\n"}, "vision language": {"Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency": "|**2023-10-5**|**Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency**|Tianhong Liet.al|[paper](https://arxiv.org/abs/2310.03734)|-|-|\n", "Revisiting the Role of Language Priors in Vision-Language Models": "|**2023-10-5**|**Revisiting the Role of Language Priors in Vision-Language Models**|Zhiqiu Linet.al|[paper](https://arxiv.org/abs/2306.01879)|[code](https://linzhiqiu.github.io/papers/visual_gpt_score/)|<details><summary>detail</summary>Website: https://linzhiqiu</details>|\n", "CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers": "|**2023-10-4**|**CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers**|Dachuan Shiet.al|[paper](https://arxiv.org/abs/2305.17455)|[code](https://github.com/sdc17/CrossGET)|<details><summary>detail</summary>Technical Report</details>|\n", "ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models": "|**2023-10-4**|**ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models**|Yi-Lin Sunget.al|[paper](https://arxiv.org/abs/2310.02998)|[code](https://ecoflap.github.io/)|<details><summary>detail</summary>Project page: https://ecoflap</details>|\n", "Probing Intersectional Biases in Vision-Language Models with Counterfactual Examples": "|**2023-10-4**|**Probing Intersectional Biases in Vision-Language Models with Counterfactual Examples**|Phillip Howardet.al|[paper](https://arxiv.org/abs/2310.02988)|-|-|\n", "Improving Vision Anomaly Detection with the Guidance of Language Modality": "|**2023-10-4**|**Improving Vision Anomaly Detection with the Guidance of Language Modality**|Dong Chenet.al|[paper](https://arxiv.org/abs/2310.02821)|-|-|\n", "The Role of Linguistic Priors in Measuring Compositional Generalization of Vision-Language Models": "|**2023-10-4**|**The Role of Linguistic Priors in Measuring Compositional Generalization of Vision-Language Models**|Chenwei Wuet.al|[paper](https://arxiv.org/abs/2310.02777)|-|-|\n", "ReForm-Eval: Evaluating Large Vision Language Models via Unified Re-Formulation of Task-Oriented Benchmarks": "|**2023-10-4**|**ReForm-Eval: Evaluating Large Vision Language Models via Unified Re-Formulation of Task-Oriented Benchmarks**|Zejun Liet.al|[paper](https://arxiv.org/abs/2310.02569)|-|-|\n", "MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokens": "|**2023-10-3**|**MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokens**|Kaizhi Zhenget.al|[paper](https://arxiv.org/abs/2310.02239)|-|-|\n", "Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model: Explorations with GPT4-Vision and Beyond": "|**2023-10-3**|**Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model: Explorations with GPT4-Vision and Beyond**|Liang Chenet.al|[paper](https://arxiv.org/abs/2310.02071)|-|-|\n", "HallE-Switch: Rethinking and Controlling Object Existence Hallucinations in Large Vision Language Models for Detailed Caption": "|**2023-10-3**|**HallE-Switch: Rethinking and Controlling Object Existence Hallucinations in Large Vision Language Models for Detailed Caption**|Bohan Zhaiet.al|[paper](https://arxiv.org/abs/2310.01779)|-|-|\n", "Fool Your (Vision and) Language Model With Embarrassingly Simple Permutations": "|**2023-10-2**|**Fool Your (Vision and) Language Model With Embarrassingly Simple Permutations**|Yongshuo Zonget.al|[paper](https://arxiv.org/abs/2310.01651)|[code](https://github.com/ys-zong/FoolyourVLLMs)|-|\n", "Vision-Language Dataset Distillation": "|**2023-10-2**|**Vision-Language Dataset Distillation**|Xindi Wuet.al|[paper](https://arxiv.org/abs/2308.07545)|-|-|\n", "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models": "|**2023-10-2**|**MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models**|Deyao Zhuet.al|[paper](https://arxiv.org/abs/2304.10592)|[code](https://minigpt-4.github.io/.)|<details><summary>detail</summary>Project Website: https://minigpt-4</details>|\n", "GeoVLN: Learning Geometry-Enhanced Visual Representation with Slot Attention for Vision-and-Language Navigation": "|**2023-10-2**|**GeoVLN: Learning Geometry-Enhanced Visual Representation with Slot Attention for Vision-and-Language Navigation**|Jingyang Huoet.al|[paper](https://arxiv.org/abs/2305.17102)|-|<details><summary>detail</summary>Accepted by CVPR 2023</details>|\n", "Weakly-Supervised HOI Detection from Interaction Labels Only and Language/Vision-Language Priors": "|**2023-10-3**|**Weakly-Supervised HOI Detection from Interaction Labels Only and Language/Vision-Language Priors**|M Erhan Unal et.al|[paper](https://ui.adsabs.harvard.edu/abs/2023arXiv230305546E/abstract)|[code](https://paperswithcode.com/paper/weakly-supervised-hoi-detection-from)|-|\n", "Scaling Vision-Language Models with Sparse Mixture of Experts": "|**2023-10-3**|**Scaling Vision-Language Models with Sparse Mixture of Experts**|S Shen et.al|[paper](https://arxiv.org/abs/2303.07226)|[code](https://github.com/google-research/vmoe)|-|\n", "Vision-Language Models as Success Detectors": "|**2023-10-3**|**Vision-Language Models as Success Detectors**|Y Du et.al|[paper](https://arxiv.org/abs/2303.07280)|[code](https://github.com/dyabel/detpro)|-|\n", "Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images": "|**2023-10-3**|**Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images**|N Bitton-Guetta et.al|[paper](https://arxiv.org/abs/2303.07274)|[code](https://paperswithcode.com/paper/breaking-common-sense-whoops-a-vision-and)|-|\n", "Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Models": "|**2023-10-1**|**Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Models**|Z Zheng et.al|[paper](https://arxiv.org/abs/2303.06628)|[code](https://github.com/thunderbeee/zscl)|-|\n", "Gradient-Regulated Meta-Prompt Learning for Generalizable Vision-Language Models": "|**2023-10-1**|**Gradient-Regulated Meta-Prompt Learning for Generalizable Vision-Language Models**|J Li et.al|[paper](https://arxiv.org/abs/2303.06571)|[code](https://paperswithcode.com/paper/gradient-regulated-meta-prompt-learning-for)|-|\n", "Towards Universal Vision-language Omni-supervised Segmentation": "|**2023-10-1**|**Towards Universal Vision-language Omni-supervised Segmentation**|B Dong et.al|[paper](https://arxiv.org/abs/2303.06547)|[code](https://paperswithcode.com/paper/towards-universal-vision-language-omni)|-|\n", "Learning Grounded Vision-Language Representation for Versatile Understanding in Untrimmed Videos": "|**2023-9-30**|**Learning Grounded Vision-Language Representation for Versatile Understanding in Untrimmed Videos**|T Wang et.al|[paper](https://arxiv.org/abs/2303.06378)|[code](https://github.com/zjr2000/gvl)|-|\n", "Tag2Text: Guiding Vision-Language Model via Image Tagging": "|**2023-9-29**|**Tag2Text: Guiding Vision-Language Model via Image Tagging**|X Huang et.al|[paper](https://arxiv.org/abs/2303.05657)|[code](https://github.com/xinyu1205/recognize-anything)|-|\n", "Robotic Applications of Pre-Trained Vision-Language Models to Various Recognition Behaviors": "|**2023-9-29**|**Robotic Applications of Pre-Trained Vision-Language Models to Various Recognition Behaviors**|K Kawaharazuka et.al|[paper](https://arxiv.org/abs/2303.05674)|-|-|\n"}}