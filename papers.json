{"source-free": {"A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation": "|**2025-9-26**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|\n", "Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation": "|**2025-9-24**|**Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|\n", "Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment": "|**2025-9-22**|**Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment**|Wenjie Liu et.al|[paper](https://arxiv.org/abs/2509.18502)|-|-|\n", "Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation": "|**2025-9-22**|**Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation**|Amirhossein Dadashzadeh et.al|[paper](https://arxiv.org/abs/2504.11669)|[code](https://github.com/Plrbear/Co-Star)|-|\n", "Prototype-Based Pseudo-Label Denoising for Source-Free Domain Adaptation in Remote Sensing Semantic Segmentation": "|**2025-9-21**|**Prototype-Based Pseudo-Label Denoising for Source-Free Domain Adaptation in Remote Sensing Semantic Segmentation**|Bin Wang et.al|[paper](https://arxiv.org/abs/2509.16942)|-|-|\n", "Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments": "|**2025-9-18**|**Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2501.02184)|-|-|\n", "Step-wise Distribution Alignment Guided Style Prompt Tuning for Source-free Cross-domain Few-shot Learning": "|**2025-9-13**|**Step-wise Distribution Alignment Guided Style Prompt Tuning for Source-free Cross-domain Few-shot Learning**|Huali Xu et.al|[paper](https://arxiv.org/abs/2411.10070)|[code](https://github.com/xuhuali-mxj/StepSPT.)|<details><summary>detail</summary>IEEE TPAMI</details>|\n", "Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment": "|**2025-9-12**|**Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment**|Rini Smita Thakur et.al|[paper](https://arxiv.org/abs/2509.10134)|[code](https://visdomlab.github.io/GCL/.)|<details><summary>detail</summary>Accepted in BMVC 2025</details>|\n", "Rethinking the Backbone in Class Imbalanced Federated Source Free Domain Adaptation: The Utility of Vision Foundation Models": "|**2025-9-10**|**Rethinking the Backbone in Class Imbalanced Federated Source Free Domain Adaptation: The Utility of Vision Foundation Models**|Kosuke Kihara et.al|[paper](https://arxiv.org/abs/2509.08372)|-|<details><summary>detail</summary>Accepted by the IEEE ICIP 2025 Satellite Workshop 1: Edge Intelligence: Smart</details>|\n", "StableSleep: Source-Free Test-Time Adaptation for Sleep Staging with Lightweight Safety Rails": "|**2025-9-2**|**StableSleep: Source-Free Test-Time Adaptation for Sleep Staging with Lightweight Safety Rails**|Hritik Arasu et.al|[paper](https://arxiv.org/abs/2509.02982)|-|<details><summary>detail</summary>5 page paper</details>|\n", "Model-Free Hovering and Source Seeking via Extremum Seeking Control: Experimental Demonstration": "|**2025-8-28**|**Model-Free Hovering and Source Seeking via Extremum Seeking Control: Experimental Demonstration**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2508.20836)|-|-|\n", "VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection": "|**2025-8-26**|**VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection**|Jianhong Han et.al|[paper](https://arxiv.org/abs/2508.11167)|-|<details><summary>detail</summary>Manuscript submitted to IEEE TCSVT</details>|\n", "Towards Source-Free Machine Unlearning": "|**2025-8-20**|**Towards Source-Free Machine Unlearning**|Sk Miraj Ahmed et.al|[paper](https://arxiv.org/abs/2508.15127)|-|<details><summary>detail</summary>Accepted by CVPR 2025</details>|\n", "Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method": "|**2025-8-14**|**Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2508.09202)|-|-|\n", "Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation": "|**2025-8-7**|**Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation**|Jianming Liu et.al|[paper](https://arxiv.org/abs/2508.05213)|[code](https://github.com/ljm198134/TVGTANet.)|-|\n"}, "object detection": {"Group Evidence Matters: Tiling-based Semantic Gating for Dense Object Detection": "|**2025-9-26**|**Group Evidence Matters: Tiling-based Semantic Gating for Dense Object Detection**|Yilun Xiao et.al|[paper](https://arxiv.org/abs/2509.10779)|-|-|\n", "OS-W2S: An Automatic Labeling Engine for Language-Guided Open-Set Aerial Object Detection": "|**2025-9-26**|**OS-W2S: An Automatic Labeling Engine for Language-Guided Open-Set Aerial Object Detection**|Guoting Wei et.al|[paper](https://arxiv.org/abs/2505.03334)|[code](https://github.com/GT-Wei/MI-OAD.)|-|\n", "HierLight-YOLO: A Hierarchical and Lightweight Object Detection Network for UAV Photography": "|**2025-9-26**|**HierLight-YOLO: A Hierarchical and Lightweight Object Detection Network for UAV Photography**|Defan Chen et.al|[paper](https://arxiv.org/abs/2509.22365)|-|-|\n", "Neptune-X: Active X-to-Maritime Generation for Universal Maritime Object Detection": "|**2025-9-25**|**Neptune-X: Active X-to-Maritime Generation for Universal Maritime Object Detection**|Yu Guo et.al|[paper](https://arxiv.org/abs/2509.20745)|[code](https://github.com/gy65896/Neptune-X.)|-|\n", "Real-Time Object Detection Meets DINOv3": "|**2025-9-25**|**Real-Time Object Detection Meets DINOv3**|Shihua Huang et.al|[paper](https://arxiv.org/abs/2509.20787)|[code](https://github.com/Intellindust-AI-Lab/DEIMv2)|<details><summary>detail</summary>Source code available at https://github</details>|\n", "MS-YOLO: Infrared Object Detection for Edge Deployment via MobileNetV4 and SlideLoss": "|**2025-9-25**|**MS-YOLO: Infrared Object Detection for Edge Deployment via MobileNetV4 and SlideLoss**|Jiali Zhang et.al|[paper](https://arxiv.org/abs/2509.21696)|-|<details><summary>detail</summary>Accepted by the International Joint Conference on Neural Networks (IJCNN) 2025</details>|\n", "SOOD++: Leveraging Unlabeled Data to Boost Oriented Object Detection": "|**2025-9-25**|**SOOD++: Leveraging Unlabeled Data to Boost Oriented Object Detection**|Dingkang Liang et.al|[paper](https://arxiv.org/abs/2407.01016)|[code](https://dk-liang.github.io/SOODv2/)|<details><summary>detail</summary>Accepted by IEEE TPAMI</details>|\n", "Lightweight Modular Parameter-Efficient Tuning for Open-Vocabulary Object Detection": "|**2025-9-25**|**Lightweight Modular Parameter-Efficient Tuning for Open-Vocabulary Object Detection**|Bilal Faye et.al|[paper](https://arxiv.org/abs/2408.10787)|-|-|\n", "Model Agnostic Defense against Adversarial Patch Attacks on Object Detection in Unmanned Aerial Vehicles": "|**2025-9-24**|**Model Agnostic Defense against Adversarial Patch Attacks on Object Detection in Unmanned Aerial Vehicles**|Saurabh Pathak et.al|[paper](https://arxiv.org/abs/2405.19179)|-|<details><summary>detail</summary>published in IROS 2024</details>|\n", "SpaRC: Sparse Radar-Camera Fusion for 3D Object Detection": "|**2025-9-24**|**SpaRC: Sparse Radar-Camera Fusion for 3D Object Detection**|Philipp Wolters et.al|[paper](https://arxiv.org/abs/2411.19860)|[code](https://github.com/phi-wol/sparc.)|-|\n", "Adaptive Guidance Semantically Enhanced via Multimodal LLM for Edge-Cloud Object Detection": "|**2025-9-24**|**Adaptive Guidance Semantically Enhanced via Multimodal LLM for Edge-Cloud Object Detection**|Yunqing Hu et.al|[paper](https://arxiv.org/abs/2509.19875)|-|-|\n", "BiTAA: A Bi-Task Adversarial Attack for Object Detection and Depth Estimation via 3D Gaussian Splatting": "|**2025-9-24**|**BiTAA: A Bi-Task Adversarial Attack for Object Detection and Depth Estimation via 3D Gaussian Splatting**|Yixun Zhang et.al|[paper](https://arxiv.org/abs/2509.19793)|-|<details><summary>detail</summary>Intend to submit to RA-L</details>|\n", "HyPSAM: Hybrid Prompt-driven Segment Anything Model for RGB-Thermal Salient Object Detection": "|**2025-9-23**|**HyPSAM: Hybrid Prompt-driven Segment Anything Model for RGB-Thermal Salient Object Detection**|Ruichao Hou et.al|[paper](https://arxiv.org/abs/2509.18738)|[code](https://github.com/milotic233/HyPSAM.)|-|\n", "LEAF-Mamba: Local Emphatic and Adaptive Fusion State Space Model for RGB-D Salient Object Detection": "|**2025-9-23**|**LEAF-Mamba: Local Emphatic and Adaptive Fusion State Space Model for RGB-D Salient Object Detection**|Lanhu Wu et.al|[paper](https://arxiv.org/abs/2509.18683)|-|<details><summary>detail</summary>ACM MM 2025</details>|\n", "MLF-4DRCNet: Multi-Level Fusion with 4D Radar and Camera for 3D Object Detection in Autonomous Driving": "|**2025-9-23**|**MLF-4DRCNet: Multi-Level Fusion with 4D Radar and Camera for 3D Object Detection in Autonomous Driving**|Yuzhi Wu et.al|[paper](https://arxiv.org/abs/2509.18613)|-|-|\n"}, "domain adaptation": {"A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation": "|**2025-9-26**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|\n", "Demystifying Domain-adaptive Post-training for Financial LLMs": "|**2025-9-25**|**Demystifying Domain-adaptive Post-training for Financial LLMs**|Zixuan Ke et.al|[paper](https://arxiv.org/abs/2501.04961)|-|<details><summary>detail</summary>EMNLP 2025 (Oral)</details>|\n", "Degree-Conscious Spiking Graph for Cross-Domain Adaptation": "|**2025-9-25**|**Degree-Conscious Spiking Graph for Cross-Domain Adaptation**|Yingxu Wang et.al|[paper](https://arxiv.org/abs/2410.06883)|-|-|\n", "Reasoning-Enhanced Domain-Adaptive Pretraining of Multimodal Large Language Models for Short Video Content Moderation": "|**2025-9-25**|**Reasoning-Enhanced Domain-Adaptive Pretraining of Multimodal Large Language Models for Short Video Content Moderation**|Zixuan Wang et.al|[paper](https://arxiv.org/abs/2509.21486)|-|-|\n", "ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining": "|**2025-9-25**|**ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining**|Seonwu Kim et.al|[paper](https://arxiv.org/abs/2507.06795)|-|<details><summary>detail</summary>EMNLP 2025 Industry Track</details>|\n", "Structure-Attribute Transformations with Markov Chain Boost Graph Domain Adaptation": "|**2025-9-25**|**Structure-Attribute Transformations with Markov Chain Boost Graph Domain Adaptation**|Zhen Liu et.al|[paper](https://arxiv.org/abs/2509.21059)|[code](https://github.com/GiantZhangYT/SATMC.)|-|\n", "Predictive Coding-based Deep Neural Network Fine-tuning for Computationally Efficient Domain Adaptation": "|**2025-9-25**|**Predictive Coding-based Deep Neural Network Fine-tuning for Computationally Efficient Domain Adaptation**|Matteo Cardoni et.al|[paper](https://arxiv.org/abs/2509.20269)|-|-|\n", "MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model": "|**2025-9-24**|**MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model**|Hsiao-Ying Huang et.al|[paper](https://arxiv.org/abs/2509.20706)|-|-|\n", "Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training": "|**2025-9-24**|**Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training**|Shuo Cheng et.al|[paper](https://arxiv.org/abs/2509.18631)|-|-|\n", "Unsupervised Domain Adaptation with an Unobservable Source Subpopulation": "|**2025-9-24**|**Unsupervised Domain Adaptation with an Unobservable Source Subpopulation**|Chao Ying et.al|[paper](https://arxiv.org/abs/2509.20587)|-|-|\n", "DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware Reinforcement Learning on Imbalanced Data": "|**2025-9-24**|**DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware Reinforcement Learning on Imbalanced Data**|Yuhang Zhou et.al|[paper](https://arxiv.org/abs/2505.15074)|[code](https://github.com/Tonyzhou98/disco_grpo.)|<details><summary>detail</summary>Accepted by EMNLP 2025 Findings</details>|\n", "Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation": "|**2025-9-24**|**Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|\n", "SDC-Net: A Domain Adaptation Framework with Semantic-Dynamic Consistency for Cross-Subject EEG Emotion Recognition": "|**2025-9-24**|**SDC-Net: A Domain Adaptation Framework with Semantic-Dynamic Consistency for Cross-Subject EEG Emotion Recognition**|Jiahao Tang et.al|[paper](https://arxiv.org/abs/2507.17524)|[code](https://github.com/XuanSuTrum/SDC-Net.)|-|\n", "Memory-Augmented Potential Field Theory: A Framework for Adaptive Control in Non-Convex Domains": "|**2025-9-23**|**Memory-Augmented Potential Field Theory: A Framework for Adaptive Control in Non-Convex Domains**|Dongzhe Zheng et.al|[paper](https://arxiv.org/abs/2509.19672)|-|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|\n", "EgoBridge: Domain Adaptation for Generalizable Imitation from Egocentric Human Data": "|**2025-9-23**|**EgoBridge: Domain Adaptation for Generalizable Imitation from Egocentric Human Data**|Ryan Punamiya et.al|[paper](https://arxiv.org/abs/2509.19626)|[code](https://ego-bridge.github.io)|<details><summary>detail</summary>39th Conference on Neural Information Processing Systems (NeurIPS 2025) and Oral at Conference on Robot Learning (CoRL 2025)</details>|\n"}, "domain generalization": {"B\u00e9zier Meets Diffusion: Robust Generation Across Domains for Medical Image Segmentation": "|**2025-9-26**|**B\u00e9zier Meets Diffusion: Robust Generation Across Domains for Medical Image Segmentation**|Chen Li et.al|[paper](https://arxiv.org/abs/2509.22476)|-|-|\n", "A Survey on LLM-based Code Generation for Low-Resource and Domain-Specific Programming Languages": "|**2025-9-26**|**A Survey on LLM-based Code Generation for Low-Resource and Domain-Specific Programming Languages**|Sathvik Joel et.al|[paper](https://arxiv.org/abs/2410.03981)|-|-|\n", "Plan2Evolve: LLM Self-Evolution for Improved Planning Capability via Automated Domain Generation": "|**2025-9-25**|**Plan2Evolve: LLM Self-Evolution for Improved Planning Capability via Automated Domain Generation**|Jinbang Huang et.al|[paper](https://arxiv.org/abs/2509.21543)|-|-|\n", "Technical report on label-informed logit redistribution for better domain generalization in low-shot classification with foundation models": "|**2025-9-25**|**Technical report on label-informed logit redistribution for better domain generalization in low-shot classification with foundation models**|Behraj Khan et.al|[paper](https://arxiv.org/abs/2501.17595)|-|-|\n", "An orderly algorithm for generation of Condorcet Domains": "|**2025-9-25**|**An orderly algorithm for generation of Condorcet Domains**|Bei Zhou et.al|[paper](https://arxiv.org/abs/2509.20865)|-|-|\n", "Federated Domain Generalization with Domain-specific Soft Prompts Generation": "|**2025-9-25**|**Federated Domain Generalization with Domain-specific Soft Prompts Generation**|Jianhan Wu et.al|[paper](https://arxiv.org/abs/2509.20807)|-|<details><summary>detail</summary>the IEEE/CVF International Conference on Computer Vision (ICCV 2025)</details>|\n", "Dual-supervised Asymmetric Co-training for Semi-supervised Medical Domain Generalization": "|**2025-9-25**|**Dual-supervised Asymmetric Co-training for Semi-supervised Medical Domain Generalization**|Jincai Song et.al|[paper](https://arxiv.org/abs/2509.20785)|-|-|\n", "SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs": "|**2025-9-25**|**SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs**|Jiacheng Lin et.al|[paper](https://arxiv.org/abs/2509.20758)|-|-|\n", "Embedding Domain Knowledge for Large Language Models via Reinforcement Learning from Augmented Generation": "|**2025-9-24**|**Embedding Domain Knowledge for Large Language Models via Reinforcement Learning from Augmented Generation**|Chaojun Nie et.al|[paper](https://arxiv.org/abs/2509.20162)|[code](https://github.com/ChaojunNie/RLAG.)|-|\n", "Minimal Semantic Sufficiency Meets Unsupervised Domain Generalization": "|**2025-9-24**|**Minimal Semantic Sufficiency Meets Unsupervised Domain Generalization**|Tan Pan et.al|[paper](https://arxiv.org/abs/2509.15791)|-|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|\n", "Diffusion-Based Action Recognition Generalizes to Untrained Domains": "|**2025-9-22**|**Diffusion-Based Action Recognition Generalizes to Untrained Domains**|Rogerio Guimaraes et.al|[paper](https://arxiv.org/abs/2509.08908)|[code](https://www.vision.caltech.edu/actiondiff.)|<details><summary>detail</summary>Project page: https://www</details>|\n", "Unsupervised Structural-Counterfactual Generation under Domain Shift": "|**2025-9-22**|**Unsupervised Structural-Counterfactual Generation under Domain Shift**|Krishn Vishwas Kher et.al|[paper](https://arxiv.org/abs/2502.12013)|-|<details><summary>detail</summary>Updated author ordering</details>|\n", "Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning": "|**2025-9-21**|**Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning**|Simon Ouellette et.al|[paper](https://arxiv.org/abs/2507.15877)|-|<details><summary>detail</summary>this version fixes errors in AlphaEvolve total % calculation</details>|\n", "From domain-landmark graph learning to problem-landmark graph generation": "|**2025-9-21**|**From domain-landmark graph learning to problem-landmark graph generation**|Cristian P\u00e9rez-Corral et.al|[paper](https://arxiv.org/abs/2509.17062)|-|-|\n", "Leveraging Multilingual Training for Authorship Representation: Enhancing Generalization across Languages and Domains": "|**2025-9-20**|**Leveraging Multilingual Training for Authorship Representation: Enhancing Generalization across Languages and Domains**|Junghwan Kim et.al|[paper](https://arxiv.org/abs/2509.16531)|-|<details><summary>detail</summary>EMNLP 2025</details>|\n"}, "vision language": {"VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search": "|**2025-9-26**|**VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search**|Wenkai Guo et.al|[paper](https://arxiv.org/abs/2509.22643)|-|-|\n", "Vision-Language Alignment from Compressed Image Representations using 2D Gaussian Splatting": "|**2025-9-26**|**Vision-Language Alignment from Compressed Image Representations using 2D Gaussian Splatting**|Yasmine Omri et.al|[paper](https://arxiv.org/abs/2509.22615)|-|-|\n", "JanusVLN: Decoupling Semantics and Spatiality with Dual Implicit Memory for Vision-Language Navigation": "|**2025-9-26**|**JanusVLN: Decoupling Semantics and Spatiality with Dual Implicit Memory for Vision-Language Navigation**|Shuang Zeng et.al|[paper](https://arxiv.org/abs/2509.22548)|[code](https://miv-xjtu.github.io/JanusVLN.github.io/.)|<details><summary>detail</summary>Project page: https://miv-xjtu</details>|\n", "Color Names in Vision-Language Models": "|**2025-9-26**|**Color Names in Vision-Language Models**|Alexandra Gomez-Villa et.al|[paper](https://arxiv.org/abs/2509.22524)|-|-|\n", "Guiding Evolution of Artificial Life Using Vision-Language Models": "|**2025-9-26**|**Guiding Evolution of Artificial Life Using Vision-Language Models**|Nikhil Baid et.al|[paper](https://arxiv.org/abs/2509.22447)|-|-|\n", "UnderwaterVLA: Dual-brain Vision-Language-Action architecture for Autonomous Underwater Navigation": "|**2025-9-26**|**UnderwaterVLA: Dual-brain Vision-Language-Action architecture for Autonomous Underwater Navigation**|Zhangyuan Wang et.al|[paper](https://arxiv.org/abs/2509.22441)|-|<details><summary>detail</summary>This paper introduces the first VLA framework for AUVs</details>|\n", "RAU: Reference-based Anatomical Understanding with Vision Language Models": "|**2025-9-26**|**RAU: Reference-based Anatomical Understanding with Vision Language Models**|Yiwei Li et.al|[paper](https://arxiv.org/abs/2509.22404)|-|-|\n", "LEO-VL: Efficient Scene Representation for Scalable 3D Vision-Language Learning": "|**2025-9-26**|**LEO-VL: Efficient Scene Representation for Scalable 3D Vision-Language Learning**|Jiangyong Huang et.al|[paper](https://arxiv.org/abs/2506.09935)|[code](https://leo-vl.github.io)|<details><summary>detail</summary>Project page: https://leo-vl</details>|\n", "Rule-Based Reinforcement Learning for Document Image Classification with Vision Language Models": "|**2025-9-26**|**Rule-Based Reinforcement Learning for Document Image Classification with Vision Language Models**|Michael Jungo et.al|[paper](https://arxiv.org/abs/2509.22283)|[code](https://github.com/jungomi/vision-finetune.)|<details><summary>detail</summary>Code available at https://github</details>|\n", "Few-Shot Adversarial Low-Rank Fine-Tuning of Vision-Language Models": "|**2025-9-26**|**Few-Shot Adversarial Low-Rank Fine-Tuning of Vision-Language Models**|Sajjad Ghiasvand et.al|[paper](https://arxiv.org/abs/2505.15130)|-|-|\n", "Towards Faithful Reasoning in Remote Sensing: A Perceptually-Grounded GeoSpatial Chain-of-Thought for Vision-Language Models": "|**2025-9-26**|**Towards Faithful Reasoning in Remote Sensing: A Perceptually-Grounded GeoSpatial Chain-of-Thought for Vision-Language Models**|Jiaqi Liu et.al|[paper](https://arxiv.org/abs/2509.22221)|-|-|\n", "MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing": "|**2025-9-26**|**MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing**|Junbo Niu et.al|[paper](https://arxiv.org/abs/2509.22186)|[code](https://github.com/opendatalab/MinerU;)|<details><summary>detail</summary>Technical Report</details>|\n", "pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for Vision-Language Models": "|**2025-9-26**|**pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for Vision-Language Models**|Sajjad Ghiasvand et.al|[paper](https://arxiv.org/abs/2507.05394)|-|-|\n", "Multilingual Vision-Language Models, A Survey": "|**2025-9-26**|**Multilingual Vision-Language Models, A Survey**|Andrei-Alexandru Manea et.al|[paper](https://arxiv.org/abs/2509.22123)|-|-|\n", "Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation": "|**2025-9-26**|**Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation**|Xiaohuan Pei et.al|[paper](https://arxiv.org/abs/2509.22093)|[code](https://vla-adp.github.io/)|-|\n"}}