{"source-free": {"Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results": "|**2025-12-28**|**Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results**|Rohan Palanikumar et.al|[paper](https://arxiv.org/abs/2511.00752)|-|-|\n", "Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection": "|**2025-12-24**|**Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection**|Sairam VCR et.al|[paper](https://arxiv.org/abs/2512.17514)|-|-|\n", "Exploiting Radio Frequency Fingerprints for Device Identification: Tackling Cross-receiver Challenges in the Source-data-free Scenario": "|**2025-12-18**|**Exploiting Radio Frequency Fingerprints for Device Identification: Tackling Cross-receiver Challenges in the Source-data-free Scenario**|Liu Yang et.al|[paper](https://arxiv.org/abs/2512.16648)|-|<details><summary>detail</summary>IEEE Transactions on Mobile Computing</details>|\n", "VocSim: A Training-free Benchmark for Zero-shot Content Identity in Single-source Audio": "|**2025-12-10**|**VocSim: A Training-free Benchmark for Zero-shot Content Identity in Single-source Audio**|Maris Basha et.al|[paper](https://arxiv.org/abs/2512.10120)|-|-|\n", "FedSCAl: Leveraging Server and Client Alignment for Unsupervised Federated Source-Free Domain Adaptation": "|**2025-12-7**|**FedSCAl: Leveraging Server and Client Alignment for Unsupervised Federated Source-Free Domain Adaptation**|M Yashwanth et.al|[paper](https://arxiv.org/abs/2512.06738)|-|<details><summary>detail</summary>Winter Conference on Applications of Computer Vision (WACV) 2026</details>|\n", "Source-free Video Domain Adaptation by Learning from Noisy Labels": "|**2025-11-28**|**Source-free Video Domain Adaptation by Learning from Noisy Labels**|Avijit Dasgupta et.al|[paper](https://arxiv.org/abs/2311.18572)|[code](https://avijit9.github.io/CleanAdapt.)|<details><summary>detail</summary>Our extended ICVGIP paper is now accepted in Pattern Recognition</details>|\n", "Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation": "|**2025-11-24**|**Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation**|Huisoo Lee et.al|[paper](https://arxiv.org/abs/2511.19147)|-|-|\n", "Unsupervised and Source-Free Ranking of Biomedical Segmentation Models": "|**2025-11-24**|**Unsupervised and Source-Free Ranking of Biomedical Segmentation Models**|Joshua Talks et.al|[paper](https://arxiv.org/abs/2503.00450)|-|-|\n", "SloMo-Fast: Slow-Momentum and Fast-Adaptive Teachers for Source-Free Continual Test-Time Adaptation": "|**2025-11-23**|**SloMo-Fast: Slow-Momentum and Fast-Adaptive Teachers for Source-Free Continual Test-Time Adaptation**|Md Akil Raihan Iftee et.al|[paper](https://arxiv.org/abs/2511.18468)|-|-|\n", "ViMix-14M: A Curated Multi-Source Video-Text Dataset with Long-Form, High-Quality Captions and Crawl-Free Access": "|**2025-11-23**|**ViMix-14M: A Curated Multi-Source Video-Text Dataset with Long-Form, High-Quality Captions and Crawl-Free Access**|Timing Yang et.al|[paper](https://arxiv.org/abs/2511.18382)|-|-|\n", "HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for Cross-Modality Medical Image Segmentation": "|**2025-11-22**|**HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for Cross-Modality Medical Image Segmentation**|Yulong Shi et.al|[paper](https://arxiv.org/abs/2511.17958)|[code](https://github.com/derekshiii/HEAL.)|<details><summary>detail</summary>Accepted by The 36th British Machine Vision Conference (BMVC 2025)</details>|\n", "Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation": "|**2025-11-19**|**Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation**|Yaxuan Song et.al|[paper](https://arxiv.org/abs/2402.06213)|[code](https://github.com/YXSong000/UAD.)|<details><summary>detail</summary>Accepted by ISBI 2024</details>|\n", "Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection": "|**2025-11-10**|**Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2511.07301)|-|<details><summary>detail</summary>AAAI 2026</details>|\n", "Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping": "|**2025-11-5**|**Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping**|Zhihang Qin et.al|[paper](https://arxiv.org/abs/2511.03691)|-|-|\n", "Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising": "|**2025-10-31**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|\n"}, "object detection": {"ZeBROD: Zero-Retraining Based Recognition and Object Detection Framework": "|**2025-12-29**|**ZeBROD: Zero-Retraining Based Recognition and Object Detection Framework**|Priyanto Hidayatullah et.al|[paper](https://arxiv.org/abs/2512.04888)|-|<details><summary>detail</summary>This manuscript was first submitted to the AI Open (Elsevier Journal)</details>|\n", "GVSynergy-Det: Synergistic Gaussian-Voxel Representations for Multi-View 3D Object Detection": "|**2025-12-28**|**GVSynergy-Det: Synergistic Gaussian-Voxel Representations for Multi-View 3D Object Detection**|Yi Zhang et.al|[paper](https://arxiv.org/abs/2512.23176)|-|-|\n", "GeoTeacher: Geometry-Guided Semi-Supervised 3D Object Detection": "|**2025-12-28**|**GeoTeacher: Geometry-Guided Semi-Supervised 3D Object Detection**|Jingyu Li et.al|[paper](https://arxiv.org/abs/2512.23147)|[code](https://github.com/SII-Whaleice/GeoTeacher)|-|\n", "YOLO-IOD: Towards Real Time Incremental Object Detection": "|**2025-12-28**|**YOLO-IOD: Towards Real Time Incremental Object Detection**|Shizhou Zhang et.al|[paper](https://arxiv.org/abs/2512.22973)|[code](https://github.com/qiangzai-lv/YOLO-IOD)|<details><summary>detail</summary>AAAAI 2026 accepted</details>|\n", "Wavelet-based Multi-View Fusion of 4D Radar Tensor and Camera for Robust 3D Object Detection": "|**2025-12-28**|**Wavelet-based Multi-View Fusion of 4D Radar Tensor and Camera for Robust 3D Object Detection**|Runwei Guan et.al|[paper](https://arxiv.org/abs/2512.22972)|-|-|\n", "CLIP-Joint-Detect: End-to-End Joint Training of Object Detectors with Contrastive Vision-Language Supervision": "|**2025-12-28**|**CLIP-Joint-Detect: End-to-End Joint Training of Object Detectors with Contrastive Vision-Language Supervision**|Behnam Raoufi et.al|[paper](https://arxiv.org/abs/2512.22969)|-|-|\n", "Learning Where to Focus: Density-Driven Guidance for Detecting Dense Tiny Objects": "|**2025-12-28**|**Learning Where to Focus: Density-Driven Guidance for Detecting Dense Tiny Objects**|Zhicheng Zhao et.al|[paper](https://arxiv.org/abs/2512.22949)|-|-|\n", "Evaluating the Performance of Open-Vocabulary Object Detection in Low-quality Image": "|**2025-12-28**|**Evaluating the Performance of Open-Vocabulary Object Detection in Low-quality Image**|Po-Chih Wu et.al|[paper](https://arxiv.org/abs/2512.22801)|-|-|\n", "WiSE-OD: Benchmarking Robustness in Infrared Object Detection": "|**2025-12-27**|**WiSE-OD: Benchmarking Robustness in Infrared Object Detection**|Heitor R. Medeiros et.al|[paper](https://arxiv.org/abs/2507.18925)|[code](https://github.com/heitorrapela/wiseod.)|<details><summary>detail</summary>WACV 2026: IEEE/CVF Winter Conf</details>|\n", "MCAQ-YOLO: Morphological Complexity-Aware Quantization for Efficient Object Detection with Curriculum Learning": "|**2025-12-27**|**MCAQ-YOLO: Morphological Complexity-Aware Quantization for Efficient Object Detection with Curriculum Learning**|Yoonjae Seo et.al|[paper](https://arxiv.org/abs/2511.12976)|-|-|\n", "SCAFusion: A Multimodal 3D Detection Framework for Small Object Detection in Lunar Surface Exploration": "|**2025-12-27**|**SCAFusion: A Multimodal 3D Detection Framework for Small Object Detection in Lunar Surface Exploration**|Xin Chen et.al|[paper](https://arxiv.org/abs/2512.22503)|-|-|\n", "Scalpel-SAM: A Semi-Supervised Paradigm for Adapting SAM to Infrared Small Object Detection": "|**2025-12-27**|**Scalpel-SAM: A Semi-Supervised Paradigm for Adapting SAM to Infrared Small Object Detection**|Zihan Liu et.al|[paper](https://arxiv.org/abs/2512.22483)|-|-|\n", "Comparing Object Detection Models for Electrical Substation Component Mapping": "|**2025-12-26**|**Comparing Object Detection Models for Electrical Substation Component Mapping**|Haley Mody et.al|[paper](https://arxiv.org/abs/2512.22454)|-|-|\n", "Towards Robust Optical-SAR Object Detection under Missing Modalities: A Dynamic Quality-Aware Fusion Framework": "|**2025-12-26**|**Towards Robust Optical-SAR Object Detection under Missing Modalities: A Dynamic Quality-Aware Fusion Framework**|Zhicheng Zhao et.al|[paper](https://arxiv.org/abs/2512.22447)|-|-|\n", "DeFloMat: Detection with Flow Matching for Stable and Efficient Generative Object Localization": "|**2025-12-26**|**DeFloMat: Detection with Flow Matching for Stable and Efficient Generative Object Localization**|Hansang Lee et.al|[paper](https://arxiv.org/abs/2512.22406)|-|-|\n"}, "domain adaptation": {"Exploring Syn-to-Real Domain Adaptation for Military Target Detection": "|**2025-12-29**|**Exploring Syn-to-Real Domain Adaptation for Military Target Detection**|Jongoh Jeong et.al|[paper](https://arxiv.org/abs/2512.23208)|-|-|\n", "Adapting In-Domain Few-Shot Segmentation to New Domains without Source Domain Retraining": "|**2025-12-28**|**Adapting In-Domain Few-Shot Segmentation to New Domains without Source Domain Retraining**|Qi Fan et.al|[paper](https://arxiv.org/abs/2504.21414)|[code](https://github.com/fanq15/ISA.)|-|\n", "Fake News Classification in Urdu: A Domain Adaptation Approach for a Low-Resource Language": "|**2025-12-27**|**Fake News Classification in Urdu: A Domain Adaptation Approach for a Low-Resource Language**|Muhammad Zain Ali et.al|[paper](https://arxiv.org/abs/2512.22778)|-|-|\n", "Unleashing Foundation Vision Models: Adaptive Transfer for Diverse Data-Limited Scientific Domains": "|**2025-12-27**|**Unleashing Foundation Vision Models: Adaptive Transfer for Diverse Data-Limited Scientific Domains**|Qiankun Li et.al|[paper](https://arxiv.org/abs/2512.22664)|[code](https://github.com/qklee-lz/CLAdapter.)|-|\n", "When Unsupervised Domain Adaptation meets One-class Anomaly Detection: Addressing the Two-fold Unsupervised Curse by Leveraging Anomaly Scarcity": "|**2025-12-26**|**When Unsupervised Domain Adaptation meets One-class Anomaly Detection: Addressing the Two-fold Unsupervised Curse by Leveraging Anomaly Scarcity**|Nesryne Mejri et.al|[paper](https://arxiv.org/abs/2502.21022)|-|<details><summary>detail</summary>Added acknowledgments</details>|\n", "Co-Teaching for Unsupervised Domain Adaptation and Expansion": "|**2025-12-25**|**Co-Teaching for Unsupervised Domain Adaptation and Expansion**|Hailan Lin et.al|[paper](https://arxiv.org/abs/2204.01210)|-|<details><summary>detail</summary>Accepted as a long paper at MMM 2026</details>|\n", "Shared & Domain Self-Adaptive Experts with Frequency-Aware Discrimination for Continual Test-Time Adaptation": "|**2025-12-25**|**Shared & Domain Self-Adaptive Experts with Frequency-Aware Discrimination for Continual Test-Time Adaptation**|JianChao Zhao et.al|[paper](https://arxiv.org/abs/2507.00502)|[code](https://github.com/ZJC25127/Domain-Self-Adaptive-CTTA.git.)|-|\n", "Beyond Weight Adaptation: Feature-Space Domain Injection for Cross-Modal Ship Re-Identification": "|**2025-12-23**|**Beyond Weight Adaptation: Feature-Space Domain Injection for Cross-Modal Ship Re-Identification**|Tingfeng Xian et.al|[paper](https://arxiv.org/abs/2512.20892)|[code](https://github.com/TingfengXian/DRI.)|-|\n", "DATTA: Domain Diversity Aware Test-Time Adaptation for Dynamic Domain Shift Data Streams": "|**2025-12-23**|**DATTA: Domain Diversity Aware Test-Time Adaptation for Dynamic Domain Shift Data Streams**|Chuyang Ye et.al|[paper](https://arxiv.org/abs/2408.08056)|[code](https://github.com/DYW77/DATTA.)|<details><summary>detail</summary>2025 IEEE International Conference on Multimedia and Expo (ICME)</details>|\n", "Statistically-Guided Dual-Domain Meta-Learning with Adaptive Multi-Prototype Aggregation for Distributed Fiber Optic Sensing": "|**2025-12-22**|**Statistically-Guided Dual-Domain Meta-Learning with Adaptive Multi-Prototype Aggregation for Distributed Fiber Optic Sensing**|Yifan He et.al|[paper](https://arxiv.org/abs/2511.17902)|-|-|\n", "Low-Resource Domain Adaptation for Speech LLMs via Text-Only Fine-Tuning": "|**2025-12-22**|**Low-Resource Domain Adaptation for Speech LLMs via Text-Only Fine-Tuning**|Yangui Fang et.al|[paper](https://arxiv.org/abs/2506.05671)|-|<details><summary>detail</summary>This paper has been ACCEPTED for publication in ASRU</details>|\n", "Navigating the Reality Gap: Privacy-Preserving Adaptation of ASR for Challenging Low-Resource Domains": "|**2025-12-22**|**Navigating the Reality Gap: Privacy-Preserving Adaptation of ASR for Challenging Low-Resource Domains**|Darshil Chauhan et.al|[paper](https://arxiv.org/abs/2512.16401)|-|-|\n", "Low-Rank Expert Merging for Multi-Source Domain Adaptation in Person Re-Identification": "|**2025-12-21**|**Low-Rank Expert Merging for Multi-Source Domain Adaptation in Person Re-Identification**|Taha Mustapha Nehdi et.al|[paper](https://arxiv.org/abs/2508.06831)|-|-|\n", "TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in Legal and Financial Domain": "|**2025-12-20**|**TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in Legal and Financial Domain**|Yidan Sun et.al|[paper](https://arxiv.org/abs/2511.09854)|-|-|\n", "Hierarchical Bayesian Framework for Multisource Domain Adaptation": "|**2025-12-20**|**Hierarchical Bayesian Framework for Multisource Domain Adaptation**|Alexander M. Glandon et.al|[paper](https://arxiv.org/abs/2512.18553)|-|-|\n"}, "domain generalization": {"Anka: A Domain-Specific Language for Reliable LLM Code Generation": "|**2025-12-29**|**Anka: A Domain-Specific Language for Reliable LLM Code Generation**|Saif Khalfan Saif Al Mazrouei et.al|[paper](https://arxiv.org/abs/2512.23214)|[code](https://github.com/BleBlo/Anka)|-|\n", "A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints": "|**2025-12-27**|**A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints**|Youssef Tawfilis et.al|[paper](https://arxiv.org/abs/2507.12979)|[code](https://github.com/youssefga28/HuSCF-GAN.)|-|\n", "HiFi-RAG: Hierarchical Content Filtering and Two-Pass Generation for Open-Domain RAG": "|**2025-12-26**|**HiFi-RAG: Hierarchical Content Filtering and Two-Pass Generation for Open-Domain RAG**|Cattalyya Nuengsigkapian et.al|[paper](https://arxiv.org/abs/2512.22442)|-|<details><summary>detail</summary>A winning solution for the NeurIPS 2025 MMU-RAGent Competition (Closed-Source Text-to-Text Static Evaluation)</details>|\n", "CAE-Net: Generalized Deepfake Image Detection using Convolution and Attention Mechanisms with Spatial and Frequency Domain Features": "|**2025-12-25**|**CAE-Net: Generalized Deepfake Image Detection using Convolution and Attention Mechanisms with Spatial and Frequency Domain Features**|Anindya Bhattacharjee et.al|[paper](https://arxiv.org/abs/2502.10682)|-|<details><summary>detail</summary>Published in Journal of Visual Communication and Image Representation</details>|\n", "CTTA-T: Continual Test-Time Adaptation for Text Understanding via Teacher-Student with a Domain-aware and Generalized Teacher": "|**2025-12-20**|**CTTA-T: Continual Test-Time Adaptation for Text Understanding via Teacher-Student with a Domain-aware and Generalized Teacher**|Tianlun Liu et.al|[paper](https://arxiv.org/abs/2512.18321)|-|-|\n", "Exploration of Augmentation Strategies in Multi-modal Retrieval-Augmented Generation for the Biomedical Domain: A Case Study Evaluating Question Answering in Glycobiology": "|**2025-12-18**|**Exploration of Augmentation Strategies in Multi-modal Retrieval-Augmented Generation for the Biomedical Domain: A Case Study Evaluating Question Answering in Glycobiology**|Primo\u017e Kocbek et.al|[paper](https://arxiv.org/abs/2512.16802)|-|<details><summary>detail</summary>Will be published in IEEE BigData 2025 proceedings</details>|\n", "Causal-Tune: Mining Causal Factors from Vision Foundation Models for Domain Generalized Semantic Segmentation": "|**2025-12-18**|**Causal-Tune: Mining Causal Factors from Vision Foundation Models for Domain Generalized Semantic Segmentation**|Yin Zhang et.al|[paper](https://arxiv.org/abs/2512.16567)|-|<details><summary>detail</summary>Accepted by AAAI 2026</details>|\n", "Exploiting Domain Properties in Language-Driven Domain Generalization for Semantic Segmentation": "|**2025-12-17**|**Exploiting Domain Properties in Language-Driven Domain Generalization for Semantic Segmentation**|Seogkyu Jeon et.al|[paper](https://arxiv.org/abs/2512.03508)|[code](https://github.com/jone1222/DPMFormer.)|<details><summary>detail</summary>ICCV 2025 (poster)</details>|\n", "XAI-Driven Diagnosis of Generalization Failure in State-Space Cerebrovascular Segmentation Models: A Case Study on Domain Shift Between RSNA and TopCoW Datasets": "|**2025-12-15**|**XAI-Driven Diagnosis of Generalization Failure in State-Space Cerebrovascular Segmentation Models: A Case Study on Domain Shift Between RSNA and TopCoW Datasets**|Youssef Abuzeid et.al|[paper](https://arxiv.org/abs/2512.13977)|-|-|\n", "Generating Reliable Synthetic Clinical Trial Data: The Role of Hyperparameter Optimization and Domain Constraints": "|**2025-12-15**|**Generating Reliable Synthetic Clinical Trial Data: The Role of Hyperparameter Optimization and Domain Constraints**|Waldemar Hahn et.al|[paper](https://arxiv.org/abs/2505.05019)|-|<details><summary>detail</summary>Published in Information Sciences</details>|\n", "From Imitation to Discrimination: Toward A Generalized Curriculum Advantage Mechanism Enhancing Cross-Domain Reasoning Tasks": "|**2025-12-15**|**From Imitation to Discrimination: Toward A Generalized Curriculum Advantage Mechanism Enhancing Cross-Domain Reasoning Tasks**|Changpeng Yang et.al|[paper](https://arxiv.org/abs/2512.02580)|-|<details><summary>detail</summary>Accepted by AAAI 2026</details>|\n", "The algorithmic muse and the public domain: Why copyrights legal philosophy precludes protection for generative AI outputs": "|**2025-12-15**|**The algorithmic muse and the public domain: Why copyrights legal philosophy precludes protection for generative AI outputs**|Ezieddin Elmahjub et.al|[paper](https://arxiv.org/abs/2512.13750)|-|-|\n", "Incremental Validation of Automated Driving Functions using Generic Volumes in Micro- Operational Design Domains": "|**2025-12-12**|**Incremental Validation of Automated Driving Functions using Generic Volumes in Micro- Operational Design Domains**|Steffen Sch\u00e4fer et.al|[paper](https://arxiv.org/abs/2512.11351)|-|-|\n", "The Finer the Better: Towards Granular-aware Open-set Domain Generalization": "|**2025-12-12**|**The Finer the Better: Towards Granular-aware Open-set Domain Generalization**|Yunyun Wang et.al|[paper](https://arxiv.org/abs/2511.16979)|-|-|\n", "Learning from a Generative Oracle: Domain Adaptation for Restoration": "|**2025-12-11**|**Learning from a Generative Oracle: Domain Adaptation for Restoration**|Yuyang Hu et.al|[paper](https://arxiv.org/abs/2512.11121)|-|-|\n"}, "vision language": {"ViLaCD-R1: A Vision-Language Framework for Semantic Change Detection in Remote Sensing": "|**2025-12-29**|**ViLaCD-R1: A Vision-Language Framework for Semantic Change Detection in Remote Sensing**|Xingwei Ma et.al|[paper](https://arxiv.org/abs/2512.23244)|-|-|\n", "Multimodal Interpretation of Remote Sensing Images: Dynamic Resolution Input Strategy and Multi-scale Vision-Language Alignment Mechanism": "|**2025-12-29**|**Multimodal Interpretation of Remote Sensing Images: Dynamic Resolution Input Strategy and Multi-scale Vision-Language Alignment Mechanism**|Siyu Zhang et.al|[paper](https://arxiv.org/abs/2512.23243)|-|-|\n", "How Much Data Is Enough? Uniform Convergence Bounds for Generative & Vision-Language Models under Low-Dimensional Structure": "|**2025-12-28**|**How Much Data Is Enough? Uniform Convergence Bounds for Generative & Vision-Language Models under Low-Dimensional Structure**|Paul M. Thompson et.al|[paper](https://arxiv.org/abs/2512.23109)|-|-|\n", "Embodied Learning of Reward for Musculoskeletal Control with Vision Language Models": "|**2025-12-28**|**Embodied Learning of Reward for Musculoskeletal Control with Vision Language Models**|Saraswati Soedarmadji et.al|[paper](https://arxiv.org/abs/2512.23077)|-|-|\n", "Rethinking Fine-Tuning: Unlocking Hidden Capabilities in Vision-Language Models": "|**2025-12-28**|**Rethinking Fine-Tuning: Unlocking Hidden Capabilities in Vision-Language Models**|Mingyuan Zhang et.al|[paper](https://arxiv.org/abs/2512.23073)|[code](https://github.com/Ming-K9/MFT-VLM)|-|\n", "CLIP-Joint-Detect: End-to-End Joint Training of Object Detectors with Contrastive Vision-Language Supervision": "|**2025-12-28**|**CLIP-Joint-Detect: End-to-End Joint Training of Object Detectors with Contrastive Vision-Language Supervision**|Behnam Raoufi et.al|[paper](https://arxiv.org/abs/2512.22969)|-|-|\n", "VPTracker: Global Vision-Language Tracking via Visual Prompt and MLLM": "|**2025-12-28**|**VPTracker: Global Vision-Language Tracking via Visual Prompt and MLLM**|Jingchao Wang et.al|[paper](https://arxiv.org/abs/2512.22799)|[code](https://github.com/jcwang0602/VPTracker.)|-|\n", "VisionDirector: Vision-Language Guided Closed-Loop Refinement for Generative Image Synthesis": "|**2025-12-27**|**VisionDirector: Vision-Language Guided Closed-Loop Refinement for Generative Image Synthesis**|Meng Chu et.al|[paper](https://arxiv.org/abs/2512.19243)|-|-|\n", "ICONS: Influence Consensus for Vision-Language Data Selection": "|**2025-12-27**|**ICONS: Influence Consensus for Vision-Language Data Selection**|Xindi Wu et.al|[paper](https://arxiv.org/abs/2501.00654)|-|-|\n", "Enhancing Vision-Language Model Reliability with Uncertainty-Guided Dropout Decoding": "|**2025-12-27**|**Enhancing Vision-Language Model Reliability with Uncertainty-Guided Dropout Decoding**|Yixiong Fang et.al|[paper](https://arxiv.org/abs/2412.06474)|[code](https://github.com/kigb/DropoutDecoding.)|<details><summary>detail</summary>39th Conference on Neural Information Processing Systems (NeurIPS 2025)</details>|\n", "Dream-VL & Dream-VLA: Open Vision-Language and Vision-Language-Action Models with Diffusion Language Model Backbone": "|**2025-12-27**|**Dream-VL & Dream-VLA: Open Vision-Language and Vision-Language-Action Models with Diffusion Language Model Backbone**|Jiacheng Ye et.al|[paper](https://arxiv.org/abs/2512.22615)|-|-|\n", "VLA-Arena: An Open-Source Framework for Benchmarking Vision-Language-Action Models": "|**2025-12-27**|**VLA-Arena: An Open-Source Framework for Benchmarking Vision-Language-Action Models**|Borong Zhang et.al|[paper](https://arxiv.org/abs/2512.22539)|[code](https://vla-arena.github.io.)|-|\n", "Clutter-Resistant Vision-Language-Action Models through Object-Centric and Geometry Grounding": "|**2025-12-27**|**Clutter-Resistant Vision-Language-Action Models through Object-Centric and Geometry Grounding**|Khoa Vo et.al|[paper](https://arxiv.org/abs/2512.22519)|[code](https://uark-aicv.github.io/OBEYED_VLA)|<details><summary>detail</summary>Under review</details>|\n", "Emergence of Human to Robot Transfer in Vision-Language-Action Models": "|**2025-12-26**|**Emergence of Human to Robot Transfer in Vision-Language-Action Models**|Simar Kareer et.al|[paper](https://arxiv.org/abs/2512.22414)|-|-|\n", "LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models": "|**2025-12-26**|**LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models**|Senyu Fei et.al|[paper](https://arxiv.org/abs/2510.13626)|-|-|\n"}}