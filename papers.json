{"source-free": {"Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces": "|**2025-10-22**|**Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces**|Osman Berke Guney et.al|[paper](https://arxiv.org/abs/2305.17403)|[code](https://github.com/osmanberke/SFDA-SSVEP-BCI)|-|\n", "Source-Free Object Detection with Detection Transformer": "|**2025-10-13**|**Source-Free Object Detection with Detection Transformer**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2510.11090)|-|<details><summary>detail</summary>IEEE Transactions on Image Processing</details>|\n", "Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning": "|**2025-10-9**|**Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning**|Ziqi Zhang et.al|[paper](https://arxiv.org/abs/2510.08393)|-|-|\n", "ESS-Flow: Training-free guidance of flow-based models as inference in source space": "|**2025-10-7**|**ESS-Flow: Training-free guidance of flow-based models as inference in source space**|Adhithyan Kalaivanan et.al|[paper](https://arxiv.org/abs/2510.05849)|-|-|\n", "Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising": "|**2025-10-7**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|\n", "A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation": "|**2025-10-6**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|\n", "Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection": "|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|\n", "Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation": "|**2025-10-3**|**Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation**|Yucheng Wang et.al|[paper](https://arxiv.org/abs/2409.19635)|-|-|\n", "OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation": "|**2025-10-2**|**OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation**|Yiming Zhang et.al|[paper](https://arxiv.org/abs/2505.11669)|-|-|\n", "Source-Free Cross-Domain Continual Learning": "|**2025-10-2**|**Source-Free Cross-Domain Continual Learning**|Muhammad Tanzil Furqon et.al|[paper](https://arxiv.org/abs/2510.01649)|-|-|\n", "Consistent Assistant Domains Transformer for Source-free Domain Adaptation": "|**2025-10-1**|**Consistent Assistant Domains Transformer for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.01559)|[code](https://github.com/RoryShao/CADTrans.git.)|-|\n", "Source-Free Domain Adaptive Object Detection with Semantics Compensation": "|**2025-9-30**|**Source-Free Domain Adaptive Object Detection with Semantics Compensation**|Song Tang et.al|[paper](https://arxiv.org/abs/2410.05557)|-|-|\n", "DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation": "|**2025-9-29**|**DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation**|Xi Chen et.al|[paper](https://arxiv.org/abs/2509.24896)|-|-|\n", "Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation": "|**2025-9-29**|**Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|\n", "Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment": "|**2025-9-22**|**Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment**|Wenjie Liu et.al|[paper](https://arxiv.org/abs/2509.18502)|-|-|\n"}, "object detection": {"Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection": "|**2025-10-23**|**Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection**|Talha Ilyas et.al|[paper](https://arxiv.org/abs/2510.20214)|-|<details><summary>detail</summary>This is the preprint version of the manuscript submitted to IEEE Journal of Biomedical and Health Informatics (JBHI) for review</details>|\n", "Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models": "|**2025-10-22**|**Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models**|Peter Robicheaux et.al|[paper](https://arxiv.org/abs/2505.20612)|[code](https://github.com/roboflow/rf100-vl)|<details><summary>detail</summary>The first two authors contributed equally</details>|\n", "A Unified Detection Pipeline for Robust Object Detection in Fisheye-Based Traffic Surveillance": "|**2025-10-22**|**A Unified Detection Pipeline for Robust Object Detection in Fisheye-Based Traffic Surveillance**|Neema Jakisa Owor et.al|[paper](https://arxiv.org/abs/2510.20016)|-|<details><summary>detail</summary>The paper was accepted at ICCV 2025 and published in CVF database</details>|\n", "Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR": "|**2025-10-22**|**Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR**|Adwait Chandorkar et.al|[paper](https://arxiv.org/abs/2508.00744)|-|<details><summary>detail</summary>Best Paper Award at the Embedded Vision Workshop ICCV 2025</details>|\n", "Can You Trust What You See? Alpha Channel No-Box Attacks on Video Object Detection": "|**2025-10-22**|**Can You Trust What You See? Alpha Channel No-Box Attacks on Video Object Detection**|Ariana Yi et.al|[paper](https://arxiv.org/abs/2510.19574)|-|-|\n", "Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts": "|**2025-10-22**|**Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts**|Chen Li et.al|[paper](https://arxiv.org/abs/2510.19487)|-|-|\n", "DitHub: A Modular Framework for Incremental Open-Vocabulary Object Detection": "|**2025-10-22**|**DitHub: A Modular Framework for Incremental Open-Vocabulary Object Detection**|Chiara Cappellino et.al|[paper](https://arxiv.org/abs/2503.09271)|[code](https://aimagelab.github.io/DitHub/)|<details><summary>detail</summary>the 39th Conference on Neural Information Processing Systems (NeurIPS 2025)</details>|\n", "Space Object Detection using Multi-frame Temporal Trajectory Completion Method": "|**2025-10-22**|**Space Object Detection using Multi-frame Temporal Trajectory Completion Method**|Xiaoqing Lan et.al|[paper](https://arxiv.org/abs/2510.19220)|-|-|\n", "SFGFusion: Surface Fitting Guided 3D Object Detection with 4D Radar and Camera Fusion": "|**2025-10-21**|**SFGFusion: Surface Fitting Guided 3D Object Detection with 4D Radar and Camera Fusion**|Xiaozhi Li et.al|[paper](https://arxiv.org/abs/2510.19215)|-|<details><summary>detail</summary>Submitted to Pattern Recognition</details>|\n", "Beyond Single Images: Retrieval Self-Augmented Unsupervised Camouflaged Object Detection": "|**2025-10-21**|**Beyond Single Images: Retrieval Self-Augmented Unsupervised Camouflaged Object Detection**|Ji Du et.al|[paper](https://arxiv.org/abs/2510.18437)|[code](https://github.com/xiaohainku/RISE.)|<details><summary>detail</summary>ICCV 2025</details>|\n", "Beyond Frequency: Scoring-Driven Debiasing for Object Detection via Blueprint-Prompted Image Synthesis": "|**2025-10-20**|**Beyond Frequency: Scoring-Driven Debiasing for Object Detection via Blueprint-Prompted Image Synthesis**|Xinhao Cai et.al|[paper](https://arxiv.org/abs/2510.18229)|-|-|\n", "Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation": "|**2025-10-20**|**Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation**|Masahiro Ogawa et.al|[paper](https://arxiv.org/abs/2507.13628)|-|-|\n", "When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models": "|**2025-10-20**|**When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models**|Samer Al-Hamadani et.al|[paper](https://arxiv.org/abs/2510.11302)|-|-|\n", "Monitoring Horses in Stalls: From Object to Event Detection": "|**2025-10-20**|**Monitoring Horses in Stalls: From Object to Event Detection**|Dmitrii Galimzianov et.al|[paper](https://arxiv.org/abs/2510.17409)|-|-|\n", "Towards a Generalizable Fusion Architecture for Multimodal Object Detection": "|**2025-10-19**|**Towards a Generalizable Fusion Architecture for Multimodal Object Detection**|Jad Berjawi et.al|[paper](https://arxiv.org/abs/2510.17078)|-|-|\n"}, "domain adaptation": {"Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation": "|**2025-10-23**|**Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation**|Ziyu Ye et.al|[paper](https://arxiv.org/abs/2510.20596)|-|<details><summary>detail</summary>MICCAI 2021</details>|\n", "IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation": "|**2025-10-23**|**IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation**|Tianyi Zhang et.al|[paper](https://arxiv.org/abs/2510.20377)|-|-|\n", "ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining": "|**2025-10-23**|**ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining**|Seonwu Kim et.al|[paper](https://arxiv.org/abs/2507.06795)|-|<details><summary>detail</summary>EMNLP 2025 Industry Track</details>|\n", "Training-Free Label Space Alignment for Universal Domain Adaptation": "|**2025-10-22**|**Training-Free Label Space Alignment for Universal Domain Adaptation**|Dujin Lee et.al|[paper](https://arxiv.org/abs/2509.17452)|-|-|\n", "Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces": "|**2025-10-22**|**Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces**|Osman Berke Guney et.al|[paper](https://arxiv.org/abs/2305.17403)|[code](https://github.com/osmanberke/SFDA-SSVEP-BCI)|-|\n", "Demystifying Domain-adaptive Post-training for Financial LLMs": "|**2025-10-21**|**Demystifying Domain-adaptive Post-training for Financial LLMs**|Zixuan Ke et.al|[paper](https://arxiv.org/abs/2501.04961)|-|<details><summary>detail</summary>EMNLP 2025 (Oral</details>|\n", "FlexiDataGen: An Adaptive LLM Framework for Dynamic Semantic Dataset Generation in Sensitive Domains": "|**2025-10-21**|**FlexiDataGen: An Adaptive LLM Framework for Dynamic Semantic Dataset Generation in Sensitive Domains**|Hamed Jelodar et.al|[paper](https://arxiv.org/abs/2510.19025)|-|-|\n", "XGen-Q: An Explainable Domain-Adaptive LLM Framework with Retrieval-Augmented Generation for Software Security": "|**2025-10-21**|**XGen-Q: An Explainable Domain-Adaptive LLM Framework with Retrieval-Augmented Generation for Software Security**|Hamed Jelodar et.al|[paper](https://arxiv.org/abs/2510.19006)|-|-|\n", "FedDEAP: Adaptive Dual-Prompt Tuning for Multi-Domain Federated Learning": "|**2025-10-21**|**FedDEAP: Adaptive Dual-Prompt Tuning for Multi-Domain Federated Learning**|Yubin Zheng et.al|[paper](https://arxiv.org/abs/2510.18837)|-|<details><summary>detail</summary>MM 2025</details>|\n", "SemiAdapt and SemiLoRA: Efficient Domain Adaptation for Transformer-based Low-Resource Language Translation with a Case Study on Irish": "|**2025-10-21**|**SemiAdapt and SemiLoRA: Efficient Domain Adaptation for Transformer-based Low-Resource Language Translation with a Case Study on Irish**|Josh McGiff et.al|[paper](https://arxiv.org/abs/2510.18725)|-|-|\n", "Towards Unsupervised Open-Set Graph Domain Adaptation via Dual Reprogramming": "|**2025-10-21**|**Towards Unsupervised Open-Set Graph Domain Adaptation via Dual Reprogramming**|Zhen Zhang et.al|[paper](https://arxiv.org/abs/2510.18363)|[code](https://github.com/cszhangzhen/GraphRTA.)|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|\n", "DAMSDAN: Distribution-Aware Multi-Source Domain Adaptation Network for Cross-Domain EEG-based Emotion Recognition": "|**2025-10-20**|**DAMSDAN: Distribution-Aware Multi-Source Domain Adaptation Network for Cross-Domain EEG-based Emotion Recognition**|Fo Hu et.al|[paper](https://arxiv.org/abs/2510.17475)|-|-|\n", "Robust Cross-Domain Adaptation in Texture Features Transferring for Wood Chip Moisture Content Prediction": "|**2025-10-19**|**Robust Cross-Domain Adaptation in Texture Features Transferring for Wood Chip Moisture Content Prediction**|Abdur Rahman et.al|[paper](https://arxiv.org/abs/2510.16832)|-|-|\n", "MOSAIC: Masked Objective with Selective Adaptation for In-domain Contrastive Learning": "|**2025-10-19**|**MOSAIC: Masked Objective with Selective Adaptation for In-domain Contrastive Learning**|Vera Pavlova et.al|[paper](https://arxiv.org/abs/2510.16797)|-|-|\n", "MedScore: Generalizable Factuality Evaluation of Free-Form Medical Answers by Domain-adapted Claim Decomposition and Verification": "|**2025-10-18**|**MedScore: Generalizable Factuality Evaluation of Free-Form Medical Answers by Domain-adapted Claim Decomposition and Verification**|Heyuan Huang et.al|[paper](https://arxiv.org/abs/2505.18452)|-|<details><summary>detail</summary>Added generalizability experiment and examples on non-medical free-form answer</details>|\n"}, "domain generalization": {"Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering": "|**2025-10-23**|**Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering**|Elman Ghazaei et.al|[paper](https://arxiv.org/abs/2508.08974)|[code](https://github.com/Elman295/TCSSM.)|-|\n", "Towards Context-Aware Domain Generalization: Understanding the Benefits and Limits of Marginal Transfer Learning": "|**2025-10-22**|**Towards Context-Aware Domain Generalization: Understanding the Benefits and Limits of Marginal Transfer Learning**|Jens M\u00fcller et.al|[paper](https://arxiv.org/abs/2312.10107)|-|-|\n", "Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts": "|**2025-10-22**|**Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts**|Chen Li et.al|[paper](https://arxiv.org/abs/2510.19487)|-|-|\n", "Exploring Scale Shift in Crowd Localization under the Context of Domain Generalization": "|**2025-10-22**|**Exploring Scale Shift in Crowd Localization under the Context of Domain Generalization**|Juncheng Wang et.al|[paper](https://arxiv.org/abs/2510.19330)|-|-|\n", "FlexiDataGen: An Adaptive LLM Framework for Dynamic Semantic Dataset Generation in Sensitive Domains": "|**2025-10-21**|**FlexiDataGen: An Adaptive LLM Framework for Dynamic Semantic Dataset Generation in Sensitive Domains**|Hamed Jelodar et.al|[paper](https://arxiv.org/abs/2510.19025)|-|-|\n", "XGen-Q: An Explainable Domain-Adaptive LLM Framework with Retrieval-Augmented Generation for Software Security": "|**2025-10-21**|**XGen-Q: An Explainable Domain-Adaptive LLM Framework with Retrieval-Augmented Generation for Software Security**|Hamed Jelodar et.al|[paper](https://arxiv.org/abs/2510.19006)|-|-|\n", "TreeFedDG: Alleviating Global Drift in Federated Domain Generalization for Medical Image Segmentation": "|**2025-10-20**|**TreeFedDG: Alleviating Global Drift in Federated Domain Generalization for Medical Image Segmentation**|Yucheng Song et.al|[paper](https://arxiv.org/abs/2510.18268)|-|-|\n", "Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains": "|**2025-10-20**|**Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains**|Austin Xu et.al|[paper](https://arxiv.org/abs/2510.17793)|-|-|\n", "HIDISC: A Hyperbolic Framework for Domain Generalization with Generalized Category Discovery": "|**2025-10-20**|**HIDISC: A Hyperbolic Framework for Domain Generalization with Generalized Category Discovery**|Vaibhav Rathore et.al|[paper](https://arxiv.org/abs/2510.17188)|-|<details><summary>detail</summary>Accpeted at NeurIPS (2025) Main Conference</details>|\n", "UniGTE: Unified Graph-Text Encoding for Zero-Shot Generalization across Graph Tasks and Domains": "|**2025-10-19**|**UniGTE: Unified Graph-Text Encoding for Zero-Shot Generalization across Graph Tasks and Domains**|Duo Wang et.al|[paper](https://arxiv.org/abs/2510.16885)|-|<details><summary>detail</summary>Journal ref:NeurIPS 2025</details>|\n", "Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization": "|**2025-10-19**|**Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization**|Tianxin Wei et.al|[paper](https://arxiv.org/abs/2510.16704)|[code](https://github.com/weitianxin/DCCL)|<details><summary>detail</summary>Accepted by KDD 2025</details>|\n", "Humanoid-inspired Causal Representation Learning for Domain Generalization": "|**2025-10-18**|**Humanoid-inspired Causal Representation Learning for Domain Generalization**|Ze Tao et.al|[paper](https://arxiv.org/abs/2510.16382)|[code](https://github.com/lambett/HSCM.)|-|\n", "Finetune Once: Decoupling General & Domain Learning with Dynamic Boosted Annealing": "|**2025-10-17**|**Finetune Once: Decoupling General & Domain Learning with Dynamic Boosted Annealing**|Yang Tang et.al|[paper](https://arxiv.org/abs/2509.26242)|-|-|\n", "Latent Retrieval Augmented Generation of Cross-Domain Protein Binders": "|**2025-10-16**|**Latent Retrieval Augmented Generation of Cross-Domain Protein Binders**|Zishen Zhang et.al|[paper](https://arxiv.org/abs/2510.10480)|-|-|\n", "Column Generation Using Domain-Independent Dynamic Programming": "|**2025-10-16**|**Column Generation Using Domain-Independent Dynamic Programming**|Ryo Kuroiwa et.al|[paper](https://arxiv.org/abs/2510.14317)|[code](https://github.com/domain-independent-dp/didp-rs/releases/tag/labeling)|<details><summary>detail</summary>Manuscript submitted to INFORMS Journal on Computing didp-rs code: https://github</details>|\n"}, "vision language": {"VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation": "|**2025-10-23**|**VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation**|Mateo Guaman Castro et.al|[paper](https://arxiv.org/abs/2510.20818)|[code](https://vamos-vla.github.io/)|-|\n", "Fast-Slow Thinking GRPO for Large Vision-Language Model Reasoning": "|**2025-10-23**|**Fast-Slow Thinking GRPO for Large Vision-Language Model Reasoning**|Wenyi Xiao et.al|[paper](https://arxiv.org/abs/2504.18458)|-|-|\n", "Mixing Importance with Diversity: Joint Optimization for KV Cache Compression in Large Vision-Language Models": "|**2025-10-23**|**Mixing Importance with Diversity: Joint Optimization for KV Cache Compression in Large Vision-Language Models**|Xuyang Liu et.al|[paper](https://arxiv.org/abs/2510.20707)|[code](https://github.com/xuyang-liu16/MixKV)|<details><summary>detail</summary>Our code is available at https://github</details>|\n", "Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging": "|**2025-10-23**|**Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging**|Ibrahim Ethem Hamamci et.al|[paper](https://arxiv.org/abs/2510.20639)|[code](https://github.com/ibrahimethemhamamci/BTB3D)|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey": "|**2025-10-23**|**Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey**|Weifan Guan et.al|[paper](https://arxiv.org/abs/2510.17111)|-|-|\n", "Spatial-DISE: A Unified Benchmark for Evaluating Spatial Reasoning in Vision-Language Models": "|**2025-10-23**|**Spatial-DISE: A Unified Benchmark for Evaluating Spatial Reasoning in Vision-Language Models**|Xinmiao Huang et.al|[paper](https://arxiv.org/abs/2510.13394)|[code](https://shinmohuang.github.io/spatialdise_page/)|<details><summary>detail</summary>Project Page: https://shinmohuang</details>|\n", "Grounding Language with Vision: A Conditional Mutual Information Calibrated Decoding Strategy for Reducing Hallucinations in LVLMs": "|**2025-10-23**|**Grounding Language with Vision: A Conditional Mutual Information Calibrated Decoding Strategy for Reducing Hallucinations in LVLMs**|Hao Fang et.al|[paper](https://arxiv.org/abs/2505.19678)|-|-|\n", "Balanced Token Pruning: Accelerating Vision Language Models Beyond Local Optimization": "|**2025-10-23**|**Balanced Token Pruning: Accelerating Vision Language Models Beyond Local Optimization**|Kaiyuan Li et.al|[paper](https://arxiv.org/abs/2505.22038)|[code](https://github.com/EmbodiedCity/NeurIPS2025-Balanced-Token-Pruning.)|<details><summary>detail</summary>Accepted by Neurips 2025</details>|\n", "Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models": "|**2025-10-23**|**Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models**|Rui Zhu et.al|[paper](https://arxiv.org/abs/2510.20477)|-|-|\n", "ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding": "|**2025-10-23**|**ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding**|Jialiang Kang et.al|[paper](https://arxiv.org/abs/2509.15235)|[code](https://github.com/KangJialiang/ViSpec.)|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "Toward a Vision-Language Foundation Model for Medical Data: Multimodal Dataset and Benchmarks for Vietnamese PET/CT Report Generation": "|**2025-10-23**|**Toward a Vision-Language Foundation Model for Medical Data: Multimodal Dataset and Benchmarks for Vietnamese PET/CT Report Generation**|Huu Tien Nguyen et.al|[paper](https://arxiv.org/abs/2509.24739)|[code](https://github.com/AIoT-Lab-BKAI/ViPET-ReportGen.)|<details><summary>detail</summary>39th Conference on Neural Information Processing Systems (NeurIPS 2025)</details>|\n", "ControlFusion: A Controllable Image Fusion Framework with Language-Vision Degradation Prompts": "|**2025-10-23**|**ControlFusion: A Controllable Image Fusion Framework with Language-Vision Degradation Prompts**|Linfeng Tang et.al|[paper](https://arxiv.org/abs/2503.23356)|[code](https://github.com/Linfeng-Tang/ControlFusion.)|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "Vision-Centric Activation and Coordination for Multimodal Large Language Models": "|**2025-10-23**|**Vision-Centric Activation and Coordination for Multimodal Large Language Models**|Yunnan Wang et.al|[paper](https://arxiv.org/abs/2510.14349)|-|-|\n", "Beyond Text: Multimodal Jailbreaking of Vision-Language and Audio Models through Perceptually Simple Transformations": "|**2025-10-23**|**Beyond Text: Multimodal Jailbreaking of Vision-Language and Audio Models through Perceptually Simple Transformations**|Divyanshu Kumar et.al|[paper](https://arxiv.org/abs/2510.20223)|-|-|\n", "MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning": "|**2025-10-23**|**MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning**|Wenhui Huang et.al|[paper](https://arxiv.org/abs/2510.18337)|-|-|\n"}}