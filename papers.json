{"source-free": {"Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection": "|**2025-11-10**|**Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2511.07301)|-|<details><summary>detail</summary>AAAI 2026</details>|\n", "Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping": "|**2025-11-5**|**Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping**|Zhihang Qin et.al|[paper](https://arxiv.org/abs/2511.03691)|-|-|\n", "Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results": "|**2025-11-1**|**Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results**|Rohan Palanikumar et.al|[paper](https://arxiv.org/abs/2511.00752)|-|-|\n", "Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising": "|**2025-10-31**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|\n", "Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation": "|**2025-10-29**|**Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation**|Yuyang Huang et.al|[paper](https://arxiv.org/abs/2510.25279)|-|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|\n", "Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation": "|**2025-10-29**|**Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation**|Quang-Khai Bui-Tran et.al|[paper](https://arxiv.org/abs/2510.25227)|-|-|\n", "Training-free Source Attribution of AI-generated Images via Resynthesis": "|**2025-10-28**|**Training-free Source Attribution of AI-generated Images via Resynthesis**|Pietro Bongini et.al|[paper](https://arxiv.org/abs/2510.24278)|-|-|\n", "Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation": "|**2025-10-24**|**Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.22142)|-|-|\n", "Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces": "|**2025-10-22**|**Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces**|Osman Berke Guney et.al|[paper](https://arxiv.org/abs/2305.17403)|[code](https://github.com/osmanberke/SFDA-SSVEP-BCI)|-|\n", "Source-Free Object Detection with Detection Transformer": "|**2025-10-13**|**Source-Free Object Detection with Detection Transformer**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2510.11090)|-|<details><summary>detail</summary>IEEE Transactions on Image Processing</details>|\n", "Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning": "|**2025-10-9**|**Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning**|Ziqi Zhang et.al|[paper](https://arxiv.org/abs/2510.08393)|-|-|\n", "ESS-Flow: Training-free guidance of flow-based models as inference in source space": "|**2025-10-7**|**ESS-Flow: Training-free guidance of flow-based models as inference in source space**|Adhithyan Kalaivanan et.al|[paper](https://arxiv.org/abs/2510.05849)|-|-|\n", "A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation": "|**2025-10-6**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|\n", "Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection": "|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|\n", "Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation": "|**2025-10-3**|**Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation**|Yucheng Wang et.al|[paper](https://arxiv.org/abs/2409.19635)|-|-|\n"}, "object detection": {"SFMNet: Sparse Focal Modulation for 3D Object Detection": "|**2025-11-16**|**SFMNet: Sparse Focal Modulation for 3D Object Detection**|Oren Shrout et.al|[paper](https://arxiv.org/abs/2503.12093)|-|<details><summary>detail</summary>WACV 2026</details>|\n", "SimROD: A Simple Baseline for Raw Object Detection with Global and Local Enhancements": "|**2025-11-16**|**SimROD: A Simple Baseline for Raw Object Detection with Global and Local Enhancements**|Haiyang Xie et.al|[paper](https://arxiv.org/abs/2503.07101)|[code](https://ocean146.github.io/SimROD2025/.)|<details><summary>detail</summary>Accepted by AAAI 2026</details>|\n", "Efficient Feature Aggregation and Scale-Aware Regression for Monocular 3D Object Detection": "|**2025-11-14**|**Efficient Feature Aggregation and Scale-Aware Regression for Monocular 3D Object Detection**|Yifan Wang et.al|[paper](https://arxiv.org/abs/2411.02747)|-|-|\n", "Adaptive LiDAR Scanning: Harnessing Temporal Cues for Efficient 3D Object Detection via Multi-Modal Fusion": "|**2025-11-14**|**Adaptive LiDAR Scanning: Harnessing Temporal Cues for Efficient 3D Object Detection via Multi-Modal Fusion**|Sara Shoouri et.al|[paper](https://arxiv.org/abs/2508.01562)|-|<details><summary>detail</summary>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</details>|\n", "PAS : Prelim Attention Score for Detecting Object Hallucinations in Large Vision--Language Models": "|**2025-11-14**|**PAS : Prelim Attention Score for Detecting Object Hallucinations in Large Vision--Language Models**|Nhat Hoang-Xuan et.al|[paper](https://arxiv.org/abs/2511.11502)|-|-|\n", "Explicit Multimodal Graph Modeling for Human-Object Interaction Detection": "|**2025-11-14**|**Explicit Multimodal Graph Modeling for Human-Object Interaction Detection**|Wenxuan Ji et.al|[paper](https://arxiv.org/abs/2509.12554)|-|-|\n", "Synthetic Object Compositions for Scalable and Accurate Learning in Detection, Segmentation, and Grounding": "|**2025-11-14**|**Synthetic Object Compositions for Scalable and Accurate Learning in Detection, Segmentation, and Grounding**|Weikai Huang et.al|[paper](https://arxiv.org/abs/2510.09110)|[code](https://github.com/weikaih04/Synthetic-Detection-Segmentation-Grounding-Data)|<details><summary>detail</summary>Project website: https://github</details>|\n", "FQ-PETR: Fully Quantized Position Embedding Transformation for Multi-View 3D Object Detection": "|**2025-11-13**|**FQ-PETR: Fully Quantized Position Embedding Transformation for Multi-View 3D Object Detection**|Jiangyong Yu et.al|[paper](https://arxiv.org/abs/2511.09347)|-|<details><summary>detail</summary>I made an operational error</details>|\n", "YOLO-Drone: An Efficient Object Detection Approach Using the GhostHead Network for Drone Images": "|**2025-11-13**|**YOLO-Drone: An Efficient Object Detection Approach Using the GhostHead Network for Drone Images**|Hyun-Ki Jung et.al|[paper](https://arxiv.org/abs/2511.10905)|-|<details><summary>detail</summary>Preprint version</details>|\n", "FreDFT: Frequency Domain Fusion Transformer for Visible-Infrared Object Detection": "|**2025-11-13**|**FreDFT: Frequency Domain Fusion Transformer for Visible-Infrared Object Detection**|Wencong Wu et.al|[paper](https://arxiv.org/abs/2511.10046)|[code](https://github.com/WenCongWu/FreDFT.)|-|\n", "FOUND: Fourier-based von Mises Distribution for Robust Single Domain Generalization in Object Detection": "|**2025-11-13**|**FOUND: Fourier-based von Mises Distribution for Robust Single Domain Generalization in Object Detection**|Mengzhu Wang et.al|[paper](https://arxiv.org/abs/2511.10352)|-|-|\n", "DGFusion: Dual-guided Fusion for Robust Multi-Modal 3D Object Detection": "|**2025-11-13**|**DGFusion: Dual-guided Fusion for Robust Multi-Modal 3D Object Detection**|Feiyang Jia et.al|[paper](https://arxiv.org/abs/2511.10035)|-|-|\n", "MOBA: A Material-Oriented Backdoor Attack against LiDAR-based 3D Object Detection Systems": "|**2025-11-13**|**MOBA: A Material-Oriented Backdoor Attack against LiDAR-based 3D Object Detection Systems**|Saket S. Chaturvedi et.al|[paper](https://arxiv.org/abs/2511.09999)|-|<details><summary>detail</summary>AAAI 2026 Conference</details>|\n", "Robust Object Detection with Pseudo Labels from VLMs using Per-Object Co-teaching": "|**2025-11-12**|**Robust Object Detection with Pseudo Labels from VLMs using Per-Object Co-teaching**|Uday Bhaskar et.al|[paper](https://arxiv.org/abs/2511.09955)|-|-|\n"}, "domain adaptation": {"One Request, Multiple Experts: LLM Orchestrates Domain Specific Models via Adaptive Task Routing": "|**2025-11-16**|**One Request, Multiple Experts: LLM Orchestrates Domain Specific Models via Adaptive Task Routing**|Xu Yang et.al|[paper](https://arxiv.org/abs/2511.12484)|-|-|\n", "From IDs to Semantics: A Generative Framework for Cross-Domain Recommendation with Adaptive Semantic Tokenization": "|**2025-11-16**|**From IDs to Semantics: A Generative Framework for Cross-Domain Recommendation with Adaptive Semantic Tokenization**|Peiyu Hu et.al|[paper](https://arxiv.org/abs/2511.08006)|-|<details><summary>detail</summary>Accepted by AAAI 2026</details>|\n", "Global Variational Inference Enhanced Robust Domain Adaptation": "|**2025-11-15**|**Global Variational Inference Enhanced Robust Domain Adaptation**|Lingkun Luo et.al|[paper](https://arxiv.org/abs/2507.03291)|-|<details><summary>detail</summary>The current version has issues in experimental protocol and presentation</details>|\n", "Cross-View Cross-Modal Unsupervised Domain Adaptation for Driver Monitoring System": "|**2025-11-15**|**Cross-View Cross-Modal Unsupervised Domain Adaptation for Driver Monitoring System**|Aditi Bhalla et.al|[paper](https://arxiv.org/abs/2511.12196)|-|-|\n", "DoSReMC: Domain Shift Resilient Mammography Classification using Batch Normalization Adaptation": "|**2025-11-15**|**DoSReMC: Domain Shift Resilient Mammography Classification using Batch Normalization Adaptation**|U\u011furcan Aky\u00fcz et.al|[paper](https://arxiv.org/abs/2508.15452)|-|-|\n", "MUDAS: Mote-scale Unsupervised Domain Adaptation in Multi-label Sound Classification": "|**2025-11-14**|**MUDAS: Mote-scale Unsupervised Domain Adaptation in Multi-label Sound Classification**|Jihoon Yun et.al|[paper](https://arxiv.org/abs/2506.11331)|-|<details><summary>detail</summary>BuildSys 25</details>|\n", "Unsupervised Robust Domain Adaptation: Paradigm, Theory and Algorithm": "|**2025-11-14**|**Unsupervised Robust Domain Adaptation: Paradigm, Theory and Algorithm**|Fuxiang Huang et.al|[paper](https://arxiv.org/abs/2511.11009)|-|<details><summary>detail</summary>To appear in IJCV</details>|\n", "Provable Domain Adaptation for Offline Reinforcement Learning with Limited Samples": "|**2025-11-14**|**Provable Domain Adaptation for Offline Reinforcement Learning with Limited Samples**|Weiqin Chen et.al|[paper](https://arxiv.org/abs/2408.12136)|-|-|\n", "Text-to-SQL Domain Adaptation via Human-LLM Collaborative Data Annotation": "|**2025-11-13**|**Text-to-SQL Domain Adaptation via Human-LLM Collaborative Data Annotation**|Yuan Tian et.al|[paper](https://arxiv.org/abs/2502.15980)|[code](https://github.com/magic-YuanTian/SQLsynth.)|<details><summary>detail</summary>Accepted by IUI'25 Code & Demo: https://github</details>|\n", "TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in Legal and Financial Domain": "|**2025-11-12**|**TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in Legal and Financial Domain**|Yidan Sun et.al|[paper](https://arxiv.org/abs/2511.09854)|-|-|\n", "Wi-CBR: Salient-aware Adaptive WiFi Sensing for Cross-domain Behavior Recognition": "|**2025-11-12**|**Wi-CBR: Salient-aware Adaptive WiFi Sensing for Cross-domain Behavior Recognition**|Ruobei Zhang et.al|[paper](https://arxiv.org/abs/2506.11616)|-|-|\n", "Domain Adaptation from Generated Multi-Weather Images for Unsupervised Maritime Object Classification": "|**2025-11-12**|**Domain Adaptation from Generated Multi-Weather Images for Unsupervised Maritime Object Classification**|Dan Song et.al|[paper](https://arxiv.org/abs/2501.15503)|[code](https://github.com/honoria0204/AIMO.)|-|\n", "Vicinity-Guided Discriminative Latent Diffusion for Privacy-Preserving Domain Adaptation": "|**2025-11-11**|**Vicinity-Guided Discriminative Latent Diffusion for Privacy-Preserving Domain Adaptation**|Jing Wang et.al|[paper](https://arxiv.org/abs/2510.00478)|-|<details><summary>detail</summary>39th Conference on Neural Information Processing Systems (NeurIPS 2025)</details>|\n", "RAFT -- A Domain Adaptation Framework for RGB & LiDAR Semantic Segmentation": "|**2025-11-11**|**RAFT -- A Domain Adaptation Framework for RGB & LiDAR Semantic Segmentation**|Edward Humes et.al|[paper](https://arxiv.org/abs/2505.04529)|-|<details><summary>detail</summary>Submitted to RA-L</details>|\n", "FS-DAG: Few Shot Domain Adapting Graph Networks for Visually Rich Document Understanding": "|**2025-11-11**|**FS-DAG: Few Shot Domain Adapting Graph Networks for Visually Rich Document Understanding**|Amit Agarwal et.al|[paper](https://arxiv.org/abs/2505.17330)|[code](https://github.com/oracle-samples/fs-dag)|<details><summary>detail</summary>Proceedings of the 31st International Conference on Computational Linguistics (COLING 2025)</details>|\n"}, "domain generalization": {"From IDs to Semantics: A Generative Framework for Cross-Domain Recommendation with Adaptive Semantic Tokenization": "|**2025-11-16**|**From IDs to Semantics: A Generative Framework for Cross-Domain Recommendation with Adaptive Semantic Tokenization**|Peiyu Hu et.al|[paper](https://arxiv.org/abs/2511.08006)|-|<details><summary>detail</summary>Accepted by AAAI 2026</details>|\n", "FGM optimization in complex domains using Gaussian process regression based profile generation algorithm": "|**2025-11-15**|**FGM optimization in complex domains using Gaussian process regression based profile generation algorithm**|Chaitanya Kumar Konda et.al|[paper](https://arxiv.org/abs/2511.12171)|-|-|\n", "M-DAIGT: A Shared Task on Multi-Domain Detection of AI-Generated Text": "|**2025-11-14**|**M-DAIGT: A Shared Task on Multi-Domain Detection of AI-Generated Text**|Salima Lamsiyah et.al|[paper](https://arxiv.org/abs/2511.11340)|-|-|\n", "Generalizing Analogical Inference from Boolean to Continuous Domains": "|**2025-11-13**|**Generalizing Analogical Inference from Boolean to Continuous Domains**|Francisco Cunha et.al|[paper](https://arxiv.org/abs/2511.10416)|-|-|\n", "FOUND: Fourier-based von Mises Distribution for Robust Single Domain Generalization in Object Detection": "|**2025-11-13**|**FOUND: Fourier-based von Mises Distribution for Robust Single Domain Generalization in Object Detection**|Mengzhu Wang et.al|[paper](https://arxiv.org/abs/2511.10352)|-|-|\n", "Simulating Distribution Dynamics: Liquid Temporal Feature Evolution for Single-Domain Generalized Object Detection": "|**2025-11-12**|**Simulating Distribution Dynamics: Liquid Temporal Feature Evolution for Single-Domain Generalized Object Detection**|Zihao Zhang et.al|[paper](https://arxiv.org/abs/2511.09909)|[code](https://github.com/2490o/LTFE.)|-|\n", "Domain Adaptation from Generated Multi-Weather Images for Unsupervised Maritime Object Classification": "|**2025-11-12**|**Domain Adaptation from Generated Multi-Weather Images for Unsupervised Maritime Object Classification**|Dan Song et.al|[paper](https://arxiv.org/abs/2501.15503)|[code](https://github.com/honoria0204/AIMO.)|-|\n", "Data Fusion-Enhanced Decision Transformer for Stable Cross-Domain Generalization": "|**2025-11-12**|**Data Fusion-Enhanced Decision Transformer for Stable Cross-Domain Generalization**|Guojian Wang et.al|[paper](https://arxiv.org/abs/2511.09173)|-|-|\n", "DG-DETR: Toward Domain Generalized Detection Transformer": "|**2025-11-12**|**DG-DETR: Toward Domain Generalized Detection Transformer**|Seongmin Hwang et.al|[paper](https://arxiv.org/abs/2504.19574)|[code](https://github.com/sminhwang/DG-DETR.)|<details><summary>detail</summary>Accepted by Pattern Recognition Letters (DOI: https://doi</details>|\n", "GAITGen: Disentangled Motion-Pathology Impaired Gait Generative Model -- Bringing Motion Generation to the Clinical Domain": "|**2025-11-11**|**GAITGen: Disentangled Motion-Pathology Impaired Gait Generative Model -- Bringing Motion Generation to the Clinical Domain**|Vida Adeli et.al|[paper](https://arxiv.org/abs/2503.22397)|-|<details><summary>detail</summary>the IEEE/CVF winter conference on applications of computer vision (WACV 2026)</details>|\n", "Benchmarking Domain Generalization Algorithms in Computational Pathology": "|**2025-11-11**|**Benchmarking Domain Generalization Algorithms in Computational Pathology**|Neda Zamanitajeddin et.al|[paper](https://arxiv.org/abs/2409.17063)|-|-|\n", "Free-T2M: Robust Text-to-Motion Generation for Humanoid Robots via Frequency-Domain": "|**2025-11-10**|**Free-T2M: Robust Text-to-Motion Generation for Humanoid Robots via Frequency-Domain**|Wenshuo Chen et.al|[paper](https://arxiv.org/abs/2501.18232)|-|-|\n", "DrKGC: Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph Completion across General and Biomedical Domains": "|**2025-11-10**|**DrKGC: Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph Completion across General and Biomedical Domains**|Yongkang Xiao et.al|[paper](https://arxiv.org/abs/2506.00708)|-|<details><summary>detail</summary>EMNLP 2025 Findings</details>|\n", "Retrieval-Augmented Feature Generation for Domain-Specific Classification": "|**2025-11-9**|**Retrieval-Augmented Feature Generation for Domain-Specific Classification**|Xinhao Zhang et.al|[paper](https://arxiv.org/abs/2406.11177)|-|<details><summary>detail</summary>Accepted by ICDM 2025</details>|\n", "GNN-MoE: Context-Aware Patch Routing using GNNs for Parameter-Efficient Domain Generalization": "|**2025-11-5**|**GNN-MoE: Context-Aware Patch Routing using GNNs for Parameter-Efficient Domain Generalization**|Mahmoud Soliman et.al|[paper](https://arxiv.org/abs/2511.04008)|-|-|\n"}, "vision language": {"ViMoNet: A Multimodal Vision-Language Framework for Human Behavior Understanding from Motion and Video": "|**2025-11-16**|**ViMoNet: A Multimodal Vision-Language Framework for Human Behavior Understanding from Motion and Video**|Rajan Das Gupta et.al|[paper](https://arxiv.org/abs/2508.09818)|-|<details><summary>detail</summary>This is the preprint version of the manuscript</details>|\n", "RedVTP: Training-Free Acceleration of Diffusion Vision-Language Models Inference via Masked Token-Guided Visual Token Pruning": "|**2025-11-15**|**RedVTP: Training-Free Acceleration of Diffusion Vision-Language Models Inference via Masked Token-Guided Visual Token Pruning**|Jingqi Xu et.al|[paper](https://arxiv.org/abs/2511.12428)|-|-|\n", "Does Bigger Mean Better? Comparitive Analysis of CNNs and Biomedical Vision Language Modles in Medical Diagnosis": "|**2025-11-15**|**Does Bigger Mean Better? Comparitive Analysis of CNNs and Biomedical Vision Language Modles in Medical Diagnosis**|Ran Tong et.al|[paper](https://arxiv.org/abs/2510.00411)|-|-|\n", "RoadBench: A Vision-Language Foundation Model and Benchmark for Road Damage Understanding": "|**2025-11-15**|**RoadBench: A Vision-Language Foundation Model and Benchmark for Road Damage Understanding**|Xi Xiao et.al|[paper](https://arxiv.org/abs/2507.17353)|-|<details><summary>detail</summary>Accepted by WACV 2026</details>|\n", "VLA-R: Vision-Language Action Retrieval toward Open-World End-to-End Autonomous Driving": "|**2025-11-15**|**VLA-R: Vision-Language Action Retrieval toward Open-World End-to-End Autonomous Driving**|Hyunki Seong et.al|[paper](https://arxiv.org/abs/2511.12405)|-|-|\n", "Reasoning under Vision: Understanding Visual-Spatial Cognition in Vision-Language Models for CAPTCHA": "|**2025-11-15**|**Reasoning under Vision: Understanding Visual-Spatial Cognition in Vision-Language Models for CAPTCHA**|Python Song et.al|[paper](https://arxiv.org/abs/2510.06067)|-|-|\n", "Landsat30-AU: A Vision-Language Dataset for Australian Landsat Imagery": "|**2025-11-15**|**Landsat30-AU: A Vision-Language Dataset for Australian Landsat Imagery**|Sai Ma et.al|[paper](https://arxiv.org/abs/2508.03127)|[code](https://github.com/papersubmit1/landsat30-au.)|-|\n", "SpaceVLM: Sub-Space Modeling of Negation in Vision-Language Models": "|**2025-11-15**|**SpaceVLM: Sub-Space Modeling of Negation in Vision-Language Models**|Sepehr Kazemi Ranjbar et.al|[paper](https://arxiv.org/abs/2511.12331)|-|-|\n", "ZoomEarth: Active Perception for Ultra-High-Resolution Geospatial Vision-Language Tasks": "|**2025-11-15**|**ZoomEarth: Active Perception for Ultra-High-Resolution Geospatial Vision-Language Tasks**|Ruixun Liu et.al|[paper](https://arxiv.org/abs/2511.12267)|-|-|\n", "DexGraspVLA: A Vision-Language-Action Framework Towards General Dexterous Grasping": "|**2025-11-15**|**DexGraspVLA: A Vision-Language-Action Framework Towards General Dexterous Grasping**|Yifan Zhong et.al|[paper](https://arxiv.org/abs/2502.20900)|[code](https://dexgraspvla.github.io.)|-|\n", "AttackVLA: Benchmarking Adversarial and Backdoor Attacks on Vision-Language-Action Models": "|**2025-11-15**|**AttackVLA: Benchmarking Adversarial and Backdoor Attacks on Vision-Language-Action Models**|Jiayu Li et.al|[paper](https://arxiv.org/abs/2511.12149)|-|-|\n", "DPL: Decoupled Prototype Learning for Enhancing Robustness of Vision-Language Transformers to Missing Modalities": "|**2025-11-15**|**DPL: Decoupled Prototype Learning for Enhancing Robustness of Vision-Language Transformers to Missing Modalities**|Jueqing Lu et.al|[paper](https://arxiv.org/abs/2505.08283)|-|<details><summary>detail</summary>Updates to v1</details>|\n", "RAC3: Retrieval-Augmented Corner Case Comprehension for Autonomous Driving with Vision-Language Models": "|**2025-11-15**|**RAC3: Retrieval-Augmented Corner Case Comprehension for Autonomous Driving with Vision-Language Models**|Yujin Wang et.al|[paper](https://arxiv.org/abs/2412.11050)|-|<details><summary>detail</summary>Accepted by IEEE Transactions on Multimedia</details>|\n", "Learning to Hear by Seeing: It's Time for Vision Language Models to Understand Artistic Emotion from Sight and Sound": "|**2025-11-15**|**Learning to Hear by Seeing: It's Time for Vision Language Models to Understand Artistic Emotion from Sight and Sound**|Dengming Zhang et.al|[paper](https://arxiv.org/abs/2511.12077)|-|-|\n", "Bridging Vision and Language for Robust Context-Aware Surgical Point Tracking: The VL-SurgPT Dataset and Benchmark": "|**2025-11-14**|**Bridging Vision and Language for Robust Context-Aware Surgical Point Tracking: The VL-SurgPT Dataset and Benchmark**|Rulin Zhou et.al|[paper](https://arxiv.org/abs/2511.12026)|-|<details><summary>detail</summary>AAAI 2026 oral</details>|\n"}}