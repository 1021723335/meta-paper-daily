{"source-free": {"Closing the Confusion Loop: CLIP-Guided Alignment for Source-Free Domain Adaptation": "|**2026-2-9**|**Closing the Confusion Loop: CLIP-Guided Alignment for Source-Free Domain Adaptation**|Shanshan Wang et.al|[paper](https://arxiv.org/abs/2602.08730)|[code](https://github.com/soloiro/CGA)|-|\n", "USBD: Universal Structural Basis Distillation for Source-Free Graph Domain Adaptation": "|**2026-2-9**|**USBD: Universal Structural Basis Distillation for Source-Free Graph Domain Adaptation**|Yingxu Wang et.al|[paper](https://arxiv.org/abs/2602.08431)|-|-|\n", "Rethinking Test-Time Training: Tilting The Latent Distribution For Few-Shot Source-Free Adaptation": "|**2026-2-2**|**Rethinking Test-Time Training: Tilting The Latent Distribution For Few-Shot Source-Free Adaptation**|Tahir Qasim Syed et.al|[paper](https://arxiv.org/abs/2602.02633)|-|-|\n", "Collision-free Source Seeking and Flocking Control of Multi-agents with Connectivity Preservation": "|**2026-1-30**|**Collision-free Source Seeking and Flocking Control of Multi-agents with Connectivity Preservation**|Tinghua Li et.al|[paper](https://arxiv.org/abs/2301.04576)|-|<details><summary>detail</summary>Published in IEEE Transactions on Automatic Control</details>|\n", "Source Coding with Free Bits and the Multi-Way Number Partitioning Problem": "|**2026-1-29**|**Source Coding with Free Bits and the Multi-Way Number Partitioning Problem**|Niloufar Ahmadypour et.al|[paper](https://arxiv.org/abs/2009.02710)|-|-|\n", "Beyond Retraining: Training-Free Unknown Class Filtering for Source-Free Open Set Domain Adaptation of Vision-Language Models": "|**2026-1-28**|**Beyond Retraining: Training-Free Unknown Class Filtering for Source-Free Open Set Domain Adaptation of Vision-Language Models**|Yongguang Li et.al|[paper](https://arxiv.org/abs/2504.14224)|-|<details><summary>detail</summary>Core methods unchanged</details>|\n", "A Source-Free Approach for Domain Adaptation via Multiview Image Transformation and Latent Space Consistency": "|**2026-1-28**|**A Source-Free Approach for Domain Adaptation via Multiview Image Transformation and Latent Space Consistency**|Debopom Sutradhar et.al|[paper](https://arxiv.org/abs/2601.20284)|-|<details><summary>detail</summary>Manuscript under review in IEEE Transactions on Image Processing</details>|\n", "Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity": "|**2026-1-24**|**Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity**|Harsharaj Pathak et.al|[paper](https://arxiv.org/abs/2601.17408)|-|-|\n", "Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results": "|**2026-1-23**|**Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results**|Rohan Palanikumar et.al|[paper](https://arxiv.org/abs/2511.00752)|-|-|\n", "Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection": "|**2026-1-20**|**Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2511.07301)|-|<details><summary>detail</summary>AAAI 2026</details>|\n", "Towards Unbiased Source-Free Object Detection via Vision Foundation Models": "|**2026-1-19**|**Towards Unbiased Source-Free Object Detection via Vision Foundation Models**|Zhi Cai et.al|[paper](https://arxiv.org/abs/2601.12765)|-|-|\n", "Unified Source-Free Domain Adaptation": "|**2026-1-18**|**Unified Source-Free Domain Adaptation**|Song Tang et.al|[paper](https://arxiv.org/abs/2403.07601)|[code](https://github.com/tntek/CausalDA.)|-|\n", "GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher and Gaussian Mixture Model-Based Pseudo-Labeling": "|**2026-1-16**|**GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher and Gaussian Mixture Model-Based Pseudo-Labeling**|Pascal Schlachter et.al|[paper](https://arxiv.org/abs/2601.11161)|[code](https://github.com/pascalschlachter/GMM-COMET.)|-|\n", "SfMamba: Efficient Source-Free Domain Adaptation via Selective Scan Modeling": "|**2026-1-13**|**SfMamba: Efficient Source-Free Domain Adaptation via Selective Scan Modeling**|Xi Chen et.al|[paper](https://arxiv.org/abs/2601.08608)|[code](https://github.com/chenxi52/SfMamba.)|-|\n", "Source-Free Domain Adaptation for Geospatial Point Cloud Semantic Segmentation": "|**2026-1-13**|**Source-Free Domain Adaptation for Geospatial Point Cloud Semantic Segmentation**|Yuan Gao et.al|[paper](https://arxiv.org/abs/2601.08375)|-|-|\n"}, "object detection": {"Cross-Modal Purification and Fusion for Small-Object RGB-D Transmission-Line Defect Detection": "|**2026-2-15**|**Cross-Modal Purification and Fusion for Small-Object RGB-D Transmission-Line Defect Detection**|Jiaming Cui et.al|[paper](https://arxiv.org/abs/2602.01696)|-|-|\n", "Explainability-Inspired Layer-Wise Pruning of Deep Neural Networks for Efficient Object Detection": "|**2026-2-15**|**Explainability-Inspired Layer-Wise Pruning of Deep Neural Networks for Efficient Object Detection**|Abhinav Shukla et.al|[paper](https://arxiv.org/abs/2602.14040)|-|-|\n", "HyperDet: 3D Object Detection with Hyper 4D Radar Point Clouds": "|**2026-2-13**|**HyperDet: 3D Object Detection with Hyper 4D Radar Point Clouds**|Yichun Xiao et.al|[paper](https://arxiv.org/abs/2602.11554)|-|-|\n", "LAF-YOLOv10 with Partial Convolution Backbone, Attention-Guided Feature Pyramid, Auxiliary P2 Head, and Wise-IoU Loss for Small Object Detection in Drone Aerial Imagery": "|**2026-2-13**|**LAF-YOLOv10 with Partial Convolution Backbone, Attention-Guided Feature Pyramid, Auxiliary P2 Head, and Wise-IoU Loss for Small Object Detection in Drone Aerial Imagery**|Sohail Ali Farooqui et.al|[paper](https://arxiv.org/abs/2602.13378)|-|-|\n", "Detecting Object Tracking Failure via Sequential Hypothesis Testing": "|**2026-2-13**|**Detecting Object Tracking Failure via Sequential Hypothesis Testing**|Alejandro Monroy Mu\u00f1oz et.al|[paper](https://arxiv.org/abs/2602.12983)|-|<details><summary>detail</summary>Accepted in WACV workshop \"Real World Surveillance: Applications and Challenges</details>|\n", "Robustness of Object Detection of Autonomous Vehicles in Adverse Weather Conditions": "|**2026-2-13**|**Robustness of Object Detection of Autonomous Vehicles in Adverse Weather Conditions**|Fox Pettersen et.al|[paper](https://arxiv.org/abs/2602.12902)|-|-|\n", "Adaptive Image Zoom-in with Bounding Box Transformation for UAV Object Detection": "|**2026-2-11**|**Adaptive Image Zoom-in with Bounding Box Transformation for UAV Object Detection**|Tao Wang et.al|[paper](https://arxiv.org/abs/2602.07512)|[code](https://github.com/twangnh/zoomdet_code.)|<details><summary>detail</summary>paper accepted by ISPRS Journal of Photogrammetry and Remote Sensing ( IF=12</details>|\n", "MambaFusion: Adaptive State-Space Fusion for Multimodal 3D Object Detection": "|**2026-2-11**|**MambaFusion: Adaptive State-Space Fusion for Multimodal 3D Object Detection**|Venkatraman Narayanan et.al|[paper](https://arxiv.org/abs/2602.08126)|-|-|\n", "Are Dense Labels Always Necessary for 3D Object Detection from Point Cloud?": "|**2026-2-11**|**Are Dense Labels Always Necessary for 3D Object Detection from Point Cloud?**|Chenqiang Gao et.al|[paper](https://arxiv.org/abs/2403.02818)|-|<details><summary>detail</summary>update</details>|\n", "FGAA-FPN: Foreground-Guided Angle-Aware Feature Pyramid Network for Oriented Object Detection": "|**2026-2-11**|**FGAA-FPN: Foreground-Guided Angle-Aware Feature Pyramid Network for Oriented Object Detection**|Jialin Ma et.al|[paper](https://arxiv.org/abs/2602.10710)|-|<details><summary>detail</summary>Submitted to The Visual Computer</details>|\n", "RAWDet-7: A Multi-Scenario Benchmark for Object Detection and Description on Quantized RAW Images": "|**2026-2-10**|**RAWDet-7: A Multi-Scenario Benchmark for Object Detection and Description on Quantized RAW Images**|Mishal Fatima et.al|[paper](https://arxiv.org/abs/2602.03760)|-|<details><summary>detail</summary>*Equal Contribution</details>|\n", "Energy-Efficient Fast Object Detection on Edge Devices for IoT Systems": "|**2026-2-10**|**Energy-Efficient Fast Object Detection on Edge Devices for IoT Systems**|Mas Nurul Achmadiah et.al|[paper](https://arxiv.org/abs/2602.09515)|-|-|\n", "ALIGN: Advanced Query Initialization with LiDAR-Image Guidance for Occlusion-Robust 3D Object Detection": "|**2026-2-9**|**ALIGN: Advanced Query Initialization with LiDAR-Image Guidance for Occlusion-Robust 3D Object Detection**|Janghyun Baek et.al|[paper](https://arxiv.org/abs/2512.18187)|-|-|\n", "Mamba-based Spatio-Frequency Motion Perception for Video Camouflaged Object Detection": "|**2026-2-7**|**Mamba-based Spatio-Frequency Motion Perception for Video Camouflaged Object Detection**|Xin Li et.al|[paper](https://arxiv.org/abs/2507.23601)|[code](https://github.com/BoydeLi/Vcamba.)|-|\n", "You Only Pose Once: A Minimalist's Detection Transformer for Monocular RGB Category-level 9D Multi-Object Pose Estimation": "|**2026-2-7**|**You Only Pose Once: A Minimalist's Detection Transformer for Monocular RGB Category-level 9D Multi-Object Pose Estimation**|Hakjin Lee et.al|[paper](https://arxiv.org/abs/2508.14965)|[code](https://mikigom.github.io/YOPO-project-page.)|<details><summary>detail</summary>This paper has been accepted by IEEE ICRA 2026</details>|\n"}, "domain adaptation": {"DRAMA: Domain Retrieval using Adaptive Module Allocation": "|**2026-2-16**|**DRAMA: Domain Retrieval using Adaptive Module Allocation**|Pranav Kasela et.al|[paper](https://arxiv.org/abs/2602.14960)|-|-|\n", "Instance-Guided Unsupervised Domain Adaptation for Robotic Semantic Segmentation": "|**2026-2-14**|**Instance-Guided Unsupervised Domain Adaptation for Robotic Semantic Segmentation**|Michele Antonazzi et.al|[paper](https://arxiv.org/abs/2602.01389)|-|<details><summary>detail</summary>Accepted for publication at ICRA 2026</details>|\n", "Tutoring Large Language Models to be Domain-adaptive, Precise, and Safe": "|**2026-2-14**|**Tutoring Large Language Models to be Domain-adaptive, Precise, and Safe**|Somnath Banerjee et.al|[paper](https://arxiv.org/abs/2602.13860)|-|<details><summary>detail</summary>the PhD Symposium at Web Conference 2026</details>|\n", "MEMTS: Internalizing Domain Knowledge via Parameterized Memory for Retrieval-Free Domain Adaptation of Time Series Foundation Models": "|**2026-2-14**|**MEMTS: Internalizing Domain Knowledge via Parameterized Memory for Retrieval-Free Domain Adaptation of Time Series Foundation Models**|Xiaoyun Yu et.al|[paper](https://arxiv.org/abs/2602.13783)|-|-|\n", "Exploring Accurate and Transparent Domain Adaptation in Predictive Healthcare via Concept-Grounded Orthogonal Inference": "|**2026-2-12**|**Exploring Accurate and Transparent Domain Adaptation in Predictive Healthcare via Concept-Grounded Orthogonal Inference**|Pengfei Hu et.al|[paper](https://arxiv.org/abs/2602.12542)|-|-|\n", "Discovering Hierarchy-Grounded Domains with Adaptive Granularity for Clinical Domain Generalization": "|**2026-2-12**|**Discovering Hierarchy-Grounded Domains with Adaptive Granularity for Clinical Domain Generalization**|Pengfei Hu et.al|[paper](https://arxiv.org/abs/2506.06977)|-|-|\n", "UPDA: Unsupervised Progressive Domain Adaptation for No-Reference Point Cloud Quality Assessment": "|**2026-2-12**|**UPDA: Unsupervised Progressive Domain Adaptation for No-Reference Point Cloud Quality Assessment**|Bingxu Xie et.al|[paper](https://arxiv.org/abs/2602.11969)|[code](https://github.com/yokeno1/UPDA-main.)|<details><summary>detail</summary>to be published in IEEE Transactions on Broadcasting</details>|\n", "GP2F: Cross-Domain Graph Prompting with Adaptive Fusion of Pre-trained Graph Neural Networks": "|**2026-2-12**|**GP2F: Cross-Domain Graph Prompting with Adaptive Fusion of Pre-trained Graph Neural Networks**|Dongxiao He et.al|[paper](https://arxiv.org/abs/2602.11629)|-|-|\n", "Move What Matters: Parameter-Efficient Domain Adaptation via Optimal Transport Flow for Collaborative Perception": "|**2026-2-11**|**Move What Matters: Parameter-Efficient Domain Adaptation via Optimal Transport Flow for Collaborative Perception**|Zesheng Jia et.al|[paper](https://arxiv.org/abs/2602.11565)|-|-|\n", "Reinforced Curriculum Pre-Alignment for Domain-Adaptive VLMs": "|**2026-2-11**|**Reinforced Curriculum Pre-Alignment for Domain-Adaptive VLMs**|Yuming Yan et.al|[paper](https://arxiv.org/abs/2602.10740)|-|-|\n", "Learning Structure-Semantic Evolution Trajectories for Graph Domain Adaptation": "|**2026-2-10**|**Learning Structure-Semantic Evolution Trajectories for Graph Domain Adaptation**|Wei Chen et.al|[paper](https://arxiv.org/abs/2602.10506)|-|<details><summary>detail</summary>accepted by ICLR 2026</details>|\n", "Learning Adaptive Distribution Alignment with Neural Characteristic Function for Graph Domain Adaptation": "|**2026-2-10**|**Learning Adaptive Distribution Alignment with Neural Characteristic Function for Graph Domain Adaptation**|Wei Chen et.al|[paper](https://arxiv.org/abs/2602.10489)|-|<details><summary>detail</summary>Accepted by ICLR 2026</details>|\n", "Impact of domain adaptation in deep learning for medical image classifications": "|**2026-2-9**|**Impact of domain adaptation in deep learning for medical image classifications**|Yihang Wu et.al|[paper](https://arxiv.org/abs/2602.09355)|-|<details><summary>detail</summary>Accepted in IEEE SMC 2025</details>|\n", "Pave Your Own Path: Graph Gradual Domain Adaptation on Fused Gromov-Wasserstein Geodesics": "|**2026-2-9**|**Pave Your Own Path: Graph Gradual Domain Adaptation on Fused Gromov-Wasserstein Geodesics**|Zhichen Zeng et.al|[paper](https://arxiv.org/abs/2505.12709)|-|-|\n", "Harvest: Adaptive Photonic Switching Schedules for Collective Communication in Scale-up Domains": "|**2026-2-9**|**Harvest: Adaptive Photonic Switching Schedules for Collective Communication in Scale-up Domains**|Mahir Rahman et.al|[paper](https://arxiv.org/abs/2602.09188)|-|-|\n"}, "domain generalization": {"Cross-view Domain Generalization via Geometric Consistency for LiDAR Semantic Segmentation": "|**2026-2-16**|**Cross-view Domain Generalization via Geometric Consistency for LiDAR Semantic Segmentation**|Jindong Zhao et.al|[paper](https://arxiv.org/abs/2602.14525)|[code](https://github.com/KintomZi/CVGC-DG)|-|\n", "Efficiently Assemble Normalization Layers and Regularization for Federated Domain Generalization": "|**2026-2-15**|**Efficiently Assemble Normalization Layers and Regularization for Federated Domain Generalization**|Khiem Le et.al|[paper](https://arxiv.org/abs/2403.15605)|-|<details><summary>detail</summary>CVPR'24</details>|\n", "Designing Staged Evaluation Workflows for LLMs: Integrating Domain Experts, Lay Users, and Model-Generated Evaluation Criteria": "|**2026-2-15**|**Designing Staged Evaluation Workflows for LLMs: Integrating Domain Experts, Lay Users, and Model-Generated Evaluation Criteria**|Annalisa Szymanski et.al|[paper](https://arxiv.org/abs/2410.02054)|-|<details><summary>detail</summary>To be published in CHI2026</details>|\n", "Panning for Gold: Expanding Domain-Specific Knowledge Graphs with General Knowledge": "|**2026-2-13**|**Panning for Gold: Expanding Domain-Specific Knowledge Graphs with General Knowledge**|Runhao Zhao et.al|[paper](https://arxiv.org/abs/2601.10485)|-|-|\n", "M6: Multi-generator, Multi-domain, Multi-lingual and cultural, Multi-genres, Multi-instrument Machine-Generated Music Detection Databases": "|**2026-2-13**|**M6: Multi-generator, Multi-domain, Multi-lingual and cultural, Multi-genres, Multi-instrument Machine-Generated Music Detection Databases**|Yupei Li et.al|[paper](https://arxiv.org/abs/2412.06001)|-|<details><summary>detail</summary>Scientific reports</details>|\n", "Discovering Hierarchy-Grounded Domains with Adaptive Granularity for Clinical Domain Generalization": "|**2026-2-12**|**Discovering Hierarchy-Grounded Domains with Adaptive Granularity for Clinical Domain Generalization**|Pengfei Hu et.al|[paper](https://arxiv.org/abs/2506.06977)|-|-|\n", "Manifold-Aware Temporal Domain Generalization for Large Language Models": "|**2026-2-12**|**Manifold-Aware Temporal Domain Generalization for Large Language Models**|Yiheng Yao et.al|[paper](https://arxiv.org/abs/2602.11965)|-|-|\n", "Pursuing Best Industrial Practices for Retrieval-Augmented Generation in the Medical Domain": "|**2026-2-11**|**Pursuing Best Industrial Practices for Retrieval-Augmented Generation in the Medical Domain**|Liz Li et.al|[paper](https://arxiv.org/abs/2602.03368)|-|-|\n", "Learning to Compose for Cross-domain Agentic Workflow Generation": "|**2026-2-11**|**Learning to Compose for Cross-domain Agentic Workflow Generation**|Jialiang Wang et.al|[paper](https://arxiv.org/abs/2602.11114)|-|-|\n", "A Swap-Adversarial Framework for Improving Domain Generalization in Electroencephalography-Based Parkinson's Disease Prediction": "|**2026-2-10**|**A Swap-Adversarial Framework for Improving Domain Generalization in Electroencephalography-Based Parkinson's Disease Prediction**|Seongwon Jin et.al|[paper](https://arxiv.org/abs/2602.10528)|-|-|\n", "Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models": "|**2026-2-10**|**Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models**|Mingzi Cao et.al|[paper](https://arxiv.org/abs/2602.08658)|-|-|\n", "Time2General: Learning Spatiotemporal Invariant Representations for Domain-Generalization Video Semantic Segmentation": "|**2026-2-10**|**Time2General: Learning Spatiotemporal Invariant Representations for Domain-Generalization Video Semantic Segmentation**|Siyu Chen et.al|[paper](https://arxiv.org/abs/2602.09648)|-|-|\n", "Semantics-Aware Generative Latent Data Augmentation for Learning in Low-Resource Domains": "|**2026-2-9**|**Semantics-Aware Generative Latent Data Augmentation for Learning in Low-Resource Domains**|Jaesung Bae et.al|[paper](https://arxiv.org/abs/2602.02841)|-|-|\n", "TriC-Motion: Tri-Domain Causal Modeling Grounded Text-to-Motion Generation": "|**2026-2-9**|**TriC-Motion: Tri-Domain Causal Modeling Grounded Text-to-Motion Generation**|Yiyang Cao et.al|[paper](https://arxiv.org/abs/2602.08462)|[code](https://caoyiyang1105.github.io/TriC-Motion/.)|-|\n", "DRAGON: Domain-specific Robust Automatic Data Generation for RAG Optimization": "|**2026-2-8**|**DRAGON: Domain-specific Robust Automatic Data Generation for RAG Optimization**|Haiyang Shen et.al|[paper](https://arxiv.org/abs/2505.10989)|-|-|\n"}, "vision language": {"ThermEval: A Structured Benchmark for Evaluation of Vision-Language Models on Thermal Imagery": "|**2026-2-16**|**ThermEval: A Structured Benchmark for Evaluation of Vision-Language Models on Thermal Imagery**|Ayush Shrivastava et.al|[paper](https://arxiv.org/abs/2602.14989)|-|<details><summary>detail</summary>8 Pages with 2 figures of main content</details>|\n", "DM0: An Embodied-Native Vision-Language-Action Model towards Physical AI": "|**2026-2-16**|**DM0: An Embodied-Native Vision-Language-Action Model towards Physical AI**|En Yu et.al|[paper](https://arxiv.org/abs/2602.14974)|[code](https://github.com/Dexmal/dexbotic)|<details><summary>detail</summary>Authors are listed in alphabetical order</details>|\n", "Efficient Test-Time Scaling for Small Vision-Language Models": "|**2026-2-16**|**Efficient Test-Time Scaling for Small Vision-Language Models**|Mehmet Onurcan Kaya et.al|[paper](https://arxiv.org/abs/2510.03574)|[code](https://monurcan.github.io/efficient_test_time_scaling)|<details><summary>detail</summary>ICLR 2026</details>|\n", "Replanning Human-Robot Collaborative Tasks with Vision-Language Models via Semantic and Physical Dual-Correction": "|**2026-2-16**|**Replanning Human-Robot Collaborative Tasks with Vision-Language Models via Semantic and Physical Dual-Correction**|Taichi Kato et.al|[paper](https://arxiv.org/abs/2602.14551)|-|-|\n", "Error Patterns in Historical OCR: A Comparative Analysis of TrOCR and a Vision-Language Model": "|**2026-2-16**|**Error Patterns in Historical OCR: A Comparative Analysis of TrOCR and a Vision-Language Model**|Ari Vesalainen et.al|[paper](https://arxiv.org/abs/2602.14524)|-|-|\n", "Uncertainty-Aware Vision-Language Segmentation for Medical Imaging": "|**2026-2-16**|**Uncertainty-Aware Vision-Language Segmentation for Medical Imaging**|Aryan Das et.al|[paper](https://arxiv.org/abs/2602.14498)|[code](https://github.com/arya-domain/UA-VLS)|-|\n", "Hierarchical Vision-Language Interaction for Facial Action Unit Detection": "|**2026-2-15**|**Hierarchical Vision-Language Interaction for Facial Action Unit Detection**|Yong Li et.al|[paper](https://arxiv.org/abs/2602.14425)|-|<details><summary>detail</summary>IEEE Transaction on Affective Computing 2026</details>|\n", "pFedNavi: Structure-Aware Personalized Federated Vision-Language Navigation for Embodied AI": "|**2026-2-15**|**pFedNavi: Structure-Aware Personalized Federated Vision-Language Navigation for Embodied AI**|Qingqian Yang et.al|[paper](https://arxiv.org/abs/2602.14401)|-|<details><summary>detail</summary>Preprint</details>|\n", "Multi-Turn Adaptive Prompting Attack on Large Vision-Language Models": "|**2026-2-15**|**Multi-Turn Adaptive Prompting Attack on Large Vision-Language Models**|In Chong Choi et.al|[paper](https://arxiv.org/abs/2602.14399)|-|-|\n", "LQA: A Lightweight Quantized-Adaptive Framework for Vision-Language Models on the Edge": "|**2026-2-15**|**LQA: A Lightweight Quantized-Adaptive Framework for Vision-Language Models on the Edge**|Xin Wang et.al|[paper](https://arxiv.org/abs/2602.07849)|-|-|\n", "LVLM-COUNT: Enhancing the Counting Ability of Large Vision-Language Models": "|**2026-2-15**|**LVLM-COUNT: Enhancing the Counting Ability of Large Vision-Language Models**|Muhammad Fetrat Qharabagh et.al|[paper](https://arxiv.org/abs/2412.00686)|-|-|\n", "Dual-Signal Adaptive KV-Cache Optimization for Long-Form Video Understanding in Vision-Language Models": "|**2026-2-15**|**Dual-Signal Adaptive KV-Cache Optimization for Long-Form Video Understanding in Vision-Language Models**|Vishnu Sai et.al|[paper](https://arxiv.org/abs/2602.14236)|-|-|\n", "Annotation-Efficient Vision-Language Model Adaptation to the Polish Language Using the LLaVA Framework": "|**2026-2-15**|**Annotation-Efficient Vision-Language Model Adaptation to the Polish Language Using the LLaVA Framework**|Grzegorz Statkiewicz et.al|[paper](https://arxiv.org/abs/2602.14073)|-|-|\n", "MarsRetrieval: Benchmarking Vision-Language Models for Planetary-Scale Geospatial Retrieval on Mars": "|**2026-2-14**|**MarsRetrieval: Benchmarking Vision-Language Models for Planetary-Scale Geospatial Retrieval on Mars**|Shuoyuan Wang et.al|[paper](https://arxiv.org/abs/2602.13961)|[code](https://github.com/ml-stat-Sustech/MarsRetrieval)|-|\n", "VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model": "|**2026-2-14**|**VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model**|Yanjiang Guo et.al|[paper](https://arxiv.org/abs/2602.12063)|[code](https://sites.google.com/view/vla-w)|<details><summary>detail</summary>Project Page: https://sites</details>|\n"}}