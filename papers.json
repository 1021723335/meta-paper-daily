{"source-free": {"Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation": "|**2025-11-24**|**Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation**|Huisoo Lee et.al|[paper](https://arxiv.org/abs/2511.19147)|-|-|\n", "Unsupervised and Source-Free Ranking of Biomedical Segmentation Models": "|**2025-11-24**|**Unsupervised and Source-Free Ranking of Biomedical Segmentation Models**|Joshua Talks et.al|[paper](https://arxiv.org/abs/2503.00450)|-|-|\n", "SloMo-Fast: Slow-Momentum and Fast-Adaptive Teachers for Source-Free Continual Test-Time Adaptation": "|**2025-11-23**|**SloMo-Fast: Slow-Momentum and Fast-Adaptive Teachers for Source-Free Continual Test-Time Adaptation**|Md Akil Raihan Iftee et.al|[paper](https://arxiv.org/abs/2511.18468)|-|-|\n", "ViMix-14M: A Curated Multi-Source Video-Text Dataset with Long-Form, High-Quality Captions and Crawl-Free Access": "|**2025-11-23**|**ViMix-14M: A Curated Multi-Source Video-Text Dataset with Long-Form, High-Quality Captions and Crawl-Free Access**|Timing Yang et.al|[paper](https://arxiv.org/abs/2511.18382)|-|-|\n", "HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for Cross-Modality Medical Image Segmentation": "|**2025-11-22**|**HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for Cross-Modality Medical Image Segmentation**|Yulong Shi et.al|[paper](https://arxiv.org/abs/2511.17958)|[code](https://github.com/derekshiii/HEAL.)|<details><summary>detail</summary>Accepted by The 36th British Machine Vision Conference (BMVC 2025)</details>|\n", "Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation": "|**2025-11-19**|**Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation**|Yaxuan Song et.al|[paper](https://arxiv.org/abs/2402.06213)|[code](https://github.com/YXSong000/UAD.)|<details><summary>detail</summary>Accepted by ISBI 2024</details>|\n", "Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection": "|**2025-11-10**|**Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2511.07301)|-|<details><summary>detail</summary>AAAI 2026</details>|\n", "Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping": "|**2025-11-5**|**Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping**|Zhihang Qin et.al|[paper](https://arxiv.org/abs/2511.03691)|-|-|\n", "Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results": "|**2025-11-1**|**Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results**|Rohan Palanikumar et.al|[paper](https://arxiv.org/abs/2511.00752)|-|-|\n", "Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising": "|**2025-10-31**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|\n", "Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation": "|**2025-10-29**|**Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation**|Yuyang Huang et.al|[paper](https://arxiv.org/abs/2510.25279)|-|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|\n", "Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation": "|**2025-10-29**|**Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation**|Quang-Khai Bui-Tran et.al|[paper](https://arxiv.org/abs/2510.25227)|-|-|\n", "Training-free Source Attribution of AI-generated Images via Resynthesis": "|**2025-10-28**|**Training-free Source Attribution of AI-generated Images via Resynthesis**|Pietro Bongini et.al|[paper](https://arxiv.org/abs/2510.24278)|-|-|\n", "Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation": "|**2025-10-24**|**Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.22142)|-|-|\n", "Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces": "|**2025-10-22**|**Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces**|Osman Berke Guney et.al|[paper](https://arxiv.org/abs/2305.17403)|[code](https://github.com/osmanberke/SFDA-SSVEP-BCI)|-|\n"}, "object detection": {"StableTrack: Stabilizing Multi-Object Tracking on Low-Frequency Detections": "|**2025-11-25**|**StableTrack: Stabilizing Multi-Object Tracking on Low-Frequency Detections**|Matvei Shelukhan et.al|[paper](https://arxiv.org/abs/2511.20418)|-|-|\n", "Zoo3D: Zero-Shot 3D Object Detection at Scene Level": "|**2025-11-25**|**Zoo3D: Zero-Shot 3D Object Detection at Scene Level**|Andrey Lemeshko et.al|[paper](https://arxiv.org/abs/2511.20253)|[code](https://github.com/col14m/zoo3d)|-|\n", "Unleashing the Power of Chain-of-Prediction for Monocular 3D Object Detection": "|**2025-11-25**|**Unleashing the Power of Chain-of-Prediction for Monocular 3D Object Detection**|Zhihao Zhang et.al|[paper](https://arxiv.org/abs/2505.04594)|-|-|\n", "Maritime Small Object Detection from UAVs using Deep Learning with Altitude-Aware Dynamic Tiling": "|**2025-11-24**|**Maritime Small Object Detection from UAVs using Deep Learning with Altitude-Aware Dynamic Tiling**|Sakib Ahmed et.al|[paper](https://arxiv.org/abs/2511.19728)|-|<details><summary>detail</summary>This is the author's accepted version of an article that has been published by IEEE</details>|\n", "SAM3-Adapter: Efficient Adaptation of Segment Anything 3 for Camouflage Object Segmentation, Shadow Detection, and Medical Image Segmentation": "|**2025-11-24**|**SAM3-Adapter: Efficient Adaptation of Segment Anything 3 for Camouflage Object Segmentation, Shadow Detection, and Medical Image Segmentation**|Tianrun Chen et.al|[paper](https://arxiv.org/abs/2511.19425)|-|-|\n", "DualGazeNet: A Biologically Inspired Dual-Gaze Query Network for Salient Object Detection": "|**2025-11-24**|**DualGazeNet: A Biologically Inspired Dual-Gaze Query Network for Salient Object Detection**|Yu Zhang et.al|[paper](https://arxiv.org/abs/2511.18865)|-|-|\n", "StereoDETR: Stereo-based Transformer for 3D Object Detection": "|**2025-11-24**|**StereoDETR: Stereo-based Transformer for 3D Object Detection**|Shiyi Mu et.al|[paper](https://arxiv.org/abs/2511.18788)|[code](https://github.com/shiyi-mu/StereoDETR-OPEN.)|<details><summary>detail</summary>Accepted by IEEE TCSVT</details>|\n", "DriveFlow: Rectified Flow Adaptation for Robust 3D Object Detection in Autonomous Driving": "|**2025-11-23**|**DriveFlow: Rectified Flow Adaptation for Robust 3D Object Detection in Autonomous Driving**|Hongbin Lin et.al|[paper](https://arxiv.org/abs/2511.18713)|[code](https://github.com/Hongbin98/DriveFlow.)|<details><summary>detail</summary>Accepted by AAAI 2026</details>|\n", "Exploring Surround-View Fisheye Camera 3D Object Detection": "|**2025-11-23**|**Exploring Surround-View Fisheye Camera 3D Object Detection**|Changcai Li et.al|[paper](https://arxiv.org/abs/2511.18695)|-|-|\n", "VK-Det: Visual Knowledge Guided Prototype Learning for Open-Vocabulary Aerial Object Detection": "|**2025-11-22**|**VK-Det: Visual Knowledge Guided Prototype Learning for Open-Vocabulary Aerial Object Detection**|Jianhang Yao et.al|[paper](https://arxiv.org/abs/2511.18075)|-|-|\n", "DMAT: An End-to-End Framework for Joint Atmospheric Turbulence Mitigation and Object Detection": "|**2025-11-22**|**DMAT: An End-to-End Framework for Joint Atmospheric Turbulence Mitigation and Object Detection**|Paul Hill et.al|[paper](https://arxiv.org/abs/2507.04323)|-|<details><summary>detail</summary>WACV2026</details>|\n", "State and Scene Enhanced Prototypes for Weakly Supervised Open-Vocabulary Object Detection": "|**2025-11-22**|**State and Scene Enhanced Prototypes for Weakly Supervised Open-Vocabulary Object Detection**|Jiaying Zhou et.al|[paper](https://arxiv.org/abs/2511.18012)|-|-|\n", "REXO: Indoor Multi-View Radar Object Detection via 3D Bounding Box Diffusion": "|**2025-11-21**|**REXO: Indoor Multi-View Radar Object Detection via 3D Bounding Box Diffusion**|Ryoma Yataka et.al|[paper](https://arxiv.org/abs/2511.17806)|-|-|\n", "YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection": "|**2025-11-21**|**YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection**|Ori Meiraz et.al|[paper](https://arxiv.org/abs/2511.13344)|-|<details><summary>detail</summary>1 figure</details>|\n", "A Unified Voxel Diffusion Module for Point Cloud 3D Object Detection": "|**2025-11-21**|**A Unified Voxel Diffusion Module for Point Cloud 3D Object Detection**|Qifeng Liu et.al|[paper](https://arxiv.org/abs/2508.16069)|-|<details><summary>detail</summary>Under review</details>|\n"}, "domain adaptation": {"CrossEarth-Gate: Fisher-Guided Adaptive Tuning Engine for Efficient Adaptation of Cross-Domain Remote Sensing Semantic Segmentation": "|**2025-11-25**|**CrossEarth-Gate: Fisher-Guided Adaptive Tuning Engine for Efficient Adaptation of Cross-Domain Remote Sensing Semantic Segmentation**|Shilei Cao et.al|[paper](https://arxiv.org/abs/2511.20302)|-|-|\n", "DAPointMamba: Domain Adaptive Point Mamba for Point Cloud Completion": "|**2025-11-25**|**DAPointMamba: Domain Adaptive Point Mamba for Point Cloud Completion**|Yinghui Li et.al|[paper](https://arxiv.org/abs/2511.20278)|-|<details><summary>detail</summary>AAAI 2026</details>|\n", "EfficientXpert: Efficient Domain Adaptation for Large Language Models via Propagation-Aware Pruning": "|**2025-11-25**|**EfficientXpert: Efficient Domain Adaptation for Large Language Models via Propagation-Aware Pruning**|Songlin Zhao et.al|[paper](https://arxiv.org/abs/2511.19935)|-|-|\n", "AraFinNews: Arabic Financial Summarisation with Domain-Adapted LLMs": "|**2025-11-24**|**AraFinNews: Arabic Financial Summarisation with Domain-Adapted LLMs**|Mo El-Haj et.al|[paper](https://arxiv.org/abs/2511.01265)|[code](https://github.com/ArabicNLP-uk/AraFinNews.)|-|\n", "Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation": "|**2025-11-24**|**Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation**|Huisoo Lee et.al|[paper](https://arxiv.org/abs/2511.19147)|-|-|\n", "Neural B-Frame Coding: Tackling Domain Shift Issues with Lightweight Online Motion Resolution Adaptation": "|**2025-11-23**|**Neural B-Frame Coding: Tackling Domain Shift Issues with Lightweight Online Motion Resolution Adaptation**|Sang NguyenQuang et.al|[paper](https://arxiv.org/abs/2511.18724)|[code](https://github.com/NYCU-MAPL/Fast-OMRA.git.)|<details><summary>detail</summary>Accepted by TCAS-II: Express Briefs</details>|\n", "Modality-Collaborative Low-Rank Decomposers for Few-Shot Video Domain Adaptation": "|**2025-11-23**|**Modality-Collaborative Low-Rank Decomposers for Few-Shot Video Domain Adaptation**|Yuyang Wanyan et.al|[paper](https://arxiv.org/abs/2511.18711)|-|-|\n", "From Simulations to Surveys: Domain Adaptation for Galaxy Observations": "|**2025-11-23**|**From Simulations to Surveys: Domain Adaptation for Galaxy Observations**|Kaley Brauer et.al|[paper](https://arxiv.org/abs/2511.18590)|-|-|\n", "NeuroVascU-Net: A Unified Multi-Scale and Cross-Domain Adaptive Feature Fusion U-Net for Precise 3D Segmentation of Brain Vessels in Contrast-Enhanced T1 MRI": "|**2025-11-23**|**NeuroVascU-Net: A Unified Multi-Scale and Cross-Domain Adaptive Feature Fusion U-Net for Precise 3D Segmentation of Brain Vessels in Contrast-Enhanced T1 MRI**|Mohammad Jafari Vayeghan et.al|[paper](https://arxiv.org/abs/2511.18422)|-|-|\n", "HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for Cross-Modality Medical Image Segmentation": "|**2025-11-22**|**HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for Cross-Modality Medical Image Segmentation**|Yulong Shi et.al|[paper](https://arxiv.org/abs/2511.17958)|[code](https://github.com/derekshiii/HEAL.)|<details><summary>detail</summary>Accepted by The 36th British Machine Vision Conference (BMVC 2025)</details>|\n", "Statistically-Guided Dual-Domain Meta-Learning with Adaptive Multi-Prototype Aggregation for Distributed Fiber Optic Sensing": "|**2025-11-21**|**Statistically-Guided Dual-Domain Meta-Learning with Adaptive Multi-Prototype Aggregation for Distributed Fiber Optic Sensing**|Yifan He et.al|[paper](https://arxiv.org/abs/2511.17902)|-|-|\n", "Dual-domain Adaptation Networks for Realistic Image Super-resolution": "|**2025-11-21**|**Dual-domain Adaptation Networks for Realistic Image Super-resolution**|Chaowei Fang et.al|[paper](https://arxiv.org/abs/2511.17217)|[code](https://github.com/dummerchen/DAN.)|-|\n", "Domain-Shared Learning and Gradual Alignment for Unsupervised Domain Adaptation Visible-Infrared Person Re-Identification": "|**2025-11-20**|**Domain-Shared Learning and Gradual Alignment for Unsupervised Domain Adaptation Visible-Infrared Person Re-Identification**|Nianchang Huang et.al|[paper](https://arxiv.org/abs/2511.16184)|-|-|\n", "L-JacobiNet and S-JacobiNet: An Analysis of Adaptive Generalization, Stabilization, and Spectral Domain Trade-offs in GNNs": "|**2025-11-20**|**L-JacobiNet and S-JacobiNet: An Analysis of Adaptive Generalization, Stabilization, and Spectral Domain Trade-offs in GNNs**|Huseyin Goksu et.al|[paper](https://arxiv.org/abs/2511.16081)|-|-|\n", "LLMs-based Augmentation for Domain Adaptation in Long-tailed Food Datasets": "|**2025-11-19**|**LLMs-based Augmentation for Domain Adaptation in Long-tailed Food Datasets**|Qing Wang et.al|[paper](https://arxiv.org/abs/2511.16037)|-|-|\n"}, "domain generalization": {"Modality-Balanced Collaborative Distillation for Multi-Modal Domain Generalization": "|**2025-11-25**|**Modality-Balanced Collaborative Distillation for Multi-Modal Domain Generalization**|Xiaohan Wang et.al|[paper](https://arxiv.org/abs/2511.20258)|-|-|\n", "Domain Fusion Controllable Generalization for Cross-Domain Time Series Forecasting from Multi-Domain Integrated Distribution": "|**2025-11-25**|**Domain Fusion Controllable Generalization for Cross-Domain Time Series Forecasting from Multi-Domain Integrated Distribution**|Xiangkai Ma et.al|[paper](https://arxiv.org/abs/2412.03068)|-|<details><summary>detail</summary>We have updated the abstract</details>|\n", "Enhancing Domain-Specific Encoder Models with LLM-Generated Data: How to Leverage Ontologies, and How to Do Without Them": "|**2025-11-24**|**Enhancing Domain-Specific Encoder Models with LLM-Generated Data: How to Leverage Ontologies, and How to Do Without Them**|Marc Brinner et.al|[paper](https://arxiv.org/abs/2503.22006)|-|<details><summary>detail</summary>Published in the Findings of the Association for Computational Linguistics: EMNLP 2025</details>|\n", "Cross-Domain Generalization of Multimodal LLMs for Global Photovoltaic Assessment": "|**2025-11-24**|**Cross-Domain Generalization of Multimodal LLMs for Global Photovoltaic Assessment**|Muhao Guo et.al|[paper](https://arxiv.org/abs/2511.19537)|-|-|\n", "When Generative Replay Meets Evolving Deepfakes: Domain-Aware Relative Weighting for Incremental Face Forgery Detection": "|**2025-11-23**|**When Generative Replay Meets Evolving Deepfakes: Domain-Aware Relative Weighting for Incremental Face Forgery Detection**|Hao Shen et.al|[paper](https://arxiv.org/abs/2511.18436)|-|-|\n", "General vs Domain-Specific CNNs: Understanding Pretraining Effects on Brain MRI Tumor Classification": "|**2025-11-23**|**General vs Domain-Specific CNNs: Understanding Pretraining Effects on Brain MRI Tumor Classification**|Helia Abedini et.al|[paper](https://arxiv.org/abs/2511.18326)|-|-|\n", "UniFlow: Towards Zero-Shot LiDAR Scene Flow for Autonomous Vehicles via Cross-Domain Generalization": "|**2025-11-22**|**UniFlow: Towards Zero-Shot LiDAR Scene Flow for Autonomous Vehicles via Cross-Domain Generalization**|Siyi Li et.al|[paper](https://arxiv.org/abs/2511.18254)|[code](https://lisiyi777.github.io/UniFlow/)|<details><summary>detail</summary>Project Page: https://lisiyi777</details>|\n", "Rethinking Retrieval: From Traditional Retrieval Augmented Generation to Agentic and Non-Vector Reasoning Systems in the Financial Domain for Large Language Models": "|**2025-11-22**|**Rethinking Retrieval: From Traditional Retrieval Augmented Generation to Agentic and Non-Vector Reasoning Systems in the Financial Domain for Large Language Models**|Elias Lumer et.al|[paper](https://arxiv.org/abs/2511.18177)|-|-|\n", "GROOT: General-Purpose Automatic Parameter Tuning Across Layers, Domains, and Use Cases": "|**2025-11-22**|**GROOT: General-Purpose Automatic Parameter Tuning Across Layers, Domains, and Use Cases**|Robert Krahn et.al|[paper](https://arxiv.org/abs/2511.17922)|-|<details><summary>detail</summary>International Conferences on Applied Computing 2025 and WWW/Internet 2025</details>|\n", "AngioDG: Interpretable Channel-informed Feature-modulated Single-source Domain Generalization for Coronary Vessel Segmentation in X-ray Angiography": "|**2025-11-21**|**AngioDG: Interpretable Channel-informed Feature-modulated Single-source Domain Generalization for Coronary Vessel Segmentation in X-ray Angiography**|Mohammad Atwany et.al|[paper](https://arxiv.org/abs/2511.17724)|-|-|\n", "Open-Set Domain Generalization through Spectral-Spatial Uncertainty Disentanglement for Hyperspectral Image Classification": "|**2025-11-21**|**Open-Set Domain Generalization through Spectral-Spatial Uncertainty Disentanglement for Hyperspectral Image Classification**|Amirreza Khoshbakht et.al|[paper](https://arxiv.org/abs/2506.09460)|-|-|\n", "The Finer the Better: Towards Granular-aware Open-set Domain Generalization": "|**2025-11-21**|**The Finer the Better: Towards Granular-aware Open-set Domain Generalization**|Yunyun Wang et.al|[paper](https://arxiv.org/abs/2511.16979)|-|-|\n", "L-JacobiNet and S-JacobiNet: An Analysis of Adaptive Generalization, Stabilization, and Spectral Domain Trade-offs in GNNs": "|**2025-11-20**|**L-JacobiNet and S-JacobiNet: An Analysis of Adaptive Generalization, Stabilization, and Spectral Domain Trade-offs in GNNs**|Huseyin Goksu et.al|[paper](https://arxiv.org/abs/2511.16081)|-|-|\n", "Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains": "|**2025-11-19**|**Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains**|Austin Xu et.al|[paper](https://arxiv.org/abs/2510.17793)|-|-|\n", "Transferable Dual-Domain Feature Importance Attack against AI-Generated Image Detector": "|**2025-11-19**|**Transferable Dual-Domain Feature Importance Attack against AI-Generated Image Detector**|Weiheng Zhu et.al|[paper](https://arxiv.org/abs/2511.15571)|-|-|\n"}, "vision language": {"Harnessing Vision-Language Models for Time Series Anomaly Detection": "|**2025-11-25**|**Harnessing Vision-Language Models for Time Series Anomaly Detection**|Zelin He et.al|[paper](https://arxiv.org/abs/2506.06836)|-|<details><summary>detail</summary>AAAI 2026 (Oral)</details>|\n", "HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model": "|**2025-11-25**|**HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model**|Youngwan Lee et.al|[paper](https://arxiv.org/abs/2506.04704)|[code](https://youngwanlee.github.io/holisafe)|<details><summary>detail</summary>Project page: https://youngwanlee</details>|\n", "ArtiBench and ArtiBrain: Benchmarking Generalizable Vision-Language Articulated Object Manipulation": "|**2025-11-25**|**ArtiBench and ArtiBrain: Benchmarking Generalizable Vision-Language Articulated Object Manipulation**|Yuhan Wu et.al|[paper](https://arxiv.org/abs/2511.20330)|-|-|\n", "Vision-Language Models for Automated 3D PET/CT Report Generation": "|**2025-11-25**|**Vision-Language Models for Automated 3D PET/CT Report Generation**|Wenpei Jiao et.al|[paper](https://arxiv.org/abs/2511.20145)|-|-|\n", "FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph": "|**2025-11-25**|**FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph**|Xiaolin Zhou et.al|[paper](https://arxiv.org/abs/2509.13733)|[code](https://horizonrobotics.github.io/robot_lab/fsr-vln/)|<details><summary>detail</summary>Demo video are available at https://horizonrobotics</details>|\n", "Cross-Layer Vision Smoothing: Enhancing Visual Understanding via Sustained Focus on Key Objects in Large Vision-Language Models": "|**2025-11-25**|**Cross-Layer Vision Smoothing: Enhancing Visual Understanding via Sustained Focus on Key Objects in Large Vision-Language Models**|Jianfei Zhao et.al|[paper](https://arxiv.org/abs/2509.12897)|-|<details><summary>detail</summary>Under Review</details>|\n", "KEPT: Knowledge-Enhanced Prediction of Trajectories from Consecutive Driving Frames with Vision-Language Models": "|**2025-11-25**|**KEPT: Knowledge-Enhanced Prediction of Trajectories from Consecutive Driving Frames with Vision-Language Models**|Yujin Wang et.al|[paper](https://arxiv.org/abs/2509.02966)|-|-|\n", "GigaBrain-0: A World Model-Powered Vision-Language-Action Model": "|**2025-11-25**|**GigaBrain-0: A World Model-Powered Vision-Language-Action Model**| GigaBrain Team et.al|[paper](https://arxiv.org/abs/2510.19430)|[code](https://gigabrain0.github.io/)|<details><summary>detail</summary>https://gigabrain0</details>|\n", "CounterVQA: Evaluating and Improving Counterfactual Reasoning in Vision-Language Models for Video Understanding": "|**2025-11-24**|**CounterVQA: Evaluating and Improving Counterfactual Reasoning in Vision-Language Models for Video Understanding**|Yuefei Chen et.al|[paper](https://arxiv.org/abs/2511.19923)|-|-|\n", "Reasoning-VLA: A Fast and General Vision-Language-Action Reasoning Model for Autonomous Driving": "|**2025-11-24**|**Reasoning-VLA: A Fast and General Vision-Language-Action Reasoning Model for Autonomous Driving**|Dapeng Zhang et.al|[paper](https://arxiv.org/abs/2511.19912)|-|-|\n", "Agent0-VL: Exploring Self-Evolving Agent for Tool-Integrated Vision-Language Reasoning": "|**2025-11-24**|**Agent0-VL: Exploring Self-Evolving Agent for Tool-Integrated Vision-Language Reasoning**|Jiaqi Liu et.al|[paper](https://arxiv.org/abs/2511.19900)|[code](https://github.com/aiming-lab/Agent0/Agent0-VL)|-|\n", "MAPS: Preserving Vision-Language Representations via Module-Wise Proximity Scheduling for Better Vision-Language-Action Generalization": "|**2025-11-24**|**MAPS: Preserving Vision-Language Representations via Module-Wise Proximity Scheduling for Better Vision-Language-Action Generalization**|Chengyue Huang et.al|[paper](https://arxiv.org/abs/2511.19878)|-|-|\n", "PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model": "|**2025-11-24**|**PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model**|Cheng Cui et.al|[paper](https://arxiv.org/abs/2510.14528)|[code](https://github.com/PaddlePaddle/PaddleOCR)|<details><summary>detail</summary>Github Repo: https://github</details>|\n", "Continually Evolving Skill Knowledge in Vision Language Action Model": "|**2025-11-24**|**Continually Evolving Skill Knowledge in Vision Language Action Model**|Yuxuan Wu et.al|[paper](https://arxiv.org/abs/2511.18085)|-|-|\n", "CropVLM: Learning to Zoom for Fine-Grained Vision-Language Perception": "|**2025-11-24**|**CropVLM: Learning to Zoom for Fine-Grained Vision-Language Perception**|Miguel Carvalho et.al|[paper](https://arxiv.org/abs/2511.19820)|-|-|\n"}}