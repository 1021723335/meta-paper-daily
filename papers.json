{"source-free": {"Source-Free Domain Adaptation via Multi-view Contrastive Learning": "|**2025-7-4**|**Source-Free Domain Adaptation via Multi-view Contrastive Learning**|Amirfarhad Farhadi et.al|[paper](https://arxiv.org/abs/2507.03321)|-|-|\n", "Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework": "|**2025-6-26**|**Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework**|Ismail Nejjar et.al|[paper](https://arxiv.org/abs/2411.12558)|-|<details><summary>detail</summary>TMLR 2025</details>|\n", "Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation": "|**2025-6-26**|**Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation**|Yihong Cao et.al|[paper](https://arxiv.org/abs/2506.21198)|[code](https://github.com/yihong-97/UNLOCK.)|<details><summary>detail</summary>ICCV 2025</details>|\n", "Context Aware Grounded Teacher for Source Free Object Detection": "|**2025-6-25**|**Context Aware Grounded Teacher for Source Free Object Detection**|Tajamul Ashraf et.al|[paper](https://arxiv.org/abs/2504.15404)|[code](https://github.com/Tajamul21/Grounded_Teacher.)|-|\n", "SFDLA: Source-Free Document Layout Analysis": "|**2025-6-18**|**SFDLA: Source-Free Document Layout Analysis**|Sebastian Tewes et.al|[paper](https://arxiv.org/abs/2503.18742)|[code](https://github.com/s3setewe/sfdla-DLAdapter.)|<details><summary>detail</summary>Accepted by ICDAR 2025</details>|\n", "Unified Source-Free Domain Adaptation": "|**2025-6-17**|**Unified Source-Free Domain Adaptation**|Song Tang et.al|[paper](https://arxiv.org/abs/2403.07601)|-|-|\n", "SRPL-SFDA: SAM-Guided Reliable Pseudo-Labels for Source-Free Domain Adaptation in Medical Image Segmentation": "|**2025-6-11**|**SRPL-SFDA: SAM-Guided Reliable Pseudo-Labels for Source-Free Domain Adaptation in Medical Image Segmentation**|Xinya Liu et.al|[paper](https://arxiv.org/abs/2506.09403)|[code](https://github.com/HiLab-git/SRPL-SFDA.)|-|\n", "DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization": "|**2025-6-5**|**DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization**|Geonyoung Lee et.al|[paper](https://arxiv.org/abs/2506.02858)|[code](https://wltschmrz.github.io/DGMO/)|<details><summary>detail</summary>Interspeech 2025</details>|\n", "Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data": "|**2025-5-30**|**Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2503.20771)|-|-|\n", "Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation": "|**2025-5-30**|**Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation**|Pascal Schlachter et.al|[paper](https://arxiv.org/abs/2504.11992)|[code](https://github.com/pascalschlachter/PLAnalysis.)|<details><summary>detail</summary>the 33rd European Signal Processing Conference (EUSIPCO 2025)</details>|\n", "Shuffle PatchMix Augmentation with Confidence-Margin Weighted Pseudo-Labels for Enhanced Source-Free Domain Adaptation": "|**2025-5-30**|**Shuffle PatchMix Augmentation with Confidence-Margin Weighted Pseudo-Labels for Enhanced Source-Free Domain Adaptation**|Prasanna Reddy Pulakurthi et.al|[paper](https://arxiv.org/abs/2505.24216)|[code](https://github.com/PrasannaPulakurthi/SPM)|-|\n", "Multi-Granularity Class Prototype Topology Distillation for Class-Incremental Source-Free Unsupervised Domain Adaptation": "|**2025-5-27**|**Multi-Granularity Class Prototype Topology Distillation for Class-Incremental Source-Free Unsupervised Domain Adaptation**|Peihua Deng et.al|[paper](https://arxiv.org/abs/2411.16064)|[code](https://github.com/dengpeihua/GROTO.)|<details><summary>detail</summary>Accepted by CVPR 2025</details>|\n", "Training-Free Multi-Step Audio Source Separation": "|**2025-5-26**|**Training-Free Multi-Step Audio Source Separation**|Yongyi Zang et.al|[paper](https://arxiv.org/abs/2505.19534)|-|-|\n", "Temporal Restoration and Spatial Rewiring for Source-Free Multivariate Time Series Domain Adaptation": "|**2025-5-23**|**Temporal Restoration and Spatial Rewiring for Source-Free Multivariate Time Series Domain Adaptation**|Peiliang Gong et.al|[paper](https://arxiv.org/abs/2505.21525)|-|-|\n", "Listen, Analyze, and Adapt to Learn New Attacks: An Exemplar-Free Class Incremental Learning Method for Audio Deepfake Source Tracing": "|**2025-5-20**|**Listen, Analyze, and Adapt to Learn New Attacks: An Exemplar-Free Class Incremental Learning Method for Audio Deepfake Source Tracing**|Yang Xiao et.al|[paper](https://arxiv.org/abs/2505.14601)|-|<details><summary>detail</summary>Accepted by Interspeech 2025</details>|\n", "Source-Free Domain Adaptation for Speaker Verification in Data-Scarce Languages and Noisy Channels": "|**2025-7-8**|**Source-Free Domain Adaptation for Speaker Verification in Data-Scarce Languages and Noisy Channels**|S Salo Elia et.al|[paper](https://ui.adsabs.harvard.edu/abs/2024arXiv240605863S/abstract)|[code](https://paperswithcode.com/paper/source-free-domain-adaptation-for-speaker)|-|\n", "Global self-sustaining and local inheritance for source-free unsupervised domain adaptation": "|**2025-7-7**|**Global self-sustaining and local inheritance for source-free unsupervised domain adaptation**|L Peng et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0031320324004308)|-|<details><summary>detail</summary>Pattern Recognition, 2024 Elsevier</details>|\n", "Unveiling the Unknown: Unleashing the Power of Unknown to Known in Open-Set Source-Free Domain Adaptation": "|**2025-7-6**|**Unveiling the Unknown: Unleashing the Power of Unknown to Known in Open-Set Source-Free Domain Adaptation**|F Wan et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Wan_Unveiling_the_Unknown_Unleashing_the_Power_of_Unknown_to_Known_CVPR_2024_paper.html)|[code](https://github.com/xdwfl/upuk)|<details><summary>detail</summary>Proceedings of the IEEE\u00a0\u2026, 2024 openaccess.thecvf.com</details>|\n", "Discriminative Pattern Calibration Mechanism for Source-Free Domain Adaptation": "|**2025-7-6**|**Discriminative Pattern Calibration Mechanism for Source-Free Domain Adaptation**|H Xia et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Xia_Discriminative_Pattern_Calibration_Mechanism_for_Source-Free_Domain_Adaptation_CVPR_2024_paper.html)|[code](https://paperswithcode.com/paper/discriminative-pattern-calibration-mechanism)|<details><summary>detail</summary>\u2026\u00a0of the IEEE/CVF Conference on\u00a0\u2026, 2024 openaccess.thecvf.com</details>|\n", "Understanding and Improving Source-free Domain Adaptation from a Theoretical Perspective": "|**2025-7-6**|**Understanding and Improving Source-free Domain Adaptation from a Theoretical Perspective**|Y Mitsuzumi et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Mitsuzumi_Understanding_and_Improving_Source-free_Domain_Adaptation_from_a_Theoretical_Perspective_CVPR_2024_paper.html)|[code](https://paperswithcode.com/paper/understanding-and-improving-source-free)|<details><summary>detail</summary>Proceedings of the IEEE\u00a0\u2026, 2024 openaccess.thecvf.com</details>|\n", "Semantics, Distortion, and Style Matter: Towards Source-free UDA for Panoramic Segmentation\u2013Supplementary Material\u2013": "|**2025-7-6**|**Semantics, Distortion, and Style Matter: Towards Source-free UDA for Panoramic Segmentation\u2013Supplementary Material\u2013**|X Zheng et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/supplemental/Zheng_Semantics_Distortion_and_CVPR_2024_supplemental.pdf)|-|<details><summary>detail</summary>openaccess.thecvf.com</details>|\n", "LEAD: Learning Decomposition for Source-free Universal Domain Adaptation\u2014Supplementary Material": "|**2025-7-6**|**LEAD: Learning Decomposition for Source-free Universal Domain Adaptation\u2014Supplementary Material**|S Qu et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/supplemental/Qu_LEAD_Learning_Decomposition_CVPR_2024_supplemental.pdf)|-|<details><summary>detail</summary>Integration openaccess.thecvf.com</details>|\n", "Stable Neighbor Denoising for Source-free Domain Adaptive Segmentation (Supplementary Material)": "|**2025-7-6**|**Stable Neighbor Denoising for Source-free Domain Adaptive Segmentation (Supplementary Material)**|D Zhao et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/supplemental/Zhao_Stable_Neighbor_Denoising_CVPR_2024_supplemental.pdf)|-|<details><summary>detail</summary>openaccess.thecvf.com</details>|\n", "EventDance: Unsupervised Source-free Cross-modal Adaptation for Event-based Object Recognition\u2013Supplementray Material\u2013": "|**2025-7-6**|**EventDance: Unsupervised Source-free Cross-modal Adaptation for Event-based Object Recognition\u2013Supplementray Material\u2013**|X Zheng et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/supplemental/Zheng_EventDance_Unsupervised_Source-free_CVPR_2024_supplemental.pdf)|-|<details><summary>detail</summary>openaccess.thecvf.com</details>|\n", "MAP: MAsk-Pruning for Source-Free Model Intellectual Property Protection\u2014Supplementary Material": "|**2025-7-6**|**MAP: MAsk-Pruning for Source-Free Model Intellectual Property Protection\u2014Supplementary Material**|B Peng et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/supplemental/Peng_MAP_MAsk-Pruning_for_CVPR_2024_supplemental.pdf)|-|<details><summary>detail</summary>openaccess.thecvf.com</details>|\n"}, "object detection": {"Uncertainty-Aware Gradient Stabilization for Small Object Detection": "|**2025-7-10**|**Uncertainty-Aware Gradient Stabilization for Small Object Detection**|Huixin Sun et.al|[paper](https://arxiv.org/abs/2303.01803)|-|-|\n", "RT-OVAD: Real-Time Open-Vocabulary Aerial Object Detection via Image-Text Collaboration": "|**2025-7-10**|**RT-OVAD: Real-Time Open-Vocabulary Aerial Object Detection via Image-Text Collaboration**|Guoting Wei et.al|[paper](https://arxiv.org/abs/2408.12246)|[code](https://github.com/GT-Wei/RT-OVAD.)|-|\n", "DenoiseCP-Net: Efficient Collective Perception in Adverse Weather via Joint LiDAR-Based 3D Object Detection and Denoising": "|**2025-7-9**|**DenoiseCP-Net: Efficient Collective Perception in Adverse Weather via Joint LiDAR-Based 3D Object Detection and Denoising**|Sven Teufel et.al|[paper](https://arxiv.org/abs/2507.06976)|-|-|\n", "PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection": "|**2025-7-9**|**PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection**|Xiao Li et.al|[paper](https://arxiv.org/abs/2506.23581)|-|<details><summary>detail</summary>Accepted by ICCV 2025</details>|\n", "From Blurry to Brilliant Detection: YOLO-Based Aerial Object Detection with Super Resolution": "|**2025-7-9**|**From Blurry to Brilliant Detection: YOLO-Based Aerial Object Detection with Super Resolution**|Ragib Amin Nihal et.al|[paper](https://arxiv.org/abs/2401.14661)|-|-|\n", "StixelNExT: Toward Monocular Low-Weight Perception for Object Segmentation and Free Space Detection": "|**2025-7-9**|**StixelNExT: Toward Monocular Low-Weight Perception for Object Segmentation and Free Space Detection**|Marcel Vosshans et.al|[paper](https://arxiv.org/abs/2407.08277)|-|<details><summary>detail</summary>Accepted Conference Paper</details>|\n", "Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection": "|**2025-7-8**|**Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection**|Yupeng Hu et.al|[paper](https://arxiv.org/abs/2507.06510)|-|<details><summary>detail</summary>ICCV 2025</details>|\n", "CFMW: Cross-modality Fusion Mamba for Robust Object Detection under Adverse Weather": "|**2025-7-8**|**CFMW: Cross-modality Fusion Mamba for Robust Object Detection under Adverse Weather**|Haoyuan Li et.al|[paper](https://arxiv.org/abs/2404.16302)|[code](https://github.com/lhy-zjut/CFMW.)|<details><summary>detail</summary>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</details>|\n", "Rethinking Detecting Salient and Camouflaged Objects in Unconstrained Scenes": "|**2025-7-7**|**Rethinking Detecting Salient and Camouflaged Objects in Unconstrained Scenes**|Zhangjun Zhou et.al|[paper](https://arxiv.org/abs/2412.10943)|[code](https://github.com/ssecv/USCNet.)|-|\n", "CVFusion: Cross-View Fusion of 4D Radar and Camera for 3D Object Detection": "|**2025-7-6**|**CVFusion: Cross-View Fusion of 4D Radar and Camera for 3D Object Detection**|Hanzhi Zhong et.al|[paper](https://arxiv.org/abs/2507.04587)|-|-|\n", "MambaFusion: Height-Fidelity Dense Global Fusion for Multi-modal 3D Object Detection": "|**2025-7-6**|**MambaFusion: Height-Fidelity Dense Global Fusion for Multi-modal 3D Object Detection**|Hanshi Wang et.al|[paper](https://arxiv.org/abs/2507.04369)|-|-|\n", "DMAT: An End-to-End Framework for Joint Atmospheric Turbulence Mitigation and Object Detection": "|**2025-7-6**|**DMAT: An End-to-End Framework for Joint Atmospheric Turbulence Mitigation and Object Detection**|Paul Hill et.al|[paper](https://arxiv.org/abs/2507.04323)|-|-|\n", "Towards Accurate and Efficient 3D Object Detection for Autonomous Driving: A Mixture of Experts Computing System on Edge": "|**2025-7-5**|**Towards Accurate and Efficient 3D Object Detection for Autonomous Driving: A Mixture of Experts Computing System on Edge**|Linshen Liu et.al|[paper](https://arxiv.org/abs/2507.04123)|-|<details><summary>detail</summary>ICCV 2025</details>|\n", "Pillar-Voxel Fusion Network for 3D Object Detection in Airborne Hyperspectral Point Clouds": "|**2025-7-4**|**Pillar-Voxel Fusion Network for 3D Object Detection in Airborne Hyperspectral Point Clouds**|Yanze Jiang et.al|[paper](https://arxiv.org/abs/2504.09506)|-|-|\n", "Hallucinatory Image Tokens: A Training-free EAZY Approach on Detecting and Mitigating Object Hallucinations in LVLMs": "|**2025-7-4**|**Hallucinatory Image Tokens: A Training-free EAZY Approach on Detecting and Mitigating Object Hallucinations in LVLMs**|Liwei Che et.al|[paper](https://arxiv.org/abs/2503.07772)|-|<details><summary>detail</summary>ICCV2025</details>|\n", "Masked Feature Compression for Object Detection": "|**2025-7-9**|**Masked Feature Compression for Object Detection**|C Dai et.al|[paper](https://www.mdpi.com/2227-7390/12/12/1848)|[code](https://github.com/bosszhe/emiff)|<details><summary>detail</summary>Mathematics, 2024 mdpi.com</details>|\n"}, "domain adaptation": {"Adaptive Graph Integration for Cross-Domain Recommendation via Heterogeneous Graph Coordinators": "|**2025-7-10**|**Adaptive Graph Integration for Cross-Domain Recommendation via Heterogeneous Graph Coordinators**|Hengyu Zhang et.al|[paper](https://arxiv.org/abs/2410.11719)|[code](https://github.com/zhy99426/HAGO.)|<details><summary>detail</summary>Accept by SIGIR 2025</details>|\n", "Sparse Causal Discovery with Generative Intervention for Unsupervised Graph Domain Adaptation": "|**2025-7-10**|**Sparse Causal Discovery with Generative Intervention for Unsupervised Graph Domain Adaptation**|Junyu Luo et.al|[paper](https://arxiv.org/abs/2507.07621)|-|<details><summary>detail</summary>ICML 2025</details>|\n", "Damba-ST: Domain-Adaptive Mamba for Efficient Urban Spatio-Temporal Prediction": "|**2025-7-10**|**Damba-ST: Domain-Adaptive Mamba for Efficient Urban Spatio-Temporal Prediction**|Rui An et.al|[paper](https://arxiv.org/abs/2506.18939)|-|-|\n", "ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining": "|**2025-7-10**|**ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining**|Seonwu Kim et.al|[paper](https://arxiv.org/abs/2507.06795)|-|<details><summary>detail</summary>under review</details>|\n", "On the Hardness of Unsupervised Domain Adaptation: Optimal Learners and Information-Theoretic Perspective": "|**2025-7-9**|**On the Hardness of Unsupervised Domain Adaptation: Optimal Learners and Information-Theoretic Perspective**|Zhiyi Dong et.al|[paper](https://arxiv.org/abs/2507.06552)|-|<details><summary>detail</summary>the 4th Conference on Lifelong Learning Agents (CoLLAs 2025)</details>|\n", "Mitigating Multi-Sequence 3D Prostate MRI Data Scarcity through Domain Adaptation using Locally-Trained Latent Diffusion Models for Prostate Cancer Detection": "|**2025-7-8**|**Mitigating Multi-Sequence 3D Prostate MRI Data Scarcity through Domain Adaptation using Locally-Trained Latent Diffusion Models for Prostate Cancer Detection**|Emerson P. Grabke et.al|[paper](https://arxiv.org/abs/2507.06384)|[code](https://github.com/grabkeem/CCELLA-plus-plus)|<details><summary>detail</summary>BT and MAH are co-senior authors on the work</details>|\n", "CoPT: Unsupervised Domain Adaptive Segmentation using Domain-Agnostic Text Embeddings": "|**2025-7-8**|**CoPT: Unsupervised Domain Adaptive Segmentation using Domain-Agnostic Text Embeddings**|Cristina Mata et.al|[paper](https://arxiv.org/abs/2507.07125)|[code](https://github.com/cfmata/CoPT.)|<details><summary>detail</summary>ECCV 2024</details>|\n", "Safe Domain Randomization via Uncertainty-Aware Out-of-Distribution Detection and Policy Adaptation": "|**2025-7-8**|**Safe Domain Randomization via Uncertainty-Aware Out-of-Distribution Detection and Policy Adaptation**|Mohamad H. Danesh et.al|[paper](https://arxiv.org/abs/2507.06111)|-|-|\n", "Optimal Transport for Domain Adaptation through Gaussian Mixture Models": "|**2025-7-8**|**Optimal Transport for Domain Adaptation through Gaussian Mixture Models**|Eduardo Fernandes Montesuma et.al|[paper](https://arxiv.org/abs/2403.13847)|[code](https://github.com/eddardd/gmm-otda/)|-|\n", "Improving Robustness of Foundation Models in Domain Adaptation with Soup-Adapters": "|**2025-7-8**|**Improving Robustness of Foundation Models in Domain Adaptation with Soup-Adapters**|Marco Roschkowski et.al|[paper](https://arxiv.org/abs/2507.05807)|-|-|\n", "Domain adaptation of large language models for geotechnical applications": "|**2025-7-7**|**Domain adaptation of large language models for geotechnical applications**|Lei Fan et.al|[paper](https://arxiv.org/abs/2507.05613)|-|-|\n", "Domain Adaptation of VLM for Soccer Video Understanding": "|**2025-7-7**|**Domain Adaptation of VLM for Soccer Video Understanding**|Tiancheng Jiang et.al|[paper](https://arxiv.org/abs/2505.13860)|-|-|\n", "Tackling Dimensional Collapse toward Comprehensive Universal Domain Adaptation": "|**2025-7-6**|**Tackling Dimensional Collapse toward Comprehensive Universal Domain Adaptation**|Hung-Chieh Fang et.al|[paper](https://arxiv.org/abs/2410.11271)|[code](https://dc-unida.github.io/)|-|\n", "Domain Adaptation of Drag Reduction Policy to Partial Measurements": "|**2025-7-6**|**Domain Adaptation of Drag Reduction Policy to Partial Measurements**|Anton Plaksin et.al|[paper](https://arxiv.org/abs/2507.04309)|-|<details><summary>detail</summary>Journal ref:Machine Learning and the Physical Sciences Workshop</details>|\n", "Beyond Independent Passages: Adaptive Passage Combination Retrieval for Retrieval Augmented Open-Domain Question Answering": "|**2025-7-5**|**Beyond Independent Passages: Adaptive Passage Combination Retrieval for Retrieval Augmented Open-Domain Question Answering**|Ting-Wen Ko et.al|[paper](https://arxiv.org/abs/2507.04069)|-|-|\n", "Confidence sharing adaptation for out-of-domain human pose and shape estimation": "|**2025-7-9**|**Confidence sharing adaptation for out-of-domain human pose and shape estimation**|T Yue et.al|[paper](https://www.sciencedirect.com/science/article/pii/S1077314224001322)|-|<details><summary>detail</summary>Computer Vision and Image\u00a0\u2026, 2024 Elsevier</details>|\n", "\u2026\u00a0Carbon Content and Temperature in Bof Steelmaking Based on Adaptive Balanced Joint Distribution Alignment Domain Adaptation with Variational Autoencoder": "|**2025-7-8**|**\u2026\u00a0Carbon Content and Temperature in Bof Steelmaking Based on Adaptive Balanced Joint Distribution Alignment Domain Adaptation with Variational Autoencoder**|Z Liu et.al|[paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4863841)|-|<details><summary>detail</summary>Available at SSRN 4863841 papers.ssrn.com</details>|\n", "POND: Multi-Source Time Series Domain Adaptation with Information-Aware Prompt Tuning": "|**2025-7-8**|**POND: Multi-Source Time Series Domain Adaptation with Information-Aware Prompt Tuning**|J Wang et.al|[paper](https://www.researchgate.net/profile/Junxiang-Wang-3/publication/381225385_POND_Multi-Source_Time_Series_Domain_Adaptation_with_Information-Aware_Prompt_Tuning/links/6663974e85a4ee7261ae011e/POND-Multi-Source-Time-Series-Domain-Adaptation-with-Information-Aware-Prompt-Tuning.pdf)|[code](https://paperswithcode.com/paper/prompt-based-domain-discrimination-for-multi)|<details><summary>detail</summary>2024 researchgate.net</details>|\n", "Continuous Test-time Domain Adaptation for Efficient Fault Detection under Evolving Operating Conditions": "|**2025-7-8**|**Continuous Test-time Domain Adaptation for Efficient Fault Detection under Evolving Operating Conditions**|H Sun et.al|[paper](https://ui.adsabs.harvard.edu/abs/2024arXiv240606607S/abstract)|[code](https://paperswithcode.com/paper/continuous-test-time-domain-adaptation-for)|-|\n", "Source-Free Domain Adaptation for Speaker Verification in Data-Scarce Languages and Noisy Channels": "|**2025-7-8**|**Source-Free Domain Adaptation for Speaker Verification in Data-Scarce Languages and Noisy Channels**|S Salo Elia et.al|[paper](https://ui.adsabs.harvard.edu/abs/2024arXiv240605863S/abstract)|[code](https://paperswithcode.com/paper/source-free-domain-adaptation-for-speaker)|-|\n", "Cross-Domain Classification Based on Frequency Component Adaptation for Remote Sensing Images": "|**2025-7-8**|**Cross-Domain Classification Based on Frequency Component Adaptation for Remote Sensing Images**|P Zhu et.al|[paper](https://www.mdpi.com/2072-4292/16/12/2134)|-|<details><summary>detail</summary>Remote Sensing, 2024 mdpi.com</details>|\n", "TSFAN: Tensorized spatial-frequency attention network with domain adaptation for cross-session EEG-based biometric recognition": "|**2025-7-8**|**TSFAN: Tensorized spatial-frequency attention network with domain adaptation for cross-session EEG-based biometric recognition**|X Jin et.al|[paper](https://automatedtest.iopscience.iop.org/article/10.1088/1741-2552/ad5761)|-|<details><summary>detail</summary>Journal of\u00a0\u2026, 2024 automatedtest.iopscience.iop.org</details>|\n", "SE/BN Adapter: Parametric Efficient Domain Adaptation for Speaker Recognition": "|**2025-7-8**|**SE/BN Adapter: Parametric Efficient Domain Adaptation for Speaker Recognition**|T Wang et.al|[paper](https://arxiv.org/abs/2406.07832)|-|-|\n", "Novel Deep Learning Domain Adaptation Approach for Object Detection Using Semi-Self Building Dataset and Modified YOLOv4": "|**2025-7-7**|**Novel Deep Learning Domain Adaptation Approach for Object Detection Using Semi-Self Building Dataset and Modified YOLOv4**|A Gomaa et.al|[paper](https://www.mdpi.com/2032-6653/15/6/255)|-|<details><summary>detail</summary>World Electric Vehicle Journal, 2024 mdpi.com</details>|\n", "Global self-sustaining and local inheritance for source-free unsupervised domain adaptation": "|**2025-7-7**|**Global self-sustaining and local inheritance for source-free unsupervised domain adaptation**|L Peng et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0031320324004308)|-|<details><summary>detail</summary>Pattern Recognition, 2024 Elsevier</details>|\n"}, "domain generalization": {"From Domain Documents to Requirements: Retrieval-Augmented Generation in the Space Industry": "|**2025-7-10**|**From Domain Documents to Requirements: Retrieval-Augmented Generation in the Space Industry**|Chetan Arora et.al|[paper](https://arxiv.org/abs/2507.07689)|-|-|\n", "Sparse Causal Discovery with Generative Intervention for Unsupervised Graph Domain Adaptation": "|**2025-7-10**|**Sparse Causal Discovery with Generative Intervention for Unsupervised Graph Domain Adaptation**|Junyu Luo et.al|[paper](https://arxiv.org/abs/2507.07621)|-|<details><summary>detail</summary>ICML 2025</details>|\n", "SynthTextEval: Synthetic Text Data Generation and Evaluation for High-Stakes Domains": "|**2025-7-9**|**SynthTextEval: Synthetic Text Data Generation and Evaluation for High-Stakes Domains**|Krithika Ramesh et.al|[paper](https://arxiv.org/abs/2507.07229)|-|-|\n", "Enhancing Food-Domain Question Answering with a Multimodal Knowledge Graph: Hybrid QA Generation and Diversity Analysis": "|**2025-7-9**|**Enhancing Food-Domain Question Answering with a Multimodal Knowledge Graph: Hybrid QA Generation and Diversity Analysis**|Srihari K B et.al|[paper](https://arxiv.org/abs/2507.06571)|-|-|\n", "Fair Domain Generalization: An Information-Theoretic View": "|**2025-7-8**|**Fair Domain Generalization: An Information-Theoretic View**|Tangzheng Lian et.al|[paper](https://arxiv.org/abs/2507.05823)|-|-|\n", "AdaptaGen: Domain-Specific Image Generation through Hierarchical Semantic Optimization Framework": "|**2025-7-7**|**AdaptaGen: Domain-Specific Image Generation through Hierarchical Semantic Optimization Framework**|Suoxiang Zhang et.al|[paper](https://arxiv.org/abs/2507.05621)|-|-|\n", "LAID: Lightweight AI-Generated Image Detection in Spatial and Spectral Domains": "|**2025-7-7**|**LAID: Lightweight AI-Generated Image Detection in Spatial and Spectral Domains**|Nicholas Chivaran et.al|[paper](https://arxiv.org/abs/2507.05162)|[code](https://github.com/nchivar/LAID.)|<details><summary>detail</summary>To appear in the proceedings of PST2025</details>|\n", "Adversarial Data Augmentation for Single Domain Generalization via Lyapunov Exponent-Guided Optimization": "|**2025-7-6**|**Adversarial Data Augmentation for Single Domain Generalization via Lyapunov Exponent-Guided Optimization**|Zuyu Zhang et.al|[paper](https://arxiv.org/abs/2507.04302)|-|<details><summary>detail</summary>ICCV 2025</details>|\n", "CLEP-DG: Contrastive Learning for Speech Emotion Domain Generalization via Soft Prompt Tuning": "|**2025-7-5**|**CLEP-DG: Contrastive Learning for Speech Emotion Domain Generalization via Soft Prompt Tuning**|Jiacheng Shi et.al|[paper](https://arxiv.org/abs/2507.04048)|-|<details><summary>detail</summary>Interspeech2025</details>|\n", "Bridging Domain Generalization to Multimodal Domain Generalization via Unified Representations": "|**2025-7-4**|**Bridging Domain Generalization to Multimodal Domain Generalization via Unified Representations**|Hai Huang et.al|[paper](https://arxiv.org/abs/2507.03304)|-|<details><summary>detail</summary>Accepted by ICCV 2025</details>|\n", "Set Valued Predictions For Robust Domain Generalization": "|**2025-7-3**|**Set Valued Predictions For Robust Domain Generalization**|Ron Tsibulsky et.al|[paper](https://arxiv.org/abs/2507.03146)|-|<details><summary>detail</summary>ICML 2025</details>|\n", "Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation": "|**2025-7-3**|**Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation**|Siyu Chen et.al|[paper](https://arxiv.org/abs/2504.12753)|[code](https://github.com/anonymouse-xzrptkvyqc/DepthForge.)|<details><summary>detail</summary>Accepted by ICCV 2025</details>|\n", "Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization": "|**2025-7-2**|**Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization**|De Cheng et.al|[paper](https://arxiv.org/abs/2507.02288)|-|-|\n", "Generalized Adaptive Transfer Network: Enhancing Transfer Learning in Reinforcement Learning Across Domains": "|**2025-7-2**|**Generalized Adaptive Transfer Network: Enhancing Transfer Learning in Reinforcement Learning Across Domains**|Abhishek Verma et.al|[paper](https://arxiv.org/abs/2507.03026)|-|-|\n", "NuSegDG: Integration of Heterogeneous Space and Gaussian Kernel for Domain-Generalized Nuclei Segmentation": "|**2025-7-2**|**NuSegDG: Integration of Heterogeneous Space and Gaussian Kernel for Domain-Generalized Nuclei Segmentation**|Zhenye Lou et.al|[paper](https://arxiv.org/abs/2408.11787)|[code](https://github.com/xq141839/NuSegDG.)|-|\n"}, "vision language": {"VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting": "|**2025-7-10**|**VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting**|Juyi Lin et.al|[paper](https://arxiv.org/abs/2507.05116)|-|-|\n", "One Object, Multiple Lies: A Benchmark for Cross-task Adversarial Attack on Unified Vision-Language Models": "|**2025-7-10**|**One Object, Multiple Lies: A Benchmark for Cross-task Adversarial Attack on Unified Vision-Language Models**|Jiale Zhao et.al|[paper](https://arxiv.org/abs/2507.07709)|-|-|\n", "ViLU: Learning Vision-Language Uncertainties for Failure Prediction": "|**2025-7-10**|**ViLU: Learning Vision-Language Uncertainties for Failure Prediction**|Marc Lafon et.al|[paper](https://arxiv.org/abs/2507.07620)|[code](https://github.com/ykrmm/ViLU.)|<details><summary>detail</summary>Journal ref:International Conference on Computer Vision</details>|\n", "Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation": "|**2025-7-10**|**Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation**|Andr\u00e9 Schakkal et.al|[paper](https://arxiv.org/abs/2506.22827)|[code](https://vlp-humanoid.github.io/)|<details><summary>detail</summary>the RSS 2025 Workshop on Robot Planning in the Era of Foundation Models</details>|\n", "ArchiveGPT: A human-centered evaluation of using a vision language model for image cataloguing": "|**2025-7-10**|**ArchiveGPT: A human-centered evaluation of using a vision language model for image cataloguing**|Line Abele et.al|[paper](https://arxiv.org/abs/2507.07551)|-|-|\n", "MapNav: A Novel Memory Representation via Annotated Semantic Maps for Vision-and-Language Navigation": "|**2025-7-9**|**MapNav: A Novel Memory Representation via Annotated Semantic Maps for Vision-and-Language Navigation**|Lingfeng Zhang et.al|[paper](https://arxiv.org/abs/2502.13451)|-|-|\n", "DLaVA: Document Language and Vision Assistant for Answer Localization with Enhanced Interpretability and Trustworthiness": "|**2025-7-9**|**DLaVA: Document Language and Vision Assistant for Answer Localization with Enhanced Interpretability and Trustworthiness**|Ahmad Mohammadshirazi et.al|[paper](https://arxiv.org/abs/2412.00151)|[code](https://github.com/ahmad-shirazi/AnnotMLLM.)|-|\n", "Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models": "|**2025-7-9**|**Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models**|Tiezheng Zhang et.al|[paper](https://arxiv.org/abs/2507.07104)|-|-|\n", "Finetuning Vision-Language Models as OCR Systems for Low-Resource Languages: A Case Study of Manchu": "|**2025-7-9**|**Finetuning Vision-Language Models as OCR Systems for Low-Resource Languages: A Case Study of Manchu**|Yan Hon Michael Chung et.al|[paper](https://arxiv.org/abs/2507.06761)|[code](https://github.com/mic7ch1/ManchuAI-OCR.)|-|\n", "DriveMRP: Enhancing Vision-Language Models with Synthetic Motion Data for Motion Risk Prediction": "|**2025-7-9**|**DriveMRP: Enhancing Vision-Language Models with Synthetic Motion Data for Motion Risk Prediction**|Zhiyi Hou et.al|[paper](https://arxiv.org/abs/2507.02948)|[code](https://github.com/hzy138/DriveMRP)|-|\n", "SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments": "|**2025-7-9**|**SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments**|Tianshun Li et.al|[paper](https://arxiv.org/abs/2507.06564)|-|-|\n", "Integrated Structural Prompt Learning for Vision-Language Models": "|**2025-7-9**|**Integrated Structural Prompt Learning for Vision-Language Models**|Jiahui Wang et.al|[paper](https://arxiv.org/abs/2507.05677)|-|-|\n", "Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection": "|**2025-7-8**|**Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection**|Yupeng Hu et.al|[paper](https://arxiv.org/abs/2507.06510)|-|<details><summary>detail</summary>ICCV 2025</details>|\n", "Refining Skewed Perceptions in Vision-Language Contrastive Models through Visual Representations": "|**2025-7-8**|**Refining Skewed Perceptions in Vision-Language Contrastive Models through Visual Representations**|Haocheng Dai et.al|[paper](https://arxiv.org/abs/2405.14030)|-|-|\n", "3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds": "|**2025-7-8**|**3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds**|Fan-Yun Sun et.al|[paper](https://arxiv.org/abs/2507.06484)|[code](https://ai.stanford.edu/)|<details><summary>detail</summary>project website: https://ai</details>|\n"}}