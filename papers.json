{"source-free": {"Step-wise Distribution Alignment Guided Style Prompt Tuning for Source-free Cross-domain Few-shot Learning": "|**2025-9-13**|**Step-wise Distribution Alignment Guided Style Prompt Tuning for Source-free Cross-domain Few-shot Learning**|Huali Xu et.al|[paper](https://arxiv.org/abs/2411.10070)|[code](https://github.com/xuhuali-mxj/StepSPT.)|<details><summary>detail</summary>IEEE TPAMI</details>|\n", "Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment": "|**2025-9-12**|**Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment**|Rini Smita Thakur et.al|[paper](https://arxiv.org/abs/2509.10134)|[code](https://visdomlab.github.io/GCL/.)|<details><summary>detail</summary>Accepted in BMVC 2025</details>|\n", "Rethinking the Backbone in Class Imbalanced Federated Source Free Domain Adaptation: The Utility of Vision Foundation Models": "|**2025-9-10**|**Rethinking the Backbone in Class Imbalanced Federated Source Free Domain Adaptation: The Utility of Vision Foundation Models**|Kosuke Kihara et.al|[paper](https://arxiv.org/abs/2509.08372)|-|<details><summary>detail</summary>Accepted by the IEEE ICIP 2025 Satellite Workshop 1: Edge Intelligence: Smart</details>|\n", "StableSleep: Source-Free Test-Time Adaptation for Sleep Staging with Lightweight Safety Rails": "|**2025-9-2**|**StableSleep: Source-Free Test-Time Adaptation for Sleep Staging with Lightweight Safety Rails**|Hritik Arasu et.al|[paper](https://arxiv.org/abs/2509.02982)|-|<details><summary>detail</summary>5 page paper</details>|\n", "Model-Free Hovering and Source Seeking via Extremum Seeking Control: Experimental Demonstration": "|**2025-8-28**|**Model-Free Hovering and Source Seeking via Extremum Seeking Control: Experimental Demonstration**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2508.20836)|-|-|\n", "VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection": "|**2025-8-26**|**VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection**|Jianhong Han et.al|[paper](https://arxiv.org/abs/2508.11167)|-|<details><summary>detail</summary>Manuscript submitted to IEEE TCSVT</details>|\n", "Towards Source-Free Machine Unlearning": "|**2025-8-20**|**Towards Source-Free Machine Unlearning**|Sk Miraj Ahmed et.al|[paper](https://arxiv.org/abs/2508.15127)|-|<details><summary>detail</summary>Accepted by CVPR 2025</details>|\n", "Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method": "|**2025-8-14**|**Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2508.09202)|-|-|\n", "Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation": "|**2025-8-7**|**Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation**|Jianming Liu et.al|[paper](https://arxiv.org/abs/2508.05213)|[code](https://github.com/ljm198134/TVGTANet.)|-|\n", "Model Recycling Framework for Multi-Source Data-Free Supervised Transfer Learning": "|**2025-8-4**|**Model Recycling Framework for Multi-Source Data-Free Supervised Transfer Learning**|Sijia Wang et.al|[paper](https://arxiv.org/abs/2508.02039)|-|-|\n", "Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments": "|**2025-7-30**|**Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2501.02184)|-|-|\n", "Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation": "|**2025-7-28**|**Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation**|Yihong Cao et.al|[paper](https://arxiv.org/abs/2506.21198)|[code](https://github.com/yihong-97/UNLOCK.)|<details><summary>detail</summary>ICCV 2025</details>|\n", "GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning": "|**2025-7-26**|**GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning**|Sanqing Qu et.al|[paper](https://arxiv.org/abs/2403.14410)|[code](https://github.com/ispc-lab/GLC-plus.)|<details><summary>detail</summary>A substantial extension of the CVPR paper \"Upcycling Models under Domain and Category Shift\"</details>|\n", "SFUOD: Source-Free Unknown Object Detection": "|**2025-7-23**|**SFUOD: Source-Free Unknown Object Detection**|Keon-Hee Park et.al|[paper](https://arxiv.org/abs/2507.17373)|-|<details><summary>detail</summary>This paper has been accepted by ICCV 2025</details>|\n", "Text-Driven Causal Representation Learning for Source-Free Domain Generalization": "|**2025-7-14**|**Text-Driven Causal Representation Learning for Source-Free Domain Generalization**|Lihua Zhou et.al|[paper](https://arxiv.org/abs/2507.09961)|-|<details><summary>detail</summary>Under Review</details>|\n"}, "object detection": {"A Novel Compression Framework for YOLOv8: Achiev-ing Real-Time Aerial Object Detection on Edge Devices via Structured Pruning and Channel-Wise Distillation": "|**2025-9-16**|**A Novel Compression Framework for YOLOv8: Achiev-ing Real-Time Aerial Object Detection on Edge Devices via Structured Pruning and Channel-Wise Distillation**|Melika Sabaghian et.al|[paper](https://arxiv.org/abs/2509.12918)|-|-|\n", "Modeling the Multivariate Relationship with Contextualized Representations for Effective Human-Object Interaction Detection": "|**2025-9-16**|**Modeling the Multivariate Relationship with Contextualized Representations for Effective Human-Object Interaction Detection**|Zhehao Li et.al|[paper](https://arxiv.org/abs/2509.12784)|-|-|\n", "SFGNet: Semantic and Frequency Guided Network for Camouflaged Object Detection": "|**2025-9-15**|**SFGNet: Semantic and Frequency Guided Network for Camouflaged Object Detection**|Dezhen Wang et.al|[paper](https://arxiv.org/abs/2509.11539)|[code](https://github.com/winter794444/SFGNetICASSP2026.)|<details><summary>detail</summary>Submitted to ICASSP 2026 by Dezhen Wang et al</details>|\n", "Explicit Multimodal Graph Modeling for Human-Object Interaction Detection": "|**2025-9-15**|**Explicit Multimodal Graph Modeling for Human-Object Interaction Detection**|Wenxuan Ji et.al|[paper](https://arxiv.org/abs/2509.12554)|-|-|\n", "SAM-TTT: Segment Anything Model via Reverse Parameter Configuration and Test-Time Training for Camouflaged Object Detection": "|**2025-9-15**|**SAM-TTT: Segment Anything Model via Reverse Parameter Configuration and Test-Time Training for Camouflaged Object Detection**|Zhenni Yu et.al|[paper](https://arxiv.org/abs/2509.11884)|[code](https://github.com/guobaoxiao/SAM-TTT.)|<details><summary>detail</summary>accepted by ACM MM 25</details>|\n", "HD-OOD3D: Supervised and Unsupervised Out-of-Distribution object detection in LiDAR data": "|**2025-9-15**|**HD-OOD3D: Supervised and Unsupervised Out-of-Distribution object detection in LiDAR data**|Louis Soum-Fontez et.al|[paper](https://arxiv.org/abs/2410.23767)|-|<details><summary>detail</summary>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</details>|\n", "Similarity-based Outlier Detection for Noisy Object Re-Identification Using Beta Mixtures": "|**2025-9-15**|**Similarity-based Outlier Detection for Noisy Object Re-Identification Using Beta Mixtures**|Waqar Ahmad et.al|[paper](https://arxiv.org/abs/2509.08926)|-|-|\n", "First RAG, Second SEG: A Training-Free Paradigm for Camouflaged Object Detection": "|**2025-9-15**|**First RAG, Second SEG: A Training-Free Paradigm for Camouflaged Object Detection**|Wutao Liu et.al|[paper](https://arxiv.org/abs/2508.15313)|[code](https://github.com/Lwt-diamond/RAG-SEG.)|-|\n", "IRDFusion: Iterative Relation-Map Difference guided Feature Fusion for Multispectral Object Detection": "|**2025-9-15**|**IRDFusion: Iterative Relation-Map Difference guided Feature Fusion for Multispectral Object Detection**|Jifeng Shen et.al|[paper](https://arxiv.org/abs/2509.09085)|[code](https://github.com/61s61min/IRDFusion.git.)|-|\n", "DAOcc: 3D Object Detection Assisted Multi-Sensor Fusion for 3D Occupancy Prediction": "|**2025-9-14**|**DAOcc: 3D Object Detection Assisted Multi-Sensor Fusion for 3D Occupancy Prediction**|Zhen Yang et.al|[paper](https://arxiv.org/abs/2409.19972)|[code](https://github.com/AlphaPlusTT/DAOcc.)|<details><summary>detail</summary>TCSVT Accepted version (not the final published version)</details>|\n", "Group Evidence Matters: Tiling-based Semantic Gating for Dense Object Detection": "|**2025-9-12**|**Group Evidence Matters: Tiling-based Semantic Gating for Dense Object Detection**|Yilun Xiao et.al|[paper](https://arxiv.org/abs/2509.10779)|-|-|\n", "HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection": "|**2025-9-11**|**HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection**|Harris Song et.al|[paper](https://arxiv.org/abs/2508.21135)|-|<details><summary>detail</summary>fix typos</details>|\n", "A Co-Training Semi-Supervised Framework Using Faster R-CNN and YOLO Networks for Object Detection in Densely Packed Retail Images": "|**2025-9-11**|**A Co-Training Semi-Supervised Framework Using Faster R-CNN and YOLO Networks for Object Detection in Densely Packed Retail Images**|Hossein Yazdanjouei et.al|[paper](https://arxiv.org/abs/2509.09750)|-|-|\n", "Model-Agnostic Open-Set Air-to-Air Visual Object Detection for Reliable UAV Perception": "|**2025-9-11**|**Model-Agnostic Open-Set Air-to-Air Visual Object Detection for Reliable UAV Perception**|Spyridon Loukovitis et.al|[paper](https://arxiv.org/abs/2509.09297)|-|-|\n", "Dark-ISP: Enhancing RAW Image Processing for Low-Light Object Detection": "|**2025-9-11**|**Dark-ISP: Enhancing RAW Image Processing for Low-Light Object Detection**|Jiasheng Guo et.al|[paper](https://arxiv.org/abs/2509.09183)|-|-|\n"}, "domain adaptation": {"Improving Anomalous Sound Detection with Attribute-aware Representation from Domain-adaptive Pre-training": "|**2025-9-16**|**Improving Anomalous Sound Detection with Attribute-aware Representation from Domain-adaptive Pre-training**|Xin Fang et.al|[paper](https://arxiv.org/abs/2509.12845)|-|-|\n", "Domain-Adaptive Pretraining Improves Primate Behavior Recognition": "|**2025-9-15**|**Domain-Adaptive Pretraining Improves Primate Behavior Recognition**|Felix B. Mueller et.al|[paper](https://arxiv.org/abs/2509.12193)|[code](https://github.com/ecker-lab/dap-behavior)|<details><summary>detail</summary>Oral at the CVPR 2025 Workshop CV4Animals</details>|\n", "FedDAF: Federated Domain Adaptation Using Model Functional Distance": "|**2025-9-15**|**FedDAF: Federated Domain Adaptation Using Model Functional Distance**|Mrinmay Sen et.al|[paper](https://arxiv.org/abs/2509.11819)|-|-|\n", "Cross-Domain Attribute Alignment with CLIP: A Rehearsal-Free Approach for Class-Incremental Unsupervised Domain Adaptation": "|**2025-9-14**|**Cross-Domain Attribute Alignment with CLIP: A Rehearsal-Free Approach for Class-Incremental Unsupervised Domain Adaptation**|Kerun Mi et.al|[paper](https://arxiv.org/abs/2509.11264)|[code](https://github.com/RyunMi/VisTA.)|<details><summary>detail</summary>ACM MM 2025</details>|\n", "Domain Adaptive SAR Wake Detection: Leveraging Similarity Filtering and Memory Guidance": "|**2025-9-14**|**Domain Adaptive SAR Wake Detection: Leveraging Similarity Filtering and Memory Guidance**|He Gao et.al|[paper](https://arxiv.org/abs/2509.12279)|-|-|\n", "Automated MCQA Benchmarking at Scale: Evaluating Reasoning Traces as Retrieval Sources for Domain Adaptation of Small Language Models": "|**2025-9-12**|**Automated MCQA Benchmarking at Scale: Evaluating Reasoning Traces as Retrieval Sources for Domain Adaptation of Small Language Models**|Ozan Gokdemir et.al|[paper](https://arxiv.org/abs/2509.10744)|-|<details><summary>detail</summary>This manuscript has been accepted for publication at the Supercomputing 25 (SC '25) Conference (Frontiers in Generative AI for HPC Science and Engineering: Foundations</details>|\n", "SearchInstruct: Enhancing Domain Adaptation via Retrieval-Based Instruction Dataset Creation": "|**2025-9-12**|**SearchInstruct: Enhancing Domain Adaptation via Retrieval-Based Instruction Dataset Creation**|Iman Barati et.al|[paper](https://arxiv.org/abs/2509.10708)|[code](https://github.com/mostafaamiri/SearchInstruct](https://github.com/mostafaamiri/SearchInstruct))|-|\n", "WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers": "|**2025-9-12**|**WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers**|Akshat Pandey et.al|[paper](https://arxiv.org/abs/2509.10452)|-|-|\n", "Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment": "|**2025-9-12**|**Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment**|Rini Smita Thakur et.al|[paper](https://arxiv.org/abs/2509.10134)|[code](https://visdomlab.github.io/GCL/.)|<details><summary>detail</summary>Accepted in BMVC 2025</details>|\n", "FetalSleepNet: A Transfer Learning Framework with Spectral Equalisation Domain Adaptation for Fetal Sleep Stage Classification": "|**2025-9-12**|**FetalSleepNet: A Transfer Learning Framework with Spectral Equalisation Domain Adaptation for Fetal Sleep Stage Classification**|Weitao Tang et.al|[paper](https://arxiv.org/abs/2509.10082)|-|-|\n", "SCoDA: Self-supervised Continual Domain Adaptation": "|**2025-9-11**|**SCoDA: Self-supervised Continual Domain Adaptation**|Chirayu Agrawal et.al|[paper](https://arxiv.org/abs/2509.09935)|-|<details><summary>detail</summary>Submitted to ICVGIP 2025</details>|\n", "Towards Adaptive ML Benchmarks: Web-Agent-Driven Construction, Domain Expansion, and Metric Optimization": "|**2025-9-11**|**Towards Adaptive ML Benchmarks: Web-Agent-Driven Construction, Domain Expansion, and Metric Optimization**|Hangyi Jia et.al|[paper](https://arxiv.org/abs/2509.09321)|-|-|\n", "E-MLNet: Enhanced Mutual Learning for Universal Domain Adaptation with Sample-Specific Weighting": "|**2025-9-10**|**E-MLNet: Enhanced Mutual Learning for Universal Domain Adaptation with Sample-Specific Weighting**|Samuel Felipe dos Santos et.al|[paper](https://arxiv.org/abs/2509.09006)|-|<details><summary>detail</summary>Journal ref:38th SIBGRAPI - Conference on Graphics</details>|\n", "Rethinking the Backbone in Class Imbalanced Federated Source Free Domain Adaptation: The Utility of Vision Foundation Models": "|**2025-9-10**|**Rethinking the Backbone in Class Imbalanced Federated Source Free Domain Adaptation: The Utility of Vision Foundation Models**|Kosuke Kihara et.al|[paper](https://arxiv.org/abs/2509.08372)|-|<details><summary>detail</summary>Accepted by the IEEE ICIP 2025 Satellite Workshop 1: Edge Intelligence: Smart</details>|\n", "GTA-Crime: A Synthetic Dataset and Generation Framework for Fatal Violence Detection with Adversarial Snippet-Level Domain Adaptation": "|**2025-9-9**|**GTA-Crime: A Synthetic Dataset and Generation Framework for Fatal Violence Detection with Adversarial Snippet-Level Domain Adaptation**|Seongho Kim et.al|[paper](https://arxiv.org/abs/2509.08232)|[code](https://github.com/ta-ho/GTA-Crime.)|-|\n"}, "domain generalization": {"Double Helix Diffusion for Cross-Domain Anomaly Image Generation": "|**2025-9-16**|**Double Helix Diffusion for Cross-Domain Anomaly Image Generation**|Linchun Wu et.al|[paper](https://arxiv.org/abs/2509.12787)|-|-|\n", "Speak-to-Structure: Evaluating LLMs in Open-domain Natural Language-Driven Molecule Generation": "|**2025-9-15**|**Speak-to-Structure: Evaluating LLMs in Open-domain Natural Language-Driven Molecule Generation**|Jiatong Li et.al|[paper](https://arxiv.org/abs/2412.14642)|[code](https://github.com/phenixace/TOMG-Bench)|<details><summary>detail</summary>Our codes and datasets are available through https://github</details>|\n", "AI-Generated Content in Cross-Domain Applications: Research Trends, Challenges and Propositions": "|**2025-9-14**|**AI-Generated Content in Cross-Domain Applications: Research Trends, Challenges and Propositions**|Jianxin Li et.al|[paper](https://arxiv.org/abs/2509.11151)|-|-|\n", "Local Density-Based Anomaly Score Normalization for Domain Generalization": "|**2025-9-13**|**Local Density-Based Anomaly Score Normalization for Domain Generalization**|Kevin Wilkinghoff et.al|[paper](https://arxiv.org/abs/2509.10951)|-|-|\n", "When and How Does CLIP Enable Domain and Compositional Generalization?": "|**2025-9-12**|**When and How Does CLIP Enable Domain and Compositional Generalization?**|Elias Kempf et.al|[paper](https://arxiv.org/abs/2502.09507)|-|<details><summary>detail</summary>ICML 2025 (Spotlight)</details>|\n", "GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method": "|**2025-9-12**|**GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method**|Hailong Yang et.al|[paper](https://arxiv.org/abs/2509.10018)|-|-|\n", "Diffusion-Based Action Recognition Generalizes to Untrained Domains": "|**2025-9-10**|**Diffusion-Based Action Recognition Generalizes to Untrained Domains**|Rogerio Guimaraes et.al|[paper](https://arxiv.org/abs/2509.08908)|[code](https://www.vision.caltech.edu/actiondiff/)|-|\n", "GTA-Crime: A Synthetic Dataset and Generation Framework for Fatal Violence Detection with Adversarial Snippet-Level Domain Adaptation": "|**2025-9-9**|**GTA-Crime: A Synthetic Dataset and Generation Framework for Fatal Violence Detection with Adversarial Snippet-Level Domain Adaptation**|Seongho Kim et.al|[paper](https://arxiv.org/abs/2509.08232)|[code](https://github.com/ta-ho/GTA-Crime.)|-|\n", "One View, Many Worlds: Single-Image to 3D Object Meets Generative Domain Randomization for One-Shot 6D Pose Estimation": "|**2025-9-9**|**One View, Many Worlds: Single-Image to 3D Object Meets Generative Domain Randomization for One-Shot 6D Pose Estimation**|Zheng Geng et.al|[paper](https://arxiv.org/abs/2509.07978)|[code](https://gzwsama.github.io/OnePoseviaGen.github.io/)|<details><summary>detail</summary>CoRL 2025 Oral</details>|\n", "Process-Supervised Reward Models for Verifying Clinical Note Generation: A Scalable Approach Guided by Domain Expertise": "|**2025-9-8**|**Process-Supervised Reward Models for Verifying Clinical Note Generation: A Scalable Approach Guided by Domain Expertise**|Hanyin Wang et.al|[paper](https://arxiv.org/abs/2412.12583)|-|-|\n", "Contrastive Anatomy-Contrast Disentanglement: A Domain-General MRI Harmonization Method": "|**2025-9-8**|**Contrastive Anatomy-Contrast Disentanglement: A Domain-General MRI Harmonization Method**|Daniel Scholz et.al|[paper](https://arxiv.org/abs/2509.06592)|-|-|\n", "ConstStyle: Robust Domain Generalization with Unified Style Transformation": "|**2025-9-7**|**ConstStyle: Robust Domain Generalization with Unified Style Transformation**|Nam Duong Tran et.al|[paper](https://arxiv.org/abs/2509.05975)|-|<details><summary>detail</summary>ICCV 2025</details>|\n", "Evaluating the Robustness of Retrieval-Augmented Generation to Adversarial Evidence in the Health Domain": "|**2025-9-3**|**Evaluating the Robustness of Retrieval-Augmented Generation to Adversarial Evidence in the Health Domain**|Shakiba Amirshahi et.al|[paper](https://arxiv.org/abs/2509.03787)|[code](https://github.com/shakibaam/RAG_ROBUSTNESS_EVAL)|-|\n", "Single Domain Generalization in Diabetic Retinopathy: A Neuro-Symbolic Learning Approach": "|**2025-9-2**|**Single Domain Generalization in Diabetic Retinopathy: A Neuro-Symbolic Learning Approach**|Midhat Urooj et.al|[paper](https://arxiv.org/abs/2509.02918)|-|<details><summary>detail</summary>Accepted in ANSyA 2025: 1st International Workshop on Advanced Neuro-Symbolic Applications</details>|\n", "SynthGenNet: a self-supervised approach for test-time generalization using synthetic multi-source domain mixing of street view images": "|**2025-9-2**|**SynthGenNet: a self-supervised approach for test-time generalization using synthetic multi-source domain mixing of street view images**|Pushpendra Dhakara et.al|[paper](https://arxiv.org/abs/2509.02287)|-|-|\n"}, "vision language": {"3D Aware Region Prompted Vision Language Model": "|**2025-9-16**|**3D Aware Region Prompted Vision Language Model**|An-Chieh Cheng et.al|[paper](https://arxiv.org/abs/2509.13317)|[code](https://www.anjiecheng.me/sr3d)|<details><summary>detail</summary>Project Website: https://www</details>|\n", "More performant and scalable: Rethinking contrastive vision-language pre-training of radiology in the LLM era": "|**2025-9-16**|**More performant and scalable: Rethinking contrastive vision-language pre-training of radiology in the LLM era**|Yingtai Li et.al|[paper](https://arxiv.org/abs/2509.13175)|[code](https://github.com/SadVoxel/More-performant-and-scalable.)|<details><summary>detail</summary>MICCAI 2025</details>|\n", "Evaluating the Robustness of Open-Source Vision-Language Models to Domain Shift in Object Captioning": "|**2025-9-16**|**Evaluating the Robustness of Open-Source Vision-Language Models to Domain Shift in Object Captioning**|Federico Tavella et.al|[paper](https://arxiv.org/abs/2506.19579)|-|-|\n", "HERO: Rethinking Visual Token Early Dropping in High-Resolution Large Vision-Language Models": "|**2025-9-16**|**HERO: Rethinking Visual Token Early Dropping in High-Resolution Large Vision-Language Models**|Xu Li et.al|[paper](https://arxiv.org/abs/2509.13067)|-|-|\n", "Perception Before Reasoning: Two-Stage Reinforcement Learning for Visual Reasoning in Vision-Language Models": "|**2025-9-16**|**Perception Before Reasoning: Two-Stage Reinforcement Learning for Visual Reasoning in Vision-Language Models**|Yan Chen et.al|[paper](https://arxiv.org/abs/2509.13031)|-|-|\n", "Talking to DINO: Bridging Self-Supervised Vision Backbones with Language for Open-Vocabulary Segmentation": "|**2025-9-16**|**Talking to DINO: Bridging Self-Supervised Vision Backbones with Language for Open-Vocabulary Segmentation**|Luca Barsellotti et.al|[paper](https://arxiv.org/abs/2411.19331)|[code](https://lorebianchi98.github.io/Talk2DINO/.)|<details><summary>detail</summary>ICCV 2025</details>|\n", "Cross-Layer Vision Smoothing: Enhancing Visual Understanding via Sustained Focus on Key Objects in Large Vision-Language Models": "|**2025-9-16**|**Cross-Layer Vision Smoothing: Enhancing Visual Understanding via Sustained Focus on Key Objects in Large Vision-Language Models**|Jianfei Zhao et.al|[paper](https://arxiv.org/abs/2509.12897)|-|-|\n", "Cross-Image Contrastive Decoding: Precise, Lossless Suppression of Language Priors in Large Vision-Language Models": "|**2025-9-16**|**Cross-Image Contrastive Decoding: Precise, Lossless Suppression of Language Priors in Large Vision-Language Models**|Jianfei Zhao et.al|[paper](https://arxiv.org/abs/2505.10634)|-|<details><summary>detail</summary>Under Review</details>|\n", "Adversarial Prompt Distillation for Vision-Language Models": "|**2025-9-16**|**Adversarial Prompt Distillation for Vision-Language Models**|Lin Luo et.al|[paper](https://arxiv.org/abs/2411.15244)|-|<details><summary>detail</summary>This work has been submitted to the IEEE for possible publication</details>|\n", "Can Generalist Vision Language Models (VLMs) Rival Specialist Medical VLMs? Benchmarking and Strategic Insights": "|**2025-9-16**|**Can Generalist Vision Language Models (VLMs) Rival Specialist Medical VLMs? Benchmarking and Strategic Insights**|Yuan Zhong et.al|[paper](https://arxiv.org/abs/2506.17337)|-|<details><summary>detail</summary>version 2</details>|\n", "Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions": "|**2025-9-16**|**Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions**|Pu Jian et.al|[paper](https://arxiv.org/abs/2507.13773)|-|<details><summary>detail</summary>ACL2025 Main (SAC Highlight Award)</details>|\n", "Defense-to-Attack: Bypassing Weak Defenses Enables Stronger Jailbreaks in Vision-Language Models": "|**2025-9-16**|**Defense-to-Attack: Bypassing Weak Defenses Enables Stronger Jailbreaks in Vision-Language Models**|Yunhan Zhao et.al|[paper](https://arxiv.org/abs/2509.12724)|-|<details><summary>detail</summary>This work has been submitted to the IEEE for possible publication</details>|\n", "AsyMoE: Leveraging Modal Asymmetry for Enhanced Expert Specialization in Large Vision-Language Models": "|**2025-9-16**|**AsyMoE: Leveraging Modal Asymmetry for Enhanced Expert Specialization in Large Vision-Language Models**|Heng Zhang et.al|[paper](https://arxiv.org/abs/2509.12715)|-|-|\n", "ActiveVLN: Towards Active Exploration via Multi-Turn RL in Vision-and-Language Navigation": "|**2025-9-15**|**ActiveVLN: Towards Active Exploration via Multi-Turn RL in Vision-and-Language Navigation**|Zekai Zhang et.al|[paper](https://arxiv.org/abs/2509.12618)|-|-|\n", "The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning": "|**2025-9-15**|**The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning**|Titong Jiang et.al|[paper](https://arxiv.org/abs/2509.12594)|[code](https://liauto-research.github.io/LightVLA)|<details><summary>detail</summary>Under review</details>|\n"}}