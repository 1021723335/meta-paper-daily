{"source-free": {"Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping": "|**2025-11-5**|**Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping**|Zhihang Qin et.al|[paper](https://arxiv.org/abs/2511.03691)|-|-|\n", "Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results": "|**2025-11-1**|**Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results**|Rohan Palanikumar et.al|[paper](https://arxiv.org/abs/2511.00752)|-|-|\n", "Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising": "|**2025-10-31**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|\n", "Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation": "|**2025-10-29**|**Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation**|Yuyang Huang et.al|[paper](https://arxiv.org/abs/2510.25279)|-|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|\n", "Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation": "|**2025-10-29**|**Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation**|Quang-Khai Bui-Tran et.al|[paper](https://arxiv.org/abs/2510.25227)|-|-|\n", "Training-free Source Attribution of AI-generated Images via Resynthesis": "|**2025-10-28**|**Training-free Source Attribution of AI-generated Images via Resynthesis**|Pietro Bongini et.al|[paper](https://arxiv.org/abs/2510.24278)|-|-|\n", "Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation": "|**2025-10-24**|**Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.22142)|-|-|\n", "Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces": "|**2025-10-22**|**Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces**|Osman Berke Guney et.al|[paper](https://arxiv.org/abs/2305.17403)|[code](https://github.com/osmanberke/SFDA-SSVEP-BCI)|-|\n", "Source-Free Object Detection with Detection Transformer": "|**2025-10-13**|**Source-Free Object Detection with Detection Transformer**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2510.11090)|-|<details><summary>detail</summary>IEEE Transactions on Image Processing</details>|\n", "Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning": "|**2025-10-9**|**Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning**|Ziqi Zhang et.al|[paper](https://arxiv.org/abs/2510.08393)|-|-|\n", "ESS-Flow: Training-free guidance of flow-based models as inference in source space": "|**2025-10-7**|**ESS-Flow: Training-free guidance of flow-based models as inference in source space**|Adhithyan Kalaivanan et.al|[paper](https://arxiv.org/abs/2510.05849)|-|-|\n", "A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation": "|**2025-10-6**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|\n", "Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection": "|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|\n", "Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation": "|**2025-10-3**|**Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation**|Yucheng Wang et.al|[paper](https://arxiv.org/abs/2409.19635)|-|-|\n", "OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation": "|**2025-10-2**|**OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation**|Yiming Zhang et.al|[paper](https://arxiv.org/abs/2505.11669)|-|-|\n"}, "object detection": {"Evaluating the Impact of Weather-Induced Sensor Occlusion on BEVFusion for 3D Object Detection": "|**2025-11-6**|**Evaluating the Impact of Weather-Induced Sensor Occlusion on BEVFusion for 3D Object Detection**|Sanjay Kumar et.al|[paper](https://arxiv.org/abs/2511.04347)|-|-|\n", "Deep learning-based object detection of offshore platforms on Sentinel-1 Imagery and the impact of synthetic training data": "|**2025-11-6**|**Deep learning-based object detection of offshore platforms on Sentinel-1 Imagery and the impact of synthetic training data**|Robin Spanier et.al|[paper](https://arxiv.org/abs/2511.04304)|-|-|\n", "RIS-Assisted 3D Spherical Splatting for Object Composition Visualization using Detection Transformers": "|**2025-11-5**|**RIS-Assisted 3D Spherical Splatting for Object Composition Visualization using Detection Transformers**|Anastasios T. Sotiropoulos et.al|[paper](https://arxiv.org/abs/2511.02573)|-|<details><summary>detail</summary>Submitted to IEEE ICC 2026</details>|\n", "ISC-Perception: A Hybrid Computer Vision Dataset for Object Detection in Novel Steel Assembly": "|**2025-11-4**|**ISC-Perception: A Hybrid Computer Vision Dataset for Object Detection in Novel Steel Assembly**|Miftahur Rahman et.al|[paper](https://arxiv.org/abs/2511.03098)|-|-|\n", "Object Detection as an Optional Basis: A Graph Matching Network for Cross-View UAV Localization": "|**2025-11-4**|**Object Detection as an Optional Basis: A Graph Matching Network for Cross-View UAV Localization**|Tao Liu et.al|[paper](https://arxiv.org/abs/2511.02489)|[code](https://github.com/liutao23/ODGNNLoc.git.)|-|\n", "Deep Fourier-embedded Network for RGB and Thermal Salient Object Detection": "|**2025-11-4**|**Deep Fourier-embedded Network for RGB and Thermal Salient Object Detection**|Pengfei Lyu et.al|[paper](https://arxiv.org/abs/2411.18409)|[code](https://github.com/JoshuaLPF/FreqSal.)|<details><summary>detail</summary>Accepted by TCSVT2025</details>|\n", "3D Point Cloud Object Detection on Edge Devices for Split Computing": "|**2025-11-4**|**3D Point Cloud Object Detection on Edge Devices for Split Computing**|Taisuke Noguchi et.al|[paper](https://arxiv.org/abs/2511.02293)|-|-|\n", "Parameterized Prompt for Incremental Object Detection": "|**2025-11-4**|**Parameterized Prompt for Incremental Object Detection**|Zijia An et.al|[paper](https://arxiv.org/abs/2510.27316)|-|-|\n", "Detection and Geographic Localization of Natural Objects in the Wild: A Case Study on Palms": "|**2025-11-3**|**Detection and Geographic Localization of Natural Objects in the Wild: A Case Study on Palms**|Kangning Cui et.al|[paper](https://arxiv.org/abs/2502.13023)|-|-|\n", "WXSOD: A Benchmark for Robust Salient Object Detection in Adverse Weather Conditions": "|**2025-11-3**|**WXSOD: A Benchmark for Robust Salient Object Detection in Adverse Weather Conditions**|Quan Chen et.al|[paper](https://arxiv.org/abs/2508.12250)|[code](https://github.com/C-water/WXSOD)|<details><summary>detail</summary>Under review</details>|\n", "FlexEvent: Towards Flexible Event-Frame Object Detection at Varying Operational Frequencies": "|**2025-11-3**|**FlexEvent: Towards Flexible Event-Frame Object Detection at Varying Operational Frequencies**|Dongyue Lu et.al|[paper](https://arxiv.org/abs/2412.06708)|[code](https://flexevent.github.io/)|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "Contrast-Guided Cross-Modal Distillation for Thermal Object Detection": "|**2025-11-3**|**Contrast-Guided Cross-Modal Distillation for Thermal Object Detection**|SiWoo Kim et.al|[paper](https://arxiv.org/abs/2511.01435)|-|-|\n", "DTAA: A Detect, Track and Avoid Architecture for navigation in spaces with Multiple Velocity Objects": "|**2025-11-3**|**DTAA: A Detect, Track and Avoid Architecture for navigation in spaces with Multiple Velocity Objects**|Samuel Nordstr\u00f6m et.al|[paper](https://arxiv.org/abs/2412.08121)|-|-|\n", "Eyes on Target: Gaze-Aware Object Detection in Egocentric Video": "|**2025-11-3**|**Eyes on Target: Gaze-Aware Object Detection in Egocentric Video**|Vishakha Lall et.al|[paper](https://arxiv.org/abs/2511.01237)|-|<details><summary>detail</summary>RAAI 2025</details>|\n", "Reflectance Prediction-based Knowledge Distillation for Robust 3D Object Detection in Compressed Point Clouds": "|**2025-11-2**|**Reflectance Prediction-based Knowledge Distillation for Robust 3D Object Detection in Compressed Point Clouds**|Hao Jing et.al|[paper](https://arxiv.org/abs/2505.17442)|[code](https://github.com/HaoJing-SX/RPKD.)|-|\n"}, "domain adaptation": {"Vision Foundation Models in Agriculture: Toward Domain-Specific Adaptation for Weed Herbicide Trials Assessment": "|**2025-11-6**|**Vision Foundation Models in Agriculture: Toward Domain-Specific Adaptation for Weed Herbicide Trials Assessment**|Leire Benito-Del-Valle et.al|[paper](https://arxiv.org/abs/2511.04288)|-|-|\n", "Active Domain Adaptation for mmWave-based HAR via Renyi Entropy-based Uncertainty Estimation": "|**2025-11-6**|**Active Domain Adaptation for mmWave-based HAR via Renyi Entropy-based Uncertainty Estimation**|Mingzhi Lin et.al|[paper](https://arxiv.org/abs/2511.04219)|-|-|\n", "Domain-Adaptive Transformer for Data-Efficient Glioma Segmentation in Sub-Saharan MRI": "|**2025-11-4**|**Domain-Adaptive Transformer for Data-Efficient Glioma Segmentation in Sub-Saharan MRI**|Ilerioluwakiiye Abolade et.al|[paper](https://arxiv.org/abs/2511.02928)|-|-|\n", "Domain adaptation of large language models for geotechnical applications": "|**2025-11-3**|**Domain adaptation of large language models for geotechnical applications**|Lei Fan et.al|[paper](https://arxiv.org/abs/2507.05613)|-|-|\n", "AraFinNews: Arabic Financial Summarisation with Domain-Adapted LLMs": "|**2025-11-3**|**AraFinNews: Arabic Financial Summarisation with Domain-Adapted LLMs**|Mo El-Haj et.al|[paper](https://arxiv.org/abs/2511.01265)|[code](https://github.com/ArabicNLP-UK/AraFinNews.)|-|\n", "Saliency-Guided Domain Adaptation for Left-Hand Driving in Autonomous Steering": "|**2025-11-2**|**Saliency-Guided Domain Adaptation for Left-Hand Driving in Autonomous Steering**|Zahra Mehraban et.al|[paper](https://arxiv.org/abs/2511.01223)|-|-|\n", "Adapt under Attack and Domain Shift: Unified Adversarial Meta-Learning and Domain Adaptation for Robust Automatic Modulation Classification": "|**2025-11-2**|**Adapt under Attack and Domain Shift: Unified Adversarial Meta-Learning and Domain Adaptation for Robust Automatic Modulation Classification**|Ali Owfi et.al|[paper](https://arxiv.org/abs/2511.01172)|-|-|\n", "Data-Efficient Domain Adaptation for LLM-based MT using Contrastive Preference Optimization": "|**2025-10-31**|**Data-Efficient Domain Adaptation for LLM-based MT using Contrastive Preference Optimization**|Inacio Vieira et.al|[paper](https://arxiv.org/abs/2510.27556)|-|-|\n", "Multilingual BERT language model for medical tasks: Evaluation on domain-specific adaptation and cross-linguality": "|**2025-10-31**|**Multilingual BERT language model for medical tasks: Evaluation on domain-specific adaptation and cross-linguality**|Yinghao Luo et.al|[paper](https://arxiv.org/abs/2510.27552)|-|-|\n", "On the Theory of Conditional Feature Alignment for Unsupervised Domain-Adaptive Counting": "|**2025-10-30**|**On the Theory of Conditional Feature Alignment for Unsupervised Domain-Adaptive Counting**|Zhuonan Liang et.al|[paper](https://arxiv.org/abs/2506.17137)|-|-|\n", "PF-DAformer: Proximal Femur Segmentation via Domain Adaptive Transformer for Dual-Center QCT": "|**2025-10-30**|**PF-DAformer: Proximal Femur Segmentation via Domain Adaptive Transformer for Dual-Center QCT**|Rochak Dhakal et.al|[paper](https://arxiv.org/abs/2510.26903)|-|<details><summary>detail</summary>22 Pages</details>|\n", "Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems": "|**2025-10-30**|**Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems**|Georgios Kamaras et.al|[paper](https://arxiv.org/abs/2510.26656)|-|-|\n", "CATCH: A Modular Cross-domain Adaptive Template with Hook": "|**2025-10-30**|**CATCH: A Modular Cross-domain Adaptive Template with Hook**|Xinjin Li et.al|[paper](https://arxiv.org/abs/2510.26582)|-|-|\n", "Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation": "|**2025-10-29**|**Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation**|Yuyang Huang et.al|[paper](https://arxiv.org/abs/2510.25279)|-|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|\n", "Adapting Small Language Models to Low-Resource Domains: A Case Study in Hindi Tourism QA": "|**2025-10-29**|**Adapting Small Language Models to Low-Resource Domains: A Case Study in Hindi Tourism QA**|Sandipan Majhi et.al|[paper](https://arxiv.org/abs/2510.25273)|-|<details><summary>detail</summary>the Forum for Information Retrieval Evaluation 2025 (VATIKA Track)</details>|\n"}, "domain generalization": {"GNN-MoE: Context-Aware Patch Routing using GNNs for Parameter-Efficient Domain Generalization": "|**2025-11-5**|**GNN-MoE: Context-Aware Patch Routing using GNNs for Parameter-Efficient Domain Generalization**|Mahmoud Soliman et.al|[paper](https://arxiv.org/abs/2511.04008)|-|-|\n", "Retrieval-Augmented Feature Generation for Domain-Specific Classification": "|**2025-11-4**|**Retrieval-Augmented Feature Generation for Domain-Specific Classification**|Xinhao Zhang et.al|[paper](https://arxiv.org/abs/2406.11177)|-|<details><summary>detail</summary>Accepted by ICDM 2025</details>|\n", "ORANGE: An Online Reflection ANd GEneration framework with Domain Knowledge for Text-to-SQL": "|**2025-11-4**|**ORANGE: An Online Reflection ANd GEneration framework with Domain Knowledge for Text-to-SQL**|Yiwen Jiao et.al|[paper](https://arxiv.org/abs/2511.00985)|-|-|\n", "Wonder3D++: Cross-domain Diffusion for High-fidelity 3D Generation from a Single Image": "|**2025-11-3**|**Wonder3D++: Cross-domain Diffusion for High-fidelity 3D Generation from a Single Image**|Yuxiao Yang et.al|[paper](https://arxiv.org/abs/2511.01767)|[code](https://github.com/xxlong0/Wonder3D/tree/Wonder3D_Plus.)|-|\n", "OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting": "|**2025-11-2**|**OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting**|Tingyue Pan et.al|[paper](https://arxiv.org/abs/2510.24028)|-|-|\n", "SynthTextEval: Synthetic Text Data Generation and Evaluation for High-Stakes Domains": "|**2025-11-2**|**SynthTextEval: Synthetic Text Data Generation and Evaluation for High-Stakes Domains**|Krithika Ramesh et.al|[paper](https://arxiv.org/abs/2507.07229)|-|<details><summary>detail</summary>EMNLP 2025 System Demonstration</details>|\n", "Generalized Category Discovery under Domain Shift: A Frequency Domain Perspective": "|**2025-11-1**|**Generalized Category Discovery under Domain Shift: A Frequency Domain Perspective**|Wei Feng et.al|[paper](https://arxiv.org/abs/2511.00573)|-|-|\n", "Robust Atypical Mitosis Classification with DenseNet121: Stain-Aware Augmentation and Hybrid Loss for Domain Generalization": "|**2025-11-1**|**Robust Atypical Mitosis Classification with DenseNet121: Stain-Aware Augmentation and Hybrid Loss for Domain Generalization**|Adinath Dukre et.al|[paper](https://arxiv.org/abs/2510.22630)|-|<details><summary>detail</summary>MIDOG 2025 MICCAI Workshop accepted</details>|\n", "Effect of Domain Generalization Techniques in Low Resource Systems": "|**2025-10-31**|**Effect of Domain Generalization Techniques in Low Resource Systems**|Mahi Aminu et.al|[paper](https://arxiv.org/abs/2510.27512)|-|-|\n", "Continuous Domain Generalization": "|**2025-10-29**|**Continuous Domain Generalization**|Zekun Cai et.al|[paper](https://arxiv.org/abs/2505.13519)|-|-|\n", "Zero Reinforcement Learning Towards General Domains": "|**2025-10-29**|**Zero Reinforcement Learning Towards General Domains**|Yuyuan Zeng et.al|[paper](https://arxiv.org/abs/2510.25528)|-|-|\n", "Retaining Mixture Representations for Domain Generalized Anomalous Sound Detection": "|**2025-10-29**|**Retaining Mixture Representations for Domain Generalized Anomalous Sound Detection**|Phurich Saengthong et.al|[paper](https://arxiv.org/abs/2510.25182)|-|<details><summary>detail</summary>Submitted to ICASSP 2026</details>|\n", "A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation": "|**2025-10-28**|**A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation**|Hao-Ran Yang et.al|[paper](https://arxiv.org/abs/2505.13043)|-|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "Model-Guided Dual-Role Alignment for High-Fidelity Open-Domain Video-to-Audio Generation": "|**2025-10-28**|**Model-Guided Dual-Role Alignment for High-Fidelity Open-Domain Video-to-Audio Generation**|Kang Zhang et.al|[paper](https://arxiv.org/abs/2510.24103)|[code](https://github.com/pantheon5100/mgaudio)|<details><summary>detail</summary>accepted by NeurIPS 2025</details>|\n", "AdvBlur: Adversarial Blur for Robust Diabetic Retinopathy Classification and Cross-Domain Generalization": "|**2025-10-27**|**AdvBlur: Adversarial Blur for Robust Diabetic Retinopathy Classification and Cross-Domain Generalization**|Heethanjan Kanagalingam et.al|[paper](https://arxiv.org/abs/2510.24000)|-|-|\n"}, "vision language": {"Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment": "|**2025-11-6**|**Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment**|Tao Lin et.al|[paper](https://arxiv.org/abs/2511.04555)|[code](https://github.com/MINT-SJTU/Evo-1)|<details><summary>detail</summary>Github: https://github</details>|\n", "ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding in Thai": "|**2025-11-6**|**ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding in Thai**|Surapon Nonesung et.al|[paper](https://arxiv.org/abs/2511.04479)|-|<details><summary>detail</summary>the IJCNLP-AACL 2025 (Main)</details>|\n", "HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model": "|**2025-11-6**|**HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model**|Youngwan Lee et.al|[paper](https://arxiv.org/abs/2506.04704)|[code](https://youngwanlee.github.io/holisafe)|<details><summary>detail</summary>Project page: https://youngwanlee</details>|\n", "TowerVision: Understanding and Improving Multilinguality in Vision-Language Models": "|**2025-11-6**|**TowerVision: Understanding and Improving Multilinguality in Vision-Language Models**|Andr\u00e9 G. Viveiros et.al|[paper](https://arxiv.org/abs/2510.21849)|[code](https://huggingface.co/collections/utter-project/towervision)|-|\n", "SafeVLA: Towards Safety Alignment of Vision-Language-Action Model via Constrained Learning": "|**2025-11-6**|**SafeVLA: Towards Safety Alignment of Vision-Language-Action Model via Constrained Learning**|Borong Zhang et.al|[paper](https://arxiv.org/abs/2503.03480)|[code](https://pku-safevla.github.io.)|<details><summary>detail</summary>Accepted by NeurIPS 2025 Spotlight Presentation</details>|\n", "RadZero: Similarity-Based Cross-Attention for Explainable Vision-Language Alignment in Chest X-ray with Zero-Shot Multi-Task Capability": "|**2025-11-6**|**RadZero: Similarity-Based Cross-Attention for Explainable Vision-Language Alignment in Chest X-ray with Zero-Shot Multi-Task Capability**|Jonggwon Park et.al|[paper](https://arxiv.org/abs/2504.07416)|[code](https://github.com/deepnoid-ai/RadZero)|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "Unveiling Deep Semantic Uncertainty Perception for Language-Anchored Multi-modal Vision-Brain Alignment": "|**2025-11-6**|**Unveiling Deep Semantic Uncertainty Perception for Language-Anchored Multi-modal Vision-Brain Alignment**|Zehui Feng et.al|[paper](https://arxiv.org/abs/2511.04078)|-|-|\n", "Poutine: Vision-Language-Trajectory Pre-Training and Reinforcement Learning Post-Training Enable Robust End-to-End Autonomous Driving": "|**2025-11-6**|**Poutine: Vision-Language-Trajectory Pre-Training and Reinforcement Learning Post-Training Enable Robust End-to-End Autonomous Driving**|Luke Rowe et.al|[paper](https://arxiv.org/abs/2506.11234)|-|-|\n", "AutoVLA: A Vision-Language-Action Model for End-to-End Autonomous Driving with Adaptive Reasoning and Reinforcement Fine-Tuning": "|**2025-11-5**|**AutoVLA: A Vision-Language-Action Model for End-to-End Autonomous Driving with Adaptive Reasoning and Reinforcement Fine-Tuning**|Zewei Zhou et.al|[paper](https://arxiv.org/abs/2506.13757)|[code](https://autovla.github.io/)|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "Context informs pragmatic interpretation in vision-language models": "|**2025-11-5**|**Context informs pragmatic interpretation in vision-language models**|Alvin Wei Ming Tan et.al|[paper](https://arxiv.org/abs/2511.03908)|-|<details><summary>detail</summary>CogInterp Workshop</details>|\n", "Hulu-Med: A Transparent Generalist Model towards Holistic Medical Vision-Language Understanding": "|**2025-11-5**|**Hulu-Med: A Transparent Generalist Model towards Holistic Medical Vision-Language Understanding**|Songtao Jiang et.al|[paper](https://arxiv.org/abs/2510.08668)|[code](https://github.com/ZJUI-AI4H/Hulu-Med.)|-|\n", "Manipulation Facing Threats: Evaluating Physical Vulnerabilities in End-to-End Vision Language Action Models": "|**2025-11-5**|**Manipulation Facing Threats: Evaluating Physical Vulnerabilities in End-to-End Vision Language Action Models**|Hao Cheng et.al|[paper](https://arxiv.org/abs/2409.13174)|-|-|\n", "Revisiting Multimodal Positional Encoding in Vision-Language Models": "|**2025-11-5**|**Revisiting Multimodal Positional Encoding in Vision-Language Models**|Jie Huang et.al|[paper](https://arxiv.org/abs/2510.23095)|[code](https://github.com/JJJYmmm/Multimodal-RoPEs.)|-|\n", "Decoupling Augmentation Bias in Prompt Learning for Vision-Language Models": "|**2025-11-5**|**Decoupling Augmentation Bias in Prompt Learning for Vision-Language Models**|Gahyeon Kim et.al|[paper](https://arxiv.org/abs/2511.03367)|[code](https://github.com/Gahyeonkim09/AAPL)|<details><summary>detail</summary>Accepted in Pattern Recognition</details>|\n", "Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models": "|**2025-11-5**|**Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models**|Shiho Matta et.al|[paper](https://arxiv.org/abs/2510.26241)|-|-|\n"}}