{"source-free": {"Collision-free Source Seeking and Flocking Control of Multi-agents with Connectivity Preservation": "|**2026-1-30**|**Collision-free Source Seeking and Flocking Control of Multi-agents with Connectivity Preservation**|Tinghua Li et.al|[paper](https://arxiv.org/abs/2301.04576)|-|<details><summary>detail</summary>Published in IEEE Transactions on Automatic Control</details>|\n", "Source Coding with Free Bits and the Multi-Way Number Partitioning Problem": "|**2026-1-29**|**Source Coding with Free Bits and the Multi-Way Number Partitioning Problem**|Niloufar Ahmadypour et.al|[paper](https://arxiv.org/abs/2009.02710)|-|-|\n", "Beyond Retraining: Training-Free Unknown Class Filtering for Source-Free Open Set Domain Adaptation of Vision-Language Models": "|**2026-1-28**|**Beyond Retraining: Training-Free Unknown Class Filtering for Source-Free Open Set Domain Adaptation of Vision-Language Models**|Yongguang Li et.al|[paper](https://arxiv.org/abs/2504.14224)|-|<details><summary>detail</summary>Core methods unchanged</details>|\n", "A Source-Free Approach for Domain Adaptation via Multiview Image Transformation and Latent Space Consistency": "|**2026-1-28**|**A Source-Free Approach for Domain Adaptation via Multiview Image Transformation and Latent Space Consistency**|Debopom Sutradhar et.al|[paper](https://arxiv.org/abs/2601.20284)|-|<details><summary>detail</summary>Manuscript under review in IEEE Transactions on Image Processing</details>|\n", "Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity": "|**2026-1-24**|**Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity**|Harsharaj Pathak et.al|[paper](https://arxiv.org/abs/2601.17408)|-|-|\n", "Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results": "|**2026-1-23**|**Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results**|Rohan Palanikumar et.al|[paper](https://arxiv.org/abs/2511.00752)|-|-|\n", "Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection": "|**2026-1-20**|**Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2511.07301)|-|<details><summary>detail</summary>AAAI 2026</details>|\n", "Towards Unbiased Source-Free Object Detection via Vision Foundation Models": "|**2026-1-19**|**Towards Unbiased Source-Free Object Detection via Vision Foundation Models**|Zhi Cai et.al|[paper](https://arxiv.org/abs/2601.12765)|-|-|\n", "Unified Source-Free Domain Adaptation": "|**2026-1-18**|**Unified Source-Free Domain Adaptation**|Song Tang et.al|[paper](https://arxiv.org/abs/2403.07601)|[code](https://github.com/tntek/CausalDA.)|-|\n", "GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher and Gaussian Mixture Model-Based Pseudo-Labeling": "|**2026-1-16**|**GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher and Gaussian Mixture Model-Based Pseudo-Labeling**|Pascal Schlachter et.al|[paper](https://arxiv.org/abs/2601.11161)|[code](https://github.com/pascalschlachter/GMM-COMET.)|-|\n", "SfMamba: Efficient Source-Free Domain Adaptation via Selective Scan Modeling": "|**2026-1-13**|**SfMamba: Efficient Source-Free Domain Adaptation via Selective Scan Modeling**|Xi Chen et.al|[paper](https://arxiv.org/abs/2601.08608)|[code](https://github.com/chenxi52/SfMamba.)|-|\n", "Source-Free Domain Adaptation for Geospatial Point Cloud Semantic Segmentation": "|**2026-1-13**|**Source-Free Domain Adaptation for Geospatial Point Cloud Semantic Segmentation**|Yuan Gao et.al|[paper](https://arxiv.org/abs/2601.08375)|-|-|\n", "Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based Curriculum Learning": "|**2026-1-5**|**Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based Curriculum Learning**|Dongjie Chen et.al|[paper](https://arxiv.org/abs/2405.18376)|[code](https://github.com/Dong-Jie-Chen/RCL.)|-|\n", "Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection": "|**2025-12-24**|**Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection**|Sairam VCR et.al|[paper](https://arxiv.org/abs/2512.17514)|-|-|\n", "Exploiting Radio Frequency Fingerprints for Device Identification: Tackling Cross-receiver Challenges in the Source-data-free Scenario": "|**2025-12-18**|**Exploiting Radio Frequency Fingerprints for Device Identification: Tackling Cross-receiver Challenges in the Source-data-free Scenario**|Liu Yang et.al|[paper](https://arxiv.org/abs/2512.16648)|-|<details><summary>detail</summary>IEEE Transactions on Mobile Computing</details>|\n"}, "object detection": {"Beyond Open Vocabulary: Multimodal Prompting for Object Detection in Remote Sensing Images": "|**2026-2-2**|**Beyond Open Vocabulary: Multimodal Prompting for Object Detection in Remote Sensing Images**|Shuai Yang et.al|[paper](https://arxiv.org/abs/2602.01954)|-|-|\n", "Samba+: General and Accurate Salient Object Detection via A More Unified Mamba-based Framework": "|**2026-2-1**|**Samba+: General and Accurate Salient Object Detection via A More Unified Mamba-based Framework**|Wenzhuo Zhao et.al|[paper](https://arxiv.org/abs/2602.01593)|-|-|\n", "Beyond Global Scanning: Adaptive Visual State Space Modeling for Salient Object Detection in Optical Remote Sensing Images": "|**2026-2-1**|**Beyond Global Scanning: Adaptive Visual State Space Modeling for Salient Object Detection in Optical Remote Sensing Images**|Mengyu Ren et.al|[paper](https://arxiv.org/abs/2508.10542)|-|-|\n", "Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT": "|**2026-2-1**|**Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT**|Ninnart Fuengfusin et.al|[paper](https://arxiv.org/abs/2601.12638)|-|-|\n", "HOI-R1: Exploring the Potential of Multimodal Large Language Models for Human-Object Interaction Detection": "|**2026-1-31**|**HOI-R1: Exploring the Potential of Multimodal Large Language Models for Human-Object Interaction Detection**|Junwen Chen et.al|[paper](https://arxiv.org/abs/2510.05609)|[code](https://github.com/cjw2021/HOI-R1.)|-|\n", "Enhancing Open-Vocabulary Object Detection through Multi-Level Fine-Grained Visual-Language Alignment": "|**2026-1-31**|**Enhancing Open-Vocabulary Object Detection through Multi-Level Fine-Grained Visual-Language Alignment**|Tianyi Zhang et.al|[paper](https://arxiv.org/abs/2602.00531)|-|-|\n", "Deep Learning-Based Object Detection for Autonomous Vehicles: A Comparative Study of One-Stage and Two-Stage Detectors on Basic Traffic Objects": "|**2026-1-30**|**Deep Learning-Based Object Detection for Autonomous Vehicles: A Comparative Study of One-Stage and Two-Stage Detectors on Basic Traffic Objects**|Bsher Karbouj et.al|[paper](https://arxiv.org/abs/2602.00385)|-|-|\n", "User Prompting Strategies and Prompt Enhancement Methods for Open-Set Object Detection in XR Environments": "|**2026-1-30**|**User Prompting Strategies and Prompt Enhancement Methods for Open-Set Object Detection in XR Environments**|Junfeng Lin et.al|[paper](https://arxiv.org/abs/2601.23281)|-|<details><summary>detail</summary>Accepted by IEEE VR 2026: GenAI-XR workshop</details>|\n", "From Label Error Detection to Correction: A Modular Framework and Benchmark for Object Detection Datasets": "|**2026-1-30**|**From Label Error Detection to Correction: A Modular Framework and Benchmark for Object Detection Datasets**|Sarina Penquitt et.al|[paper](https://arxiv.org/abs/2508.06556)|-|-|\n", "A Comparative Evaluation of Large Vision-Language Models for 2D Object Detection under SOTIF Conditions": "|**2026-1-30**|**A Comparative Evaluation of Large Vision-Language Models for 2D Object Detection under SOTIF Conditions**|Ji Zhou et.al|[paper](https://arxiv.org/abs/2601.22830)|-|-|\n", "OOVDet: Low-Density Prior Learning for Zero-Shot Out-of-Vocabulary Object Detection": "|**2026-1-30**|**OOVDet: Low-Density Prior Learning for Zero-Shot Out-of-Vocabulary Object Detection**|Binyi Su et.al|[paper](https://arxiv.org/abs/2601.22685)|[code](https://github.com/binyisu/OOV-detector.)|-|\n", "UniGeo: A Unified 3D Indoor Object Detection Framework Integrating Geometry-Aware Learning and Dynamic Channel Gating": "|**2026-1-30**|**UniGeo: A Unified 3D Indoor Object Detection Framework Integrating Geometry-Aware Learning and Dynamic Channel Gating**|Xing Yi et.al|[paper](https://arxiv.org/abs/2601.22616)|-|-|\n", "YOLO26: Key Architectural Enhancements and Performance Benchmarking for Real-Time Object Detection": "|**2026-1-29**|**YOLO26: Key Architectural Enhancements and Performance Benchmarking for Real-Time Object Detection**|Ranjan Sapkota et.al|[paper](https://arxiv.org/abs/2509.25164)|-|-|\n", "SSCATeR: Sparse Scatter-Based Convolution Algorithm with Temporal Data Recycling for Real-Time 3D Object Detection in LiDAR Point Clouds": "|**2026-1-29**|**SSCATeR: Sparse Scatter-Based Convolution Algorithm with Temporal Data Recycling for Real-Time 3D Object Detection in LiDAR Point Clouds**|Alexander Dow et.al|[paper](https://arxiv.org/abs/2512.08557)|-|<details><summary>detail</summary>23 Pages</details>|\n", "SDCM: Simulated Densifying and Compensatory Modeling Fusion for Radar-Vision 3-D Object Detection in Internet of Vehicles": "|**2026-1-29**|**SDCM: Simulated Densifying and Compensatory Modeling Fusion for Radar-Vision 3-D Object Detection in Internet of Vehicles**|Shucong Li et.al|[paper](https://arxiv.org/abs/2602.00149)|-|-|\n"}, "domain adaptation": {"Instance-Guided Unsupervised Domain Adaptation for Robotic Semantic Segmentation": "|**2026-2-1**|**Instance-Guided Unsupervised Domain Adaptation for Robotic Semantic Segmentation**|Michele Antonazzi et.al|[paper](https://arxiv.org/abs/2602.01389)|-|<details><summary>detail</summary>Accepted for publication at ICRA 2026</details>|\n", "Rethinking the Flow-Based Gradual Domain Adaption: A Semi-Dual Optimal Transport Perspective": "|**2026-2-1**|**Rethinking the Flow-Based Gradual Domain Adaption: A Semi-Dual Optimal Transport Perspective**|Zhichao Chen et.al|[paper](https://arxiv.org/abs/2602.01179)|-|-|\n", "When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs": "|**2026-1-31**|**When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs**|Junyi Zou et.al|[paper](https://arxiv.org/abs/2601.18350)|-|-|\n", "Domain-Adaptive and Scalable Dense Retrieval for Content-Based Recommendation": "|**2026-1-31**|**Domain-Adaptive and Scalable Dense Retrieval for Content-Based Recommendation**|Mritunjay Pandey et.al|[paper](https://arxiv.org/abs/2602.00899)|-|-|\n", "Domain Adaptation of Attention Heads for Zero-shot Anomaly Detection": "|**2026-1-31**|**Domain Adaptation of Attention Heads for Zero-shot Anomaly Detection**|Kiyoon Jeong et.al|[paper](https://arxiv.org/abs/2505.22259)|[code](https://github.com/kiyoonjeong0305/HeadCLIP.)|-|\n", "Riemannian Flow Matching for Disentangled Graph Domain Adaptation": "|**2026-1-31**|**Riemannian Flow Matching for Disentangled Graph Domain Adaptation**|Yingxu Wang et.al|[paper](https://arxiv.org/abs/2602.00656)|-|-|\n", "InstructDiff: Domain-Adaptive Data Selection via Differential Entropy for Efficient LLM Fine-Tuning": "|**2026-1-30**|**InstructDiff: Domain-Adaptive Data Selection via Differential Entropy for Efficient LLM Fine-Tuning**|Junyou Su et.al|[paper](https://arxiv.org/abs/2601.23006)|-|-|\n", "CiMRAG: CiM-Aware Domain-Adaptive and Noise-Resilient Retrieval-Augmented Generation for Edge-Based LLMs": "|**2026-1-30**|**CiMRAG: CiM-Aware Domain-Adaptive and Noise-Resilient Retrieval-Augmented Generation for Edge-Based LLMs**|Shih-Hsuan Chiu et.al|[paper](https://arxiv.org/abs/2601.20041)|-|<details><summary>detail</summary>Accepted by ICASSP 2026</details>|\n", "OmniLens: Towards Universal Lens Aberration Correction via LensLib-to-Specific Domain Adaptation": "|**2026-1-29**|**OmniLens: Towards Universal Lens Aberration Correction via LensLib-to-Specific Domain Adaptation**|Qi Jiang et.al|[paper](https://arxiv.org/abs/2409.05809)|[code](https://github.com/zju-jiangqi/OmniLens.)|<details><summary>detail</summary>Optics & Laser Technology (JOLT)</details>|\n", "Influence Guided Sampling for Domain Adaptation of Text Retrievers": "|**2026-1-29**|**Influence Guided Sampling for Domain Adaptation of Text Retrievers**|Meet Doshi et.al|[paper](https://arxiv.org/abs/2601.21759)|-|-|\n", "Few-Shot Domain Adaptation with Temporal References and Static Priors for Glacier Calving Front Delineation": "|**2026-1-29**|**Few-Shot Domain Adaptation with Temporal References and Static Priors for Glacier Calving Front Delineation**|Marcel Dreier et.al|[paper](https://arxiv.org/abs/2601.21663)|-|-|\n", "EEG-based Graph-guided Domain Adaptation for Robust Cross-Session Emotion Recognition": "|**2026-1-29**|**EEG-based Graph-guided Domain Adaptation for Robust Cross-Session Emotion Recognition**|Maryam Mirzaei et.al|[paper](https://arxiv.org/abs/2512.23526)|-|-|\n", "MOSAIC: Masked Objective with Selective Adaptation for In-domain Contrastive Learning": "|**2026-1-29**|**MOSAIC: Masked Objective with Selective Adaptation for In-domain Contrastive Learning**|Vera Pavlova et.al|[paper](https://arxiv.org/abs/2510.16797)|-|-|\n", "Distributionally Robust Classification for Multi-source Unsupervised Domain Adaptation": "|**2026-1-29**|**Distributionally Robust Classification for Multi-source Unsupervised Domain Adaptation**|Seonghwi Kim et.al|[paper](https://arxiv.org/abs/2601.21315)|-|<details><summary>detail</summary>ICLR 2026</details>|\n", "Beyond Retraining: Training-Free Unknown Class Filtering for Source-Free Open Set Domain Adaptation of Vision-Language Models": "|**2026-1-28**|**Beyond Retraining: Training-Free Unknown Class Filtering for Source-Free Open Set Domain Adaptation of Vision-Language Models**|Yongguang Li et.al|[paper](https://arxiv.org/abs/2504.14224)|-|<details><summary>detail</summary>Core methods unchanged</details>|\n"}, "domain generalization": {"Robust Domain Generalization under Divergent Marginal and Conditional Distributions": "|**2026-2-2**|**Robust Domain Generalization under Divergent Marginal and Conditional Distributions**|Jewon Yeom et.al|[paper](https://arxiv.org/abs/2602.02015)|-|-|\n", "Contrastive Domain Generalization for Cross-Instrument Molecular Identification in Mass Spectrometry": "|**2026-1-31**|**Contrastive Domain Generalization for Cross-Instrument Molecular Identification in Mass Spectrometry**|Seunghyun Yoo et.al|[paper](https://arxiv.org/abs/2602.00547)|-|-|\n", "CiMRAG: CiM-Aware Domain-Adaptive and Noise-Resilient Retrieval-Augmented Generation for Edge-Based LLMs": "|**2026-1-30**|**CiMRAG: CiM-Aware Domain-Adaptive and Noise-Resilient Retrieval-Augmented Generation for Edge-Based LLMs**|Shih-Hsuan Chiu et.al|[paper](https://arxiv.org/abs/2601.20041)|-|<details><summary>detail</summary>Accepted by ICASSP 2026</details>|\n", "Think Less, Label Better: Multi-Stage Domain-Grounded Synthetic Data Generation for Fine-Tuning Large Language Models in Telecommunications": "|**2026-1-29**|**Think Less, Label Better: Multi-Stage Domain-Grounded Synthetic Data Generation for Fine-Tuning Large Language Models in Telecommunications**|Chenhua Shi et.al|[paper](https://arxiv.org/abs/2509.25736)|-|-|\n", "Decentralized Domain Generalization with Style Sharing: Formal Model and Convergence Analysis": "|**2026-1-29**|**Decentralized Domain Generalization with Style Sharing: Formal Model and Convergence Analysis**|Shahryar Zehtabi et.al|[paper](https://arxiv.org/abs/2504.06235)|-|-|\n", "Negatives-Dominant Contrastive Learning for Generalization in Imbalanced Domains": "|**2026-1-29**|**Negatives-Dominant Contrastive Learning for Generalization in Imbalanced Domains**|Meng Cao et.al|[paper](https://arxiv.org/abs/2601.21999)|[code](https://github.com/Alrash/NDCL.)|-|\n", "MMGRid: Navigating Temporal-aware and Cross-domain Generative Recommendation via Model Merging": "|**2026-1-29**|**MMGRid: Navigating Temporal-aware and Cross-domain Generative Recommendation via Model Merging**|Tianjun Wei et.al|[paper](https://arxiv.org/abs/2601.15930)|[code](https://github.com/Joinn99/MMGRid)|<details><summary>detail</summary>https://github</details>|\n", "Panning for Gold: Expanding Domain-Specific Knowledge Graphs with General Knowledge": "|**2026-1-28**|**Panning for Gold: Expanding Domain-Specific Knowledge Graphs with General Knowledge**|Runhao Zhao et.al|[paper](https://arxiv.org/abs/2601.10485)|-|-|\n", "SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs": "|**2026-1-28**|**SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs**|Jiacheng Lin et.al|[paper](https://arxiv.org/abs/2509.20758)|-|<details><summary>detail</summary>Accepted by ICLR 2026</details>|\n", "Leveraging Generative AI for Enhancing Domain-Driven Software Design": "|**2026-1-28**|**Leveraging Generative AI for Enhancing Domain-Driven Software Design**|G\u00f6tz-Henrik Wiegand et.al|[paper](https://arxiv.org/abs/2601.20909)|-|<details><summary>detail</summary>Part of the Proceedings of the Upper-Rhine Artificial Intelligence Symposium 2024</details>|\n", "P2S: Probabilistic Process Supervision for General-Domain Reasoning Question Answering": "|**2026-1-28**|**P2S: Probabilistic Process Supervision for General-Domain Reasoning Question Answering**|Wenlin Zhong et.al|[paper](https://arxiv.org/abs/2601.20649)|-|-|\n", "Automated Benchmark Generation from Domain Guidelines Informed by Bloom's Taxonomy": "|**2026-1-28**|**Automated Benchmark Generation from Domain Guidelines Informed by Bloom's Taxonomy**|Si Chen et.al|[paper](https://arxiv.org/abs/2601.20253)|-|-|\n", "Modality-Balanced Collaborative Distillation for Multi-Modal Domain Generalization": "|**2026-1-27**|**Modality-Balanced Collaborative Distillation for Multi-Modal Domain Generalization**|Xiaohan Wang et.al|[paper](https://arxiv.org/abs/2511.20258)|-|-|\n", "Semantic-aware Random Convolution and Source Matching for Domain Generalization in Medical Image Segmentation": "|**2026-1-27**|**Semantic-aware Random Convolution and Source Matching for Domain Generalization in Medical Image Segmentation**|Franz Thaler et.al|[paper](https://arxiv.org/abs/2512.01510)|-|-|\n", "DSP-Reg: Domain-Sensitive Parameter Regularization for Robust Domain Generalization": "|**2026-1-27**|**DSP-Reg: Domain-Sensitive Parameter Regularization for Robust Domain Generalization**|Xudong Han et.al|[paper](https://arxiv.org/abs/2601.19394)|-|-|\n"}, "vision language": {"U2-BENCH: Benchmarking Large Vision-Language Models on Ultrasound Understanding": "|**2026-2-2**|**U2-BENCH: Benchmarking Large Vision-Language Models on Ultrasound Understanding**|Anjie Le et.al|[paper](https://arxiv.org/abs/2505.17779)|-|-|\n", "See2Refine: Vision-Language Feedback Improves LLM-Based eHMI Action Designers": "|**2026-2-2**|**See2Refine: Vision-Language Feedback Improves LLM-Based eHMI Action Designers**|Ding Xia et.al|[paper](https://arxiv.org/abs/2602.02063)|-|<details><summary>detail</summary>Under Review</details>|\n", "Auto-Comp: An Automated Pipeline for Scalable Compositional Probing of Contrastive Vision-Language Models": "|**2026-2-2**|**Auto-Comp: An Automated Pipeline for Scalable Compositional Probing of Contrastive Vision-Language Models**|Cristian Sbrolli et.al|[paper](https://arxiv.org/abs/2602.02043)|[code](https://huggingface.co/AutoComp).)|-|\n", "VL-JEPA: Joint Embedding Predictive Architecture for Vision-language": "|**2026-2-2**|**VL-JEPA: Joint Embedding Predictive Architecture for Vision-language**|Delong Chen et.al|[paper](https://arxiv.org/abs/2512.10942)|-|-|\n", "A Survey on Efficient Vision-Language-Action Models": "|**2026-2-2**|**A Survey on Efficient Vision-Language-Action Models**|Zhaoshu Yu et.al|[paper](https://arxiv.org/abs/2510.24795)|[code](https://evla-survey.github.io/.)|-|\n", "Towards Faithful Reasoning in Remote Sensing: A Perceptually-Grounded GeoSpatial Chain-of-Thought for Vision-Language Models": "|**2026-2-2**|**Towards Faithful Reasoning in Remote Sensing: A Perceptually-Grounded GeoSpatial Chain-of-Thought for Vision-Language Models**|Jiaqi Liu et.al|[paper](https://arxiv.org/abs/2509.22221)|-|-|\n", "Concept-Based Dictionary Learning for Inference-Time Safety in Vision Language Action Models": "|**2026-2-2**|**Concept-Based Dictionary Learning for Inference-Time Safety in Vision Language Action Models**|Siqi Wen et.al|[paper](https://arxiv.org/abs/2602.01834)|-|-|\n", "LaST$_{0}$: Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model": "|**2026-2-2**|**LaST$_{0}$: Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model**|Zhuoyang Liu et.al|[paper](https://arxiv.org/abs/2601.05248)|-|-|\n", "CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding": "|**2026-2-2**|**CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding**|Yuling Shi et.al|[paper](https://arxiv.org/abs/2602.01785)|[code](https://github.com/YerbaPage/CodeOCR)|<details><summary>detail</summary>Code and data are available at https://github</details>|\n", "SGHA-Attack: Semantic-Guided Hierarchical Alignment for Transferable Targeted Attacks on Vision-Language Models": "|**2026-2-1**|**SGHA-Attack: Semantic-Guided Hierarchical Alignment for Transferable Targeted Attacks on Vision-Language Models**|Haobo Wang et.al|[paper](https://arxiv.org/abs/2602.01574)|-|-|\n", "VULCA-Bench: A Multicultural Vision-Language Benchmark for Evaluating Cultural Understanding": "|**2026-2-1**|**VULCA-Bench: A Multicultural Vision-Language Benchmark for Evaluating Cultural Understanding**|Haorui Yu et.al|[paper](https://arxiv.org/abs/2601.07986)|-|-|\n", "PolyGen: Fully Synthetic Vision-Language Training via Multi-Generator Ensembles": "|**2026-2-1**|**PolyGen: Fully Synthetic Vision-Language Training via Multi-Generator Ensembles**|Leonardo Brusini et.al|[paper](https://arxiv.org/abs/2602.01370)|-|-|\n", "Model Specific Task Similarity for Vision Language Model Selection via Layer Conductance": "|**2026-2-1**|**Model Specific Task Similarity for Vision Language Model Selection via Layer Conductance**|Wei Yang et.al|[paper](https://arxiv.org/abs/2602.01346)|-|<details><summary>detail</summary>Preprint</details>|\n", "Toward a Vision-Language Foundation Model for Medical Data: Multimodal Dataset and Benchmarks for Vietnamese PET/CT Report Generation": "|**2026-2-1**|**Toward a Vision-Language Foundation Model for Medical Data: Multimodal Dataset and Benchmarks for Vietnamese PET/CT Report Generation**|Huu Tien Nguyen et.al|[paper](https://arxiv.org/abs/2509.24739)|[code](https://github.com/AIoT-Lab-BKAI/ViPET-ReportGen.)|<details><summary>detail</summary>39th Conference on Neural Information Processing Systems (NeurIPS 2025) Track on Datasets and Benchmarks</details>|\n", "Med3D-R1: Incentivizing Clinical Reasoning in 3D Medical Vision-Language Models for Abnormality Diagnosis": "|**2026-2-1**|**Med3D-R1: Incentivizing Clinical Reasoning in 3D Medical Vision-Language Models for Abnormality Diagnosis**|Haoran Lai et.al|[paper](https://arxiv.org/abs/2602.01200)|-|-|\n"}}