{"source-free": {"Source-Free Domain Adaptive Object Detection with Semantics Compensation": "|**2025-9-30**|**Source-Free Domain Adaptive Object Detection with Semantics Compensation**|Song Tang et.al|[paper](https://arxiv.org/abs/2410.05557)|-|-|\n", "DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation": "|**2025-9-29**|**DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation**|Xi Chen et.al|[paper](https://arxiv.org/abs/2509.24896)|-|-|\n", "Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation": "|**2025-9-29**|**Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|\n", "A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation": "|**2025-9-26**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|\n", "Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment": "|**2025-9-22**|**Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment**|Wenjie Liu et.al|[paper](https://arxiv.org/abs/2509.18502)|-|-|\n", "Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation": "|**2025-9-22**|**Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation**|Amirhossein Dadashzadeh et.al|[paper](https://arxiv.org/abs/2504.11669)|[code](https://github.com/Plrbear/Co-Star)|-|\n", "Prototype-Based Pseudo-Label Denoising for Source-Free Domain Adaptation in Remote Sensing Semantic Segmentation": "|**2025-9-21**|**Prototype-Based Pseudo-Label Denoising for Source-Free Domain Adaptation in Remote Sensing Semantic Segmentation**|Bin Wang et.al|[paper](https://arxiv.org/abs/2509.16942)|-|-|\n", "Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments": "|**2025-9-18**|**Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2501.02184)|-|-|\n", "Step-wise Distribution Alignment Guided Style Prompt Tuning for Source-free Cross-domain Few-shot Learning": "|**2025-9-13**|**Step-wise Distribution Alignment Guided Style Prompt Tuning for Source-free Cross-domain Few-shot Learning**|Huali Xu et.al|[paper](https://arxiv.org/abs/2411.10070)|[code](https://github.com/xuhuali-mxj/StepSPT.)|<details><summary>detail</summary>IEEE TPAMI</details>|\n", "Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment": "|**2025-9-12**|**Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment**|Rini Smita Thakur et.al|[paper](https://arxiv.org/abs/2509.10134)|[code](https://visdomlab.github.io/GCL/.)|<details><summary>detail</summary>Accepted in BMVC 2025</details>|\n", "Rethinking the Backbone in Class Imbalanced Federated Source Free Domain Adaptation: The Utility of Vision Foundation Models": "|**2025-9-10**|**Rethinking the Backbone in Class Imbalanced Federated Source Free Domain Adaptation: The Utility of Vision Foundation Models**|Kosuke Kihara et.al|[paper](https://arxiv.org/abs/2509.08372)|-|<details><summary>detail</summary>Accepted by the IEEE ICIP 2025 Satellite Workshop 1: Edge Intelligence: Smart</details>|\n", "StableSleep: Source-Free Test-Time Adaptation for Sleep Staging with Lightweight Safety Rails": "|**2025-9-2**|**StableSleep: Source-Free Test-Time Adaptation for Sleep Staging with Lightweight Safety Rails**|Hritik Arasu et.al|[paper](https://arxiv.org/abs/2509.02982)|-|<details><summary>detail</summary>5 page paper</details>|\n", "Model-Free Hovering and Source Seeking via Extremum Seeking Control: Experimental Demonstration": "|**2025-8-28**|**Model-Free Hovering and Source Seeking via Extremum Seeking Control: Experimental Demonstration**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2508.20836)|-|-|\n", "VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection": "|**2025-8-26**|**VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection**|Jianhong Han et.al|[paper](https://arxiv.org/abs/2508.11167)|-|<details><summary>detail</summary>Manuscript submitted to IEEE TCSVT</details>|\n", "Towards Source-Free Machine Unlearning": "|**2025-8-20**|**Towards Source-Free Machine Unlearning**|Sk Miraj Ahmed et.al|[paper](https://arxiv.org/abs/2508.15127)|-|<details><summary>detail</summary>Accepted by CVPR 2025</details>|\n"}, "object detection": {"Adaptive Event Stream Slicing for Open-Vocabulary Event-Based Object Detection via Vision-Language Knowledge Distillation": "|**2025-10-1**|**Adaptive Event Stream Slicing for Open-Vocabulary Event-Based Object Detection via Vision-Language Knowledge Distillation**|Jinchang Zhang et.al|[paper](https://arxiv.org/abs/2510.00681)|-|-|\n", "PAN: Pillars-Attention-Based Network for 3D Object Detection": "|**2025-10-1**|**PAN: Pillars-Attention-Based Network for 3D Object Detection**|Ruan Bispo et.al|[paper](https://arxiv.org/abs/2509.15935)|-|-|\n", "DPDETR: Decoupled Position Detection Transformer for Infrared-Visible Object Detection": "|**2025-10-1**|**DPDETR: Decoupled Position Detection Transformer for Infrared-Visible Object Detection**|Junjie Guo et.al|[paper](https://arxiv.org/abs/2408.06123)|[code](https://github.com/gjj45/DPDETR)|-|\n", "Are All Marine Species Created Equal? Performance Disparities in Underwater Object Detection": "|**2025-10-1**|**Are All Marine Species Created Equal? Performance Disparities in Underwater Object Detection**|Melanie Wille et.al|[paper](https://arxiv.org/abs/2508.18729)|-|-|\n", "Source-Free Domain Adaptive Object Detection with Semantics Compensation": "|**2025-9-30**|**Source-Free Domain Adaptive Object Detection with Semantics Compensation**|Song Tang et.al|[paper](https://arxiv.org/abs/2410.05557)|-|-|\n", "Looking Beyond the Known: Towards a Data Discovery Guided Open-World Object Detection": "|**2025-9-30**|**Looking Beyond the Known: Towards a Data Discovery Guided Open-World Object Detection**|Anay Majee et.al|[paper](https://arxiv.org/abs/2510.00303)|-|<details><summary>detail</summary>NeurIPS'25</details>|\n", "Adaptive Modality Balanced Online Knowledge Distillation for Brain-Eye-Computer based Dim Object Detection": "|**2025-9-30**|**Adaptive Modality Balanced Online Knowledge Distillation for Brain-Eye-Computer based Dim Object Detection**|Zixing Li et.al|[paper](https://arxiv.org/abs/2407.01894)|-|-|\n", "Object Detection with Multimodal Large Vision-Language Models: An In-depth Review": "|**2025-9-30**|**Object Detection with Multimodal Large Vision-Language Models: An In-depth Review**|Ranjan Sapkota et.al|[paper](https://arxiv.org/abs/2508.19294)|-|<details><summary>detail</summary>First Peer Reviewed Review Paper for Object Detection with Vision-Language Models (VLMs)</details>|\n", "Adapting SAM with Dynamic Similarity Graphs for Few-Shot Parameter-Efficient Small Dense Object Detection: A Case Study of Chickpea Pods in Field Conditions": "|**2025-9-30**|**Adapting SAM with Dynamic Similarity Graphs for Few-Shot Parameter-Efficient Small Dense Object Detection: A Case Study of Chickpea Pods in Field Conditions**|Xintong Jiang et.al|[paper](https://arxiv.org/abs/2509.25805)|-|-|\n", "YOLO26: Key Architectural Enhancements and Performance Benchmarking for Real-Time Object Detection": "|**2025-9-29**|**YOLO26: Key Architectural Enhancements and Performance Benchmarking for Real-Time Object Detection**|Ranjan Sapkota et.al|[paper](https://arxiv.org/abs/2509.25164)|-|-|\n", "Investigating Long-term Training for Remote Sensing Object Detection": "|**2025-9-29**|**Investigating Long-term Training for Remote Sensing Object Detection**|JongHyun Park et.al|[paper](https://arxiv.org/abs/2407.15143)|[code](https://github.com/unique-chan/dbf.)|<details><summary>detail</summary>Machine Vision and Applications (MVA)</details>|\n", "DEPFusion: Dual-Domain Enhancement and Priority-Guided Mamba Fusion for UAV Multispectral Object Detection": "|**2025-9-29**|**DEPFusion: Dual-Domain Enhancement and Priority-Guided Mamba Fusion for UAV Multispectral Object Detection**|Shucong Li et.al|[paper](https://arxiv.org/abs/2509.07327)|-|-|\n", "Talk in Pieces, See in Whole: Disentangling and Hierarchical Aggregating Representations for Language-based Object Detection": "|**2025-9-28**|**Talk in Pieces, See in Whole: Disentangling and Hierarchical Aggregating Representations for Language-based Object Detection**|Sojung An et.al|[paper](https://arxiv.org/abs/2509.24192)|-|-|\n", "Learning Adaptive Pseudo-Label Selection for Semi-Supervised 3D Object Detection": "|**2025-9-28**|**Learning Adaptive Pseudo-Label Selection for Semi-Supervised 3D Object Detection**|Taehun Kong et.al|[paper](https://arxiv.org/abs/2509.23880)|-|-|\n", "Synthetic-to-Real Camouflaged Object Detection": "|**2025-9-27**|**Synthetic-to-Real Camouflaged Object Detection**|Zhihao Luo et.al|[paper](https://arxiv.org/abs/2507.18911)|[code](https://github.com/Muscape/S2R-COD.)|<details><summary>detail</summary>Accepted by ACM MM 2025</details>|\n"}, "domain adaptation": {"Signal Classification Recovery Across Domains Using Unsupervised Domain Adaptation": "|**2025-10-1**|**Signal Classification Recovery Across Domains Using Unsupervised Domain Adaptation**|Mohammad Ali et.al|[paper](https://arxiv.org/abs/2510.00589)|-|-|\n", "Black-Box Time-Series Domain Adaptation via Cross-Prompt Foundation Models": "|**2025-10-1**|**Black-Box Time-Series Domain Adaptation via Cross-Prompt Foundation Models**|M. T. Furqon et.al|[paper](https://arxiv.org/abs/2510.00487)|-|-|\n", "Vicinity-Guided Discriminative Latent Diffusion for Privacy-Preserving Domain Adaptation": "|**2025-9-30**|**Vicinity-Guided Discriminative Latent Diffusion for Privacy-Preserving Domain Adaptation**|Jing Wang et.al|[paper](https://arxiv.org/abs/2510.00478)|-|-|\n", "Source-Free Domain Adaptive Object Detection with Semantics Compensation": "|**2025-9-30**|**Source-Free Domain Adaptive Object Detection with Semantics Compensation**|Song Tang et.al|[paper](https://arxiv.org/abs/2410.05557)|-|-|\n", "MPCA-based Domain Adaptation for Transfer Learning in Ultrasonic Guided Waves": "|**2025-9-30**|**MPCA-based Domain Adaptation for Transfer Learning in Ultrasonic Guided Waves**|Lucio Pinello et.al|[paper](https://arxiv.org/abs/2508.02726)|-|-|\n", "Multi-View Projection for Unsupervised Domain Adaptation in 3D Semantic Segmentation": "|**2025-9-30**|**Multi-View Projection for Unsupervised Domain Adaptation in 3D Semantic Segmentation**|Andrew Caunes et.al|[paper](https://arxiv.org/abs/2505.15545)|-|-|\n", "DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation": "|**2025-9-29**|**DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation**|Xi Chen et.al|[paper](https://arxiv.org/abs/2509.24896)|-|-|\n", "A Self-Adaptive Frequency Domain Network for Continuous Intraoperative Hypotension Prediction": "|**2025-9-28**|**A Self-Adaptive Frequency Domain Network for Continuous Intraoperative Hypotension Prediction**|Xian Zeng et.al|[paper](https://arxiv.org/abs/2509.23720)|-|<details><summary>detail</summary>ECAI 2025 main conference</details>|\n", "Efficient Domain-Adaptive Multi-Task Dense Prediction with Vision Foundation Models": "|**2025-9-28**|**Efficient Domain-Adaptive Multi-Task Dense Prediction with Vision Foundation Models**|Beomseok Kang et.al|[paper](https://arxiv.org/abs/2509.23626)|-|-|\n", "Robust Multi-Modal Face Anti-Spoofing with Domain Adaptation: Tackling Missing Modalities, Noisy Pseudo-Labels, and Model Degradation": "|**2025-9-27**|**Robust Multi-Modal Face Anti-Spoofing with Domain Adaptation: Tackling Missing Modalities, Noisy Pseudo-Labels, and Model Degradation**|Ming-Tsung Hsu et.al|[paper](https://arxiv.org/abs/2509.23475)|-|-|\n", "Preventing Robotic Jailbreaking via Multimodal Domain Adaptation": "|**2025-9-27**|**Preventing Robotic Jailbreaking via Multimodal Domain Adaptation**|Francesco Marchiori et.al|[paper](https://arxiv.org/abs/2509.23281)|[code](https://j-dapt.github.io.)|<details><summary>detail</summary>Project page: https://j-dapt</details>|\n", "SynDoc: A Hybrid Discriminative-Generative Framework for Enhancing Synthetic Domain-Adaptive Document Key Information Extraction": "|**2025-9-27**|**SynDoc: A Hybrid Discriminative-Generative Framework for Enhancing Synthetic Domain-Adaptive Document Key Information Extraction**|Yihao Ding et.al|[paper](https://arxiv.org/abs/2509.23273)|-|<details><summary>detail</summary>Work in progress</details>|\n", "A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation": "|**2025-9-26**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|\n", "Demystifying Domain-adaptive Post-training for Financial LLMs": "|**2025-9-25**|**Demystifying Domain-adaptive Post-training for Financial LLMs**|Zixuan Ke et.al|[paper](https://arxiv.org/abs/2501.04961)|-|<details><summary>detail</summary>EMNLP 2025 (Oral)</details>|\n", "Degree-Conscious Spiking Graph for Cross-Domain Adaptation": "|**2025-9-25**|**Degree-Conscious Spiking Graph for Cross-Domain Adaptation**|Yingxu Wang et.al|[paper](https://arxiv.org/abs/2410.06883)|-|-|\n"}, "domain generalization": {"Finetune Once: Decoupling General & Domain Learning with Dynamic Boosted Annealing": "|**2025-9-30**|**Finetune Once: Decoupling General & Domain Learning with Dynamic Boosted Annealing**|Yang Tang et.al|[paper](https://arxiv.org/abs/2509.26242)|-|-|\n", "Scaling Up Temporal Domain Generalization via Temporal Experts Averaging": "|**2025-9-30**|**Scaling Up Temporal Domain Generalization via Temporal Experts Averaging**|Aoming Liu et.al|[paper](https://arxiv.org/abs/2509.26045)|-|<details><summary>detail</summary>Accepted by EMNLP 2025 main</details>|\n", "Think Less, Label Better: Multi-Stage Domain-Grounded Synthetic Data Generation for Fine-Tuning Large Language Models in Telecommunications": "|**2025-9-29**|**Think Less, Label Better: Multi-Stage Domain-Grounded Synthetic Data Generation for Fine-Tuning Large Language Models in Telecommunications**|Chenhua Shi et.al|[paper](https://arxiv.org/abs/2509.25736)|-|-|\n", "SING-SQL: A Synthetic Data Generation Framework for In-Domain Text-to-SQL Translation": "|**2025-9-29**|**SING-SQL: A Synthetic Data Generation Framework for In-Domain Text-to-SQL Translation**|Hasan Alp Cafero\u011flu et.al|[paper](https://arxiv.org/abs/2509.25672)|-|-|\n", "Embedding Domain Knowledge for Large Language Models via Reinforcement Learning from Augmented Generation": "|**2025-9-27**|**Embedding Domain Knowledge for Large Language Models via Reinforcement Learning from Augmented Generation**|Chaojun Nie et.al|[paper](https://arxiv.org/abs/2509.20162)|[code](https://github.com/ChaojunNie/RLAG.)|<details><summary>detail</summary>Corrected author name spelling</details>|\n", "SynDoc: A Hybrid Discriminative-Generative Framework for Enhancing Synthetic Domain-Adaptive Document Key Information Extraction": "|**2025-9-27**|**SynDoc: A Hybrid Discriminative-Generative Framework for Enhancing Synthetic Domain-Adaptive Document Key Information Extraction**|Yihao Ding et.al|[paper](https://arxiv.org/abs/2509.23273)|-|<details><summary>detail</summary>Work in progress</details>|\n", "B\u00e9zier Meets Diffusion: Robust Generation Across Domains for Medical Image Segmentation": "|**2025-9-26**|**B\u00e9zier Meets Diffusion: Robust Generation Across Domains for Medical Image Segmentation**|Chen Li et.al|[paper](https://arxiv.org/abs/2509.22476)|-|-|\n", "A Survey on LLM-based Code Generation for Low-Resource and Domain-Specific Programming Languages": "|**2025-9-26**|**A Survey on LLM-based Code Generation for Low-Resource and Domain-Specific Programming Languages**|Sathvik Joel et.al|[paper](https://arxiv.org/abs/2410.03981)|-|-|\n", "Plan2Evolve: LLM Self-Evolution for Improved Planning Capability via Automated Domain Generation": "|**2025-9-25**|**Plan2Evolve: LLM Self-Evolution for Improved Planning Capability via Automated Domain Generation**|Jinbang Huang et.al|[paper](https://arxiv.org/abs/2509.21543)|-|-|\n", "Technical report on label-informed logit redistribution for better domain generalization in low-shot classification with foundation models": "|**2025-9-25**|**Technical report on label-informed logit redistribution for better domain generalization in low-shot classification with foundation models**|Behraj Khan et.al|[paper](https://arxiv.org/abs/2501.17595)|-|-|\n", "An orderly algorithm for generation of Condorcet Domains": "|**2025-9-25**|**An orderly algorithm for generation of Condorcet Domains**|Bei Zhou et.al|[paper](https://arxiv.org/abs/2509.20865)|-|-|\n", "Federated Domain Generalization with Domain-specific Soft Prompts Generation": "|**2025-9-25**|**Federated Domain Generalization with Domain-specific Soft Prompts Generation**|Jianhan Wu et.al|[paper](https://arxiv.org/abs/2509.20807)|-|<details><summary>detail</summary>the IEEE/CVF International Conference on Computer Vision (ICCV 2025)</details>|\n", "Dual-supervised Asymmetric Co-training for Semi-supervised Medical Domain Generalization": "|**2025-9-25**|**Dual-supervised Asymmetric Co-training for Semi-supervised Medical Domain Generalization**|Jincai Song et.al|[paper](https://arxiv.org/abs/2509.20785)|-|-|\n", "SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs": "|**2025-9-25**|**SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs**|Jiacheng Lin et.al|[paper](https://arxiv.org/abs/2509.20758)|-|-|\n", "Minimal Semantic Sufficiency Meets Unsupervised Domain Generalization": "|**2025-9-24**|**Minimal Semantic Sufficiency Meets Unsupervised Domain Generalization**|Tan Pan et.al|[paper](https://arxiv.org/abs/2509.15791)|-|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|\n"}, "vision language": {"DepthLM: Metric Depth From Vision Language Models": "|**2025-10-1**|**DepthLM: Metric Depth From Vision Language Models**|Zhipeng Cai et.al|[paper](https://arxiv.org/abs/2509.25413)|-|-|\n", "Strategic Fusion of Vision Language Models: Shapley-Credited Context-Aware Dawid-Skene for Multi-Label Tasks in Autonomous Driving": "|**2025-10-1**|**Strategic Fusion of Vision Language Models: Shapley-Credited Context-Aware Dawid-Skene for Multi-Label Tasks in Autonomous Driving**|Yuxiang Feng et.al|[paper](https://arxiv.org/abs/2510.01126)|-|-|\n", "CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification": "|**2025-10-1**|**CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification**|Wei Li et.al|[paper](https://arxiv.org/abs/2508.21046)|[code](https://github.com/JiuTian-VL/CogVLA.)|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "ReWatch-R1: Boosting Complex Video Reasoning in Large Vision-Language Models through Agentic Data Synthesis": "|**2025-10-1**|**ReWatch-R1: Boosting Complex Video Reasoning in Large Vision-Language Models through Agentic Data Synthesis**|Congzhi Zhang et.al|[paper](https://arxiv.org/abs/2509.23652)|[code](https://rewatch-r1.github.io)|-|\n", "Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned": "|**2025-10-1**|**Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned**|Brandon Ong et.al|[paper](https://arxiv.org/abs/2509.23250)|-|-|\n", "PRPO: Paragraph-level Policy Optimization for Vision-Language Deepfake Detection": "|**2025-10-1**|**PRPO: Paragraph-level Policy Optimization for Vision-Language Deepfake Detection**|Tuan Nguyen et.al|[paper](https://arxiv.org/abs/2509.26272)|-|-|\n", "From Seeing to Predicting: A Vision-Language Framework for Trajectory Forecasting and Controlled Video Generation": "|**2025-10-1**|**From Seeing to Predicting: A Vision-Language Framework for Trajectory Forecasting and Controlled Video Generation**|Fan Yang et.al|[paper](https://arxiv.org/abs/2510.00806)|-|-|\n", "Solar PV Installation Potential Assessment on Building Facades Based on Vision and Language Foundation Models": "|**2025-10-1**|**Solar PV Installation Potential Assessment on Building Facades Based on Vision and Language Foundation Models**|Ruyu Liu et.al|[paper](https://arxiv.org/abs/2510.00797)|-|-|\n", "HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy": "|**2025-10-1**|**HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy**|Myungkyu Koo et.al|[paper](https://arxiv.org/abs/2510.00695)|[code](https://myungkyukoo.github.io/hamlet/)|<details><summary>detail</summary>Project page: https://myungkyukoo</details>|\n", "ACPO: Adaptive Curriculum Policy Optimization for Aligning Vision-Language Models in Complex Reasoning": "|**2025-10-1**|**ACPO: Adaptive Curriculum Policy Optimization for Aligning Vision-Language Models in Complex Reasoning**|Yunhao Wang et.al|[paper](https://arxiv.org/abs/2510.00690)|-|-|\n", "Adaptive Event Stream Slicing for Open-Vocabulary Event-Based Object Detection via Vision-Language Knowledge Distillation": "|**2025-10-1**|**Adaptive Event Stream Slicing for Open-Vocabulary Event-Based Object Detection via Vision-Language Knowledge Distillation**|Jinchang Zhang et.al|[paper](https://arxiv.org/abs/2510.00681)|-|-|\n", "Disentangling Foreground and Background for vision-Language Navigation via Online Augmentation": "|**2025-10-1**|**Disentangling Foreground and Background for vision-Language Navigation via Online Augmentation**|Yunbo Xu et.al|[paper](https://arxiv.org/abs/2510.00604)|-|-|\n", "Hybrid Training for Vision-Language-Action Models": "|**2025-10-1**|**Hybrid Training for Vision-Language-Action Models**|Pietro Mazzaglia et.al|[paper](https://arxiv.org/abs/2510.00600)|-|-|\n", "Poutine: Vision-Language-Trajectory Pre-Training and Reinforcement Learning Post-Training Enable Robust End-to-End Autonomous Driving": "|**2025-10-1**|**Poutine: Vision-Language-Trajectory Pre-Training and Reinforcement Learning Post-Training Enable Robust End-to-End Autonomous Driving**|Luke Rowe et.al|[paper](https://arxiv.org/abs/2506.11234)|-|-|\n", "GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents": "|**2025-10-1**|**GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents**|Run Luo et.al|[paper](https://arxiv.org/abs/2504.10458)|-|-|\n"}}