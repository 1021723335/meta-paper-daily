{"source-free": {"SFUOD: Source-Free Unknown Object Detection": "|**2025-7-23**|**SFUOD: Source-Free Unknown Object Detection**|Keon-Hee Park et.al|[paper](https://arxiv.org/abs/2507.17373)|-|<details><summary>detail</summary>This paper has been accepted by ICCV 2025</details>|\n", "Model-Free and Real-Time Bioinspired Unicycle-Based Source Seeking: Differential Wheeled Robotic Experiments": "|**2025-7-21**|**Model-Free and Real-Time Bioinspired Unicycle-Based Source Seeking: Differential Wheeled Robotic Experiments**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2501.02184)|-|-|\n", "Text-Driven Causal Representation Learning for Source-Free Domain Generalization": "|**2025-7-14**|**Text-Driven Causal Representation Learning for Source-Free Domain Generalization**|Lihua Zhou et.al|[paper](https://arxiv.org/abs/2507.09961)|-|<details><summary>detail</summary>Under Review</details>|\n", "Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting": "|**2025-7-12**|**Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting**|Zheang Huai et.al|[paper](https://arxiv.org/abs/2505.08527)|[code](https://github.com/xmed-lab/DFG.)|<details><summary>detail</summary>Accepted in TMI 2025</details>|\n", "Source-Free Domain Adaptation via Multi-view Contrastive Learning": "|**2025-7-4**|**Source-Free Domain Adaptation via Multi-view Contrastive Learning**|Amirfarhad Farhadi et.al|[paper](https://arxiv.org/abs/2507.03321)|-|-|\n", "Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework": "|**2025-6-26**|**Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework**|Ismail Nejjar et.al|[paper](https://arxiv.org/abs/2411.12558)|-|<details><summary>detail</summary>TMLR 2025</details>|\n", "Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation": "|**2025-6-26**|**Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation**|Yihong Cao et.al|[paper](https://arxiv.org/abs/2506.21198)|[code](https://github.com/yihong-97/UNLOCK.)|<details><summary>detail</summary>ICCV 2025</details>|\n", "Context Aware Grounded Teacher for Source Free Object Detection": "|**2025-6-25**|**Context Aware Grounded Teacher for Source Free Object Detection**|Tajamul Ashraf et.al|[paper](https://arxiv.org/abs/2504.15404)|[code](https://github.com/Tajamul21/Grounded_Teacher.)|-|\n", "SFDLA: Source-Free Document Layout Analysis": "|**2025-6-18**|**SFDLA: Source-Free Document Layout Analysis**|Sebastian Tewes et.al|[paper](https://arxiv.org/abs/2503.18742)|[code](https://github.com/s3setewe/sfdla-DLAdapter.)|<details><summary>detail</summary>Accepted by ICDAR 2025</details>|\n", "Unified Source-Free Domain Adaptation": "|**2025-6-17**|**Unified Source-Free Domain Adaptation**|Song Tang et.al|[paper](https://arxiv.org/abs/2403.07601)|-|-|\n", "SRPL-SFDA: SAM-Guided Reliable Pseudo-Labels for Source-Free Domain Adaptation in Medical Image Segmentation": "|**2025-6-11**|**SRPL-SFDA: SAM-Guided Reliable Pseudo-Labels for Source-Free Domain Adaptation in Medical Image Segmentation**|Xinya Liu et.al|[paper](https://arxiv.org/abs/2506.09403)|[code](https://github.com/HiLab-git/SRPL-SFDA.)|-|\n", "DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization": "|**2025-6-5**|**DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization**|Geonyoung Lee et.al|[paper](https://arxiv.org/abs/2506.02858)|[code](https://wltschmrz.github.io/DGMO/)|<details><summary>detail</summary>Interspeech 2025</details>|\n", "Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data": "|**2025-5-30**|**Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2503.20771)|-|-|\n", "Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation": "|**2025-5-30**|**Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation**|Pascal Schlachter et.al|[paper](https://arxiv.org/abs/2504.11992)|[code](https://github.com/pascalschlachter/PLAnalysis.)|<details><summary>detail</summary>the 33rd European Signal Processing Conference (EUSIPCO 2025)</details>|\n", "Shuffle PatchMix Augmentation with Confidence-Margin Weighted Pseudo-Labels for Enhanced Source-Free Domain Adaptation": "|**2025-5-30**|**Shuffle PatchMix Augmentation with Confidence-Margin Weighted Pseudo-Labels for Enhanced Source-Free Domain Adaptation**|Prasanna Reddy Pulakurthi et.al|[paper](https://arxiv.org/abs/2505.24216)|[code](https://github.com/PrasannaPulakurthi/SPM)|-|\n"}, "object detection": {"MambaNeXt-YOLO: A Hybrid State Space Model for Real-time Object Detection": "|**2025-7-24**|**MambaNeXt-YOLO: A Hybrid State Space Model for Real-time Object Detection**|Xiaochun Lei et.al|[paper](https://arxiv.org/abs/2506.03654)|-|<details><summary>detail</summary>This paper is under consideration at Image and Vision Computing</details>|\n", "Towards Large Scale Geostatistical Methane Monitoring with Part-based Object Detection": "|**2025-7-24**|**Towards Large Scale Geostatistical Methane Monitoring with Part-based Object Detection**|Adhemar de Senneville et.al|[paper](https://arxiv.org/abs/2507.18513)|-|-|\n", "Revisiting Physically Realizable Adversarial Object Attack against LiDAR-based Detection: Clarifying Problem Formulation and Experimental Protocols": "|**2025-7-24**|**Revisiting Physically Realizable Adversarial Object Attack against LiDAR-based Detection: Clarifying Problem Formulation and Experimental Protocols**|Luo Cheng et.al|[paper](https://arxiv.org/abs/2507.18457)|-|-|\n", "Boosting Multi-View Indoor 3D Object Detection via Adaptive 3D Volume Construction": "|**2025-7-24**|**Boosting Multi-View Indoor 3D Object Detection via Adaptive 3D Volume Construction**|Runmin Zhang et.al|[paper](https://arxiv.org/abs/2507.18331)|[code](https://github.com/RM-Zhang/SGCDet.)|<details><summary>detail</summary>Accepted by ICCV2025</details>|\n", "LMM-Det: Make Large Multimodal Models Excel in Object Detection": "|**2025-7-24**|**LMM-Det: Make Large Multimodal Models Excel in Object Detection**|Jincheng Li et.al|[paper](https://arxiv.org/abs/2507.18300)|[code](https://github.com/360CVGroup/LMM-Det.)|<details><summary>detail</summary>ICCV 2025</details>|\n", "Real-Time Object Detection and Classification using YOLO for Edge FPGAs": "|**2025-7-24**|**Real-Time Object Detection and Classification using YOLO for Edge FPGAs**|Rashed Al Amin et.al|[paper](https://arxiv.org/abs/2507.18174)|-|<details><summary>detail</summary>This paper has been accepted for the 67th International Symposium on ELMAR 2025</details>|\n", "WaveMamba: Wavelet-Driven Mamba Fusion for RGB-Infrared Object Detection": "|**2025-7-24**|**WaveMamba: Wavelet-Driven Mamba Fusion for RGB-Infrared Object Detection**|Haodong Zhu et.al|[paper](https://arxiv.org/abs/2507.18173)|-|<details><summary>detail</summary>Journal ref:ICCV</details>|\n", "Perspective-Invariant 3D Object Detection": "|**2025-7-23**|**Perspective-Invariant 3D Object Detection**|Ao Liang et.al|[paper](https://arxiv.org/abs/2507.17665)|[code](https://pi3det.github.io)|<details><summary>detail</summary>ICCV 2025</details>|\n", "BoxFusion: Reconstruction-Free Open-Vocabulary 3D Object Detection via Real-Time Multi-View Box Fusion": "|**2025-7-23**|**BoxFusion: Reconstruction-Free Open-Vocabulary 3D Object Detection via Real-Time Multi-View Box Fusion**|Yuqing Lan et.al|[paper](https://arxiv.org/abs/2506.15610)|[code](https://lanlan96.github.io/BoxFusion/)|<details><summary>detail</summary>Project page: https://lanlan96</details>|\n", "RGBX-DiffusionDet: A Framework for Multi-Modal RGB-X Object Detection Using DiffusionDet": "|**2025-7-23**|**RGBX-DiffusionDet: A Framework for Multi-Modal RGB-X Object Detection Using DiffusionDet**|Eliraz Orfaig et.al|[paper](https://arxiv.org/abs/2505.02586)|-|-|\n", "Illicit object detection in X-ray imaging using deep learning techniques: A comparative evaluation": "|**2025-7-23**|**Illicit object detection in X-ray imaging using deep learning techniques: A comparative evaluation**|Jorgen Cani et.al|[paper](https://arxiv.org/abs/2507.17508)|[code](https://github.com/jgenc/xray-comparative-evaluation.)|-|\n", "Dynamic Scoring with Enhanced Semantics for Training-Free Human-Object Interaction Detection": "|**2025-7-23**|**Dynamic Scoring with Enhanced Semantics for Training-Free Human-Object Interaction Detection**|Francesco Tonini et.al|[paper](https://arxiv.org/abs/2507.17456)|[code](https://github.com/francescotonini/dysco.)|<details><summary>detail</summary>ACM Multimedia 2025</details>|\n", "IndoorBEV: Joint Detection and Footprint Completion of Objects via Mask-based Prediction in Indoor Scenarios for Bird's-Eye View Perception": "|**2025-7-23**|**IndoorBEV: Joint Detection and Footprint Completion of Objects via Mask-based Prediction in Indoor Scenarios for Bird's-Eye View Perception**|Haichuan Li et.al|[paper](https://arxiv.org/abs/2507.17445)|-|-|\n", "Dynamic-DINO: Fine-Grained Mixture of Experts Tuning for Real-time Open-Vocabulary Object Detection": "|**2025-7-23**|**Dynamic-DINO: Fine-Grained Mixture of Experts Tuning for Real-time Open-Vocabulary Object Detection**|Yehao Lu et.al|[paper](https://arxiv.org/abs/2507.17436)|-|<details><summary>detail</summary>Accepted by ICCV 2025</details>|\n", "SFUOD: Source-Free Unknown Object Detection": "|**2025-7-23**|**SFUOD: Source-Free Unknown Object Detection**|Keon-Hee Park et.al|[paper](https://arxiv.org/abs/2507.17373)|-|<details><summary>detail</summary>This paper has been accepted by ICCV 2025</details>|\n"}, "domain adaptation": {"SIDA: Synthetic Image Driven Zero-shot Domain Adaptation": "|**2025-7-24**|**SIDA: Synthetic Image Driven Zero-shot Domain Adaptation**|Ye-Chan Kim et.al|[paper](https://arxiv.org/abs/2507.18632)|-|<details><summary>detail</summary>ACM MM 2025</details>|\n", "crossMoDA Challenge: Evolution of Cross-Modality Domain Adaptation Techniques for Vestibular Schwannoma and Cochlea Segmentation from 2021 to 2023": "|**2025-7-24**|**crossMoDA Challenge: Evolution of Cross-Modality Domain Adaptation Techniques for Vestibular Schwannoma and Cochlea Segmentation from 2021 to 2023**|Navodini Wijethilake et.al|[paper](https://arxiv.org/abs/2506.12006)|-|-|\n", "Att-Adapter: A Robust and Precise Domain-Specific Multi-Attributes T2I Diffusion Adapter via Conditional Variational Autoencoder": "|**2025-7-24**|**Att-Adapter: A Robust and Precise Domain-Specific Multi-Attributes T2I Diffusion Adapter via Conditional Variational Autoencoder**|Wonwoong Cho et.al|[paper](https://arxiv.org/abs/2503.11937)|[code](https://tri-mac.github.io/att-adapter/)|<details><summary>detail</summary>ICCV'25 (Highlight)</details>|\n", "Unsupervised Domain Adaptation for 3D LiDAR Semantic Segmentation Using Contrastive Learning and Multi-Model Pseudo Labeling": "|**2025-7-24**|**Unsupervised Domain Adaptation for 3D LiDAR Semantic Segmentation Using Contrastive Learning and Multi-Model Pseudo Labeling**|Abhishek Kaushik et.al|[paper](https://arxiv.org/abs/2507.18176)|-|-|\n", "AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation": "|**2025-7-23**|**AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation**|Md. Al-Masrur Khan et.al|[paper](https://arxiv.org/abs/2507.17957)|[code](https://github.com/Masrur02/AFRDA)|-|\n", "ODES: Domain Adaptation with Expert Guidance for Online Medical Image Segmentation": "|**2025-7-23**|**ODES: Domain Adaptation with Expert Guidance for Online Medical Image Segmentation**|Md Shazid Islam et.al|[paper](https://arxiv.org/abs/2312.05407)|-|-|\n", "SDC-Net: A Domain Adaptation Framework with Semantic-Dynamic Consistency for Cross-Subject EEG Emotion Recognition": "|**2025-7-23**|**SDC-Net: A Domain Adaptation Framework with Semantic-Dynamic Consistency for Cross-Subject EEG Emotion Recognition**|Jiahao Tang et.al|[paper](https://arxiv.org/abs/2507.17524)|[code](https://github.com/XuanSuTrum/SDC-Net.)|-|\n", "Towards Railway Domain Adaptation for LiDAR-based 3D Detection: Road-to-Rail and Sim-to-Real via SynDRA-BBox": "|**2025-7-22**|**Towards Railway Domain Adaptation for LiDAR-based 3D Detection: Road-to-Rail and Sim-to-Real via SynDRA-BBox**|Xavier Diaz et.al|[paper](https://arxiv.org/abs/2507.16413)|[code](https://syndra.retis.santannapisa.it.)|<details><summary>detail</summary>IEEE International Conference on Intelligent Rail Transportation (ICIRT) 2025</details>|\n", "UPRE: Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement": "|**2025-7-21**|**UPRE: Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement**|Xiao Zhang et.al|[paper](https://arxiv.org/abs/2507.00721)|[code](https://github.com/AMAP-ML/UPRE.)|<details><summary>detail</summary>ICCV2025</details>|\n", "MORDA: A Synthetic Dataset to Facilitate Adaptation of Object Detectors to Unseen Real-target Domain While Preserving Performance on Real-source Domain": "|**2025-7-21**|**MORDA: A Synthetic Dataset to Facilitate Adaptation of Object Detectors to Unseen Real-target Domain While Preserving Performance on Real-source Domain**|Hojun Lim et.al|[paper](https://arxiv.org/abs/2501.04950)|-|-|\n", "PHATNet: A Physics-guided Haze Transfer Network for Domain-adaptive Real-world Image Dehazing": "|**2025-7-20**|**PHATNet: A Physics-guided Haze Transfer Network for Domain-adaptive Real-world Image Dehazing**|Fu-Jen Tsai et.al|[paper](https://arxiv.org/abs/2507.14826)|-|<details><summary>detail</summary>ICCV 2025</details>|\n", "Domain-Adaptive Small Language Models for Structured Tax Code Prediction": "|**2025-7-19**|**Domain-Adaptive Small Language Models for Structured Tax Code Prediction**|Souvik Nath et.al|[paper](https://arxiv.org/abs/2507.10880)|-|-|\n", "Fourier Domain Adaptation for Traffic Light Detection in Adverse Weather": "|**2025-7-19**|**Fourier Domain Adaptation for Traffic Light Detection in Adverse Weather**|Ishaan Gakhar et.al|[paper](https://arxiv.org/abs/2411.07901)|-|<details><summary>detail</summary>the 2COOOL Workshop</details>|\n", "When few labeled target data suffice: a theory of semi-supervised domain adaptation via fine-tuning from multiple adaptive starts": "|**2025-7-19**|**When few labeled target data suffice: a theory of semi-supervised domain adaptation via fine-tuning from multiple adaptive starts**|Wooseok Ha et.al|[paper](https://arxiv.org/abs/2507.14661)|-|-|\n", "SuperCM: Improving Semi-Supervised Learning and Domain Adaptation through differentiable clustering": "|**2025-7-18**|**SuperCM: Improving Semi-Supervised Learning and Domain Adaptation through differentiable clustering**|Durgesh Singh et.al|[paper](https://arxiv.org/abs/2507.13779)|-|<details><summary>detail</summary>Journal ref:Pattern Recognition 2025</details>|\n"}, "domain generalization": {"Omni-Thinker: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards": "|**2025-7-24**|**Omni-Thinker: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards**|Derek Li et.al|[paper](https://arxiv.org/abs/2507.14783)|-|-|\n", "VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks": "|**2025-7-24**|**VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks**|Juhwan Choi et.al|[paper](https://arxiv.org/abs/2407.19795)|-|<details><summary>detail</summary>ICCV 2025 Workshop on Curated Data for Efficient Learning (CDEL)</details>|\n", "Fully Automated SAM for Single-source Domain Generalization in Medical Image Segmentation": "|**2025-7-23**|**Fully Automated SAM for Single-source Domain Generalization in Medical Image Segmentation**|Huanli Zhuo et.al|[paper](https://arxiv.org/abs/2507.17281)|-|<details><summary>detail</summary>This manuscript has been accepted for presentation at the IEEE International Conference on Systems</details>|\n", "Gradient-Guided Annealing for Domain Generalization": "|**2025-7-21**|**Gradient-Guided Annealing for Domain Generalization**|Aristotelis Ballas et.al|[paper](https://arxiv.org/abs/2502.20162)|-|<details><summary>detail</summary>Paper accepted in CVPR2025</details>|\n", "DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation": "|**2025-7-20**|**DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation**|Bo Liu et.al|[paper](https://arxiv.org/abs/2501.03466)|-|-|\n", "Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification": "|**2025-7-19**|**Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification**|Subhendu Khatuya et.al|[paper](https://arxiv.org/abs/2506.06806)|-|<details><summary>detail</summary>This work has been accepted to appear at the Association for Computational Linguistics (ACL)</details>|\n", "Generative Multi-Target Cross-Domain Recommendation": "|**2025-7-17**|**Generative Multi-Target Cross-Domain Recommendation**|Jinqiu Jin et.al|[paper](https://arxiv.org/abs/2507.12871)|-|<details><summary>detail</summary>fix author information</details>|\n", "Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning": "|**2025-7-17**|**Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning**|Simon Ouellette et.al|[paper](https://arxiv.org/abs/2507.15877)|-|-|\n", "Addressing the ML Domain Adaptation Problem for Networking: Realistic and Controllable Training Data Generation with NetReplica": "|**2025-7-17**|**Addressing the ML Domain Adaptation Problem for Networking: Realistic and Controllable Training Data Generation with NetReplica**|Jaber Daneshamooz et.al|[paper](https://arxiv.org/abs/2507.13476)|-|-|\n", "CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings": "|**2025-7-17**|**CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings**|Daniil Orel et.al|[paper](https://arxiv.org/abs/2503.13733)|-|-|\n", "Generative AI Models for Learning Flow Maps of Stochastic Dynamical Systems in Bounded Domains": "|**2025-7-17**|**Generative AI Models for Learning Flow Maps of Stochastic Dynamical Systems in Bounded Domains**|Minglei Yang et.al|[paper](https://arxiv.org/abs/2507.15990)|-|-|\n", "A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints": "|**2025-7-17**|**A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints**|Youssef Tawfilis et.al|[paper](https://arxiv.org/abs/2507.12979)|[code](https://github.com/youssefga28/HuSCF-GAN.)|-|\n", "Simulate, Refocus and Ensemble: An Attention-Refocusing Scheme for Domain Generalization": "|**2025-7-17**|**Simulate, Refocus and Ensemble: An Attention-Refocusing Scheme for Domain Generalization**|Ziyi Wang et.al|[paper](https://arxiv.org/abs/2507.12851)|[code](https://github.com/bitPrincy/SRE-DG.)|<details><summary>detail</summary>\\c{opyright} 20XX IEEE</details>|\n", "Domain Generalization via Pareto Optimal Gradient Matching": "|**2025-7-16**|**Domain Generalization via Pareto Optimal Gradient Matching**|Khoi Do et.al|[paper](https://arxiv.org/abs/2507.14227)|-|-|\n", "Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation": "|**2025-7-15**|**Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation**|Siyu Chen et.al|[paper](https://arxiv.org/abs/2504.12753)|[code](https://github.com/anonymouse-xzrptkvyqc/DepthForge.)|<details><summary>detail</summary>Accepted by ICCV 2025</details>|\n"}, "vision language": {"DiagR1: A Vision-Language Model Trained via Reinforcement Learning for Digestive Pathology Diagnosis": "|**2025-7-24**|**DiagR1: A Vision-Language Model Trained via Reinforcement Learning for Digestive Pathology Diagnosis**|Minxi Ouyang et.al|[paper](https://arxiv.org/abs/2507.18433)|-|-|\n", "Personalization Toolkit: Training Free Personalization of Large Vision Language Models": "|**2025-7-24**|**Personalization Toolkit: Training Free Personalization of Large Vision Language Models**|Soroush Seifi et.al|[paper](https://arxiv.org/abs/2502.02452)|-|-|\n", "Improving Large Vision-Language Models' Understanding for Field Data": "|**2025-7-24**|**Improving Large Vision-Language Models' Understanding for Field Data**|Xiaomei Zhang et.al|[paper](https://arxiv.org/abs/2507.18311)|-|-|\n", "Aligning Vision to Language: Annotation-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning": "|**2025-7-24**|**Aligning Vision to Language: Annotation-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning**|Junming Liu et.al|[paper](https://arxiv.org/abs/2503.12972)|[code](https://github.com/Wings-Of-Disaster/VaLiK.)|-|\n", "VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks": "|**2025-7-24**|**VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks**|Juhwan Choi et.al|[paper](https://arxiv.org/abs/2407.19795)|-|<details><summary>detail</summary>ICCV 2025 Workshop on Curated Data for Efficient Learning (CDEL)</details>|\n", "EVEv2: Improved Baselines for Encoder-Free Vision-Language Models": "|**2025-7-24**|**EVEv2: Improved Baselines for Encoder-Free Vision-Language Models**|Haiwen Diao et.al|[paper](https://arxiv.org/abs/2502.06788)|[code](https://github.com/baaivision/EVE.)|-|\n", "ViLU: Learning Vision-Language Uncertainties for Failure Prediction": "|**2025-7-24**|**ViLU: Learning Vision-Language Uncertainties for Failure Prediction**|Marc Lafon et.al|[paper](https://arxiv.org/abs/2507.07620)|[code](https://github.com/ykrmm/ViLU.)|<details><summary>detail</summary>Journal ref:International Conference on Computer Vision</details>|\n", "When Large Vision-Language Model Meets Large Remote Sensing Imagery: Coarse-to-Fine Text-Guided Token Pruning": "|**2025-7-24**|**When Large Vision-Language Model Meets Large Remote Sensing Imagery: Coarse-to-Fine Text-Guided Token Pruning**|Junwei Luo et.al|[paper](https://arxiv.org/abs/2503.07588)|[code](https://github.com/VisionXLab/LRS-VQA.)|-|\n", "RECALLED: An Unbounded Resource Consumption Attack on Large Vision-Language Models": "|**2025-7-23**|**RECALLED: An Unbounded Resource Consumption Attack on Large Vision-Language Models**|Haoran Gao et.al|[paper](https://arxiv.org/abs/2507.18053)|-|-|\n", "ViGText: Deepfake Image Detection with Vision-Language Model Explanations and Graph Neural Networks": "|**2025-7-23**|**ViGText: Deepfake Image Detection with Vision-Language Model Explanations and Graph Neural Networks**|Ahmad ALBarqawi et.al|[paper](https://arxiv.org/abs/2507.18031)|-|-|\n", "Analyzing Fairness of Computer Vision and Natural Language Processing Models": "|**2025-7-23**|**Analyzing Fairness of Computer Vision and Natural Language Processing Models**|Ahmed Rashed et.al|[paper](https://arxiv.org/abs/2412.09900)|-|-|\n", "InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation": "|**2025-7-23**|**InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation**|Shuai Yang et.al|[paper](https://arxiv.org/abs/2507.17520)|-|-|\n", "Probing Vision-Language Understanding through the Visual Entailment Task: promises and pitfalls": "|**2025-7-23**|**Probing Vision-Language Understanding through the Visual Entailment Task: promises and pitfalls**|Elena Pitta et.al|[paper](https://arxiv.org/abs/2507.17467)|-|<details><summary>detail</summary>LUHME: 2nd Workshop on Language Understanding in the Human-Machine Era</details>|\n", "AirCache: Activating Inter-modal Relevancy KV Cache Compression for Efficient Large Vision-Language Model Inference": "|**2025-7-23**|**AirCache: Activating Inter-modal Relevancy KV Cache Compression for Efficient Large Vision-Language Model Inference**|Kai Huang et.al|[paper](https://arxiv.org/abs/2503.23956)|-|-|\n", "Confidence Calibration in Vision-Language-Action Models": "|**2025-7-23**|**Confidence Calibration in Vision-Language-Action Models**|Thomas P Zollo et.al|[paper](https://arxiv.org/abs/2507.17383)|-|-|\n"}}