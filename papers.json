{"source-free": {"Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based Curriculum Learning": "|**2026-1-5**|**Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based Curriculum Learning**|Dongjie Chen et.al|[paper](https://arxiv.org/abs/2405.18376)|[code](https://github.com/Dong-Jie-Chen/RCL.)|-|\n", "Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results": "|**2025-12-28**|**Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results**|Rohan Palanikumar et.al|[paper](https://arxiv.org/abs/2511.00752)|-|-|\n", "Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection": "|**2025-12-24**|**Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection**|Sairam VCR et.al|[paper](https://arxiv.org/abs/2512.17514)|-|-|\n", "Exploiting Radio Frequency Fingerprints for Device Identification: Tackling Cross-receiver Challenges in the Source-data-free Scenario": "|**2025-12-18**|**Exploiting Radio Frequency Fingerprints for Device Identification: Tackling Cross-receiver Challenges in the Source-data-free Scenario**|Liu Yang et.al|[paper](https://arxiv.org/abs/2512.16648)|-|<details><summary>detail</summary>IEEE Transactions on Mobile Computing</details>|\n", "VocSim: A Training-free Benchmark for Zero-shot Content Identity in Single-source Audio": "|**2025-12-10**|**VocSim: A Training-free Benchmark for Zero-shot Content Identity in Single-source Audio**|Maris Basha et.al|[paper](https://arxiv.org/abs/2512.10120)|-|-|\n", "FedSCAl: Leveraging Server and Client Alignment for Unsupervised Federated Source-Free Domain Adaptation": "|**2025-12-7**|**FedSCAl: Leveraging Server and Client Alignment for Unsupervised Federated Source-Free Domain Adaptation**|M Yashwanth et.al|[paper](https://arxiv.org/abs/2512.06738)|-|<details><summary>detail</summary>Winter Conference on Applications of Computer Vision (WACV) 2026</details>|\n", "Source-free Video Domain Adaptation by Learning from Noisy Labels": "|**2025-11-28**|**Source-free Video Domain Adaptation by Learning from Noisy Labels**|Avijit Dasgupta et.al|[paper](https://arxiv.org/abs/2311.18572)|[code](https://avijit9.github.io/CleanAdapt.)|<details><summary>detail</summary>Our extended ICVGIP paper is now accepted in Pattern Recognition</details>|\n", "Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation": "|**2025-11-24**|**Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation**|Huisoo Lee et.al|[paper](https://arxiv.org/abs/2511.19147)|-|-|\n", "Unsupervised and Source-Free Ranking of Biomedical Segmentation Models": "|**2025-11-24**|**Unsupervised and Source-Free Ranking of Biomedical Segmentation Models**|Joshua Talks et.al|[paper](https://arxiv.org/abs/2503.00450)|-|-|\n", "SloMo-Fast: Slow-Momentum and Fast-Adaptive Teachers for Source-Free Continual Test-Time Adaptation": "|**2025-11-23**|**SloMo-Fast: Slow-Momentum and Fast-Adaptive Teachers for Source-Free Continual Test-Time Adaptation**|Md Akil Raihan Iftee et.al|[paper](https://arxiv.org/abs/2511.18468)|-|-|\n", "ViMix-14M: A Curated Multi-Source Video-Text Dataset with Long-Form, High-Quality Captions and Crawl-Free Access": "|**2025-11-23**|**ViMix-14M: A Curated Multi-Source Video-Text Dataset with Long-Form, High-Quality Captions and Crawl-Free Access**|Timing Yang et.al|[paper](https://arxiv.org/abs/2511.18382)|-|-|\n", "HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for Cross-Modality Medical Image Segmentation": "|**2025-11-22**|**HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for Cross-Modality Medical Image Segmentation**|Yulong Shi et.al|[paper](https://arxiv.org/abs/2511.17958)|[code](https://github.com/derekshiii/HEAL.)|<details><summary>detail</summary>Accepted by The 36th British Machine Vision Conference (BMVC 2025)</details>|\n", "Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation": "|**2025-11-19**|**Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation**|Yaxuan Song et.al|[paper](https://arxiv.org/abs/2402.06213)|[code](https://github.com/YXSong000/UAD.)|<details><summary>detail</summary>Accepted by ISBI 2024</details>|\n", "Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection": "|**2025-11-10**|**Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2511.07301)|-|<details><summary>detail</summary>AAAI 2026</details>|\n", "Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping": "|**2025-11-5**|**Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping**|Zhihang Qin et.al|[paper](https://arxiv.org/abs/2511.03691)|-|-|\n"}, "object detection": {"From Dataset to Real-world: General 3D Object Detection via Generalized Cross-domain Few-shot Learning": "|**2026-1-7**|**From Dataset to Real-world: General 3D Object Detection via Generalized Cross-domain Few-shot Learning**|Shuangzhi Li et.al|[paper](https://arxiv.org/abs/2503.06282)|-|<details><summary>detail</summary>The latest version refines the few-shot setting on common classes</details>|\n", "Few-Shot LoRA Adaptation of a Flow-Matching Foundation Model for Cross-Spectral Object Detection": "|**2026-1-7**|**Few-Shot LoRA Adaptation of a Flow-Matching Foundation Model for Cross-Spectral Object Detection**|Maxim Clouser et.al|[paper](https://arxiv.org/abs/2601.04381)|-|-|\n", "SortWaste: A Densely Annotated Dataset for Object Detection in Industrial Waste Sorting": "|**2026-1-7**|**SortWaste: A Densely Annotated Dataset for Object Detection in Industrial Waste Sorting**|Sara In\u00e1cio et.al|[paper](https://arxiv.org/abs/2601.02299)|-|-|\n", "Correcting Autonomous Driving Object Detection Misclassifications with Automated Commonsense Reasoning": "|**2026-1-7**|**Correcting Autonomous Driving Object Detection Misclassifications with Automated Commonsense Reasoning**|Keegan Kimbrell et.al|[paper](https://arxiv.org/abs/2601.04271)|-|<details><summary>detail</summary>In Proceedings ICLP 2025</details>|\n", "HyperCOD: The First Challenging Benchmark and Baseline for Hyperspectral Camouflaged Object Detection": "|**2026-1-7**|**HyperCOD: The First Challenging Benchmark and Baseline for Hyperspectral Camouflaged Object Detection**|Shuyan Bai et.al|[paper](https://arxiv.org/abs/2601.03736)|-|-|\n", "D^3ETOR: Debate-Enhanced Pseudo Labeling and Frequency-Aware Progressive Debiasing for Weakly-Supervised Camouflaged Object Detection with Scribble Annotations": "|**2026-1-6**|**D^3ETOR: Debate-Enhanced Pseudo Labeling and Frequency-Aware Progressive Debiasing for Weakly-Supervised Camouflaged Object Detection with Scribble Annotations**|Jiawei Ge et.al|[paper](https://arxiv.org/abs/2512.20260)|-|-|\n", "Towards Efficient 3D Object Detection for Vehicle-Infrastructure Collaboration via Risk-Intent Selection": "|**2026-1-6**|**Towards Efficient 3D Object Detection for Vehicle-Infrastructure Collaboration via Risk-Intent Selection**|Li Wang et.al|[paper](https://arxiv.org/abs/2601.03001)|-|-|\n", "DGA-Net: Enhancing SAM with Depth Prompting and Graph-Anchor Guidance for Camouflaged Object Detection": "|**2026-1-6**|**DGA-Net: Enhancing SAM with Depth Prompting and Graph-Anchor Guidance for Camouflaged Object Detection**|Yuetong Li et.al|[paper](https://arxiv.org/abs/2601.02831)|-|-|\n", "D$^3$R-DETR: DETR with Dual-Domain Density Refinement for Tiny Object Detection in Aerial Images": "|**2026-1-6**|**D$^3$R-DETR: DETR with Dual-Domain Density Refinement for Tiny Object Detection in Aerial Images**|Zixiao Wen et.al|[paper](https://arxiv.org/abs/2601.02747)|-|<details><summary>detail</summary>This work has been submitted to the IEEE for possible publication</details>|\n", "CT Scans As Video: Efficient Intracranial Hemorrhage Detection Using Multi-Object Tracking": "|**2026-1-5**|**CT Scans As Video: Efficient Intracranial Hemorrhage Detection Using Multi-Object Tracking**|Amirreza Parvahan et.al|[paper](https://arxiv.org/abs/2601.02521)|-|-|\n", "SLGNet: Synergizing Structural Priors and Language-Guided Modulation for Multimodal Object Detection": "|**2026-1-5**|**SLGNet: Synergizing Structural Priors and Language-Guided Modulation for Multimodal Object Detection**|Xiantai Xiang et.al|[paper](https://arxiv.org/abs/2601.02249)|-|-|\n", "Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach": "|**2026-1-5**|**Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach**|Matthias Bartolo et.al|[paper](https://arxiv.org/abs/2601.02016)|[code](https://github.com/mbar0075/lupi-for-object-detection)|<details><summary>detail</summary>Code available on GitHub: https://github</details>|\n", "DGE-YOLO: Dual-Branch Gathering and Attention for Accurate UAV Object Detection": "|**2026-1-4**|**DGE-YOLO: Dual-Branch Gathering and Attention for Accurate UAV Object Detection**|Kunwei Lv et.al|[paper](https://arxiv.org/abs/2506.23252)|-|-|\n", "RFAssigner: A Generic Label Assignment Strategy for Dense Object Detection": "|**2026-1-3**|**RFAssigner: A Generic Label Assignment Strategy for Dense Object Detection**|Ziqian Guan et.al|[paper](https://arxiv.org/abs/2601.01240)|-|-|\n", "Mono3DV: Monocular 3D Object Detection with 3D-Aware Bipartite Matching and Variational Query DeNoising": "|**2026-1-2**|**Mono3DV: Monocular 3D Object Detection with 3D-Aware Bipartite Matching and Variational Query DeNoising**|Kiet Dang Vu et.al|[paper](https://arxiv.org/abs/2601.01036)|-|-|\n"}, "domain adaptation": {"LELA: an LLM-based Entity Linking Approach with Zero-Shot Domain Adaptation": "|**2026-1-8**|**LELA: an LLM-based Entity Linking Approach with Zero-Shot Domain Adaptation**|Samy Haffoudhi et.al|[paper](https://arxiv.org/abs/2601.05192)|-|-|\n", "Towards Real-world Lens Active Alignment with Unlabeled Data via Domain Adaptation": "|**2026-1-7**|**Towards Real-world Lens Active Alignment with Unlabeled Data via Domain Adaptation**|Wenyong Li et.al|[paper](https://arxiv.org/abs/2601.03718)|-|-|\n", "Causally-Aware Information Bottleneck for Domain Adaptation": "|**2026-1-7**|**Causally-Aware Information Bottleneck for Domain Adaptation**|Mohammad Ali Javidian et.al|[paper](https://arxiv.org/abs/2601.04361)|-|<details><summary>detail</summary>An extended abstract version of this work was accepted for the Proceedings of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)</details>|\n", "Domain Adaptation of the Pyannote Diarization Pipeline for Conversational Indonesian Audio": "|**2026-1-7**|**Domain Adaptation of the Pyannote Diarization Pipeline for Conversational Indonesian Audio**|Muhammad Daffa'i Rafi Prasetyo et.al|[paper](https://arxiv.org/abs/2601.03684)|-|<details><summary>detail</summary>Experiments conducted using synthetic Indonesian conversational speech for domain adaptation</details>|\n", "An Expectation-Maximization Algorithm for Domain Adaptation in Gaussian Causal Models": "|**2026-1-6**|**An Expectation-Maximization Algorithm for Domain Adaptation in Gaussian Causal Models**|Mohammad Ali Javidian et.al|[paper](https://arxiv.org/abs/2601.03459)|-|<details><summary>detail</summary>An earlier version of this work was accepted for the Proceedings of the 2025 IEEE International Conference on Data Mining (ICDM)</details>|\n", "Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based Curriculum Learning": "|**2026-1-5**|**Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based Curriculum Learning**|Dongjie Chen et.al|[paper](https://arxiv.org/abs/2405.18376)|[code](https://github.com/Dong-Jie-Chen/RCL.)|-|\n", "TopoLoRA-SAM: Topology-Aware Parameter-Efficient Adaptation of Foundation Segmenters for Thin-Structure and Cross-Domain Binary Semantic Segmentation": "|**2026-1-5**|**TopoLoRA-SAM: Topology-Aware Parameter-Efficient Adaptation of Foundation Segmenters for Thin-Structure and Cross-Domain Binary Semantic Segmentation**|Salim Khazem et.al|[paper](https://arxiv.org/abs/2601.02273)|[code](https://github.com/salimkhazem/Seglab.git)|-|\n", "Parameter-Efficient Domain Adaption for CSI Crowd-Counting via Self-Supervised Learning with Adapter Modules": "|**2026-1-5**|**Parameter-Efficient Domain Adaption for CSI Crowd-Counting via Self-Supervised Learning with Adapter Modules**|Oliver Custance et.al|[paper](https://arxiv.org/abs/2601.02203)|-|-|\n", "Domain Adaptation of Carotid Ultrasound Images using Generative Adversarial Network": "|**2026-1-4**|**Domain Adaptation of Carotid Ultrasound Images using Generative Adversarial Network**|Mohd Usama et.al|[paper](https://arxiv.org/abs/2601.01460)|-|-|\n", "In defense of the two-stage framework for open-set domain adaptive semantic segmentation": "|**2026-1-4**|**In defense of the two-stage framework for open-set domain adaptive semantic segmentation**|Wenqi Ren et.al|[paper](https://arxiv.org/abs/2601.01439)|-|-|\n", "Damba-ST: Domain-Adaptive Mamba for Efficient Urban Spatio-Temporal Prediction": "|**2026-1-3**|**Damba-ST: Domain-Adaptive Mamba for Efficient Urban Spatio-Temporal Prediction**|Rui An et.al|[paper](https://arxiv.org/abs/2506.18939)|-|<details><summary>detail</summary>Accepted by ICDE 2026</details>|\n", "CTTA-T: Continual Test-Time Adaptation for Text Understanding via Teacher-Student with a Domain-aware and Generalized Teacher": "|**2026-1-1**|**CTTA-T: Continual Test-Time Adaptation for Text Understanding via Teacher-Student with a Domain-aware and Generalized Teacher**|Tianlun Liu et.al|[paper](https://arxiv.org/abs/2512.18321)|-|-|\n", "IntraStyler: Exemplar-based Style Synthesis for Cross-modality Domain Adaptation": "|**2026-1-1**|**IntraStyler: Exemplar-based Style Synthesis for Cross-modality Domain Adaptation**|Han Liu et.al|[paper](https://arxiv.org/abs/2601.00212)|[code](https://github.com/han-liu/IntraStyler.)|<details><summary>detail</summary>Extension of our 1st place solution for the CrossMoDA 2023 challenge</details>|\n", "Semi-Supervised Diversity-Aware Domain Adaptation for 3D Object detection": "|**2025-12-31**|**Semi-Supervised Diversity-Aware Domain Adaptation for 3D Object detection**|Bart\u0142omiej Olber et.al|[paper](https://arxiv.org/abs/2512.24922)|-|-|\n", "ExPLoRA: Parameter-Efficient Extended Pre-Training to Adapt Vision Transformers under Domain Shifts": "|**2025-12-30**|**ExPLoRA: Parameter-Efficient Extended Pre-Training to Adapt Vision Transformers under Domain Shifts**|Samar Khanna et.al|[paper](https://arxiv.org/abs/2406.10973)|[code](https://samar-khanna.github.io/ExPLoRA/)|<details><summary>detail</summary>Published at ICML 2025</details>|\n"}, "domain generalization": {"Learning from Mistakes: Negative Reasoning Samples Enhance Out-of-Domain Generalization": "|**2026-1-8**|**Learning from Mistakes: Negative Reasoning Samples Enhance Out-of-Domain Generalization**|Xueyun Tian et.al|[paper](https://arxiv.org/abs/2601.04992)|[code](https://github.com/Eureka-Maggie/GLOW)|<details><summary>detail</summary>Code and data are available at https://github</details>|\n", "RiskAtlas: Exposing Domain-Specific Risks in LLMs through Knowledge-Graph-Guided Harmful Prompt Generation": "|**2026-1-8**|**RiskAtlas: Exposing Domain-Specific Risks in LLMs through Knowledge-Graph-Guided Harmful Prompt Generation**|Huawei Zheng et.al|[paper](https://arxiv.org/abs/2601.04740)|-|-|\n", "From Dataset to Real-world: General 3D Object Detection via Generalized Cross-domain Few-shot Learning": "|**2026-1-7**|**From Dataset to Real-world: General 3D Object Detection via Generalized Cross-domain Few-shot Learning**|Shuangzhi Li et.al|[paper](https://arxiv.org/abs/2503.06282)|-|<details><summary>detail</summary>The latest version refines the few-shot setting on common classes</details>|\n", "Complex Domain Approach for Reversible Data Hiding and Homomorphic Encryption: General Framework and Application to Dispersed Data": "|**2026-1-7**|**Complex Domain Approach for Reversible Data Hiding and Homomorphic Encryption: General Framework and Application to Dispersed Data**|David Megias et.al|[paper](https://arxiv.org/abs/2510.03770)|-|-|\n", "Mitigating Label Noise using Prompt-Based Hyperbolic Meta-Learning in Open-Set Domain Generalization": "|**2026-1-7**|**Mitigating Label Noise using Prompt-Based Hyperbolic Meta-Learning in Open-Set Domain Generalization**|Kunyu Peng et.al|[paper](https://arxiv.org/abs/2412.18342)|[code](https://github.com/KPeng9510/HyProMeta.)|<details><summary>detail</summary>International Journal of Computer Vision (IJCV)</details>|\n", "Personalized Medication Planning via Direct Domain Modeling and LLM-Generated Heuristics": "|**2026-1-7**|**Personalized Medication Planning via Direct Domain Modeling and LLM-Generated Heuristics**|Yonatan Vernik et.al|[paper](https://arxiv.org/abs/2601.03687)|-|-|\n", "From Chains to Graphs: Self-Structured Reasoning for General-Domain LLMs": "|**2026-1-7**|**From Chains to Graphs: Self-Structured Reasoning for General-Domain LLMs**|Yingjian Chen et.al|[paper](https://arxiv.org/abs/2601.03597)|-|-|\n", "Reinforcement Learning for Tool-Integrated Interleaved Thinking towards Cross-Domain Generalization": "|**2026-1-6**|**Reinforcement Learning for Tool-Integrated Interleaved Thinking towards Cross-Domain Generalization**|Zhengyu Chen et.al|[paper](https://arxiv.org/abs/2510.11184)|-|-|\n", "Domain Generalization for Time Series: Enhancing Drilling Regression Models for Stick-Slip Index Prediction": "|**2026-1-6**|**Domain Generalization for Time Series: Enhancing Drilling Regression Models for Stick-Slip Index Prediction**|Hana Yahia et.al|[paper](https://arxiv.org/abs/2601.02884)|-|<details><summary>detail</summary>Journal ref:Transactions on Machine Learning Research Journal</details>|\n", "XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging": "|**2026-1-5**|**XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging**|Midhat Urooj et.al|[paper](https://arxiv.org/abs/2601.02008)|-|<details><summary>detail</summary>AAAI Bridge Program 2026</details>|\n", "SerpentFlow: Generative Unpaired Domain Alignment via Shared-Structure Decomposition": "|**2026-1-5**|**SerpentFlow: Generative Unpaired Domain Alignment via Shared-Structure Decomposition**|Julie Keisler et.al|[paper](https://arxiv.org/abs/2601.01979)|-|-|\n", "HCVP: Leveraging Hierarchical Contrastive Visual Prompt for Domain Generalization": "|**2026-1-4**|**HCVP: Leveraging Hierarchical Contrastive Visual Prompt for Domain Generalization**|Guanglin Zhou et.al|[paper](https://arxiv.org/abs/2401.09716)|-|-|\n", "Higher-Order Domain Generalization in Magnetic Resonance-Based Assessment of Alzheimer's Disease": "|**2026-1-4**|**Higher-Order Domain Generalization in Magnetic Resonance-Based Assessment of Alzheimer's Disease**|Zobia Batool et.al|[paper](https://arxiv.org/abs/2601.01485)|[code](https://github.com/zobia111/Extended-Mixstyle.)|-|\n", "Domain Adaptation of Carotid Ultrasound Images using Generative Adversarial Network": "|**2026-1-4**|**Domain Adaptation of Carotid Ultrasound Images using Generative Adversarial Network**|Mohd Usama et.al|[paper](https://arxiv.org/abs/2601.01460)|-|-|\n", "RaffeSDG: Random Frequency Filtering enabled Single-source Domain Generalization for Medical Image Segmentation": "|**2026-1-3**|**RaffeSDG: Random Frequency Filtering enabled Single-source Domain Generalization for Medical Image Segmentation**|Heng Li et.al|[paper](https://arxiv.org/abs/2405.01228)|[code](https://github.com/liamheng/Non-IID_Medical_Image_Segmentation.)|-|\n"}, "vision language": {"Mechanisms of Prompt-Induced Hallucination in Vision-Language Models": "|**2026-1-8**|**Mechanisms of Prompt-Induced Hallucination in Vision-Language Models**|William Rudman et.al|[paper](https://arxiv.org/abs/2601.05201)|-|<details><summary>detail</summary>ACM Class:I</details>|\n", "MVT: Mask-Grounded Vision-Language Models for Taxonomy-Aligned Land-Cover Tagging": "|**2026-1-8**|**MVT: Mask-Grounded Vision-Language Models for Taxonomy-Aligned Land-Cover Tagging**|Siyi Chen et.al|[paper](https://arxiv.org/abs/2509.18693)|[code](https://charlescsyyy.github.io/MVT)|<details><summary>detail</summary>The project is available at https://charlescsyyy</details>|\n", "Vision-Language Introspection: Mitigating Overconfident Hallucinations in MLLMs via Interpretable Bi-Causal Steering": "|**2026-1-8**|**Vision-Language Introspection: Mitigating Overconfident Hallucinations in MLLMs via Interpretable Bi-Causal Steering**|Shuliang Liu et.al|[paper](https://arxiv.org/abs/2601.05159)|-|-|\n", "A Lightweight and Explainable Vision-Language Framework for Crop Disease Visual Question Answering": "|**2026-1-8**|**A Lightweight and Explainable Vision-Language Framework for Crop Disease Visual Question Answering**|Md. Zahid Hossain et.al|[paper](https://arxiv.org/abs/2601.05143)|-|<details><summary>detail</summary>Preprint</details>|\n", ": A Vision-Language-Action Flow Model for General Robot Control": "|**2026-1-8**|**: A Vision-Language-Action Flow Model for General Robot Control**|Kevin Black et.al|[paper](https://arxiv.org/abs/2410.24164)|[code](https://physicalintelligence.company/blog/pi0)|<details><summary>detail</summary>See project website for videos: https://physicalintelligence</details>|\n", "POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering": "|**2026-1-8**|**POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering**|Yichen Xu et.al|[paper](https://arxiv.org/abs/2507.11939)|-|<details><summary>detail</summary>Work in Progress</details>|\n", "From Understanding to Engagement: Personalized pharmacy Video Clips via Vision Language Models (VLMs)": "|**2026-1-8**|**From Understanding to Engagement: Personalized pharmacy Video Clips via Vision Language Models (VLMs)**|Suyash Mishra et.al|[paper](https://arxiv.org/abs/2601.05059)|-|<details><summary>detail</summary>Contributed original research to top tier conference in VLM</details>|\n", "Scaling Vision Language Models for Pharmaceutical Long Form Video Reasoning on Industrial GenAI Platform": "|**2026-1-8**|**Scaling Vision Language Models for Pharmaceutical Long Form Video Reasoning on Industrial GenAI Platform**|Suyash Mishra et.al|[paper](https://arxiv.org/abs/2601.04891)|-|<details><summary>detail</summary>Submitted to the Industry Track of Top Tier Conference</details>|\n", "ImagineNav++: Prompting Vision-Language Models as Embodied Navigator through Scene Imagination": "|**2026-1-8**|**ImagineNav++: Prompting Vision-Language Models as Embodied Navigator through Scene Imagination**|Teng Wang et.al|[paper](https://arxiv.org/abs/2512.17435)|-|-|\n", "Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization": "|**2026-1-8**|**Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization**|Jiwei Guan et.al|[paper](https://arxiv.org/abs/2601.01747)|-|<details><summary>detail</summary>EACL</details>|\n", "Skeletonization-Based Adversarial Perturbations on Large Vision Language Model's Mathematical Text Recognition": "|**2026-1-8**|**Skeletonization-Based Adversarial Perturbations on Large Vision Language Model's Mathematical Text Recognition**|Masatomo Yoshida et.al|[paper](https://arxiv.org/abs/2601.04752)|-|<details><summary>detail</summary>accepted to ITC-CSCC 2025</details>|\n", "RoboReward: General-Purpose Vision-Language Reward Models for Robotics": "|**2026-1-8**|**RoboReward: General-Purpose Vision-Language Reward Models for Robotics**|Tony Lee et.al|[paper](https://arxiv.org/abs/2601.00675)|[code](https://crfm.stanford.edu/helm/robo-reward-bench)|-|\n", "SeqWalker: Sequential-Horizon Vision-and-Language Navigation with Hierarchical Planning": "|**2026-1-8**|**SeqWalker: Sequential-Horizon Vision-and-Language Navigation with Hierarchical Planning**|Zebin Han et.al|[paper](https://arxiv.org/abs/2601.04699)|-|-|\n", "Agri-R1: Empowering Generalizable Agricultural Reasoning in Vision-Language Models with Reinforcement Learning": "|**2026-1-8**|**Agri-R1: Empowering Generalizable Agricultural Reasoning in Vision-Language Models with Reinforcement Learning**|Wentao Zhang et.al|[paper](https://arxiv.org/abs/2601.04672)|-|<details><summary>detail</summary>This paper is submitted for review to ACL 2026</details>|\n", "GeoReason: Aligning Thinking And Answering In Remote Sensing Vision-Language Models Via Logical Consistency Reinforcement Learning": "|**2026-1-8**|**GeoReason: Aligning Thinking And Answering In Remote Sensing Vision-Language Models Via Logical Consistency Reinforcement Learning**|Wenshuai Li et.al|[paper](https://arxiv.org/abs/2601.04118)|-|-|\n"}}