{"source-free": {"Trust your Good Friends: Source-free Domain Adaptation by Reciprocal Neighborhood Clustering": "|**2023-9-1**|**Trust your Good Friends: Source-free Domain Adaptation by Reciprocal Neighborhood Clustering**|Shiqi Yanget.al|[paper](https://arxiv.org/abs/2309.00528)|-|<details><summary>detail</summary>Accepted by IEEE TPAMI</details>|\n", "Uncertainty-Aware Source-Free Adaptive Image Super-Resolution with Wavelet Augmentation Transformer": "|**2023-8-30**|**Uncertainty-Aware Source-Free Adaptive Image Super-Resolution with Wavelet Augmentation Transformer**|Yuang Aiet.al|[paper](https://arxiv.org/abs/2303.17783)|-|-|\n", "Local-Global Pseudo-label Correction for Source-free Domain Adaptive Medical Image Segmentation": "|**2023-8-28**|**Local-Global Pseudo-label Correction for Source-free Domain Adaptive Medical Image Segmentation**|Yanyu Yeet.al|[paper](https://arxiv.org/abs/2308.14312)|-|-|\n", "Domain-Specificity Inducing Transformers for Source-Free Domain Adaptation": "|**2023-8-27**|**Domain-Specificity Inducing Transformers for Source-Free Domain Adaptation**|Sunandini Sanyalet.al|[paper](https://arxiv.org/abs/2308.14023)|[code](http://val.cds.iisc.ac.in/DSiT-SFDA)|<details><summary>detail</summary>ICCV 2023</details>|\n", "Prior-guided Source-free Domain Adaptation for Human Pose Estimation": "|**2023-8-26**|**Prior-guided Source-free Domain Adaptation for Human Pose Estimation**|Dripta S. Raychaudhuriet.al|[paper](https://arxiv.org/abs/2308.13954)|-|<details><summary>detail</summary>ICCV 2023</details>|\n", "Rethinking the Role of Pre-Trained Networks in Source-Free Domain Adaptation": "|**2023-8-25**|**Rethinking the Role of Pre-Trained Networks in Source-Free Domain Adaptation**|Wenyu Zhanget.al|[paper](https://arxiv.org/abs/2212.07585)|-|<details><summary>detail</summary>ICCV 2023</details>|\n", "Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis": "|**2023-8-23**|**Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis**|Yuqi Fanget.al|[paper](https://arxiv.org/abs/2308.12495)|-|-|\n", "Black-box Source-free Domain Adaptation via Two-stage Knowledge Distillation": "|**2023-8-23**|**Black-box Source-free Domain Adaptation via Two-stage Knowledge Distillation**|Shuai Wanget.al|[paper](https://arxiv.org/abs/2305.07881)|-|<details><summary>detail</summary>The short version is accepted by IJCAI 1st International Workshop on Generalizing from Limited Resources in the Open World</details>|\n", "SUMMIT: Source-Free Adaptation of Uni-Modal Models to Multi-Modal Targets": "|**2023-8-22**|**SUMMIT: Source-Free Adaptation of Uni-Modal Models to Multi-Modal Targets**|Cody Simonset.al|[paper](https://arxiv.org/abs/2308.11880)|[code](https://github.com/csimo005/SUMMIT.)|-|\n", "The Unreasonable Effectiveness of Large Language-Vision Models for Source-free Video Domain Adaptation": "|**2023-8-22**|**The Unreasonable Effectiveness of Large Language-Vision Models for Source-free Video Domain Adaptation**|Giacomo Zaraet.al|[paper](https://arxiv.org/abs/2308.09139)|[code](https://github.com/giaczara/dallv)|<details><summary>detail</summary>ICCV2023</details>|\n", "COCA: Classifier-Oriented Calibration for Source-Free Universal Domain Adaptation via Textual Prototype": "|**2023-8-20**|**COCA: Classifier-Oriented Calibration for Source-Free Universal Domain Adaptation via Textual Prototype**|Xinghong Liuet.al|[paper](https://arxiv.org/abs/2308.10450)|-|-|\n", "Source-free Domain Adaptive Human Pose Estimation": "|**2023-8-18**|**Source-free Domain Adaptive Human Pose Estimation**|Qucheng Penget.al|[paper](https://arxiv.org/abs/2308.03202)|[code](https://github.com/davidpengucf/SFDAHPE.)|<details><summary>detail</summary>Accepted by ICCV 2023</details>|\n", "Source-free Depth for Object Pop-out": "|**2023-8-16**|**Source-free Depth for Object Pop-out**|Zongwei Wuet.al|[paper](https://arxiv.org/abs/2212.05370)|-|<details><summary>detail</summary>ICCV 2023</details>|\n", "Context-Aware Pseudo-Label Refinement for Source-Free Domain Adaptive Fundus Image Segmentation": "|**2023-8-15**|**Context-Aware Pseudo-Label Refinement for Source-Free Domain Adaptive Fundus Image Segmentation**|Zheang Huaiet.al|[paper](https://arxiv.org/abs/2308.07731)|[code](https://github.com/xmed-lab/CPR.)|<details><summary>detail</summary>Accepted by MICCAI 2023</details>|\n", "PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization": "|**2023-8-15**|**PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization**|Junhyeong Choet.al|[paper](https://arxiv.org/abs/2307.15199)|[code](https://promptstyler.github.io/)|<details><summary>detail</summary>ICCV 2023</details>|\n", "In Search for a Generalizable Method for Source Free Domain Adaptation": "|**2023-8-31**|**In Search for a Generalizable Method for Source Free Domain Adaptation**|M Boudiaf et.al|[paper](https://arxiv.org/abs/2302.06658)|[code](https://paperswithcode.com/paper/in-search-for-a-generalizable-method-for)|-|\n", "MAPS: A Noise-Robust Progressive Learning Approach for Source-Free Domain Adaptive Keypoint Detection": "|**2023-8-28**|**MAPS: A Noise-Robust Progressive Learning Approach for Source-Free Domain Adaptive Keypoint Detection**|Y Ding et.al|[paper](https://arxiv.org/abs/2302.04589)|[code](https://github.com/yuhed/maps)|-|\n", "Universal source-free domain adaptation method for cross-domain fault diagnosis of machines": "|**2023-8-21**|**Universal source-free domain adaptation method for cross-domain fault diagnosis of machines**|Y Zhang et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0888327023000663)|-|<details><summary>detail</summary>Mechanical Systems and\u00a0\u2026, 2023 Elsevier</details>|\n", "Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation": "|**2023-8-19**|**Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation**|Y Chen et.al|[paper](https://arxiv.org/abs/2301.13428)|[code](https://github.com/yukilulu/cac)|-|\n", "TIDo: Source-free Task Incremental Learning in Non-stationary Environments": "|**2023-8-15**|**TIDo: Source-free Task Incremental Learning in Non-stationary Environments**|AK Ambastha et.al|[paper](https://arxiv.org/abs/2301.12055)|[code](https://paperswithcode.com/paper/tido-source-free-task-incremental-learning-in)|-|\n", "Adversarial Learning Networks: Source-free Unsupervised Domain Incremental Learning": "|**2023-8-15**|**Adversarial Learning Networks: Source-free Unsupervised Domain Incremental Learning**|AK Ambastha et.al|[paper](https://arxiv.org/abs/2301.12054)|[code](https://paperswithcode.com/paper/adversarial-learning-networks-source-free)|-|\n", "Cross-platform privacy-preserving CT image COVID-19 diagnosis based on source-free domain adaptation": "|**2023-8-10**|**Cross-platform privacy-preserving CT image COVID-19 diagnosis based on source-free domain adaptation**|Y Feng et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0950705123000746)|-|<details><summary>detail</summary>Knowledge Based Systems, 2023 Elsevier</details>|\n", "Source-free Subject Adaptation for EEG-based Visual Recognition": "|**2023-8-7**|**Source-free Subject Adaptation for EEG-based Visual Recognition**|P Lee et.al|[paper](https://arxiv.org/abs/2301.08448)|[code](https://github.com/DeepBCI/Deep-BCI)|-|\n", "When Source-Free Domain Adaptation Meets Label Propagation": "|**2023-8-7**|**When Source-Free Domain Adaptation Meets Label Propagation**|C Wu et.al|[paper](https://arxiv.org/abs/2301.08413)|-|-|\n", "Source-Free Domain Adaptive Detection of Concealed Objects in Passive Millimeter-Wave Images": "|**2023-8-5**|**Source-Free Domain Adaptive Detection of Concealed Objects in Passive Millimeter-Wave Images**|H Yang et.al|[paper](https://ieeexplore.ieee.org/abstract/document/10019315/)|-|<details><summary>detail</summary>IEEE Transactions on\u00a0\u2026, 2023 ieeexplore.ieee.org</details>|\n"}, "object detection": {"SparseBEV: High-Performance Sparse 3D Object Detection from Multi-Camera Videos": "|**2023-9-5**|**SparseBEV: High-Performance Sparse 3D Object Detection from Multi-Camera Videos**|Haisong Liuet.al|[paper](https://arxiv.org/abs/2308.09244)|[code](https://github.com/MCG-NJU/SparseBEV.)|<details><summary>detail</summary>ICCV 2023</details>|\n", "Diffusion-based 3D Object Detection with Random Boxes": "|**2023-9-5**|**Diffusion-based 3D Object Detection with Random Boxes**|Xin Zhouet.al|[paper](https://arxiv.org/abs/2309.02049)|-|<details><summary>detail</summary>Accepted by PRCV 2023</details>|\n", "Predict to Detect: Prediction-guided 3D Object Detection using Sequential Images": "|**2023-9-5**|**Predict to Detect: Prediction-guided 3D Object Detection using Sequential Images**|Sanmin Kimet.al|[paper](https://arxiv.org/abs/2306.08528)|[code](https://github.com/sanmin0312/P2D)|<details><summary>detail</summary>ICCV 2023</details>|\n", "SSVOD: Semi-Supervised Video Object Detection with Sparse Annotations": "|**2023-9-4**|**SSVOD: Semi-Supervised Video Object Detection with Sparse Annotations**|Tanvir Mahmudet.al|[paper](https://arxiv.org/abs/2309.01391)|-|-|\n", "Recurrent Multi-scale Transformer for High-Resolution Salient Object Detection": "|**2023-9-4**|**Recurrent Multi-scale Transformer for High-Resolution Salient Object Detection**|Xinhao Denget.al|[paper](https://arxiv.org/abs/2308.03826)|[code](https://github.com/DrowsyMon/RMFormer.)|<details><summary>detail</summary>This work is the camera-ready version of ACM MM2023</details>|\n", "MS3D++: Ensemble of Experts for Multi-Source Unsupervised Domain Adaptation in 3D Object Detection": "|**2023-9-4**|**MS3D++: Ensemble of Experts for Multi-Source Unsupervised Domain Adaptation in 3D Object Detection**|Darren Tsaiet.al|[paper](https://arxiv.org/abs/2308.05988)|[code](https://github.com/darrenjkt/MS3D)|-|\n", "3D Object Detection from Images for Autonomous Driving: A Survey": "|**2023-9-4**|**3D Object Detection from Images for Autonomous Driving: A Survey**|Xinzhu Maet.al|[paper](https://arxiv.org/abs/2202.02980)|-|-|\n", "MS23D: A 3D Object Detection Method Using Multi-Scale Semantic Feature Points to Construct 3D Feature Layer": "|**2023-9-3**|**MS23D: A 3D Object Detection Method Using Multi-Scale Semantic Feature Points to Construct 3D Feature Layer**|Yongxin Shaoet.al|[paper](https://arxiv.org/abs/2308.16518)|-|-|\n", "Improved Multi-Scale Grid Rendering of Point Clouds for Radar Object Detection Networks": "|**2023-9-3**|**Improved Multi-Scale Grid Rendering of Point Clouds for Radar Object Detection Networks**|Daniel K\u00f6hleret.al|[paper](https://arxiv.org/abs/2305.15836)|-|<details><summary>detail</summary>(c) 2023 IEEE</details>|\n", "EdaDet: Open-Vocabulary Object Detection Using Early Dense Alignment": "|**2023-9-3**|**EdaDet: Open-Vocabulary Object Detection Using Early Dense Alignment**|Cheng Shiet.al|[paper](https://arxiv.org/abs/2309.01151)|[code](https://chengshiest.github.io/edadet)|<details><summary>detail</summary>ICCV 2023</details>|\n", "AdvMono3D: Advanced Monocular 3D Object Detection with Depth-Aware Robust Adversarial Training": "|**2023-9-3**|**AdvMono3D: Advanced Monocular 3D Object Detection with Depth-Aware Robust Adversarial Training**|Xingyuan Liet.al|[paper](https://arxiv.org/abs/2309.01106)|-|-|\n", "CoTDet: Affordance Knowledge Prompting for Task Driven Object Detection": "|**2023-9-3**|**CoTDet: Affordance Knowledge Prompting for Task Driven Object Detection**|Jiajin Tanget.al|[paper](https://arxiv.org/abs/2309.01093)|-|<details><summary>detail</summary>Accepted by ICCV 2023</details>|\n", "MILA: Memory-Based Instance-Level Adaptation for Cross-Domain Object Detection": "|**2023-9-3**|**MILA: Memory-Based Instance-Level Adaptation for Cross-Domain Object Detection**|Onkar Krishnaet.al|[paper](https://arxiv.org/abs/2309.01086)|-|-|\n", "Integration of Vision-based Object Detection and Grasping for Articulated Manipulator in Lunar Conditions": "|**2023-9-2**|**Integration of Vision-based Object Detection and Grasping for Articulated Manipulator in Lunar Conditions**|Camille Boucheret.al|[paper](https://arxiv.org/abs/2309.01055)|-|-|\n", "S$^3$-MonoDETR: Supervised Shape&Scale-perceptive Deformable Transformer for Monocular 3D Object Detection": "|**2023-9-2**|**S$^3$-MonoDETR: Supervised Shape&Scale-perceptive Deformable Transformer for Monocular 3D Object Detection**|Xuan Heet.al|[paper](https://arxiv.org/abs/2309.00928)|[code](https://github.com/mikasa3lili/S3-MonoDETR.)|<details><summary>detail</summary>The source code will be made publicly available at https://github</details>|\n", "E-detector: Asynchronous Spatio-temporal for Event-based Object Detection in Intelligent Transportation System": "|**2023-9-5**|**E-detector: Asynchronous Spatio-temporal for Event-based Object Detection in Intelligent Transportation System**|S Zhang et.al|[paper](https://dl.acm.org/doi/abs/10.1145/3584361)|-|<details><summary>detail</summary>ACM Transactions on Multimedia\u00a0\u2026, 2023 dl.acm.org</details>|\n", "\u2026\u00a0Simultaneous Defects Visualizing Algorithm for Both Macro and Micro Defects Based on Nonlinear Lamb Wave with an Application of Faster R-Cnn Object Detection": "|**2023-9-4**|**\u2026\u00a0Simultaneous Defects Visualizing Algorithm for Both Macro and Micro Defects Based on Nonlinear Lamb Wave with an Application of Faster R-Cnn Object Detection**|Y Lee et.al|[paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4362451)|-|<details><summary>detail</summary>Available at SSRN 4362451 papers.ssrn.com</details>|\n", "YOGA: Deep Object Detection in the Wild with Lightweight Feature Learning and Multiscale Attention": "|**2023-9-4**|**YOGA: Deep Object Detection in the Wild with Lightweight Feature Learning and Multiscale Attention**|R Sunkara et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0031320323001516)|[code](https://paperswithcode.com/paper/yoga-deep-object-detection-in-the-wild-with)|<details><summary>detail</summary>Pattern Recognition, 2023 Elsevier</details>|\n", "Spectral-Spatial Feature Enhancement Algorithm for Nighttime Object Detection and Tracking": "|**2023-9-4**|**Spectral-Spatial Feature Enhancement Algorithm for Nighttime Object Detection and Tracking**|Y Lv et.al|[paper](https://www.mdpi.com/2073-8994/15/2/546)|-|<details><summary>detail</summary>Symmetry, 2023 mdpi.com</details>|\n", "CRRNet: Channel Relation Reasoning Network for Salient Object Detection": "|**2023-9-4**|**CRRNet: Channel Relation Reasoning Network for Salient Object Detection**|S Gao et.al|[paper](https://link.springer.com/chapter/10.1007/978-981-99-0301-6_2)|-|<details><summary>detail</summary>\u2026\u00a0Conference, CCF CIRAC 2022, Xi'an\u00a0\u2026, 2023 Springer</details>|\n", "Iterative Fusion and Dual Enhancement for Accurate and Efficient Object Detection": "|**2023-9-4**|**Iterative Fusion and Dual Enhancement for Accurate and Efficient Object Detection**|Z Duan et.al|[paper](https://www.worldscientific.com/doi/abs/10.1142/S0218126623502328)|-|<details><summary>detail</summary>Journal of Circuits\u00a0\u2026, 2023 World Scientific</details>|\n", "CTA-FPN: Channel-Target Attention Feature Pyramid Network for Prohibited Object Detection in X-ray Images": "|**2023-9-4**|**CTA-FPN: Channel-Target Attention Feature Pyramid Network for Prohibited Object Detection in X-ray Images**|Y Zhang et.al|[paper](https://www.researchsquare.com/article/rs-2584406/latest.pdf)|-|<details><summary>detail</summary>2023 researchsquare.com</details>|\n", "Hierarchical Cross-modal Transformer for RGB-D Salient Object Detection": "|**2023-9-4**|**Hierarchical Cross-modal Transformer for RGB-D Salient Object Detection**|H Chen et.al|[paper](https://arxiv.org/abs/2302.08052)|[code](https://github.com/liuzywen/swinnet)|-|\n", "3M3D: Multi-view, Multi-path, Multi-representation for 3D Object Detection": "|**2023-9-4**|**3M3D: Multi-view, Multi-path, Multi-representation for 3D Object Detection**|J Park et.al|[paper](https://arxiv.org/abs/2302.08231)|[code](https://paperswithcode.com/paper/3m3d-multi-view-multi-path-multi)|-|\n", "Research on road object detection algorithm based on improved YOLOX": "|**2023-9-4**|**Research on road object detection algorithm based on improved YOLOX**|T Yang et.al|[paper](https://arxiv.org/abs/2302.08156)|[code](https://paperswithcode.com/paper/research-on-road-object-detection-algorithm)|-|\n"}, "domain adaptation": {"Domain Adaptation for Satellite-Borne Hyperspectral Cloud Detection": "|**2023-9-5**|**Domain Adaptation for Satellite-Borne Hyperspectral Cloud Detection**|Andrew Duet.al|[paper](https://arxiv.org/abs/2309.02150)|-|-|\n", "StereoFlowGAN: Co-training for Stereo and Flow with Unsupervised Domain Adaptation": "|**2023-9-4**|**StereoFlowGAN: Co-training for Stereo and Flow with Unsupervised Domain Adaptation**|Zhexiao Xionget.al|[paper](https://arxiv.org/abs/2309.01842)|-|<details><summary>detail</summary>Accepted by BMVC 2023</details>|\n", "MS3D++: Ensemble of Experts for Multi-Source Unsupervised Domain Adaptation in 3D Object Detection": "|**2023-9-4**|**MS3D++: Ensemble of Experts for Multi-Source Unsupervised Domain Adaptation in 3D Object Detection**|Darren Tsaiet.al|[paper](https://arxiv.org/abs/2308.05988)|[code](https://github.com/darrenjkt/MS3D)|-|\n", "Adaptive Parametric Prototype Learning for Cross-Domain Few-Shot Classification": "|**2023-9-3**|**Adaptive Parametric Prototype Learning for Cross-Domain Few-Shot Classification**|Marzi Heidariet.al|[paper](https://arxiv.org/abs/2309.01342)|-|-|\n", "Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation": "|**2023-9-3**|**Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation**|Jiajin Zhanget.al|[paper](https://arxiv.org/abs/2309.01207)|-|<details><summary>detail</summary>Accepted by MICCAI 2023</details>|\n", "MILA: Memory-Based Instance-Level Adaptation for Cross-Domain Object Detection": "|**2023-9-3**|**MILA: Memory-Based Instance-Level Adaptation for Cross-Domain Object Detection**|Onkar Krishnaet.al|[paper](https://arxiv.org/abs/2309.01086)|-|-|\n", "Trust your Good Friends: Source-free Domain Adaptation by Reciprocal Neighborhood Clustering": "|**2023-9-1**|**Trust your Good Friends: Source-free Domain Adaptation by Reciprocal Neighborhood Clustering**|Shiqi Yanget.al|[paper](https://arxiv.org/abs/2309.00528)|-|<details><summary>detail</summary>Accepted by IEEE TPAMI</details>|\n", "BTSeg: Barlow Twins Regularization for Domain Adaptation in Semantic Segmentation": "|**2023-8-31**|**BTSeg: Barlow Twins Regularization for Domain Adaptation in Semantic Segmentation**|Johannes K\u00fcnzelet.al|[paper](https://arxiv.org/abs/2308.16819)|-|-|\n", "Domain-adaptive Message Passing Graph Neural Network": "|**2023-8-31**|**Domain-adaptive Message Passing Graph Neural Network**|Xiao Shenet.al|[paper](https://arxiv.org/abs/2308.16470)|-|<details><summary>detail</summary>Journal ref:Neural Networks</details>|\n", "Federated Adaptive Prompt Tuning for Multi-domain Collaborative Learning": "|**2023-8-31**|**Federated Adaptive Prompt Tuning for Multi-domain Collaborative Learning**|Shangchao Suet.al|[paper](https://arxiv.org/abs/2211.07864)|-|-|\n", "Domain Adaptive Synapse Detection with Weak Point Annotations": "|**2023-8-31**|**Domain Adaptive Synapse Detection with Weak Point Annotations**|Qi Chenet.al|[paper](https://arxiv.org/abs/2308.16461)|-|-|\n", "Discriminator-free Unsupervised Domain Adaptation for Multi-label Image Classification": "|**2023-8-30**|**Discriminator-free Unsupervised Domain Adaptation for Multi-label Image Classification**|Indel Pal Singhet.al|[paper](https://arxiv.org/abs/2301.10611)|-|-|\n", "Semi-supervised Domain Adaptation with Inter and Intra-domain Mixing for Semantic Segmentation": "|**2023-8-30**|**Semi-supervised Domain Adaptation with Inter and Intra-domain Mixing for Semantic Segmentation**|Weifu Fuet.al|[paper](https://arxiv.org/abs/2308.15855)|-|-|\n", "Generalized Universal Domain Adaptation with Generative Flow Networks": "|**2023-8-29**|**Generalized Universal Domain Adaptation with Generative Flow Networks**|Didi Zhuet.al|[paper](https://arxiv.org/abs/2305.04466)|-|-|\n", "Universal Domain Adaptation via Compressive Attention Matching": "|**2023-8-29**|**Universal Domain Adaptation via Compressive Attention Matching**|Didi Zhuet.al|[paper](https://arxiv.org/abs/2304.11862)|-|-|\n", "Kurcuma: a kitchen utensil recognition collection for unsupervised domain adaptation": "|**2023-9-4**|**Kurcuma: a kitchen utensil recognition collection for unsupervised domain adaptation**|A Rosello et.al|[paper](https://link.springer.com/article/10.1007/s10044-023-01147-x)|-|<details><summary>detail</summary>Mas, AJ Gallego\u2026 Pattern Analysis and\u00a0\u2026, 2023 Springer</details>|\n", "An improved multi-source domain adaptation network for inter-subject mental fatigue detection based on DANN": "|**2023-9-4**|**An improved multi-source domain adaptation network for inter-subject mental fatigue detection based on DANN**|K Chen et.al|[paper](https://www.degruyter.com/document/doi/10.1515/bmt-2022-0354/html)|-|<details><summary>detail</summary>Biomedical Engineering\u00a0\u2026, 2023 degruyter.com</details>|\n", "A multi-source transfer learning model based on LSTM and domain adaptation for building energy prediction": "|**2023-9-4**|**A multi-source transfer learning model based on LSTM and domain adaptation for building energy prediction**|H Lu et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0142061523000819)|-|<details><summary>detail</summary>International Journal of\u00a0\u2026, 2023 Elsevier</details>|\n", "Open Set Domain Adaptation with Latent Structure Discovery and Kernelized Classifier Learning": "|**2023-9-4**|**Open Set Domain Adaptation with Latent Structure Discovery and Kernelized Classifier Learning**|Y Tang et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0925231223001509)|-|<details><summary>detail</summary>Neurocomputing, 2023 Elsevier</details>|\n", "Towards Real-Time Online Unsupervised Domain Adaptation for Real-World Person Re-identification": "|**2023-9-4**|**Towards Real-Time Online Unsupervised Domain Adaptation for Real-World Person Re-identification**|C Neff et.al|[paper](https://www.researchsquare.com/article/rs-2588554/latest.pdf)|-|<details><summary>detail</summary>2023 researchsquare.com</details>|\n", "Unsupervised Domain Adaptation for MRI Volume Segmentation and Classification Using Image-to-Image Translation": "|**2023-9-4**|**Unsupervised Domain Adaptation for MRI Volume Segmentation and Classification Using Image-to-Image Translation**|S Kondo et.al|[paper](https://arxiv.org/abs/2302.08016)|[code](https://paperswithcode.com/paper/unsupervised-domain-adaptation-for-mri-volume)|-|\n", "High-Intensified Resemblance and Statistic-Restructured Alignment in Few-Shot Domain Adaptation for Industrial-Specialized Employment": "|**2023-9-3**|**High-Intensified Resemblance and Statistic-Restructured Alignment in Few-Shot Domain Adaptation for Industrial-Specialized Employment**|J Petchhan et.al|[paper](https://ieeexplore.ieee.org/abstract/document/10045719/)|-|<details><summary>detail</summary>IEEE Transactions on Consumer\u00a0\u2026, 2023 ieeexplore.ieee.org</details>|\n", "KRADA: Known-region-aware Domain Alignment for Open-set Domain Adaptation in Semantic Segmentation": "|**2023-9-3**|**KRADA: Known-region-aware Domain Alignment for Open-set Domain Adaptation in Semantic Segmentation**|C Zhou et.al|[paper](https://europepmc.org/article/ppr/ppr617459)|[code](https://github.com/chenhong-zhou/krada)|<details><summary>detail</summary>2023 europepmc.org</details>|\n", "Blade crack detection based on domain adaptation and autoencoder of multidimensional vibro-acoustic feature fusion": "|**2023-9-3**|**Blade crack detection based on domain adaptation and autoencoder of multidimensional vibro-acoustic feature fusion**|J Shen et.al|[paper](https://journals.sagepub.com/doi/abs/10.1177/14759217221139134)|-|<details><summary>detail</summary>Structural Health Monitoring, 2023 journals.sagepub.com</details>|\n", "Infrared ship target segmentation based on Adversarial Domain Adaptation": "|**2023-9-2**|**Infrared ship target segmentation based on Adversarial Domain Adaptation**|T Zhang et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0950705123000941)|-|<details><summary>detail</summary>Knowledge Based\u00a0\u2026, 2023 Elsevier</details>|\n"}, "domain generalization": {"MAP: Domain Generalization via Meta-Learning on Anatomy-Consistent Pseudo-Modalities": "|**2023-9-3**|**MAP: Domain Generalization via Meta-Learning on Anatomy-Consistent Pseudo-Modalities**|Dewei Huet.al|[paper](https://arxiv.org/abs/2309.01286)|[code](https://github.com/DeweiHu/MAP.)|-|\n", "Domain Generalization via Balancing Training Difficulty and Model Capability": "|**2023-9-2**|**Domain Generalization via Balancing Training Difficulty and Model Capability**|Xueying Jianget.al|[paper](https://arxiv.org/abs/2309.00844)|-|-|\n", "Domain-Agnostic Molecular Generation with Self-feedback": "|**2023-9-1**|**Domain-Agnostic Molecular Generation with Self-feedback**|Yin Fanget.al|[paper](https://arxiv.org/abs/2301.11259)|[code](https://github.com/zjunlp/MolGen.)|<details><summary>detail</summary>Work in progress</details>|\n", "Domain Generalization without Excess Empirical Risk": "|**2023-8-30**|**Domain Generalization without Excess Empirical Risk**|Ozan Seneret.al|[paper](https://arxiv.org/abs/2308.15856)|-|<details><summary>detail</summary>Published at NeurIPS 2022</details>|\n", "Generalized Universal Domain Adaptation with Generative Flow Networks": "|**2023-8-29**|**Generalized Universal Domain Adaptation with Generative Flow Networks**|Didi Zhuet.al|[paper](https://arxiv.org/abs/2305.04466)|-|-|\n", "Learning Content-enhanced Mask Transformer for Domain Generalized Urban-Scene Segmentation": "|**2023-8-29**|**Learning Content-enhanced Mask Transformer for Domain Generalized Urban-Scene Segmentation**|Qi Biet.al|[paper](https://arxiv.org/abs/2307.00371)|[code](https://github.com/BiQiWHU/domain-generalized-urban-scene-segmentation)|-|\n", "Confidence Attention and Generalization Enhanced Distillation for Continuous Video Domain Adaptation": "|**2023-8-29**|**Confidence Attention and Generalization Enhanced Distillation for Continuous Video Domain Adaptation**|Xiyu Wanget.al|[paper](https://arxiv.org/abs/2303.10452)|-|-|\n", "Domain Generalization with Correlated Style Uncertainty": "|**2023-8-28**|**Domain Generalization with Correlated Style Uncertainty**|Zheyuan Zhanget.al|[paper](https://arxiv.org/abs/2212.09950)|[code](https://github.com/freshman97/CSU.)|<details><summary>detail</summary>Accepted by WACV2024</details>|\n", "Multi-Scale and Multi-Layer Contrastive Learning for Domain Generalization": "|**2023-8-28**|**Multi-Scale and Multi-Layer Contrastive Learning for Domain Generalization**|Aristotelis Ballaset.al|[paper](https://arxiv.org/abs/2308.14418)|-|<details><summary>detail</summary>Manuscript under review at: IEEE Transactions on Artificial Intelligence</details>|\n", "Exploring the Transfer Learning Capabilities of CLIP in Domain Generalization for Diabetic Retinopathy": "|**2023-8-27**|**Exploring the Transfer Learning Capabilities of CLIP in Domain Generalization for Diabetic Retinopathy**|Sanoojan Baliahet.al|[paper](https://arxiv.org/abs/2308.14212)|[code](https://github.com/Sanoojan/CLIP-DRDG.)|-|\n", "A Re-Parameterized Vision Transformer (ReVT) for Domain-Generalized Semantic Segmentation": "|**2023-8-25**|**A Re-Parameterized Vision Transformer (ReVT) for Domain-Generalized Semantic Segmentation**|Jan-Aike Term\u00f6hlenet.al|[paper](https://arxiv.org/abs/2308.13331)|-|-|\n", "On the Generalization of PINNs outside the training domain and the Hyperparameters influencing it": "|**2023-8-24**|**On the Generalization of PINNs outside the training domain and the Hyperparameters influencing it**|Andrea Bonfantiet.al|[paper](https://arxiv.org/abs/2302.07557)|-|-|\n", "HCDG: A Hierarchical Consistency Framework for Domain Generalization on Medical Image Segmentation": "|**2023-8-24**|**HCDG: A Hierarchical Consistency Framework for Domain Generalization on Medical Image Segmentation**|Yijun Yanget.al|[paper](https://arxiv.org/abs/2109.05742)|-|<details><summary>detail</summary>this paper is currently not published</details>|\n", "Learning to Generalize towards Unseen Domains via a Content-Aware Style Invariant Model for Disease Detection from Chest X-rays": "|**2023-8-23**|**Learning to Generalize towards Unseen Domains via a Content-Aware Style Invariant Model for Disease Detection from Chest X-rays**|Mohammad Zunaedet.al|[paper](https://arxiv.org/abs/2302.13991)|-|-|\n", "Understanding Hessian Alignment for Domain Generalization": "|**2023-8-22**|**Understanding Hessian Alignment for Domain Generalization**|Sobhan Hematiet.al|[paper](https://arxiv.org/abs/2308.11778)|[code](https://github.com/huawei-noah/Federated-Learning/tree/main/HessianAlignment)|<details><summary>detail</summary>ICCV 2023</details>|\n", "Domain Generalization with Global Sample Mixup": "|**2023-9-5**|**Domain Generalization with Global Sample Mixup**|Y Lu et.al|[paper](https://link.springer.com/chapter/10.1007/978-3-031-25075-0_35)|-|<details><summary>detail</summary>European Conference on Computer\u00a0\u2026, 2023 Springer</details>|\n", "Cross-Domain Augmentation Diagnosis: An Adversarial Domain-Augmented Generalization Method for Fault Diagnosis under Unseen Working Conditions": "|**2023-9-5**|**Cross-Domain Augmentation Diagnosis: An Adversarial Domain-Augmented Generalization Method for Fault Diagnosis under Unseen Working Conditions**|Q Li et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0951832023000868)|-|<details><summary>detail</summary>Reliability Engineering &\u00a0\u2026, 2023 Elsevier</details>|\n", "On the Hyperparameters influencing a PINN's generalization beyond the training domain": "|**2023-9-3**|**On the Hyperparameters influencing a PINN's generalization beyond the training domain**|A Bonfanti et.al|[paper](https://arxiv.org/abs/2302.07557)|-|-|\n", "Robust Representation Learning with Self-Distillation for Domain Generalization": "|**2023-9-2**|**Robust Representation Learning with Self-Distillation for Domain Generalization**|A Singh et.al|[paper](https://arxiv.org/abs/2302.06874)|[code](https://github.com/tongkunguan/ccd)|-|\n", "Cross-corpora spoken language identification with domain diversification and generalization": "|**2023-8-31**|**Cross-corpora spoken language identification with domain diversification and generalization**|S Dey et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0885230823000086)|[code](https://paperswithcode.com/paper/cross-corpora-spoken-language-identification)|<details><summary>detail</summary>Computer Speech & Language, 2023 Elsevier</details>|\n", "Domain-Conditioned Normalization for Test-Time Domain Generalization": "|**2023-8-29**|**Domain-Conditioned Normalization for Test-Time Domain Generalization**|Y Jiang et.al|[paper](https://link.springer.com/chapter/10.1007/978-3-031-25085-9_17)|-|<details><summary>detail</summary>Computer Vision\u2013ECCV\u00a0\u2026, 2023 Springer</details>|\n", "Domain Generalization by Functional Regression": "|**2023-8-28**|**Domain Generalization by Functional Regression**|M Holzleitner et.al|[paper](https://arxiv.org/abs/2302.04724)|[code](https://github.com/mlr-org/mlr)|-|\n", "Leveraging Domain Relations for Domain Generalization": "|**2023-8-25**|**Leveraging Domain Relations for Domain Generalization**|H Yao et.al|[paper](https://arxiv.org/abs/2302.02609)|[code](https://github.com/rusty1s/pytorch_geometric)|-|\n", "Aggregation of Disentanglement: Reconsidering Domain Variations in Domain Generalization": "|**2023-8-23**|**Aggregation of Disentanglement: Reconsidering Domain Variations in Domain Generalization**|D Zhang et.al|[paper](https://arxiv.org/abs/2302.02350)|[code](https://paperswithcode.com/paper/aggregation-of-disentanglement-reconsidering)|-|\n", "Domain Generalization Emerges from Dreaming": "|**2023-8-21**|**Domain Generalization Emerges from Dreaming**|H Heo et.al|[paper](https://arxiv.org/abs/2302.00980)|[code](https://paperswithcode.com/paper/domain-generalization-emerges-from-dreaming)|-|\n"}, "vision language": {"TouchStone: Evaluating Vision-Language Models by Language Models": "|**2023-9-4**|**TouchStone: Evaluating Vision-Language Models by Language Models**|Shuai Baiet.al|[paper](https://arxiv.org/abs/2308.16890)|[code](https://github.com/OFA-Sys/TouchStone.)|<details><summary>detail</summary>https://github</details>|\n", "DeViL: Decoding Vision features into Language": "|**2023-9-4**|**DeViL: Decoding Vision features into Language**|Meghal Daniet.al|[paper](https://arxiv.org/abs/2309.01617)|[code](https://github.com/ExplainableML/DeViL)|<details><summary>detail</summary>GCPR 2023 (Oral)</details>|\n", "AnomalyGPT: Detecting Industrial Anomalies using Large Vision-Language Models": "|**2023-9-4**|**AnomalyGPT: Detecting Industrial Anomalies using Large Vision-Language Models**|Zhaopeng Guet.al|[paper](https://arxiv.org/abs/2308.15366)|[code](https://github.com/CASIA-IVA-Lab/AnomalyGPT.)|<details><summary>detail</summary>Project page: https://anomalygpt</details>|\n", "Recognition of Heat-Induced Food State Changes by Time-Series Use of Vision-Language Model for Cooking Robot": "|**2023-9-4**|**Recognition of Heat-Induced Food State Changes by Time-Series Use of Vision-Language Model for Cooking Robot**|Naoaki Kanazawaet.al|[paper](https://arxiv.org/abs/2309.01528)|-|<details><summary>detail</summary>IAS18-2023</details>|\n", "Parameter and Computation Efficient Transfer Learning for Vision-Language Pre-trained Models": "|**2023-9-4**|**Parameter and Computation Efficient Transfer Learning for Vision-Language Pre-trained Models**|Qiong Wuet.al|[paper](https://arxiv.org/abs/2309.01479)|-|-|\n", "BDC-Adapter: Brownian Distance Covariance for Better Vision-Language Reasoning": "|**2023-9-3**|**BDC-Adapter: Brownian Distance Covariance for Better Vision-Language Reasoning**|Yi Zhanget.al|[paper](https://arxiv.org/abs/2309.01256)|-|<details><summary>detail</summary>Accepted by BMVC 2023</details>|\n", "LoGoPrompt: Synthetic Text Images Can Be Good Visual Prompts for Vision-Language Models": "|**2023-9-3**|**LoGoPrompt: Synthetic Text Images Can Be Good Visual Prompts for Vision-Language Models**|Cheng Shiet.al|[paper](https://arxiv.org/abs/2309.01155)|[code](https://chengshiest.github.io/logo)|<details><summary>detail</summary>ICCV 2023</details>|\n", "Leveraging per Image-Token Consistency for Vision-Language Pre-training": "|**2023-9-2**|**Leveraging per Image-Token Consistency for Vision-Language Pre-training**|Yunhao Gouet.al|[paper](https://arxiv.org/abs/2211.15398)|[code](https://github.com/gyhdog99/epic.)|<details><summary>detail</summary>Accepted by CVPR 2023</details>|\n", "Zero-Shot Video Moment Retrieval from Frozen Vision-Language Models": "|**2023-9-1**|**Zero-Shot Video Moment Retrieval from Frozen Vision-Language Models**|Dezhao Luoet.al|[paper](https://arxiv.org/abs/2309.00661)|-|<details><summary>detail</summary>Accepted by WACV 2024</details>|\n", "Towards Addressing the Misalignment of Object Proposal Evaluation for Vision-Language Tasks via Semantic Grounding": "|**2023-8-31**|**Towards Addressing the Misalignment of Object Proposal Evaluation for Vision-Language Tasks via Semantic Grounding**|Joshua Feinglasset.al|[paper](https://arxiv.org/abs/2309.00215)|-|<details><summary>detail</summary>WACV 2024 (Round 1)</details>|\n", "RS5M: A Large Scale Vision-Language Dataset for Remote Sensing Vision-Language Foundation Model": "|**2023-8-31**|**RS5M: A Large Scale Vision-Language Dataset for Remote Sensing Vision-Language Foundation Model**|Zilun Zhanget.al|[paper](https://arxiv.org/abs/2306.11300)|[code](https://github.com/om-ai-lab/RS5M)|<details><summary>detail</summary>RS5M dataset v4</details>|\n", "ViLTA: Enhancing Vision-Language Pre-training through Textual Augmentation": "|**2023-8-31**|**ViLTA: Enhancing Vision-Language Pre-training through Textual Augmentation**|Weihan Wanget.al|[paper](https://arxiv.org/abs/2308.16689)|-|-|\n", "Expanding Frozen Vision-Language Models without Retraining: Towards Improved Robot Perception": "|**2023-8-31**|**Expanding Frozen Vision-Language Models without Retraining: Towards Improved Robot Perception**|Riley Tavassoliet.al|[paper](https://arxiv.org/abs/2308.16493)|-|<details><summary>detail</summary>Preprint submitted to Information Fusion</details>|\n", "Catalog Phrase Grounding (CPG): Grounding of Product Textual Attributes in Product Images for e-commerce Vision-Language Applications": "|**2023-8-30**|**Catalog Phrase Grounding (CPG): Grounding of Product Textual Attributes in Product Images for e-commerce Vision-Language Applications**|Wenyi Wuet.al|[paper](https://arxiv.org/abs/2308.16354)|-|<details><summary>detail</summary>KDD 2022 Workshop on First Content Understanding and Generation for e-Commerce</details>|\n", "Going Beyond Nouns With Vision & Language Models Using Synthetic Data": "|**2023-8-30**|**Going Beyond Nouns With Vision & Language Models Using Synthetic Data**|Paola Cascante-Bonillaet.al|[paper](https://arxiv.org/abs/2303.17590)|[code](https://synthetic-vic.github.io/)|<details><summary>detail</summary>ICCV 2023</details>|\n"}}