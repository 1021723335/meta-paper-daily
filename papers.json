{"source-free": {"Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation": "|**2025-10-29**|**Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation**|Yuyang Huang et.al|[paper](https://arxiv.org/abs/2510.25279)|-|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|\n", "Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation": "|**2025-10-29**|**Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation**|Quang-Khai Bui-Tran et.al|[paper](https://arxiv.org/abs/2510.25227)|-|-|\n", "Training-free Source Attribution of AI-generated Images via Resynthesis": "|**2025-10-28**|**Training-free Source Attribution of AI-generated Images via Resynthesis**|Pietro Bongini et.al|[paper](https://arxiv.org/abs/2510.24278)|-|-|\n", "Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation": "|**2025-10-24**|**Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.22142)|-|-|\n", "Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces": "|**2025-10-22**|**Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces**|Osman Berke Guney et.al|[paper](https://arxiv.org/abs/2305.17403)|[code](https://github.com/osmanberke/SFDA-SSVEP-BCI)|-|\n", "Source-Free Object Detection with Detection Transformer": "|**2025-10-13**|**Source-Free Object Detection with Detection Transformer**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2510.11090)|-|<details><summary>detail</summary>IEEE Transactions on Image Processing</details>|\n", "Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning": "|**2025-10-9**|**Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning**|Ziqi Zhang et.al|[paper](https://arxiv.org/abs/2510.08393)|-|-|\n", "ESS-Flow: Training-free guidance of flow-based models as inference in source space": "|**2025-10-7**|**ESS-Flow: Training-free guidance of flow-based models as inference in source space**|Adhithyan Kalaivanan et.al|[paper](https://arxiv.org/abs/2510.05849)|-|-|\n", "Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising": "|**2025-10-7**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|\n", "A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation": "|**2025-10-6**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|\n", "Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection": "|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|\n", "Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation": "|**2025-10-3**|**Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation**|Yucheng Wang et.al|[paper](https://arxiv.org/abs/2409.19635)|-|-|\n", "OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation": "|**2025-10-2**|**OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation**|Yiming Zhang et.al|[paper](https://arxiv.org/abs/2505.11669)|-|-|\n", "Source-Free Cross-Domain Continual Learning": "|**2025-10-2**|**Source-Free Cross-Domain Continual Learning**|Muhammad Tanzil Furqon et.al|[paper](https://arxiv.org/abs/2510.01649)|-|-|\n", "Consistent Assistant Domains Transformer for Source-free Domain Adaptation": "|**2025-10-1**|**Consistent Assistant Domains Transformer for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.01559)|[code](https://github.com/RoryShao/CADTrans.git.)|-|\n"}, "object detection": {"All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles": "|**2025-10-30**|**All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles**|Sayed Pedram Haeri Boroujeni et.al|[paper](https://arxiv.org/abs/2510.26641)|-|-|\n", "VerifIoU - Robustness of Object Detection to Perturbations": "|**2025-10-30**|**VerifIoU - Robustness of Object Detection to Perturbations**|No\u00e9mie Cohen et.al|[paper](https://arxiv.org/abs/2403.08788)|-|<details><summary>detail</summary>Journal ref:44th Digital Avionics Systems Conference (DASC)</details>|\n", "U-DECN: End-to-End Underwater Object Detection ConvNet with Improved DeNoising Training": "|**2025-10-29**|**U-DECN: End-to-End Underwater Object Detection ConvNet with Improved DeNoising Training**|Zhuoyan Liu et.al|[paper](https://arxiv.org/abs/2408.05780)|[code](https://github.com/LEFTeyex/U-DECN.)|-|\n", "Prototype-Driven Adaptation for Few-Shot Object Detection": "|**2025-10-29**|**Prototype-Driven Adaptation for Few-Shot Object Detection**|Yushen Huang et.al|[paper](https://arxiv.org/abs/2510.25318)|-|-|\n", "RT-DETRv4: Painlessly Furthering Real-Time Object Detection with Vision Foundation Models": "|**2025-10-29**|**RT-DETRv4: Painlessly Furthering Real-Time Object Detection with Vision Foundation Models**|Zijun Liao et.al|[paper](https://arxiv.org/abs/2510.25257)|-|-|\n", "Test-Time Adaptive Object Detection with Foundation Model": "|**2025-10-29**|**Test-Time Adaptive Object Detection with Foundation Model**|Yingjie Gao et.al|[paper](https://arxiv.org/abs/2510.25175)|[code](https://github.com/gaoyingjay/ttaod_foundation.)|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|\n", "DINO-YOLO: Self-Supervised Pre-training for Data-Efficient Object Detection in Civil Engineering Applications": "|**2025-10-28**|**DINO-YOLO: Self-Supervised Pre-training for Data-Efficient Object Detection in Civil Engineering Applications**|Malaisree P et.al|[paper](https://arxiv.org/abs/2510.25140)|-|-|\n", "Enhancing Underwater Object Detection through Spatio-Temporal Analysis and Spatial Attention Networks": "|**2025-10-28**|**Enhancing Underwater Object Detection through Spatio-Temporal Analysis and Spatial Attention Networks**|Sai Likhith Karri et.al|[paper](https://arxiv.org/abs/2510.25797)|-|-|\n", "MIC-BEV: Multi-Infrastructure Camera Bird's-Eye-View Transformer with Relation-Aware Fusion for 3D Object Detection": "|**2025-10-28**|**MIC-BEV: Multi-Infrastructure Camera Bird's-Eye-View Transformer with Relation-Aware Fusion for 3D Object Detection**|Yun Zhang et.al|[paper](https://arxiv.org/abs/2510.24688)|[code](https://github.com/HandsomeYun/MIC-BEV.)|-|\n", "Multispectral State-Space Feature Fusion: Bridging Shared and Cross-Parametric Interactions for Object Detection": "|**2025-10-28**|**Multispectral State-Space Feature Fusion: Bridging Shared and Cross-Parametric Interactions for Object Detection**|Jifeng Shen et.al|[paper](https://arxiv.org/abs/2507.14643)|[code](https://github.com/61s61min/MS2Fusion.git.)|<details><summary>detail</summary>submitted on 30/4/2025</details>|\n", "Delving into Cascaded Instability: A Lipschitz Continuity View on Image Restoration and Object Detection Synergy": "|**2025-10-28**|**Delving into Cascaded Instability: A Lipschitz Continuity View on Image Restoration and Object Detection Synergy**|Qing Zhao et.al|[paper](https://arxiv.org/abs/2510.24232)|-|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "AG-Fusion: adaptive gated multimodal fusion for 3d object detection in complex scenes": "|**2025-10-27**|**AG-Fusion: adaptive gated multimodal fusion for 3d object detection in complex scenes**|Sixian Liu et.al|[paper](https://arxiv.org/abs/2510.23151)|-|-|\n", "DQ3D: Depth-guided Query for Transformer-Based 3D Object Detection in Traffic Scenarios": "|**2025-10-27**|**DQ3D: Depth-guided Query for Transformer-Based 3D Object Detection in Traffic Scenarios**|Ziyu Wang et.al|[paper](https://arxiv.org/abs/2510.23144)|-|-|\n", "3D Roadway Scene Object Detection with LIDARs in Snowfall Conditions": "|**2025-10-25**|**3D Roadway Scene Object Detection with LIDARs in Snowfall Conditions**|Ghazal Farhani et.al|[paper](https://arxiv.org/abs/2510.22436)|-|<details><summary>detail</summary>2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC)</details>|\n", "S3OD: Towards Generalizable Salient Object Detection with Synthetic Data": "|**2025-10-24**|**S3OD: Towards Generalizable Salient Object Detection with Synthetic Data**|Orest Kupyn et.al|[paper](https://arxiv.org/abs/2510.21605)|-|-|\n"}, "domain adaptation": {"Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems": "|**2025-10-30**|**Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems**|Georgios Kamaras et.al|[paper](https://arxiv.org/abs/2510.26656)|-|-|\n", "CATCH: A Modular Cross-domain Adaptive Template with Hook": "|**2025-10-30**|**CATCH: A Modular Cross-domain Adaptive Template with Hook**|Xinjin Li et.al|[paper](https://arxiv.org/abs/2510.26582)|-|-|\n", "Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation": "|**2025-10-29**|**Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation**|Yuyang Huang et.al|[paper](https://arxiv.org/abs/2510.25279)|-|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|\n", "Adapting Small Language Models to Low-Resource Domains: A Case Study in Hindi Tourism QA": "|**2025-10-29**|**Adapting Small Language Models to Low-Resource Domains: A Case Study in Hindi Tourism QA**|Sandipan Majhi et.al|[paper](https://arxiv.org/abs/2510.25273)|-|<details><summary>detail</summary>the Forum for Information Retrieval Evaluation 2025 (VATIKA Track)</details>|\n", "Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation": "|**2025-10-29**|**Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation**|Quang-Khai Bui-Tran et.al|[paper](https://arxiv.org/abs/2510.25227)|-|-|\n", "BEST-RQ-Based Self-Supervised Learning for Whisper Domain Adaptation": "|**2025-10-28**|**BEST-RQ-Based Self-Supervised Learning for Whisper Domain Adaptation**|Rapha\u00ebl Bagat et.al|[paper](https://arxiv.org/abs/2510.24570)|-|<details><summary>detail</summary>Submitted to ICASSP 2026</details>|\n", "DPGLA: Bridging the Gap between Synthetic and Real Data for Unsupervised Domain Adaptation in 3D LiDAR Semantic Segmentation": "|**2025-10-27**|**DPGLA: Bridging the Gap between Synthetic and Real Data for Unsupervised Domain Adaptation in 3D LiDAR Semantic Segmentation**|Wanmeng Li et.al|[paper](https://arxiv.org/abs/2510.23525)|-|<details><summary>detail</summary>This paper has been accepted for publication at the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</details>|\n", "PTPP-Aware Adaptation Scaling Laws: Predicting Domain-Adaptation Performance at Unseen Pre-Training Budgets": "|**2025-10-27**|**PTPP-Aware Adaptation Scaling Laws: Predicting Domain-Adaptation Performance at Unseen Pre-Training Budgets**|Etienne Goffinet et.al|[paper](https://arxiv.org/abs/2510.23198)|-|-|\n", "DeepSalt: Bridging Laboratory and Satellite Spectra through Domain Adaptation and Knowledge Distillation for Large-Scale Soil Salinity Estimation": "|**2025-10-27**|**DeepSalt: Bridging Laboratory and Satellite Spectra through Domain Adaptation and Knowledge Distillation for Large-Scale Soil Salinity Estimation**|Rupasree Dey et.al|[paper](https://arxiv.org/abs/2510.23124)|-|-|\n", "Progressive Multi-Source Domain Adaptation for Personalized Facial Expression Recognition": "|**2025-10-26**|**Progressive Multi-Source Domain Adaptation for Personalized Facial Expression Recognition**|Muhammad Osama Zeeshan et.al|[paper](https://arxiv.org/abs/2504.04252)|-|<details><summary>detail</summary>Transactions on Affective Computing 2025</details>|\n", "GALA: A GlobAl-LocAl Approach for Multi-Source Active Domain Adaptation": "|**2025-10-25**|**GALA: A GlobAl-LocAl Approach for Multi-Source Active Domain Adaptation**|Juepeng Zheng et.al|[paper](https://arxiv.org/abs/2510.22214)|-|-|\n", "Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation": "|**2025-10-24**|**Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.22142)|-|-|\n", "DAP-MAE: Domain-Adaptive Point Cloud Masked Autoencoder for Effective Cross-Domain Learning": "|**2025-10-24**|**DAP-MAE: Domain-Adaptive Point Cloud Masked Autoencoder for Effective Cross-Domain Learning**|Ziqi Gao et.al|[paper](https://arxiv.org/abs/2510.21635)|-|-|\n", "Video-Skill-CoT: Skill-based Chain-of-Thoughts for Domain-Adaptive Video Reasoning": "|**2025-10-24**|**Video-Skill-CoT: Skill-based Chain-of-Thoughts for Domain-Adaptive Video Reasoning**|Daeun Lee et.al|[paper](https://arxiv.org/abs/2506.03525)|[code](https://video-skill-cot.github.io/)|<details><summary>detail</summary>Project website: https://video-skill-cot</details>|\n", "Domain Adaptation-based Edge Computing for Cross-Conditions Fault Diagnosis": "|**2025-10-24**|**Domain Adaptation-based Edge Computing for Cross-Conditions Fault Diagnosis**|Yanzhi Wang et.al|[paper](https://arxiv.org/abs/2411.10340)|-|-|\n"}, "domain generalization": {"Continuous Domain Generalization": "|**2025-10-29**|**Continuous Domain Generalization**|Zekun Cai et.al|[paper](https://arxiv.org/abs/2505.13519)|-|-|\n", "Zero Reinforcement Learning Towards General Domains": "|**2025-10-29**|**Zero Reinforcement Learning Towards General Domains**|Yuyuan Zeng et.al|[paper](https://arxiv.org/abs/2510.25528)|-|-|\n", "Retaining Mixture Representations for Domain Generalized Anomalous Sound Detection": "|**2025-10-29**|**Retaining Mixture Representations for Domain Generalized Anomalous Sound Detection**|Phurich Saengthong et.al|[paper](https://arxiv.org/abs/2510.25182)|-|<details><summary>detail</summary>Submitted to ICASSP 2026</details>|\n", "A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation": "|**2025-10-28**|**A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation**|Hao-Ran Yang et.al|[paper](https://arxiv.org/abs/2505.13043)|-|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "Model-Guided Dual-Role Alignment for High-Fidelity Open-Domain Video-to-Audio Generation": "|**2025-10-28**|**Model-Guided Dual-Role Alignment for High-Fidelity Open-Domain Video-to-Audio Generation**|Kang Zhang et.al|[paper](https://arxiv.org/abs/2510.24103)|[code](https://github.com/pantheon5100/mgaudio)|<details><summary>detail</summary>accepted by NeurIPS 2025</details>|\n", "OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting": "|**2025-10-27**|**OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting**|Tingyue Pan et.al|[paper](https://arxiv.org/abs/2510.24028)|-|-|\n", "AdvBlur: Adversarial Blur for Robust Diabetic Retinopathy Classification and Cross-Domain Generalization": "|**2025-10-27**|**AdvBlur: Adversarial Blur for Robust Diabetic Retinopathy Classification and Cross-Domain Generalization**|Heethanjan Kanagalingam et.al|[paper](https://arxiv.org/abs/2510.24000)|-|-|\n", "Local Density-Based Anomaly Score Normalization for Domain Generalization": "|**2025-10-27**|**Local Density-Based Anomaly Score Normalization for Domain Generalization**|Kevin Wilkinghoff et.al|[paper](https://arxiv.org/abs/2509.10951)|-|-|\n", "Robust Atypical Mitosis Classification with DenseNet121: Stain-Aware Augmentation and Hybrid Loss for Domain Generalization": "|**2025-10-26**|**Robust Atypical Mitosis Classification with DenseNet121: Stain-Aware Augmentation and Hybrid Loss for Domain Generalization**|Adinath Dukre et.al|[paper](https://arxiv.org/abs/2510.22630)|-|<details><summary>detail</summary>MIDOG 2025 MICCAI Workshop accepted</details>|\n", "Emotion Recognition with Minimal Wearable Sensing: Multi-domain Feature, Hybrid Feature Selection, and Personalized vs. Generalized Ensemble Model Analysis": "|**2025-10-25**|**Emotion Recognition with Minimal Wearable Sensing: Multi-domain Feature, Hybrid Feature Selection, and Personalized vs. Generalized Ensemble Model Analysis**|Muhammad Irfan et.al|[paper](https://arxiv.org/abs/2510.22498)|-|-|\n", "Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering": "|**2025-10-24**|**Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering**|Elman Ghazaei et.al|[paper](https://arxiv.org/abs/2508.08974)|[code](https://github.com/Elman295/TCSSM.)|-|\n", "How Many Domains Suffice for Domain Generalization? A Tight Characterization via the Domain Shattering Dimension": "|**2025-10-23**|**How Many Domains Suffice for Domain Generalization? A Tight Characterization via the Domain Shattering Dimension**|Cynthia Dwork et.al|[paper](https://arxiv.org/abs/2506.16704)|-|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "Towards Context-Aware Domain Generalization: Understanding the Benefits and Limits of Marginal Transfer Learning": "|**2025-10-22**|**Towards Context-Aware Domain Generalization: Understanding the Benefits and Limits of Marginal Transfer Learning**|Jens M\u00fcller et.al|[paper](https://arxiv.org/abs/2312.10107)|-|-|\n", "Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts": "|**2025-10-22**|**Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts**|Chen Li et.al|[paper](https://arxiv.org/abs/2510.19487)|-|-|\n", "Exploring Scale Shift in Crowd Localization under the Context of Domain Generalization": "|**2025-10-22**|**Exploring Scale Shift in Crowd Localization under the Context of Domain Generalization**|Juncheng Wang et.al|[paper](https://arxiv.org/abs/2510.19330)|-|-|\n"}, "vision language": {"SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models": "|**2025-10-30**|**SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models**|Anushka Sivakumar et.al|[paper](https://arxiv.org/abs/2510.26769)|-|-|\n", "CronusVLA: Towards Efficient and Robust Manipulation via Multi-Frame Vision-Language-Action Modeling": "|**2025-10-30**|**CronusVLA: Towards Efficient and Robust Manipulation via Multi-Frame Vision-Language-Action Modeling**|Hao Li et.al|[paper](https://arxiv.org/abs/2506.19816)|-|-|\n", "Dynamic Context-Aware Scene Reasoning Using Vision-Language Alignment in Zero-Shot Real-World Scenarios": "|**2025-10-30**|**Dynamic Context-Aware Scene Reasoning Using Vision-Language Alignment in Zero-Shot Real-World Scenarios**|Manjunath Prasad Holenarasipura Rajiv et.al|[paper](https://arxiv.org/abs/2510.26580)|-|<details><summary>detail</summary>Preprint under review at IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</details>|\n", "Towards Fine-Grained Vision-Language Alignment for Few-Shot Anomaly Detection": "|**2025-10-30**|**Towards Fine-Grained Vision-Language Alignment for Few-Shot Anomaly Detection**|Yuanting Fan et.al|[paper](https://arxiv.org/abs/2510.26464)|-|-|\n", "A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models": "|**2025-10-30**|**A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models**|Shihab Aaqil Ahamed et.al|[paper](https://arxiv.org/abs/2510.26441)|-|-|\n", "Understanding Hardness of Vision-Language Compositionality from A Token-level Causal Lens": "|**2025-10-30**|**Understanding Hardness of Vision-Language Compositionality from A Token-level Causal Lens**|Ziliang Chen et.al|[paper](https://arxiv.org/abs/2510.26302)|-|-|\n", "Distilling Multilingual Vision-Language Models: When Smaller Models Stay Multilingual": "|**2025-10-30**|**Distilling Multilingual Vision-Language Models: When Smaller Models Stay Multilingual**|Sukrit Sriratanawilai et.al|[paper](https://arxiv.org/abs/2510.26271)|-|<details><summary>detail</summary>Work in progress</details>|\n", "Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models": "|**2025-10-30**|**Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models**|Shiho Matta et.al|[paper](https://arxiv.org/abs/2510.26241)|-|-|\n", "SAFE: Multitask Failure Detection for Vision-Language-Action Models": "|**2025-10-30**|**SAFE: Multitask Failure Detection for Vision-Language-Action Models**|Qiao Gu et.al|[paper](https://arxiv.org/abs/2506.09937)|[code](https://vla-safe.github.io/)|<details><summary>detail</summary>NeurIPS 2025 camera ready</details>|\n", "FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph": "|**2025-10-30**|**FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph**|Xiaolin Zhou et.al|[paper](https://arxiv.org/abs/2509.13733)|-|-|\n", "PureKV: Plug-and-Play KV Cache Optimization with Spatial-Temporal Sparse Attention for Vision-Language Large Models": "|**2025-10-29**|**PureKV: Plug-and-Play KV Cache Optimization with Spatial-Temporal Sparse Attention for Vision-Language Large Models**|Zhonghua Jiang et.al|[paper](https://arxiv.org/abs/2510.25600)|-|-|\n", "ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models": "|**2025-10-29**|**ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models**|Liyan Tang et.al|[paper](https://arxiv.org/abs/2505.13444)|-|<details><summary>detail</summary>NeurIPS 2025 Datasets & Benchmarks</details>|\n", "Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It": "|**2025-10-29**|**Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It**|Yulu Qin et.al|[paper](https://arxiv.org/abs/2507.13328)|-|-|\n", "MoralCLIP: Contrastive Alignment of Vision-and-Language Representations with Moral Foundations Theory": "|**2025-10-29**|**MoralCLIP: Contrastive Alignment of Vision-and-Language Representations with Moral Foundations Theory**|Ana Carolina Condez et.al|[paper](https://arxiv.org/abs/2506.05696)|-|<details><summary>detail</summary>Updated version: corresponds to the ACM MM '25 published paper and includes full appendix material</details>|\n", ": Online RL Fine-tuning for Flow-based Vision-Language-Action Models": "|**2025-10-29**|**: Online RL Fine-tuning for Flow-based Vision-Language-Action Models**|Kang Chen et.al|[paper](https://arxiv.org/abs/2510.25889)|-|<details><summary>detail</summary>Preprint</details>|\n"}}