{"source-free": {"ReCLIP: Refine Contrastive Language Image Pre-Training with Source Free Domain Adaptation": "|**2023-12-13**|**ReCLIP: Refine Contrastive Language Image Pre-Training with Source Free Domain Adaptation**|Xuefeng Hu et.al|[paper](https://arxiv.org/abs/2308.03793)|[code](https://github.com/michiganleon/ReCLIP_WACV.)|<details><summary>detail</summary>Accepted as Oral Paper by 2024 IEEE CVF Winter Conference on Applications of Computer Vision (WACV)</details>|\n", "Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation": "|**2023-11-28**|**Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation**|Y Chen et.al|[paper](https://arxiv.org/abs/2301.13428)|[code](https://github.com/yukilulu/cac)|-|\n", "Source-Free Domain Adaptation for RGB-D Semantic Segmentation with Vision Transformers": "|**2023-12-6**|**Source-Free Domain Adaptation for RGB-D Semantic Segmentation with Vision Transformers**|Giulia Rizzoli et.al|[paper](https://arxiv.org/abs/2305.14269)|-|<details><summary>detail</summary>WACV 2024</details>|\n", "Unknown Sample Discovery for Source Free Open Set Domain Adaptation": "|**2023-12-5**|**Unknown Sample Discovery for Source Free Open Set Domain Adaptation**|Chowdhury Sadman Jahan et.al|[paper](https://arxiv.org/abs/2312.03767)|-|-|\n", "Source Free Unsupervised Graph Domain Adaptation": "|**2023-12-4**|**Source Free Unsupervised Graph Domain Adaptation**|Haitao Mao et.al|[paper](https://arxiv.org/abs/2112.00955)|-|-|\n", "Enhancing and Adapting in the Clinic: Source-free Unsupervised Domain Adaptation for Medical Image Enhancement": "|**2023-12-3**|**Enhancing and Adapting in the Clinic: Source-free Unsupervised Domain Adaptation for Medical Image Enhancement**|Heng Li et.al|[paper](https://arxiv.org/abs/2312.01338)|[code](https://github.com/liamheng/Annotation-free-Medical-Image-Enhancement.)|-|\n", "Uncertainty-Aware Source-Free Adaptive Image Super-Resolution with Wavelet Augmentation Transformer": "|**2023-12-2**|**Uncertainty-Aware Source-Free Adaptive Image Super-Resolution with Wavelet Augmentation Transformer**|Yuang Ai et.al|[paper](https://arxiv.org/abs/2303.17783)|-|-|\n", "Improving Source-Free Target Adaptation with Vision Transformers Leveraging Domain Representation Images": "|**2023-12-2**|**Improving Source-Free Target Adaptation with Vision Transformers Leveraging Domain Representation Images**|Gauransh Sawhney et.al|[paper](https://arxiv.org/abs/2311.12589)|-|<details><summary>detail</summary>Requesting withdrawal due to significant overlap with prior research that wasn't appropriately acknowledged in our manuscript</details>|\n", "Target-agnostic Source-free Domain Adaptation for Regression Tasks": "|**2023-12-1**|**Target-agnostic Source-free Domain Adaptation for Regression Tasks**|Tianlang He et.al|[paper](https://arxiv.org/abs/2312.00540)|-|<details><summary>detail</summary>Accepted by ICDE 2024</details>|\n", "Overcoming Label Noise for Source-free Unsupervised Video Domain Adaptation": "|**2023-11-30**|**Overcoming Label Noise for Source-free Unsupervised Video Domain Adaptation**|Avijit Dasgupta et.al|[paper](https://arxiv.org/abs/2311.18572)|[code](https://avijit9.github.io/CleanAdapt.)|<details><summary>detail</summary>Extended version of our ICVGIP paper</details>|\n", "Aligning Non-Causal Factors for Transformer-Based Source-Free Domain Adaptation": "|**2023-11-27**|**Aligning Non-Causal Factors for Transformer-Based Source-Free Domain Adaptation**|Sunandini Sanyal et.al|[paper](https://arxiv.org/abs/2311.16294)|[code](https://val.cds.iisc.ac.in/C-SFTrans/)|<details><summary>detail</summary>WACV 2024</details>|\n", "Source-Free Domain Adaptation with Frozen Multimodal Foundation Model": "|**2023-11-27**|**Source-Free Domain Adaptation with Frozen Multimodal Foundation Model**|Song Tang et.al|[paper](https://arxiv.org/abs/2311.16510)|-|-|\n", "Periodically Exchange Teacher-Student for Source-Free Object Detection": "|**2023-11-23**|**Periodically Exchange Teacher-Student for Source-Free Object Detection**|Qipeng Liu et.al|[paper](https://arxiv.org/abs/2311.13930)|-|<details><summary>detail</summary>ICCV 2023</details>|\n", "Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces": "|**2023-11-19**|**Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces**|Osman Berke Guney et.al|[paper](https://arxiv.org/abs/2305.17403)|[code](https://github.com/osmanberke/SFDA-SSVEP-BCI)|-|\n", "Model-Free Source Seeking by a Novel Single-Integrator with Attenuating Oscillations and Better Convergence: Robotic Experiments": "|**2023-11-7**|**Model-Free Source Seeking by a Novel Single-Integrator with Attenuating Oscillations and Better Convergence: Robotic Experiments**|Shivam Bajpai et.al|[paper](https://arxiv.org/abs/2311.04330)|-|-|\n", "In Search for a Generalizable Method for Source Free Domain Adaptation": "|**2023-12-10**|**In Search for a Generalizable Method for Source Free Domain Adaptation**|M Boudiaf et.al|[paper](https://arxiv.org/abs/2302.06658)|[code](https://paperswithcode.com/paper/in-search-for-a-generalizable-method-for)|-|\n", "MAPS: A Noise-Robust Progressive Learning Approach for Source-Free Domain Adaptive Keypoint Detection": "|**2023-12-7**|**MAPS: A Noise-Robust Progressive Learning Approach for Source-Free Domain Adaptive Keypoint Detection**|Y Ding et.al|[paper](https://arxiv.org/abs/2302.04589)|[code](https://github.com/yuhed/maps)|-|\n", "Universal source-free domain adaptation method for cross-domain fault diagnosis of machines": "|**2023-11-30**|**Universal source-free domain adaptation method for cross-domain fault diagnosis of machines**|Y Zhang et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0888327023000663)|-|<details><summary>detail</summary>Mechanical Systems and\u00a0\u2026, 2023 Elsevier</details>|\n", "TIDo: Source-free Task Incremental Learning in Non-stationary Environments": "|**2023-11-24**|**TIDo: Source-free Task Incremental Learning in Non-stationary Environments**|AK Ambastha et.al|[paper](https://arxiv.org/abs/2301.12055)|[code](https://paperswithcode.com/paper/tido-source-free-task-incremental-learning-in)|-|\n", "Adversarial Learning Networks: Source-free Unsupervised Domain Incremental Learning": "|**2023-11-24**|**Adversarial Learning Networks: Source-free Unsupervised Domain Incremental Learning**|AK Ambastha et.al|[paper](https://arxiv.org/abs/2301.12054)|[code](https://paperswithcode.com/paper/adversarial-learning-networks-source-free)|-|\n", "Cross-platform privacy-preserving CT image COVID-19 diagnosis based on source-free domain adaptation": "|**2023-11-19**|**Cross-platform privacy-preserving CT image COVID-19 diagnosis based on source-free domain adaptation**|Y Feng et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0950705123000746)|-|<details><summary>detail</summary>Knowledge Based Systems, 2023 Elsevier</details>|\n", "Source-free Subject Adaptation for EEG-based Visual Recognition": "|**2023-11-16**|**Source-free Subject Adaptation for EEG-based Visual Recognition**|P Lee et.al|[paper](https://arxiv.org/abs/2301.08448)|[code](https://github.com/DeepBCI/Deep-BCI)|-|\n", "When Source-Free Domain Adaptation Meets Label Propagation": "|**2023-11-16**|**When Source-Free Domain Adaptation Meets Label Propagation**|C Wu et.al|[paper](https://arxiv.org/abs/2301.08413)|-|-|\n", "Source-Free Domain Adaptive Detection of Concealed Objects in Passive Millimeter-Wave Images": "|**2023-11-14**|**Source-Free Domain Adaptive Detection of Concealed Objects in Passive Millimeter-Wave Images**|H Yang et.al|[paper](https://ieeexplore.ieee.org/abstract/document/10019315/)|-|<details><summary>detail</summary>IEEE Transactions on\u00a0\u2026, 2023 ieeexplore.ieee.org</details>|\n"}, "object detection": {"Class-Wise Buffer Management for Incremental Object Detection: An Effective Buffer Training Strategy": "|**2023-12-14**|**Class-Wise Buffer Management for Incremental Object Detection: An Effective Buffer Training Strategy**|Junsu Kim et.al|[paper](https://arxiv.org/abs/2312.09139)|-|-|\n", "Learned Fusion: 3D Object Detection using Calibration-Free Transformer Feature Fusion": "|**2023-12-14**|**Learned Fusion: 3D Object Detection using Calibration-Free Transformer Feature Fusion**|Michael F\u00fcrst et.al|[paper](https://arxiv.org/abs/2312.09082)|-|-|\n", "AMSP-UOD: When Vortex Convolution and Stochastic Perturbation Meet Underwater Object Detection": "|**2023-12-14**|**AMSP-UOD: When Vortex Convolution and Stochastic Perturbation Meet Underwater Object Detection**|Jingchun Zhou et.al|[paper](https://arxiv.org/abs/2308.11918)|[code](https://github.com/zhoujingchun03/AMSP-UOD.)|-|\n", "Learning Remote Sensing Object Detection with Single Point Supervision": "|**2023-12-14**|**Learning Remote Sensing Object Detection with Single Point Supervision**|Shitian He et.al|[paper](https://arxiv.org/abs/2305.14141)|[code](https://github.com/heshitian/PLUG.)|<details><summary>detail</summary>Accepted by IEEE TGRS</details>|\n", "Challenges of YOLO Series for Object Detection in Extremely Heavy Rain: CALRA Simulator based Synthetic Evaluation Dataset": "|**2023-12-14**|**Challenges of YOLO Series for Object Detection in Extremely Heavy Rain: CALRA Simulator based Synthetic Evaluation Dataset**|T. Kim et.al|[paper](https://arxiv.org/abs/2312.07976)|-|-|\n", "A Simple Knowledge Distillation Framework for Open-world Object Detection": "|**2023-12-13**|**A Simple Knowledge Distillation Framework for Open-world Object Detection**|Shuailei Ma et.al|[paper](https://arxiv.org/abs/2312.08653)|-|<details><summary>detail</summary>arXiv admin note: substantial text overlap with arXiv:2303</details>|\n", "DRUformer: Enhancing the driving scene Important object detection with driving relationship self-understanding": "|**2023-12-13**|**DRUformer: Enhancing the driving scene Important object detection with driving relationship self-understanding**|Yingjie Niu et.al|[paper](https://arxiv.org/abs/2311.06497)|-|-|\n", "Focus on Local Regions for Query-based Object Detection": "|**2023-12-13**|**Focus on Local Regions for Query-based Object Detection**|Hongbin Xu et.al|[paper](https://arxiv.org/abs/2310.06470)|-|-|\n", "PTT: Point-Trajectory Transformer for Efficient Temporal 3D Object Detection": "|**2023-12-13**|**PTT: Point-Trajectory Transformer for Efficient Temporal 3D Object Detection**|Kuan-Chih Huang et.al|[paper](https://arxiv.org/abs/2312.08371)|[code](https://github.com/kuanchihhuang/PTT.)|<details><summary>detail</summary>Project page: https://github</details>|\n", "Instance-aware Multi-Camera 3D Object Detection with Structural Priors Mining and Self-Boosting Learning": "|**2023-12-13**|**Instance-aware Multi-Camera 3D Object Detection with Structural Priors Mining and Self-Boosting Learning**|Yang Jiao et.al|[paper](https://arxiv.org/abs/2312.08004)|-|<details><summary>detail</summary>AAAI 2024</details>|\n", "Revisiting Token Pruning for Object Detection and Instance Segmentation": "|**2023-12-12**|**Revisiting Token Pruning for Object Detection and Instance Segmentation**|Yifei Liu et.al|[paper](https://arxiv.org/abs/2306.07050)|-|<details><summary>detail</summary>Journal ref:IEEE Winter Conference on Applications of Computer Vision (WACV 2024)</details>|\n", "MedYOLO: A Medical Image Object Detection Framework": "|**2023-12-12**|**MedYOLO: A Medical Image Object Detection Framework**|Joseph Sobek et.al|[paper](https://arxiv.org/abs/2312.07729)|-|-|\n", "Weakly Supervised 3D Object Detection via Multi-Level Visual Guidance": "|**2023-12-12**|**Weakly Supervised 3D Object Detection via Multi-Level Visual Guidance**|Kuan-Chih Huang et.al|[paper](https://arxiv.org/abs/2312.07530)|[code](https://github.com/kuanchihhuang/VG-W3D.)|<details><summary>detail</summary>Project page: https://github</details>|\n", "Efficient Object Detection in Autonomous Driving using Spiking Neural Networks: Performance, Energy Consumption Analysis, and Insights into Open-set Object Discovery": "|**2023-12-12**|**Efficient Object Detection in Autonomous Driving using Spiking Neural Networks: Performance, Energy Consumption Analysis, and Insights into Open-set Object Discovery**|Aitor Martinez Seras et.al|[paper](https://arxiv.org/abs/2312.07466)|-|-|\n", "ProxyDet: Synthesizing Proxy Novel Classes via Classwise Mixup for Open Vocabulary Object Detection": "|**2023-12-12**|**ProxyDet: Synthesizing Proxy Novel Classes via Classwise Mixup for Open Vocabulary Object Detection**|Joonhyun Jeong et.al|[paper](https://arxiv.org/abs/2312.07266)|-|<details><summary>detail</summary>Accepted in AAAI24</details>|\n"}, "domain adaptation": {"Subspace Identification for Multi-Source Domain Adaptation": "|**2023-12-14**|**Subspace Identification for Multi-Source Domain Adaptation**|Zijian Li et.al|[paper](https://arxiv.org/abs/2310.04723)|-|<details><summary>detail</summary>NeurIPS2023 Spotlight</details>|\n", "ReCLIP: Refine Contrastive Language Image Pre-Training with Source Free Domain Adaptation": "|**2023-12-13**|**ReCLIP: Refine Contrastive Language Image Pre-Training with Source Free Domain Adaptation**|Xuefeng Hu et.al|[paper](https://arxiv.org/abs/2308.03793)|[code](https://github.com/michiganleon/ReCLIP_WACV.)|<details><summary>detail</summary>Accepted as Oral Paper by 2024 IEEE CVF Winter Conference on Applications of Computer Vision (WACV)</details>|\n", "MLNet: Mutual Learning Network with Neighborhood Invariance for Universal Domain Adaptation": "|**2023-12-13**|**MLNet: Mutual Learning Network with Neighborhood Invariance for Universal Domain Adaptation**|Yanzuo Lu et.al|[paper](https://arxiv.org/abs/2312.07871)|[code](https://github.com/YanzuoLu/MLNet.)|<details><summary>detail</summary>Accepted by AAAI2024</details>|\n", "Learning to Adapt SAM for Segmenting Cross-domain Point Clouds": "|**2023-12-13**|**Learning to Adapt SAM for Segmenting Cross-domain Point Clouds**|Xidong Peng et.al|[paper](https://arxiv.org/abs/2310.08820)|-|-|\n", "Explainable AI in Grassland Monitoring: Enhancing Model Performance and Domain Adaptability": "|**2023-12-13**|**Explainable AI in Grassland Monitoring: Enhancing Model Performance and Domain Adaptability**|Shanghua Liu et.al|[paper](https://arxiv.org/abs/2312.08408)|-|-|\n", "Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation": "|**2023-12-13**|**Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation**|Yuqi Chen et.al|[paper](https://arxiv.org/abs/2301.13428)|-|<details><summary>detail</summary>Journal articles</details>|\n", "Learning to See Low-Light Images via Feature Domain Adaptation": "|**2023-12-12**|**Learning to See Low-Light Images via Feature Domain Adaptation**|Qirui Yang et.al|[paper](https://arxiv.org/abs/2312.06723)|-|-|\n", "Graph Harmony: Denoising and Nuclear-Norm Wasserstein Adaptation for Enhanced Domain Transfer in Graph-Structured Data": "|**2023-12-12**|**Graph Harmony: Denoising and Nuclear-Norm Wasserstein Adaptation for Enhanced Domain Transfer in Graph-Structured Data**|Mengxi Wu et.al|[paper](https://arxiv.org/abs/2301.12361)|-|-|\n", "Adapting Self-Supervised Representations to Multi-Domain Setups": "|**2023-12-12**|**Adapting Self-Supervised Representations to Multi-Domain Setups**|Neha Kalibhat et.al|[paper](https://arxiv.org/abs/2309.03999)|-|<details><summary>detail</summary>Published at BMVC 2023</details>|\n", "Adversarial Semi-Supervised Domain Adaptation for Semantic Segmentation: A New Role for Labeled Target Samples": "|**2023-12-12**|**Adversarial Semi-Supervised Domain Adaptation for Semantic Segmentation: A New Role for Labeled Target Samples**|Marwa Kechaou et.al|[paper](https://arxiv.org/abs/2312.07370)|-|-|\n", "Mean Teacher DETR with Masked Feature Alignment: A Robust Domain Adaptive Detection Transformer Framework": "|**2023-12-12**|**Mean Teacher DETR with Masked Feature Alignment: A Robust Domain Adaptive Detection Transformer Framework**|Weixi Weng et.al|[paper](https://arxiv.org/abs/2310.15646)|-|<details><summary>detail</summary>AAAI2024</details>|\n", "Robust End-to-End Diarization with Domain Adaptive Training and Multi-Task Learning": "|**2023-12-12**|**Robust End-to-End Diarization with Domain Adaptive Training and Multi-Task Learning**|Ivan Fung et.al|[paper](https://arxiv.org/abs/2312.07136)|-|-|\n", "ADOD: Adaptive Domain-Aware Object Detection with Residual Attention for Underwater Environments": "|**2023-12-11**|**ADOD: Adaptive Domain-Aware Object Detection with Residual Attention for Underwater Environments**|Lyes Saad Saoud et.al|[paper](https://arxiv.org/abs/2312.06801)|-|-|\n", "DG-TTA: Out-of-domain medical image segmentation through Domain Generalization and Test-Time Adaptation": "|**2023-12-11**|**DG-TTA: Out-of-domain medical image segmentation through Domain Generalization and Test-Time Adaptation**|Christian Weihsbach et.al|[paper](https://arxiv.org/abs/2312.06275)|[code](https://github.com/multimodallearning/DG-TTA)|<details><summary>detail</summary>This work has been submitted to the IEEE for possible publication</details>|\n", "Combining inherent knowledge of vision-language models with unsupervised domain adaptation through self-knowledge distillation": "|**2023-12-10**|**Combining inherent knowledge of vision-language models with unsupervised domain adaptation through self-knowledge distillation**|Thomas Westfechtel et.al|[paper](https://arxiv.org/abs/2312.04066)|-|-|\n"}, "domain generalization": {"Revisiting Depth Completion from a Stereo Matching Perspective for Cross-domain Generalization": "|**2023-12-14**|**Revisiting Depth Completion from a Stereo Matching Perspective for Cross-domain Generalization**|Luca Bartolomei et.al|[paper](https://arxiv.org/abs/2312.09254)|[code](https://github.com/bartn8/vppdc)|<details><summary>detail</summary>3DV 2024</details>|\n", "Stronger, Fewer, & Superior: Harnessing Vision Foundation Models for Domain Generalized Semantic Segmentation": "|**2023-12-14**|**Stronger, Fewer, & Superior: Harnessing Vision Foundation Models for Domain Generalized Semantic Segmentation**|Zhixiang Wei et.al|[paper](https://arxiv.org/abs/2312.04265)|[code](https://github.com/w1oves/Rein.git.)|-|\n", "Domain Generalization with Fourier Transform and Soft Thresholding": "|**2023-12-12**|**Domain Generalization with Fourier Transform and Soft Thresholding**|Hongyi Pan et.al|[paper](https://arxiv.org/abs/2309.09866)|-|<details><summary>detail</summary>This paper was accepted to ICASSP 2024</details>|\n", "DG-TTA: Out-of-domain medical image segmentation through Domain Generalization and Test-Time Adaptation": "|**2023-12-11**|**DG-TTA: Out-of-domain medical image segmentation through Domain Generalization and Test-Time Adaptation**|Christian Weihsbach et.al|[paper](https://arxiv.org/abs/2312.06275)|[code](https://github.com/multimodallearning/DG-TTA)|<details><summary>detail</summary>This work has been submitted to the IEEE for possible publication</details>|\n", "VLTSeg: Simple Transfer of CLIP-Based Vision-Language Representations for Domain Generalized Semantic Segmentation": "|**2023-12-11**|**VLTSeg: Simple Transfer of CLIP-Based Vision-Language Representations for Domain Generalized Semantic Segmentation**|Christoph H\u00fcmmer et.al|[paper](https://arxiv.org/abs/2312.02021)|-|-|\n", "Learning Content-enhanced Mask Transformer for Domain Generalized Urban-Scene Segmentation": "|**2023-12-9**|**Learning Content-enhanced Mask Transformer for Domain Generalized Urban-Scene Segmentation**|Qi Bi et.al|[paper](https://arxiv.org/abs/2307.00371)|[code](https://github.com/BiQiWHU/CMFormer)|-|\n", "Cross Domain Generative Augmentation: Domain Generalization with Latent Diffusion Models": "|**2023-12-8**|**Cross Domain Generative Augmentation: Domain Generalization with Latent Diffusion Models**|Sobhan Hemati et.al|[paper](https://arxiv.org/abs/2312.05387)|-|-|\n", "Open Domain Generalization with a Single Network by Regularization Exploiting Pre-trained Features": "|**2023-12-8**|**Open Domain Generalization with a Single Network by Regularization Exploiting Pre-trained Features**|Inseop Chung et.al|[paper](https://arxiv.org/abs/2312.05141)|-|-|\n", "ZeroNLG: Aligning and Autoencoding Domains for Zero-Shot Multimodal and Multilingual Natural Language Generation": "|**2023-12-6**|**ZeroNLG: Aligning and Autoencoding Domains for Zero-Shot Multimodal and Multilingual Natural Language Generation**|Bang Yang et.al|[paper](https://arxiv.org/abs/2303.06458)|[code](https://github.com/yangbang18/ZeroNLG)|<details><summary>detail</summary>Our code and data are available at https://github</details>|\n", "Few-shot Hybrid Domain Adaptation of Image Generators": "|**2023-12-6**|**Few-shot Hybrid Domain Adaptation of Image Generators**|Hengjia Li et.al|[paper](https://arxiv.org/abs/2310.19378)|-|-|\n", "Domain-wise Invariant Learning for Panoptic Scene Graph Generation": "|**2023-12-5**|**Domain-wise Invariant Learning for Panoptic Scene Graph Generation**|Li Li et.al|[paper](https://arxiv.org/abs/2310.05867)|-|<details><summary>detail</summary>arXiv admin note: text overlap with arXiv:2307</details>|\n", "Domain Generalization via Nuclear Norm Regularization": "|**2023-12-4**|**Domain Generalization via Nuclear Norm Regularization**|Zhenmei Shi et.al|[paper](https://arxiv.org/abs/2303.07527)|-|-|\n", "ContriMix: Unsupervised disentanglement of content and attribute for domain generalization in microscopy image analysis": "|**2023-12-4**|**ContriMix: Unsupervised disentanglement of content and attribute for domain generalization in microscopy image analysis**|Tan H. Nguyen et.al|[paper](https://arxiv.org/abs/2306.04527)|[code](https://gitlab.com/huutan86/contrimix)|-|\n", "Generalization by Adaptation: Diffusion-Based Domain Extension for Domain-Generalized Semantic Segmentation": "|**2023-12-4**|**Generalization by Adaptation: Diffusion-Based Domain Extension for Domain-Generalized Semantic Segmentation**|Joshua Niemeijer et.al|[paper](https://arxiv.org/abs/2312.01850)|[code](https://github.com/JNiemeijer/DIDEX)|<details><summary>detail</summary>WACV 2024</details>|\n", "CNN Feature Map Augmentation for Single-Source Domain Generalization": "|**2023-12-4**|**CNN Feature Map Augmentation for Single-Source Domain Generalization**|Aristotelis Ballas et.al|[paper](https://arxiv.org/abs/2305.16746)|[code](https://ieeebigdataservice.com/))|<details><summary>detail</summary>In proceedings of IEEE BigDataService2023 (https://ieeebigdataservice</details>|\n"}, "vision language": {"VL-GPT: A Generative Pre-trained Transformer for Vision and Language Understanding and Generation": "|**2023-12-14**|**VL-GPT: A Generative Pre-trained Transformer for Vision and Language Understanding and Generation**|Jinguo Zhu et.al|[paper](https://arxiv.org/abs/2312.09251)|-|-|\n", "Vision-Language Models as a Source of Rewards": "|**2023-12-14**|**Vision-Language Models as a Source of Rewards**|Kate Baumli et.al|[paper](https://arxiv.org/abs/2312.09187)|-|-|\n", "InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition": "|**2023-12-14**|**InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition**|Pan Zhang et.al|[paper](https://arxiv.org/abs/2309.15112)|[code](https://github.com/InternLM/InternLM-XComposer.)|<details><summary>detail</summary>Code and models are available at https://github</details>|\n", "TiMix: Text-aware Image Mixing for Effective Vision-Language Pre-training": "|**2023-12-14**|**TiMix: Text-aware Image Mixing for Effective Vision-Language Pre-training**|Chaoya Jiang et.al|[paper](https://arxiv.org/abs/2312.08846)|-|<details><summary>detail</summary>Accepted on AAAI2024</details>|\n", "Grounding Everything: Emerging Localization Properties in Vision-Language Transformers": "|**2023-12-14**|**Grounding Everything: Emerging Localization Properties in Vision-Language Transformers**|Walid Bousselham et.al|[paper](https://arxiv.org/abs/2312.00878)|[code](https://github.com/WalBouss/GEM)|<details><summary>detail</summary>Code available at https://github</details>|\n", "Prompt-based Context- and Domain-aware Pretraining for Vision and Language Navigation": "|**2023-12-14**|**Prompt-based Context- and Domain-aware Pretraining for Vision and Language Navigation**|Ting Liu et.al|[paper](https://arxiv.org/abs/2309.03661)|-|-|\n", "FigStep: Jailbreaking Large Vision-language Models via Typographic Visual Prompts": "|**2023-12-13**|**FigStep: Jailbreaking Large Vision-language Models via Typographic Visual Prompts**|Yichen Gong et.al|[paper](https://arxiv.org/abs/2311.05608)|-|<details><summary>detail</summary>Technical Report</details>|\n", "A Foundational Multimodal Vision Language AI Assistant for Human Pathology": "|**2023-12-12**|**A Foundational Multimodal Vision Language AI Assistant for Human Pathology**|Ming Y. Lu et.al|[paper](https://arxiv.org/abs/2312.07814)|-|-|\n", "Daily Assistive View Control Learning of Low-Cost Low-Rigidity Robot via Large-Scale Vision-Language Model": "|**2023-12-12**|**Daily Assistive View Control Learning of Low-Cost Low-Rigidity Robot via Large-Scale Vision-Language Model**|Kento Kawaharazuka et.al|[paper](https://arxiv.org/abs/2312.07451)|-|<details><summary>detail</summary>accepted at Humanoids2023</details>|\n", "Turbo: Informativity-Driven Acceleration Plug-In for Vision-Language Models": "|**2023-12-12**|**Turbo: Informativity-Driven Acceleration Plug-In for Vision-Language Models**|Chen Ju et.al|[paper](https://arxiv.org/abs/2312.07408)|-|-|\n", "Vision-language Assisted Attribute Learning": "|**2023-12-12**|**Vision-language Assisted Attribute Learning**|Kongming Liang et.al|[paper](https://arxiv.org/abs/2312.07009)|-|<details><summary>detail</summary>Accepted by IEEE IC-NIDC 2023</details>|\n", "CoPL: Contextual Prompt Learning for Vision-Language Understanding": "|**2023-12-12**|**CoPL: Contextual Prompt Learning for Vision-Language Understanding**|Koustava Goswami et.al|[paper](https://arxiv.org/abs/2307.00910)|-|<details><summary>detail</summary>AAAI 2024</details>|\n", "Remote Sensing Vision-Language Foundation Models without Annotations via Ground Remote Alignment": "|**2023-12-11**|**Remote Sensing Vision-Language Foundation Models without Annotations via Ground Remote Alignment**|Utkarsh Mall et.al|[paper](https://arxiv.org/abs/2312.06960)|-|-|\n", "DiffVL: Scaling Up Soft Body Manipulation using Vision-Language Driven Differentiable Physics": "|**2023-12-11**|**DiffVL: Scaling Up Soft Body Manipulation using Vision-Language Driven Differentiable Physics**|Zhiao Huang et.al|[paper](https://arxiv.org/abs/2312.06408)|-|-|\n", "Learning Hierarchical Prompt with Structured Linguistic Knowledge for Vision-Language Models": "|**2023-12-11**|**Learning Hierarchical Prompt with Structured Linguistic Knowledge for Vision-Language Models**|Yubin Wang et.al|[paper](https://arxiv.org/abs/2312.06323)|[code](https://github.com/Vill-Lab/2024-AAAI-HPT.)|<details><summary>detail</summary>AAAI2024</details>|\n"}}