{"source-free": {"Source-Free Object Detection with Detection Transformer": "|**2025-10-13**|**Source-Free Object Detection with Detection Transformer**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2510.11090)|-|<details><summary>detail</summary>IEEE Transactions on Image Processing</details>|\n", "Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning": "|**2025-10-9**|**Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning**|Ziqi Zhang et.al|[paper](https://arxiv.org/abs/2510.08393)|-|-|\n", "ESS-Flow: Training-free guidance of flow-based models as inference in source space": "|**2025-10-7**|**ESS-Flow: Training-free guidance of flow-based models as inference in source space**|Adhithyan Kalaivanan et.al|[paper](https://arxiv.org/abs/2510.05849)|-|-|\n", "Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising": "|**2025-10-7**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|\n", "A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation": "|**2025-10-6**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|\n", "Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection": "|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|\n", "Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation": "|**2025-10-3**|**Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation**|Yucheng Wang et.al|[paper](https://arxiv.org/abs/2409.19635)|-|-|\n", "OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation": "|**2025-10-2**|**OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation**|Yiming Zhang et.al|[paper](https://arxiv.org/abs/2505.11669)|-|-|\n", "Source-Free Cross-Domain Continual Learning": "|**2025-10-2**|**Source-Free Cross-Domain Continual Learning**|Muhammad Tanzil Furqon et.al|[paper](https://arxiv.org/abs/2510.01649)|-|-|\n", "Consistent Assistant Domains Transformer for Source-free Domain Adaptation": "|**2025-10-1**|**Consistent Assistant Domains Transformer for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.01559)|[code](https://github.com/RoryShao/CADTrans.git.)|-|\n", "Source-Free Domain Adaptive Object Detection with Semantics Compensation": "|**2025-9-30**|**Source-Free Domain Adaptive Object Detection with Semantics Compensation**|Song Tang et.al|[paper](https://arxiv.org/abs/2410.05557)|-|-|\n", "DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation": "|**2025-9-29**|**DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation**|Xi Chen et.al|[paper](https://arxiv.org/abs/2509.24896)|-|-|\n", "Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation": "|**2025-9-29**|**Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|\n", "Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment": "|**2025-9-22**|**Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment**|Wenjie Liu et.al|[paper](https://arxiv.org/abs/2509.18502)|-|-|\n", "Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation": "|**2025-9-22**|**Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation**|Amirhossein Dadashzadeh et.al|[paper](https://arxiv.org/abs/2504.11669)|[code](https://github.com/Plrbear/Co-Star)|-|\n"}, "object detection": {"When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models": "|**2025-10-13**|**When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models**|Samer Al-Hamadani et.al|[paper](https://arxiv.org/abs/2510.11302)|-|-|\n", "Source-Free Object Detection with Detection Transformer": "|**2025-10-13**|**Source-Free Object Detection with Detection Transformer**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2510.11090)|-|<details><summary>detail</summary>IEEE Transactions on Image Processing</details>|\n", "RoHOI: Robustness Benchmark for Human-Object Interaction Detection": "|**2025-10-13**|**RoHOI: Robustness Benchmark for Human-Object Interaction Detection**|Di Wen et.al|[paper](https://arxiv.org/abs/2507.09111)|[code](https://github.com/KratosWen/RoHOI.)|<details><summary>detail</summary>Benchmarks</details>|\n", "MRS-YOLO Railroad Transmission Line Foreign Object Detection Based on Improved YOLO11 and Channel Pruning": "|**2025-10-12**|**MRS-YOLO Railroad Transmission Line Foreign Object Detection Based on Improved YOLO11 and Channel Pruning**|Siyuan Liu et.al|[paper](https://arxiv.org/abs/2510.10553)|-|-|\n", "Bridging Perspectives: Foundation Model Guided BEV Maps for 3D Object Detection and Tracking": "|**2025-10-11**|**Bridging Perspectives: Foundation Model Guided BEV Maps for 3D Object Detection and Tracking**|Markus K\u00e4ppeler et.al|[paper](https://arxiv.org/abs/2510.10287)|[code](https://dualviewdistill.cs.uni-freiburg.de)|-|\n", "TARO: Toward Semantically Rich Open-World Object Detection": "|**2025-10-10**|**TARO: Toward Semantically Rich Open-World Object Detection**|Yuchen Zhang et.al|[paper](https://arxiv.org/abs/2510.09173)|-|-|\n", "CQ-DINO: Mitigating Gradient Dilution via Category Queries for Vast Vocabulary Object Detection": "|**2025-10-10**|**CQ-DINO: Mitigating Gradient Dilution via Category Queries for Vast Vocabulary Object Detection**|Zhichao Sun et.al|[paper](https://arxiv.org/abs/2503.18430)|[code](https://github.com/FireRedTeam/CQ-DINO.)|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "SOS: Synthetic Object Segments Improve Detection, Segmentation, and Grounding": "|**2025-10-10**|**SOS: Synthetic Object Segments Improve Detection, Segmentation, and Grounding**|Weikai Huang et.al|[paper](https://arxiv.org/abs/2510.09110)|[code](https://github.com/weikaih04/SOS)|<details><summary>detail</summary>Project website: https://github</details>|\n", "Ultra-Efficient On-Device Object Detection on AI-Integrated Smart Glasses with TinyissimoYOLO": "|**2025-10-9**|**Ultra-Efficient On-Device Object Detection on AI-Integrated Smart Glasses with TinyissimoYOLO**|Julian Moosmann et.al|[paper](https://arxiv.org/abs/2311.01057)|[code](https://github.com/ETH-PBL/TinyissimoYOLO)|<details><summary>detail</summary>This paper has been accepted for publication at ECCV 2024 Workshops</details>|\n", "Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models": "|**2025-10-8**|**Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models**|Peter Robicheaux et.al|[paper](https://arxiv.org/abs/2505.20612)|[code](https://github.com/roboflow/rf100-vl)|<details><summary>detail</summary>The first two authors contributed equally</details>|\n", "SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation": "|**2025-10-7**|**SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation**|Ayush Zenith et.al|[paper](https://arxiv.org/abs/2510.06596)|[code](https://github.com/ayushzenith/SDQM)|-|\n", "Enhancing Maritime Object Detection in Real-Time with RT-DETR and Data Augmentation": "|**2025-10-7**|**Enhancing Maritime Object Detection in Real-Time with RT-DETR and Data Augmentation**|Nader Nemati et.al|[paper](https://arxiv.org/abs/2510.07346)|-|-|\n", "Incremental Object Detection with Prompt-based Methods": "|**2025-10-7**|**Incremental Object Detection with Prompt-based Methods**|Matthias Neuwirth-Trapp et.al|[paper](https://arxiv.org/abs/2508.14599)|-|<details><summary>detail</summary>ICCV Workshops 2025: v2 update affiliation</details>|\n", "RICO: Two Realistic Benchmarks and an In-Depth Analysis for Incremental Learning in Object Detection": "|**2025-10-7**|**RICO: Two Realistic Benchmarks and an In-Depth Analysis for Incremental Learning in Object Detection**|Matthias Neuwirth-Trapp et.al|[paper](https://arxiv.org/abs/2508.13878)|-|<details><summary>detail</summary>ICCV Workshops 2025</details>|\n", "HOI-R1: Exploring the Potential of Multimodal Large Language Models for Human-Object Interaction Detection": "|**2025-10-7**|**HOI-R1: Exploring the Potential of Multimodal Large Language Models for Human-Object Interaction Detection**|Junwen Chen et.al|[paper](https://arxiv.org/abs/2510.05609)|[code](https://github.com/cjw2021/HOI-R1.)|-|\n"}, "domain adaptation": {"Early Detection and Reduction of Memorisation for Domain Adaptation and Instruction Tuning": "|**2025-10-13**|**Early Detection and Reduction of Memorisation for Domain Adaptation and Instruction Tuning**|Dean L. Slack et.al|[paper](https://arxiv.org/abs/2510.11372)|-|<details><summary>detail</summary>Transactions of the ACL (TACL)</details>|\n", "Domain-Specific Data Generation Framework for RAG Adaptation": "|**2025-10-13**|**Domain-Specific Data Generation Framework for RAG Adaptation**|Chris Xing Tian et.al|[paper](https://arxiv.org/abs/2510.11217)|-|-|\n", "HAMUR: Hyper Adapter for Multi-Domain Recommendation": "|**2025-10-12**|**HAMUR: Hyper Adapter for Multi-Domain Recommendation**|Xiaopeng Li et.al|[paper](https://arxiv.org/abs/2309.06217)|-|<details><summary>detail</summary>Accepted by CIKM'2023</details>|\n", "Reinforced Domain Selection for Continuous Domain Adaptation": "|**2025-10-12**|**Reinforced Domain Selection for Continuous Domain Adaptation**|Hanbing Liu et.al|[paper](https://arxiv.org/abs/2510.10530)|-|<details><summary>detail</summary>Journal ref:ICASSP 2025 - 2025 IEEE International Conference on Acoustics</details>|\n", "Vicinity-Guided Discriminative Latent Diffusion for Privacy-Preserving Domain Adaptation": "|**2025-10-11**|**Vicinity-Guided Discriminative Latent Diffusion for Privacy-Preserving Domain Adaptation**|Jing Wang et.al|[paper](https://arxiv.org/abs/2510.00478)|-|<details><summary>detail</summary>39th Conference on Neural Information Processing Systems (NeurIPS 2025)</details>|\n", "Sim-to-real supervised domain adaptation for radioisotope identification": "|**2025-10-10**|**Sim-to-real supervised domain adaptation for radioisotope identification**|Peter Lalor et.al|[paper](https://arxiv.org/abs/2412.07069)|-|-|\n", "Domain-Adapted Pre-trained Language Models for Implicit Information Extraction in Crash Narratives": "|**2025-10-10**|**Domain-Adapted Pre-trained Language Models for Implicit Information Extraction in Crash Narratives**|Xixi Wang et.al|[paper](https://arxiv.org/abs/2510.09434)|-|-|\n", "The 1st Solution for CARE Liver Task Challenge 2025: Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation": "|**2025-10-10**|**The 1st Solution for CARE Liver Task Challenge 2025: Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation**|Jincan Lou et.al|[paper](https://arxiv.org/abs/2510.04243)|-|-|\n", "Unsupervised Multi-Source Federated Domain Adaptation under Domain Diversity through Group-Wise Discrepancy Minimization": "|**2025-10-10**|**Unsupervised Multi-Source Federated Domain Adaptation under Domain Diversity through Group-Wise Discrepancy Minimization**|Larissa Reichart et.al|[paper](https://arxiv.org/abs/2510.08150)|-|-|\n", "AB-PINNs: Adaptive-Basis Physics-Informed Neural Networks for Residual-Driven Domain Decomposition": "|**2025-10-9**|**AB-PINNs: Adaptive-Basis Physics-Informed Neural Networks for Residual-Driven Domain Decomposition**|Jonah Botvinick-Greenhouse et.al|[paper](https://arxiv.org/abs/2510.08924)|-|-|\n", "Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning": "|**2025-10-9**|**Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning**|Ziqi Zhang et.al|[paper](https://arxiv.org/abs/2510.08393)|-|-|\n", "Prepared mind, fast response: A temporal decoupling framework for adaptive knowledge orchestration in open-domain dialogue": "|**2025-10-9**|**Prepared mind, fast response: A temporal decoupling framework for adaptive knowledge orchestration in open-domain dialogue**|Jinling Gan et.al|[paper](https://arxiv.org/abs/2510.08175)|-|-|\n", "DACP: Domain-Adaptive Continual Pre-Training of Large Language Models for Phone Conversation Summarization": "|**2025-10-9**|**DACP: Domain-Adaptive Continual Pre-Training of Large Language Models for Phone Conversation Summarization**|Xue-Yong Fu et.al|[paper](https://arxiv.org/abs/2510.05858)|-|<details><summary>detail</summary>the NewSumm Workshop at EMNLP 2025</details>|\n", "DACIP-RC: Domain Adaptive Continual Instruction Pre-Training via Reading Comprehension on Business Conversations": "|**2025-10-9**|**DACIP-RC: Domain Adaptive Continual Instruction Pre-Training via Reading Comprehension on Business Conversations**|Elena Khasanova et.al|[paper](https://arxiv.org/abs/2510.08152)|-|<details><summary>detail</summary>the EMNLP 2025 Industry Track</details>|\n", "When Light Bends to the Collective Will: A Theory and Vision for Adaptive Photonic Scale-up Domains": "|**2025-10-9**|**When Light Bends to the Collective Will: A Theory and Vision for Adaptive Photonic Scale-up Domains**|Vamsi Addanki et.al|[paper](https://arxiv.org/abs/2510.08072)|-|-|\n"}, "domain generalization": {"Uncertainty-Aware ControlNet: Bridging Domain Gaps with Synthetic Image Generation": "|**2025-10-13**|**Uncertainty-Aware ControlNet: Bridging Domain Gaps with Synthetic Image Generation**|Joshua Niemeijer et.al|[paper](https://arxiv.org/abs/2510.11346)|-|<details><summary>detail</summary>Accepted for presentation at ICCV Workshops 2025</details>|\n", "Next Interest Flow: A Generative Pre-training Paradigm for Recommender Systems by Modeling All-domain Movelines": "|**2025-10-13**|**Next Interest Flow: A Generative Pre-training Paradigm for Recommender Systems by Modeling All-domain Movelines**|Chen Gao et.al|[paper](https://arxiv.org/abs/2510.11317)|-|-|\n", "Domain-Specific Data Generation Framework for RAG Adaptation": "|**2025-10-13**|**Domain-Specific Data Generation Framework for RAG Adaptation**|Chris Xing Tian et.al|[paper](https://arxiv.org/abs/2510.11217)|-|-|\n", "Can Tool-Integrated Reinforcement Learning Generalize Across Diverse Domains?": "|**2025-10-13**|**Can Tool-Integrated Reinforcement Learning Generalize Across Diverse Domains?**|Zhengyu Chen et.al|[paper](https://arxiv.org/abs/2510.11184)|-|-|\n", "Class-Invariant Test-Time Augmentation for Domain Generalization": "|**2025-10-12**|**Class-Invariant Test-Time Augmentation for Domain Generalization**|Zhicheng Lin et.al|[paper](https://arxiv.org/abs/2509.14420)|-|-|\n", "Latent Retrieval Augmented Generation of Cross-Domain Protein Binders": "|**2025-10-12**|**Latent Retrieval Augmented Generation of Cross-Domain Protein Binders**|Zishen Zhang et.al|[paper](https://arxiv.org/abs/2510.10480)|-|-|\n", "The 1st Solution for CARE Liver Task Challenge 2025: Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation": "|**2025-10-10**|**The 1st Solution for CARE Liver Task Challenge 2025: Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation**|Jincan Lou et.al|[paper](https://arxiv.org/abs/2510.04243)|-|-|\n", "Exploring Single Domain Generalization of LiDAR-based Semantic Segmentation under Imperfect Labels": "|**2025-10-10**|**Exploring Single Domain Generalization of LiDAR-based Semantic Segmentation under Imperfect Labels**|Weitong Kong et.al|[paper](https://arxiv.org/abs/2510.09035)|-|-|\n", "Mirror Flow Matching with Heavy-Tailed Priors for Generative Modeling on Convex Domains": "|**2025-10-9**|**Mirror Flow Matching with Heavy-Tailed Priors for Generative Modeling on Convex Domains**|Yunrui Guan et.al|[paper](https://arxiv.org/abs/2510.08929)|-|-|\n", "High-Rate Mixout: Revisiting Mixout for Robust Domain Generalization": "|**2025-10-9**|**High-Rate Mixout: Revisiting Mixout for Robust Domain Generalization**|Masih Aminbeidokhti et.al|[paper](https://arxiv.org/abs/2510.06955)|-|<details><summary>detail</summary>WACV 2026: Winter Conference on Applications of Computer Vision 2026</details>|\n", "Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations": "|**2025-10-8**|**Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations**|Ha Min Son et.al|[paper](https://arxiv.org/abs/2508.21769)|-|-|\n", "Lemma Dilemma: On Lemma Generation Without Domain- or Language-Specific Training Data": "|**2025-10-8**|**Lemma Dilemma: On Lemma Generation Without Domain- or Language-Specific Training Data**|Olia Toporkov et.al|[paper](https://arxiv.org/abs/2510.07434)|[code](https://github.com/oltoporkov/lemma-dilemma)|-|\n", "Domain Generalization by Rejecting Extreme Augmentations": "|**2025-10-8**|**Domain Generalization by Rejecting Extreme Augmentations**|Masih Aminbeidokhti et.al|[paper](https://arxiv.org/abs/2310.06670)|[code](https://github.com/Masseeh/DCAug)|<details><summary>detail</summary>WACV 2024: Winter Conference on Applications of Computer Vision 2024</details>|\n", "Redefining Generalization in Visual Domains: A Two-Axis Framework for Fake Image Detection with FusionDetect": "|**2025-10-7**|**Redefining Generalization in Visual Domains: A Two-Axis Framework for Fake Image Detection with FusionDetect**|Amirtaha Amanzadi et.al|[paper](https://arxiv.org/abs/2510.05740)|[code](http://github.com/amir-aman/FusionDetect)|<details><summary>detail</summary>Project code: http://github</details>|\n", "Domain Generalization: A Tale of Two ERMs": "|**2025-10-5**|**Domain Generalization: A Tale of Two ERMs**|Yilun Zhu et.al|[paper](https://arxiv.org/abs/2510.04441)|-|-|\n"}, "vision language": {"The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models": "|**2025-10-13**|**The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models**|Lijun Sheng et.al|[paper](https://arxiv.org/abs/2506.24000)|[code](https://github.com/TomSheng21/tta-vlm)|<details><summary>detail</summary>NeurIPS 2025 Datasets and Benchmarks Track</details>|\n", "FOSSIL: Harnessing Feedback on Suboptimal Samples for Data-Efficient Generalisation with Imitation Learning for Embodied Vision-and-Language Tasks": "|**2025-10-13**|**FOSSIL: Harnessing Feedback on Suboptimal Samples for Data-Efficient Generalisation with Imitation Learning for Embodied Vision-and-Language Tasks**|Sabrina McCallum et.al|[paper](https://arxiv.org/abs/2510.11307)|-|<details><summary>detail</summary>EMNLP 2025 Findings</details>|\n", "When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models": "|**2025-10-13**|**When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models**|Samer Al-Hamadani et.al|[paper](https://arxiv.org/abs/2510.11302)|-|-|\n", ": Optimizing Energy Change During Vision-Language Alignment Improves both OOD Detection and OOD Generalization": "|**2025-10-13**|**: Optimizing Energy Change During Vision-Language Alignment Improves both OOD Detection and OOD Generalization**|Lin Zhu et.al|[paper](https://arxiv.org/abs/2510.11296)|-|<details><summary>detail</summary>Accepted by NeruIPS2025</details>|\n", "TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision-Language-Action Models": "|**2025-10-13**|**TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision-Language-Action Models**|Chenghao Liu et.al|[paper](https://arxiv.org/abs/2508.19257)|-|<details><summary>detail</summary>Manuscript submitted to AAAI 2026</details>|\n", "Evaluating Reasoning Faithfulness in Medical Vision-Language Models using Multimodal Perturbations": "|**2025-10-13**|**Evaluating Reasoning Faithfulness in Medical Vision-Language Models using Multimodal Perturbations**|Johannes Moll et.al|[paper](https://arxiv.org/abs/2510.11196)|-|-|\n", "When Language Model Guides Vision: Grounding DINO for Cattle Muzzle Detection": "|**2025-10-13**|**When Language Model Guides Vision: Grounding DINO for Cattle Muzzle Detection**|Rabin Dulal et.al|[paper](https://arxiv.org/abs/2509.06427)|-|<details><summary>detail</summary>Journal ref:Australasian Joint Conference on Artificial Intelligence 2025</details>|\n", "BLEnD-Vis: Benchmarking Multimodal Cultural Understanding in Vision Language Models": "|**2025-10-13**|**BLEnD-Vis: Benchmarking Multimodal Cultural Understanding in Vision Language Models**|Bryan Chen Zhengyu Tan et.al|[paper](https://arxiv.org/abs/2510.11178)|-|<details><summary>detail</summary>Code and Dataset to be released</details>|\n", "A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning": "|**2025-10-13**|**A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning**|Keke Gai et.al|[paper](https://arxiv.org/abs/2508.10315)|[code](https://anonymous.4open.science/r/CLIP-Fed.)|-|\n", "Contrastive Representation Regularization for Vision-Language-Action Models": "|**2025-10-13**|**Contrastive Representation Regularization for Vision-Language-Action Models**|Taeyoung Kim et.al|[paper](https://arxiv.org/abs/2510.01711)|-|-|\n", "Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning": "|**2025-10-13**|**Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning**|Ganlin Yang et.al|[paper](https://arxiv.org/abs/2510.11027)|-|-|\n", "GeoVLMath: Enhancing Geometry Reasoning in Vision-Language Models via Cross-Modal Reward for Auxiliary Line Creation": "|**2025-10-13**|**GeoVLMath: Enhancing Geometry Reasoning in Vision-Language Models via Cross-Modal Reward for Auxiliary Line Creation**|Shasha Guo et.al|[paper](https://arxiv.org/abs/2510.11020)|-|-|\n", "COCO-Tree: Compositional Hierarchical Concept Trees for Enhanced Reasoning in Vision Language Models": "|**2025-10-13**|**COCO-Tree: Compositional Hierarchical Concept Trees for Enhanced Reasoning in Vision Language Models**|Sanchit Sinha et.al|[paper](https://arxiv.org/abs/2510.11012)|-|<details><summary>detail</summary>EMNLP 2025 (main)</details>|\n", "Goal-Based Vision-Language Driving": "|**2025-10-13**|**Goal-Based Vision-Language Driving**|Santosh Patapati et.al|[paper](https://arxiv.org/abs/2507.23042)|-|-|\n", "Vision-Language Cross-Attention for Real-Time Autonomous Driving": "|**2025-10-13**|**Vision-Language Cross-Attention for Real-Time Autonomous Driving**|Santosh Patapati et.al|[paper](https://arxiv.org/abs/2507.23064)|-|-|\n"}}