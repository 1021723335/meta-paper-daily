{"source-free": {"Source-free Depth for Object Pop-out": "|**2023-9-25**|**Source-free Depth for Object Pop-out**|Zongwei Wuet.al|[paper](https://arxiv.org/abs/2212.05370)|-|<details><summary>detail</summary>ICCV 2023</details>|\n", "Dual-Reference Source-Free Active Domain Adaptation for Nasopharyngeal Carcinoma Tumor Segmentation across Multiple Hospitals": "|**2023-9-23**|**Dual-Reference Source-Free Active Domain Adaptation for Nasopharyngeal Carcinoma Tumor Segmentation across Multiple Hospitals**|Hongqiu Wanget.al|[paper](https://arxiv.org/abs/2309.13401)|-|-|\n", "Source-free Active Domain Adaptation for Diabetic Retinopathy Grading Based on Ultra-wide-field Fundus Image": "|**2023-9-19**|**Source-free Active Domain Adaptation for Diabetic Retinopathy Grading Based on Ultra-wide-field Fundus Image**|Jinye Ranet.al|[paper](https://arxiv.org/abs/2309.10619)|-|-|\n", "UPL-SFDA: Uncertainty-aware Pseudo Label Guided Source-Free Domain Adaptation for Medical Image Segmentation": "|**2023-9-18**|**UPL-SFDA: Uncertainty-aware Pseudo Label Guided Source-Free Domain Adaptation for Medical Image Segmentation**|Jianghao Wuet.al|[paper](https://arxiv.org/abs/2309.10244)|-|-|\n", "Trust your Good Friends: Source-free Domain Adaptation by Reciprocal Neighborhood Clustering": "|**2023-9-1**|**Trust your Good Friends: Source-free Domain Adaptation by Reciprocal Neighborhood Clustering**|Shiqi Yanget.al|[paper](https://arxiv.org/abs/2309.00528)|-|<details><summary>detail</summary>Accepted by IEEE TPAMI</details>|\n", "Uncertainty-Aware Source-Free Adaptive Image Super-Resolution with Wavelet Augmentation Transformer": "|**2023-8-30**|**Uncertainty-Aware Source-Free Adaptive Image Super-Resolution with Wavelet Augmentation Transformer**|Yuang Aiet.al|[paper](https://arxiv.org/abs/2303.17783)|-|-|\n", "Local-Global Pseudo-label Correction for Source-free Domain Adaptive Medical Image Segmentation": "|**2023-8-28**|**Local-Global Pseudo-label Correction for Source-free Domain Adaptive Medical Image Segmentation**|Yanyu Yeet.al|[paper](https://arxiv.org/abs/2308.14312)|-|-|\n", "Domain-Specificity Inducing Transformers for Source-Free Domain Adaptation": "|**2023-8-27**|**Domain-Specificity Inducing Transformers for Source-Free Domain Adaptation**|Sunandini Sanyalet.al|[paper](https://arxiv.org/abs/2308.14023)|[code](http://val.cds.iisc.ac.in/DSiT-SFDA)|<details><summary>detail</summary>ICCV 2023</details>|\n", "Prior-guided Source-free Domain Adaptation for Human Pose Estimation": "|**2023-8-26**|**Prior-guided Source-free Domain Adaptation for Human Pose Estimation**|Dripta S. Raychaudhuriet.al|[paper](https://arxiv.org/abs/2308.13954)|-|<details><summary>detail</summary>ICCV 2023</details>|\n", "Rethinking the Role of Pre-Trained Networks in Source-Free Domain Adaptation": "|**2023-8-25**|**Rethinking the Role of Pre-Trained Networks in Source-Free Domain Adaptation**|Wenyu Zhanget.al|[paper](https://arxiv.org/abs/2212.07585)|-|<details><summary>detail</summary>ICCV 2023</details>|\n", "Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis": "|**2023-8-23**|**Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis**|Yuqi Fanget.al|[paper](https://arxiv.org/abs/2308.12495)|-|-|\n", "Black-box Source-free Domain Adaptation via Two-stage Knowledge Distillation": "|**2023-8-23**|**Black-box Source-free Domain Adaptation via Two-stage Knowledge Distillation**|Shuai Wanget.al|[paper](https://arxiv.org/abs/2305.07881)|-|<details><summary>detail</summary>The short version is accepted by IJCAI 1st International Workshop on Generalizing from Limited Resources in the Open World</details>|\n", "SUMMIT: Source-Free Adaptation of Uni-Modal Models to Multi-Modal Targets": "|**2023-8-22**|**SUMMIT: Source-Free Adaptation of Uni-Modal Models to Multi-Modal Targets**|Cody Simonset.al|[paper](https://arxiv.org/abs/2308.11880)|[code](https://github.com/csimo005/SUMMIT.)|-|\n", "The Unreasonable Effectiveness of Large Language-Vision Models for Source-free Video Domain Adaptation": "|**2023-8-22**|**The Unreasonable Effectiveness of Large Language-Vision Models for Source-free Video Domain Adaptation**|Giacomo Zaraet.al|[paper](https://arxiv.org/abs/2308.09139)|[code](https://github.com/giaczara/dallv)|<details><summary>detail</summary>ICCV2023</details>|\n", "COCA: Classifier-Oriented Calibration for Source-Free Universal Domain Adaptation via Textual Prototype": "|**2023-8-20**|**COCA: Classifier-Oriented Calibration for Source-Free Universal Domain Adaptation via Textual Prototype**|Xinghong Liuet.al|[paper](https://arxiv.org/abs/2308.10450)|-|-|\n", "In Search for a Generalizable Method for Source Free Domain Adaptation": "|**2023-9-21**|**In Search for a Generalizable Method for Source Free Domain Adaptation**|M Boudiaf et.al|[paper](https://arxiv.org/abs/2302.06658)|[code](https://paperswithcode.com/paper/in-search-for-a-generalizable-method-for)|-|\n", "MAPS: A Noise-Robust Progressive Learning Approach for Source-Free Domain Adaptive Keypoint Detection": "|**2023-9-18**|**MAPS: A Noise-Robust Progressive Learning Approach for Source-Free Domain Adaptive Keypoint Detection**|Y Ding et.al|[paper](https://arxiv.org/abs/2302.04589)|[code](https://github.com/yuhed/maps)|-|\n", "Universal source-free domain adaptation method for cross-domain fault diagnosis of machines": "|**2023-9-11**|**Universal source-free domain adaptation method for cross-domain fault diagnosis of machines**|Y Zhang et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0888327023000663)|-|<details><summary>detail</summary>Mechanical Systems and\u00a0\u2026, 2023 Elsevier</details>|\n", "Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation": "|**2023-9-9**|**Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation**|Y Chen et.al|[paper](https://arxiv.org/abs/2301.13428)|[code](https://github.com/yukilulu/cac)|-|\n", "TIDo: Source-free Task Incremental Learning in Non-stationary Environments": "|**2023-9-5**|**TIDo: Source-free Task Incremental Learning in Non-stationary Environments**|AK Ambastha et.al|[paper](https://arxiv.org/abs/2301.12055)|[code](https://paperswithcode.com/paper/tido-source-free-task-incremental-learning-in)|-|\n", "Adversarial Learning Networks: Source-free Unsupervised Domain Incremental Learning": "|**2023-9-5**|**Adversarial Learning Networks: Source-free Unsupervised Domain Incremental Learning**|AK Ambastha et.al|[paper](https://arxiv.org/abs/2301.12054)|[code](https://paperswithcode.com/paper/adversarial-learning-networks-source-free)|-|\n", "Cross-platform privacy-preserving CT image COVID-19 diagnosis based on source-free domain adaptation": "|**2023-8-31**|**Cross-platform privacy-preserving CT image COVID-19 diagnosis based on source-free domain adaptation**|Y Feng et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0950705123000746)|-|<details><summary>detail</summary>Knowledge Based Systems, 2023 Elsevier</details>|\n", "Source-free Subject Adaptation for EEG-based Visual Recognition": "|**2023-8-28**|**Source-free Subject Adaptation for EEG-based Visual Recognition**|P Lee et.al|[paper](https://arxiv.org/abs/2301.08448)|[code](https://github.com/DeepBCI/Deep-BCI)|-|\n", "When Source-Free Domain Adaptation Meets Label Propagation": "|**2023-8-28**|**When Source-Free Domain Adaptation Meets Label Propagation**|C Wu et.al|[paper](https://arxiv.org/abs/2301.08413)|-|-|\n", "Source-Free Domain Adaptive Detection of Concealed Objects in Passive Millimeter-Wave Images": "|**2023-8-26**|**Source-Free Domain Adaptive Detection of Concealed Objects in Passive Millimeter-Wave Images**|H Yang et.al|[paper](https://ieeexplore.ieee.org/abstract/document/10019315/)|-|<details><summary>detail</summary>IEEE Transactions on\u00a0\u2026, 2023 ieeexplore.ieee.org</details>|\n"}, "object detection": {"Tensor Factorization for Leveraging Cross-Modal Knowledge in Data-Constrained Infrared Object Detection": "|**2023-9-28**|**Tensor Factorization for Leveraging Cross-Modal Knowledge in Data-Constrained Infrared Object Detection**|Manish Sharmaet.al|[paper](https://arxiv.org/abs/2309.16592)|-|<details><summary>detail</summary>ICCV 2023</details>|\n", "HIC-YOLOv5: Improved YOLOv5 For Small Object Detection": "|**2023-9-28**|**HIC-YOLOv5: Improved YOLOv5 For Small Object Detection**|Shiyi Tanget.al|[paper](https://arxiv.org/abs/2309.16393)|-|-|\n", "EvCenterNet: Uncertainty Estimation for Object Detection using Evidential Learning": "|**2023-9-28**|**EvCenterNet: Uncertainty Estimation for Object Detection using Evidential Learning**|Monish R. Nallapareddyet.al|[paper](https://arxiv.org/abs/2303.03037)|-|-|\n", "BEVHeight++: Toward Robust Visual Centric 3D Object Detection": "|**2023-9-28**|**BEVHeight++: Toward Robust Visual Centric 3D Object Detection**|Lei Yanget.al|[paper](https://arxiv.org/abs/2309.16179)|-|<details><summary>detail</summary>arXiv admin note: substantial text overlap with arXiv:2303</details>|\n", "Detecting Objects with Context-Likelihood Graphs and Graph Refinement": "|**2023-9-27**|**Detecting Objects with Context-Likelihood Graphs and Graph Refinement**|Aritra Bhowmiket.al|[paper](https://arxiv.org/abs/2212.12395)|-|-|\n", "MoCaE: Mixture of Calibrated Experts Significantly Improves Object Detection": "|**2023-9-27**|**MoCaE: Mixture of Calibrated Experts Significantly Improves Object Detection**|Kemal Oksuzet.al|[paper](https://arxiv.org/abs/2309.14976)|-|-|\n", "Object-aware Gaze Target Detection": "|**2023-9-27**|**Object-aware Gaze Target Detection**|Francesco Toniniet.al|[paper](https://arxiv.org/abs/2307.09662)|[code](https://github.com/francescotonini/object-aware-gaze-target-detection)|<details><summary>detail</summary>ICCV 2023</details>|\n", "Highly Efficient SNNs for High-speed Object Detection": "|**2023-9-27**|**Highly Efficient SNNs for High-speed Object Detection**|Nemin Qiuet.al|[paper](https://arxiv.org/abs/2309.15883)|-|-|\n", "Low Latency of object detection for spikng neural network": "|**2023-9-27**|**Low Latency of object detection for spikng neural network**|Nemin Qiuet.al|[paper](https://arxiv.org/abs/2309.15555)|-|-|\n", "DistillBEV: Boosting Multi-Camera 3D Object Detection with Cross-Modal Knowledge Distillation": "|**2023-9-26**|**DistillBEV: Boosting Multi-Camera 3D Object Detection with Cross-Modal Knowledge Distillation**|Zeyu Wanget.al|[paper](https://arxiv.org/abs/2309.15109)|-|<details><summary>detail</summary>ICCV 2023</details>|\n", "Multi-Source Domain Adaptation for Object Detection with Prototype-based Mean-teacher": "|**2023-9-26**|**Multi-Source Domain Adaptation for Object Detection with Prototype-based Mean-teacher**|Atif Belalet.al|[paper](https://arxiv.org/abs/2309.14950)|-|-|\n", "MonoNeRD: NeRF-like Representations for Monocular 3D Object Detection": "|**2023-9-26**|**MonoNeRD: NeRF-like Representations for Monocular 3D Object Detection**|Junkai Xuet.al|[paper](https://arxiv.org/abs/2308.09421)|[code](https://github.com/cskkxjk/MonoNeRD.)|<details><summary>detail</summary>Accepted by ICCV 2023</details>|\n", "Dynablox: Real-time Detection of Diverse Dynamic Objects in Complex Environments": "|**2023-9-26**|**Dynablox: Real-time Detection of Diverse Dynamic Objects in Complex Environments**|Lukas Schmidet.al|[paper](https://arxiv.org/abs/2304.10049)|[code](https://github.com/ethz-asl/dynablox)|<details><summary>detail</summary>Code released at https://github</details>|\n", "UniBEV: Multi-modal 3D Object Detection with Uniform BEV Encoders for Robustness against Missing Sensor Modalities": "|**2023-9-25**|**UniBEV: Multi-modal 3D Object Detection with Uniform BEV Encoders for Robustness against Missing Sensor Modalities**|Shiming Wanget.al|[paper](https://arxiv.org/abs/2309.14516)|-|-|\n", "AFPN: Asymptotic Feature Pyramid Network for Object Detection": "|**2023-9-24**|**AFPN: Asymptotic Feature Pyramid Network for Object Detection**|Guoyu Yanget.al|[paper](https://arxiv.org/abs/2306.15988)|[code](https://github.com/gyyang23/AFPN)|-|\n", "E-detector: Asynchronous Spatio-temporal for Event-based Object Detection in Intelligent Transportation System": "|**2023-9-26**|**E-detector: Asynchronous Spatio-temporal for Event-based Object Detection in Intelligent Transportation System**|S Zhang et.al|[paper](https://dl.acm.org/doi/abs/10.1145/3584361)|-|<details><summary>detail</summary>ACM Transactions on Multimedia\u00a0\u2026, 2023 dl.acm.org</details>|\n", "\u2026\u00a0Simultaneous Defects Visualizing Algorithm for Both Macro and Micro Defects Based on Nonlinear Lamb Wave with an Application of Faster R-Cnn Object Detection": "|**2023-9-25**|**\u2026\u00a0Simultaneous Defects Visualizing Algorithm for Both Macro and Micro Defects Based on Nonlinear Lamb Wave with an Application of Faster R-Cnn Object Detection**|Y Lee et.al|[paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4362451)|-|<details><summary>detail</summary>Available at SSRN 4362451 papers.ssrn.com</details>|\n", "YOGA: Deep Object Detection in the Wild with Lightweight Feature Learning and Multiscale Attention": "|**2023-9-25**|**YOGA: Deep Object Detection in the Wild with Lightweight Feature Learning and Multiscale Attention**|R Sunkara et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0031320323001516)|[code](https://paperswithcode.com/paper/yoga-deep-object-detection-in-the-wild-with)|<details><summary>detail</summary>Pattern Recognition, 2023 Elsevier</details>|\n", "Spectral-Spatial Feature Enhancement Algorithm for Nighttime Object Detection and Tracking": "|**2023-9-25**|**Spectral-Spatial Feature Enhancement Algorithm for Nighttime Object Detection and Tracking**|Y Lv et.al|[paper](https://www.mdpi.com/2073-8994/15/2/546)|-|<details><summary>detail</summary>Symmetry, 2023 mdpi.com</details>|\n", "CRRNet: Channel Relation Reasoning Network for Salient Object Detection": "|**2023-9-25**|**CRRNet: Channel Relation Reasoning Network for Salient Object Detection**|S Gao et.al|[paper](https://link.springer.com/chapter/10.1007/978-981-99-0301-6_2)|-|<details><summary>detail</summary>\u2026\u00a0Conference, CCF CIRAC 2022, Xi'an\u00a0\u2026, 2023 Springer</details>|\n", "Iterative Fusion and Dual Enhancement for Accurate and Efficient Object Detection": "|**2023-9-25**|**Iterative Fusion and Dual Enhancement for Accurate and Efficient Object Detection**|Z Duan et.al|[paper](https://www.worldscientific.com/doi/abs/10.1142/S0218126623502328)|-|<details><summary>detail</summary>Journal of Circuits\u00a0\u2026, 2023 World Scientific</details>|\n", "CTA-FPN: Channel-Target Attention Feature Pyramid Network for Prohibited Object Detection in X-ray Images": "|**2023-9-25**|**CTA-FPN: Channel-Target Attention Feature Pyramid Network for Prohibited Object Detection in X-ray Images**|Y Zhang et.al|[paper](https://www.researchsquare.com/article/rs-2584406/latest.pdf)|-|<details><summary>detail</summary>2023 researchsquare.com</details>|\n", "Hierarchical Cross-modal Transformer for RGB-D Salient Object Detection": "|**2023-9-25**|**Hierarchical Cross-modal Transformer for RGB-D Salient Object Detection**|H Chen et.al|[paper](https://arxiv.org/abs/2302.08052)|[code](https://github.com/liuzywen/swinnet)|-|\n", "3M3D: Multi-view, Multi-path, Multi-representation for 3D Object Detection": "|**2023-9-25**|**3M3D: Multi-view, Multi-path, Multi-representation for 3D Object Detection**|J Park et.al|[paper](https://arxiv.org/abs/2302.08231)|[code](https://paperswithcode.com/paper/3m3d-multi-view-multi-path-multi)|-|\n", "Research on road object detection algorithm based on improved YOLOX": "|**2023-9-25**|**Research on road object detection algorithm based on improved YOLOX**|T Yang et.al|[paper](https://arxiv.org/abs/2302.08156)|[code](https://paperswithcode.com/paper/research-on-road-object-detection-algorithm)|-|\n"}, "domain adaptation": {"DIRA: Dynamic Domain Incremental Regularised Adaptation": "|**2023-9-28**|**DIRA: Dynamic Domain Incremental Regularised Adaptation**|Abanoub Ghobrialet.al|[paper](https://arxiv.org/abs/2205.00147)|-|-|\n", "Open Compound Domain Adaptation with Object Style Compensation for Semantic Segmentation": "|**2023-9-27**|**Open Compound Domain Adaptation with Object Style Compensation for Semantic Segmentation**|Tingliang Fenget.al|[paper](https://arxiv.org/abs/2309.16127)|-|<details><summary>detail</summary>Accepted by NeurlPS2023</details>|\n", "Leveraging Topology for Domain Adaptive Road Segmentation in Satellite and Aerial Imagery": "|**2023-9-27**|**Leveraging Topology for Domain Adaptive Road Segmentation in Satellite and Aerial Imagery**|Javed Iqbalet.al|[paper](https://arxiv.org/abs/2309.15625)|-|-|\n", "Confidence-based Visual Dispersal for Few-shot Unsupervised Domain Adaptation": "|**2023-9-27**|**Confidence-based Visual Dispersal for Few-shot Unsupervised Domain Adaptation**|Yizhe Xionget.al|[paper](https://arxiv.org/abs/2309.15575)|[code](https://github.com/Bostoncake/C-VisDiT.)|<details><summary>detail</summary>Accepted as ICCV 2023 poster</details>|\n", "Learning from SAM: Harnessing a Segmentation Foundation Model for Sim2Real Domain Adaptation through Regularization": "|**2023-9-27**|**Learning from SAM: Harnessing a Segmentation Foundation Model for Sim2Real Domain Adaptation through Regularization**|Mayara E. Bonaniet.al|[paper](https://arxiv.org/abs/2309.15562)|-|-|\n", "Cross-City Matters: A Multimodal Remote Sensing Benchmark Dataset for Cross-City Semantic Segmentation using High-Resolution Domain Adaptation Networks": "|**2023-9-26**|**Cross-City Matters: A Multimodal Remote Sensing Benchmark Dataset for Cross-City Semantic Segmentation using High-Resolution Domain Adaptation Networks**|Danfeng Honget.al|[paper](https://arxiv.org/abs/2309.16499)|[code](https://github.com/danfenghong.)|-|\n", "Domain Adaptive and Generalizable Network Architectures and Training Strategies for Semantic Image Segmentation": "|**2023-9-26**|**Domain Adaptive and Generalizable Network Architectures and Training Strategies for Semantic Image Segmentation**|Lukas Hoyeret.al|[paper](https://arxiv.org/abs/2304.13615)|[code](https://github.com/lhoyer/HRDA.)|<details><summary>detail</summary>TPAMI 2023</details>|\n", "STANCE-C3: Domain-adaptive Cross-target Stance Detection via Contrastive Learning and Counterfactual Generation": "|**2023-9-26**|**STANCE-C3: Domain-adaptive Cross-target Stance Detection via Contrastive Learning and Counterfactual Generation**|Nayoung Kimet.al|[paper](https://arxiv.org/abs/2309.15176)|-|-|\n", "Synthia's Melody: A Benchmark Framework for Unsupervised Domain Adaptation in Audio": "|**2023-9-26**|**Synthia's Melody: A Benchmark Framework for Unsupervised Domain Adaptation in Audio**|Chia-Hsin Linet.al|[paper](https://arxiv.org/abs/2309.15024)|-|-|\n", "Multi-Source Domain Adaptation for Object Detection with Prototype-based Mean-teacher": "|**2023-9-26**|**Multi-Source Domain Adaptation for Object Detection with Prototype-based Mean-teacher**|Atif Belalet.al|[paper](https://arxiv.org/abs/2309.14950)|-|-|\n", "Multi-Domain Adaptation by Self-Supervised Learning for Speaker Verification": "|**2023-9-25**|**Multi-Domain Adaptation by Self-Supervised Learning for Speaker Verification**|Wan Linet.al|[paper](https://arxiv.org/abs/2309.14149)|-|<details><summary>detail</summary>submitted to ICASSP 2024</details>|\n", "Self-supervised Domain-agnostic Domain Adaptation for Satellite Images": "|**2023-9-25**|**Self-supervised Domain-agnostic Domain Adaptation for Satellite Images**|Fahong Zhanget.al|[paper](https://arxiv.org/abs/2309.11109)|-|-|\n", "Mining Label Distribution Drift in Unsupervised Domain Adaptation": "|**2023-9-24**|**Mining Label Distribution Drift in Unsupervised Domain Adaptation**|Peizhao Liet.al|[paper](https://arxiv.org/abs/2006.09565)|-|<details><summary>detail</summary>AJCAI'23</details>|\n", "Efficient Domain Adaptation of Sentence Embeddings Using Adapters": "|**2023-9-24**|**Efficient Domain Adaptation of Sentence Embeddings Using Adapters**|Tim Schopfet.al|[paper](https://arxiv.org/abs/2307.03104)|-|<details><summary>detail</summary>the 14th International Conference on Recent Advances in Natural Language Processing (RANLP 2023)</details>|\n", "LiDAR-UDA: Self-ensembling Through Time for Unsupervised LiDAR Domain Adaptation": "|**2023-9-23**|**LiDAR-UDA: Self-ensembling Through Time for Unsupervised LiDAR Domain Adaptation**|Amirreza Shabanet.al|[paper](https://arxiv.org/abs/2309.13523)|[code](https://github.com/JHLee0513/LiDARUDA.)|<details><summary>detail</summary>Accepted ICCV 2023 (Oral)</details>|\n", "Kurcuma: a kitchen utensil recognition collection for unsupervised domain adaptation": "|**2023-9-25**|**Kurcuma: a kitchen utensil recognition collection for unsupervised domain adaptation**|A Rosello et.al|[paper](https://link.springer.com/article/10.1007/s10044-023-01147-x)|-|<details><summary>detail</summary>Mas, AJ Gallego\u2026 Pattern Analysis and\u00a0\u2026, 2023 Springer</details>|\n", "An improved multi-source domain adaptation network for inter-subject mental fatigue detection based on DANN": "|**2023-9-25**|**An improved multi-source domain adaptation network for inter-subject mental fatigue detection based on DANN**|K Chen et.al|[paper](https://www.degruyter.com/document/doi/10.1515/bmt-2022-0354/html)|-|<details><summary>detail</summary>Biomedical Engineering\u00a0\u2026, 2023 degruyter.com</details>|\n", "A multi-source transfer learning model based on LSTM and domain adaptation for building energy prediction": "|**2023-9-25**|**A multi-source transfer learning model based on LSTM and domain adaptation for building energy prediction**|H Lu et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0142061523000819)|-|<details><summary>detail</summary>International Journal of\u00a0\u2026, 2023 Elsevier</details>|\n", "Open Set Domain Adaptation with Latent Structure Discovery and Kernelized Classifier Learning": "|**2023-9-25**|**Open Set Domain Adaptation with Latent Structure Discovery and Kernelized Classifier Learning**|Y Tang et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0925231223001509)|-|<details><summary>detail</summary>Neurocomputing, 2023 Elsevier</details>|\n", "Towards Real-Time Online Unsupervised Domain Adaptation for Real-World Person Re-identification": "|**2023-9-25**|**Towards Real-Time Online Unsupervised Domain Adaptation for Real-World Person Re-identification**|C Neff et.al|[paper](https://www.researchsquare.com/article/rs-2588554/latest.pdf)|-|<details><summary>detail</summary>2023 researchsquare.com</details>|\n", "Unsupervised Domain Adaptation for MRI Volume Segmentation and Classification Using Image-to-Image Translation": "|**2023-9-25**|**Unsupervised Domain Adaptation for MRI Volume Segmentation and Classification Using Image-to-Image Translation**|S Kondo et.al|[paper](https://arxiv.org/abs/2302.08016)|[code](https://paperswithcode.com/paper/unsupervised-domain-adaptation-for-mri-volume)|-|\n", "High-Intensified Resemblance and Statistic-Restructured Alignment in Few-Shot Domain Adaptation for Industrial-Specialized Employment": "|**2023-9-24**|**High-Intensified Resemblance and Statistic-Restructured Alignment in Few-Shot Domain Adaptation for Industrial-Specialized Employment**|J Petchhan et.al|[paper](https://ieeexplore.ieee.org/abstract/document/10045719/)|-|<details><summary>detail</summary>IEEE Transactions on Consumer\u00a0\u2026, 2023 ieeexplore.ieee.org</details>|\n", "KRADA: Known-region-aware Domain Alignment for Open-set Domain Adaptation in Semantic Segmentation": "|**2023-9-24**|**KRADA: Known-region-aware Domain Alignment for Open-set Domain Adaptation in Semantic Segmentation**|C Zhou et.al|[paper](https://europepmc.org/article/ppr/ppr617459)|[code](https://github.com/chenhong-zhou/krada)|<details><summary>detail</summary>2023 europepmc.org</details>|\n", "Blade crack detection based on domain adaptation and autoencoder of multidimensional vibro-acoustic feature fusion": "|**2023-9-24**|**Blade crack detection based on domain adaptation and autoencoder of multidimensional vibro-acoustic feature fusion**|J Shen et.al|[paper](https://journals.sagepub.com/doi/abs/10.1177/14759217221139134)|-|<details><summary>detail</summary>Structural Health Monitoring, 2023 journals.sagepub.com</details>|\n", "Infrared ship target segmentation based on Adversarial Domain Adaptation": "|**2023-9-23**|**Infrared ship target segmentation based on Adversarial Domain Adaptation**|T Zhang et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0950705123000941)|-|<details><summary>detail</summary>Knowledge Based\u00a0\u2026, 2023 Elsevier</details>|\n"}, "domain generalization": {"Rethinking Domain Generalization: Discriminability and Generalizability": "|**2023-9-28**|**Rethinking Domain Generalization: Discriminability and Generalizability**|Shaocong Longet.al|[paper](https://arxiv.org/abs/2309.16483)|-|-|\n", "Diverse Target and Contribution Scheduling for Domain Generalization": "|**2023-9-28**|**Diverse Target and Contribution Scheduling for Domain Generalization**|Shaocong Longet.al|[paper](https://arxiv.org/abs/2309.16460)|-|-|\n", "Domain generalization across tumor types, laboratories, and species -- insights from the 2022 edition of the Mitosis Domain Generalization Challenge": "|**2023-9-27**|**Domain generalization across tumor types, laboratories, and species -- insights from the 2022 edition of the Mitosis Domain Generalization Challenge**|Marc Aubrevilleet.al|[paper](https://arxiv.org/abs/2309.15589)|-|-|\n", "Robust Internal Representations for Domain Generalization": "|**2023-9-27**|**Robust Internal Representations for Domain Generalization**|Mohammad Rostamiet.al|[paper](https://arxiv.org/abs/2309.15522)|-|<details><summary>detail</summary>to appear in AI Magazine Winter 2023 Issue</details>|\n", "CauDR: A Causality-inspired Domain Generalization Framework for Fundus-based Diabetic Retinopathy Grading": "|**2023-9-27**|**CauDR: A Causality-inspired Domain Generalization Framework for Fundus-based Diabetic Retinopathy Grading**|Hao Weiet.al|[paper](https://arxiv.org/abs/2309.15493)|-|-|\n", "STANCE-C3: Domain-adaptive Cross-target Stance Detection via Contrastive Learning and Counterfactual Generation": "|**2023-9-26**|**STANCE-C3: Domain-adaptive Cross-target Stance Detection via Contrastive Learning and Counterfactual Generation**|Nayoung Kimet.al|[paper](https://arxiv.org/abs/2309.15176)|-|-|\n", "Domain Generalization with Fourier Transform and Soft Thresholding": "|**2023-9-25**|**Domain Generalization with Fourier Transform and Soft Thresholding**|Hongyi Panet.al|[paper](https://arxiv.org/abs/2309.09866)|-|-|\n", "Calibration-based Dual Prototypical Contrastive Learning Approach for Domain Generalization Semantic Segmentation": "|**2023-9-25**|**Calibration-based Dual Prototypical Contrastive Learning Approach for Domain Generalization Semantic Segmentation**|Muxin Liaoet.al|[paper](https://arxiv.org/abs/2309.14282)|-|<details><summary>detail</summary>Accepted by ACM MM'23</details>|\n", "Multivariate Prototype Representation for Domain-Generalized Incremental Learning": "|**2023-9-24**|**Multivariate Prototype Representation for Domain-Generalized Incremental Learning**|Can Penget.al|[paper](https://arxiv.org/abs/2309.13563)|-|-|\n", "Semi-Supervised Domain Generalization for Object Detection via Language-Guided Feature Alignment": "|**2023-9-23**|**Semi-Supervised Domain Generalization for Object Detection via Language-Guided Feature Alignment**|Sina Malakoutiet.al|[paper](https://arxiv.org/abs/2309.13525)|-|<details><summary>detail</summary>BMVC 2023</details>|\n", "Randomize to Generalize: Domain Randomization for Runway FOD Detection": "|**2023-9-23**|**Randomize to Generalize: Domain Randomization for Runway FOD Detection**|Javaria Farooqet.al|[paper](https://arxiv.org/abs/2309.13264)|-|-|\n", "Order-preserving Consistency Regularization for Domain Adaptation and Generalization": "|**2023-9-23**|**Order-preserving Consistency Regularization for Domain Adaptation and Generalization**|Mengmeng Jinget.al|[paper](https://arxiv.org/abs/2309.13258)|-|<details><summary>detail</summary>Accepted by ICCV 2023</details>|\n", "PASTA: Proportional Amplitude Spectrum Training Augmentation for Syn-to-Real Domain Generalization": "|**2023-9-22**|**PASTA: Proportional Amplitude Spectrum Training Augmentation for Syn-to-Real Domain Generalization**|Prithvijit Chattopadhyayet.al|[paper](https://arxiv.org/abs/2212.00979)|[code](https://github.com/prithv1/PASTA)|<details><summary>detail</summary>ICCV 2023</details>|\n", "Assessment of the Reliablity of a Model's Decision by Generalizing Attribution to the Wavelet Domain": "|**2023-9-22**|**Assessment of the Reliablity of a Model's Decision by Generalizing Attribution to the Wavelet Domain**|Gabriel Kasmiet.al|[paper](https://arxiv.org/abs/2305.14979)|-|-|\n", "A Sentence Speaks a Thousand Images: Domain Generalization through Distilling CLIP with Language Guidance": "|**2023-9-21**|**A Sentence Speaks a Thousand Images: Domain Generalization through Distilling CLIP with Language Guidance**|Zeyi Huanget.al|[paper](https://arxiv.org/abs/2309.12530)|-|<details><summary>detail</summary>to appear at ICCV2023</details>|\n", "Domain Generalization with Global Sample Mixup": "|**2023-9-26**|**Domain Generalization with Global Sample Mixup**|Y Lu et.al|[paper](https://link.springer.com/chapter/10.1007/978-3-031-25075-0_35)|-|<details><summary>detail</summary>European Conference on Computer\u00a0\u2026, 2023 Springer</details>|\n", "Cross-Domain Augmentation Diagnosis: An Adversarial Domain-Augmented Generalization Method for Fault Diagnosis under Unseen Working Conditions": "|**2023-9-26**|**Cross-Domain Augmentation Diagnosis: An Adversarial Domain-Augmented Generalization Method for Fault Diagnosis under Unseen Working Conditions**|Q Li et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0951832023000868)|-|<details><summary>detail</summary>Reliability Engineering &\u00a0\u2026, 2023 Elsevier</details>|\n", "On the Hyperparameters influencing a PINN's generalization beyond the training domain": "|**2023-9-24**|**On the Hyperparameters influencing a PINN's generalization beyond the training domain**|A Bonfanti et.al|[paper](https://arxiv.org/abs/2302.07557)|-|-|\n", "Robust Representation Learning with Self-Distillation for Domain Generalization": "|**2023-9-23**|**Robust Representation Learning with Self-Distillation for Domain Generalization**|A Singh et.al|[paper](https://arxiv.org/abs/2302.06874)|[code](https://github.com/tongkunguan/ccd)|-|\n", "Cross-corpora spoken language identification with domain diversification and generalization": "|**2023-9-21**|**Cross-corpora spoken language identification with domain diversification and generalization**|S Dey et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0885230823000086)|[code](https://paperswithcode.com/paper/cross-corpora-spoken-language-identification)|<details><summary>detail</summary>Computer Speech & Language, 2023 Elsevier</details>|\n", "Domain-Conditioned Normalization for Test-Time Domain Generalization": "|**2023-9-19**|**Domain-Conditioned Normalization for Test-Time Domain Generalization**|Y Jiang et.al|[paper](https://link.springer.com/chapter/10.1007/978-3-031-25085-9_17)|-|<details><summary>detail</summary>Computer Vision\u2013ECCV\u00a0\u2026, 2023 Springer</details>|\n", "Domain Generalization by Functional Regression": "|**2023-9-18**|**Domain Generalization by Functional Regression**|M Holzleitner et.al|[paper](https://arxiv.org/abs/2302.04724)|[code](https://github.com/mlr-org/mlr)|-|\n", "Leveraging Domain Relations for Domain Generalization": "|**2023-9-15**|**Leveraging Domain Relations for Domain Generalization**|H Yao et.al|[paper](https://arxiv.org/abs/2302.02609)|[code](https://github.com/rusty1s/pytorch_geometric)|-|\n", "Aggregation of Disentanglement: Reconsidering Domain Variations in Domain Generalization": "|**2023-9-13**|**Aggregation of Disentanglement: Reconsidering Domain Variations in Domain Generalization**|D Zhang et.al|[paper](https://arxiv.org/abs/2302.02350)|[code](https://paperswithcode.com/paper/aggregation-of-disentanglement-reconsidering)|-|\n", "Domain Generalization Emerges from Dreaming": "|**2023-9-11**|**Domain Generalization Emerges from Dreaming**|H Heo et.al|[paper](https://arxiv.org/abs/2302.00980)|[code](https://paperswithcode.com/paper/domain-generalization-emerges-from-dreaming)|-|\n"}, "vision language": {"Semantic Scene Difference Detection in Daily Life Patroling by Mobile Robots using Pre-Trained Large-Scale Vision-Language Model": "|**2023-9-28**|**Semantic Scene Difference Detection in Daily Life Patroling by Mobile Robots using Pre-Trained Large-Scale Vision-Language Model**|Yoshiki Obinataet.al|[paper](https://arxiv.org/abs/2309.16552)|-|<details><summary>detail</summary>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023)</details>|\n", "QwenGrasp: A Usage of Large Vision Language Model for Target-oriented Grasping": "|**2023-9-28**|**QwenGrasp: A Usage of Large Vision Language Model for Target-oriented Grasping**|Xinyu Chenet.al|[paper](https://arxiv.org/abs/2309.16426)|-|-|\n", "AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models": "|**2023-9-28**|**AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models**|Jan Hendrik Metzenet.al|[paper](https://arxiv.org/abs/2309.16414)|-|-|\n", "VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use": "|**2023-9-27**|**VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use**|Yonatan Bittonet.al|[paper](https://arxiv.org/abs/2308.06595)|-|-|\n", "InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition": "|**2023-9-27**|**InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition**|Pan Zhanget.al|[paper](https://arxiv.org/abs/2309.15112)|[code](https://github.com/InternLM/InternLM-XComposer.)|<details><summary>detail</summary>Code is available at https://github</details>|\n", "Noise-Tolerant Unsupervised Adapter for Vision-Language Models": "|**2023-9-26**|**Noise-Tolerant Unsupervised Adapter for Vision-Language Models**|Eman Aliet.al|[paper](https://arxiv.org/abs/2309.14928)|-|-|\n", "MO-VLN: A Multi-Task Benchmark for Open-set Zero-Shot Vision-and-Language Navigation": "|**2023-9-26**|**MO-VLN: A Multi-Task Benchmark for Open-set Zero-Shot Vision-and-Language Navigation**|Xiwen Lianget.al|[paper](https://arxiv.org/abs/2306.10322)|-|-|\n", "Unsupervised 3D Perception with 2D Vision-Language Distillation for Autonomous Driving": "|**2023-9-25**|**Unsupervised 3D Perception with 2D Vision-Language Distillation for Autonomous Driving**|Mahyar Najibiet.al|[paper](https://arxiv.org/abs/2309.14491)|-|<details><summary>detail</summary>ICCV 2023</details>|\n", "Med-UniC: Unifying Cross-Lingual Medical Vision-Language Pre-Training by Diminishing Bias": "|**2023-9-25**|**Med-UniC: Unifying Cross-Lingual Medical Vision-Language Pre-Training by Diminishing Bias**|Zhongwei Wanet.al|[paper](https://arxiv.org/abs/2305.19894)|-|<details><summary>detail</summary>NeurIPS 2023 Main track</details>|\n", "Language Models as Black-Box Optimizers for Vision-Language Models": "|**2023-9-25**|**Language Models as Black-Box Optimizers for Vision-Language Models**|Shihong Liuet.al|[paper](https://arxiv.org/abs/2309.05950)|-|-|\n", "Survey of Social Bias in Vision-Language Models": "|**2023-9-24**|**Survey of Social Bias in Vision-Language Models**|Nayeon Leeet.al|[paper](https://arxiv.org/abs/2309.14381)|-|-|\n", "GraphAdapter: Tuning Vision-Language Models With Dual Knowledge Graph": "|**2023-9-24**|**GraphAdapter: Tuning Vision-Language Models With Dual Knowledge Graph**|Xin Liet.al|[paper](https://arxiv.org/abs/2309.13625)|[code](https://github.com/lixinustc/GraphAdapter)|<details><summary>detail</summary>Accepted by NeurIPS 2023</details>|\n", "Zero-Shot Object Counting with Language-Vision Models": "|**2023-9-22**|**Zero-Shot Object Counting with Language-Vision Models**|Jingyi Xuet.al|[paper](https://arxiv.org/abs/2309.13097)|-|<details><summary>detail</summary>Extended version of CVPR23 arXiv:2303</details>|\n", "Synthetic Boost: Leveraging Synthetic Data for Enhanced Vision-Language Segmentation in Echocardiography": "|**2023-9-22**|**Synthetic Boost: Leveraging Synthetic Data for Enhanced Vision-Language Segmentation in Echocardiography**|Rabin Adhikariet.al|[paper](https://arxiv.org/abs/2309.12829)|[code](https://github.com/naamiinepal/synthetic-boost.)|<details><summary>detail</summary>the 4th International Workshop of Advances in Simplifying Medical UltraSound (ASMUS)</details>|\n", "Exploring Transfer Learning in Medical Image Segmentation using Vision-Language Models": "|**2023-9-22**|**Exploring Transfer Learning in Medical Image Segmentation using Vision-Language Models**|Kanchan Poudelet.al|[paper](https://arxiv.org/abs/2308.07706)|-|-|\n", "Weakly-Supervised HOI Detection from Interaction Labels Only and Language/Vision-Language Priors": "|**2023-9-24**|**Weakly-Supervised HOI Detection from Interaction Labels Only and Language/Vision-Language Priors**|M Erhan Unal et.al|[paper](https://ui.adsabs.harvard.edu/abs/2023arXiv230305546E/abstract)|[code](https://paperswithcode.com/paper/weakly-supervised-hoi-detection-from)|-|\n", "Scaling Vision-Language Models with Sparse Mixture of Experts": "|**2023-9-24**|**Scaling Vision-Language Models with Sparse Mixture of Experts**|S Shen et.al|[paper](https://arxiv.org/abs/2303.07226)|[code](https://github.com/google-research/vmoe)|-|\n", "Vision-Language Models as Success Detectors": "|**2023-9-24**|**Vision-Language Models as Success Detectors**|Y Du et.al|[paper](https://arxiv.org/abs/2303.07280)|[code](https://github.com/dyabel/detpro)|-|\n", "Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images": "|**2023-9-24**|**Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images**|N Bitton-Guetta et.al|[paper](https://arxiv.org/abs/2303.07274)|[code](https://paperswithcode.com/paper/breaking-common-sense-whoops-a-vision-and)|-|\n", "Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Models": "|**2023-9-22**|**Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Models**|Z Zheng et.al|[paper](https://arxiv.org/abs/2303.06628)|[code](https://github.com/thunderbeee/zscl)|-|\n", "Gradient-Regulated Meta-Prompt Learning for Generalizable Vision-Language Models": "|**2023-9-22**|**Gradient-Regulated Meta-Prompt Learning for Generalizable Vision-Language Models**|J Li et.al|[paper](https://arxiv.org/abs/2303.06571)|[code](https://paperswithcode.com/paper/gradient-regulated-meta-prompt-learning-for)|-|\n", "Towards Universal Vision-language Omni-supervised Segmentation": "|**2023-9-22**|**Towards Universal Vision-language Omni-supervised Segmentation**|B Dong et.al|[paper](https://arxiv.org/abs/2303.06547)|[code](https://paperswithcode.com/paper/towards-universal-vision-language-omni)|-|\n", "Learning Grounded Vision-Language Representation for Versatile Understanding in Untrimmed Videos": "|**2023-9-21**|**Learning Grounded Vision-Language Representation for Versatile Understanding in Untrimmed Videos**|T Wang et.al|[paper](https://arxiv.org/abs/2303.06378)|[code](https://github.com/zjr2000/gvl)|-|\n", "Tag2Text: Guiding Vision-Language Model via Image Tagging": "|**2023-9-20**|**Tag2Text: Guiding Vision-Language Model via Image Tagging**|X Huang et.al|[paper](https://arxiv.org/abs/2303.05657)|[code](https://github.com/xinyu1205/recognize-anything)|-|\n", "Robotic Applications of Pre-Trained Vision-Language Models to Various Recognition Behaviors": "|**2023-9-20**|**Robotic Applications of Pre-Trained Vision-Language Models to Various Recognition Behaviors**|K Kawaharazuka et.al|[paper](https://arxiv.org/abs/2303.05674)|-|-|\n"}}