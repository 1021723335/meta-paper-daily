{"source-free": {"Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework": "|**2025-6-26**|**Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework**|Ismail Nejjar et.al|[paper](https://arxiv.org/abs/2411.12558)|-|<details><summary>detail</summary>TMLR 2025</details>|\n", "Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation": "|**2025-6-26**|**Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation**|Yihong Cao et.al|[paper](https://arxiv.org/abs/2506.21198)|[code](https://github.com/yihong-97/UNLOCK.)|<details><summary>detail</summary>ICCV 2025</details>|\n", "Context Aware Grounded Teacher for Source Free Object Detection": "|**2025-6-25**|**Context Aware Grounded Teacher for Source Free Object Detection**|Tajamul Ashraf et.al|[paper](https://arxiv.org/abs/2504.15404)|[code](https://github.com/Tajamul21/Grounded_Teacher.)|-|\n", "SFDLA: Source-Free Document Layout Analysis": "|**2025-6-18**|**SFDLA: Source-Free Document Layout Analysis**|Sebastian Tewes et.al|[paper](https://arxiv.org/abs/2503.18742)|[code](https://github.com/s3setewe/sfdla-DLAdapter.)|<details><summary>detail</summary>Accepted by ICDAR 2025</details>|\n", "Unified Source-Free Domain Adaptation": "|**2025-6-17**|**Unified Source-Free Domain Adaptation**|Song Tang et.al|[paper](https://arxiv.org/abs/2403.07601)|-|-|\n", "SRPL-SFDA: SAM-Guided Reliable Pseudo-Labels for Source-Free Domain Adaptation in Medical Image Segmentation": "|**2025-6-11**|**SRPL-SFDA: SAM-Guided Reliable Pseudo-Labels for Source-Free Domain Adaptation in Medical Image Segmentation**|Xinya Liu et.al|[paper](https://arxiv.org/abs/2506.09403)|[code](https://github.com/HiLab-git/SRPL-SFDA.)|-|\n", "DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization": "|**2025-6-5**|**DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization**|Geonyoung Lee et.al|[paper](https://arxiv.org/abs/2506.02858)|[code](https://wltschmrz.github.io/DGMO/)|<details><summary>detail</summary>Interspeech 2025</details>|\n", "Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data": "|**2025-5-30**|**Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2503.20771)|-|-|\n", "Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation": "|**2025-5-30**|**Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation**|Pascal Schlachter et.al|[paper](https://arxiv.org/abs/2504.11992)|[code](https://github.com/pascalschlachter/PLAnalysis.)|<details><summary>detail</summary>the 33rd European Signal Processing Conference (EUSIPCO 2025)</details>|\n", "Shuffle PatchMix Augmentation with Confidence-Margin Weighted Pseudo-Labels for Enhanced Source-Free Domain Adaptation": "|**2025-5-30**|**Shuffle PatchMix Augmentation with Confidence-Margin Weighted Pseudo-Labels for Enhanced Source-Free Domain Adaptation**|Prasanna Reddy Pulakurthi et.al|[paper](https://arxiv.org/abs/2505.24216)|[code](https://github.com/PrasannaPulakurthi/SPM)|-|\n", "Multi-Granularity Class Prototype Topology Distillation for Class-Incremental Source-Free Unsupervised Domain Adaptation": "|**2025-5-27**|**Multi-Granularity Class Prototype Topology Distillation for Class-Incremental Source-Free Unsupervised Domain Adaptation**|Peihua Deng et.al|[paper](https://arxiv.org/abs/2411.16064)|[code](https://github.com/dengpeihua/GROTO.)|<details><summary>detail</summary>Accepted by CVPR 2025</details>|\n", "Training-Free Multi-Step Audio Source Separation": "|**2025-5-26**|**Training-Free Multi-Step Audio Source Separation**|Yongyi Zang et.al|[paper](https://arxiv.org/abs/2505.19534)|-|-|\n", "Temporal Restoration and Spatial Rewiring for Source-Free Multivariate Time Series Domain Adaptation": "|**2025-5-23**|**Temporal Restoration and Spatial Rewiring for Source-Free Multivariate Time Series Domain Adaptation**|Peiliang Gong et.al|[paper](https://arxiv.org/abs/2505.21525)|-|-|\n", "Listen, Analyze, and Adapt to Learn New Attacks: An Exemplar-Free Class Incremental Learning Method for Audio Deepfake Source Tracing": "|**2025-5-20**|**Listen, Analyze, and Adapt to Learn New Attacks: An Exemplar-Free Class Incremental Learning Method for Audio Deepfake Source Tracing**|Yang Xiao et.al|[paper](https://arxiv.org/abs/2505.14601)|-|<details><summary>detail</summary>Accepted by Interspeech 2025</details>|\n", "DDFP: Data-dependent Frequency Prompt for Source Free Domain Adaptation of Medical Image Segmentation": "|**2025-5-14**|**DDFP: Data-dependent Frequency Prompt for Source Free Domain Adaptation of Medical Image Segmentation**|Siqi Yin et.al|[paper](https://arxiv.org/abs/2505.09927)|-|-|\n"}, "object detection": {"Continual Adaptation: Environment-Conditional Parameter Generation for Object Detection in Dynamic Scenarios": "|**2025-6-30**|**Continual Adaptation: Environment-Conditional Parameter Generation for Object Detection in Dynamic Scenarios**|Deng Li et.al|[paper](https://arxiv.org/abs/2506.24063)|-|-|\n", "Visual Textualization for Image Prompted Object Detection": "|**2025-6-30**|**Visual Textualization for Image Prompted Object Detection**|Yongjian Wu et.al|[paper](https://arxiv.org/abs/2506.23785)|[code](https://github.com/WitGotFlg/VisTex-OVLM.)|<details><summary>detail</summary>Accepted by ICCV 2025</details>|\n", "Methodology for an Analysis of Influencing Factors on 3D Object Detection Performance": "|**2025-6-30**|**Methodology for an Analysis of Influencing Factors on 3D Object Detection Performance**|Anton Kuznietsov et.al|[paper](https://arxiv.org/abs/2411.08482)|-|<details><summary>detail</summary>IEEE International Conference on Autonomous and Trusted Computing (IEEE ATC)</details>|\n", "PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection": "|**2025-6-30**|**PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection**|Xiao Li et.al|[paper](https://arxiv.org/abs/2506.23581)|-|<details><summary>detail</summary>Accepted by ICCV 2025</details>|\n", "Event-based Tiny Object Detection: A Benchmark Dataset and Baseline": "|**2025-6-30**|**Event-based Tiny Object Detection: A Benchmark Dataset and Baseline**|Nuo Chen et.al|[paper](https://arxiv.org/abs/2506.23575)|[code](https://github.com/ChenYichen9527/Ev-UAV.)|-|\n", "OcRFDet: Object-Centric Radiance Fields for Multi-View 3D Object Detection in Autonomous Driving": "|**2025-6-30**|**OcRFDet: Object-Centric Radiance Fields for Multi-View 3D Object Detection in Autonomous Driving**|Mingqian Ji et.al|[paper](https://arxiv.org/abs/2506.23565)|[code](https://github.com/Mingqj/OcRFDet.)|<details><summary>detail</summary>Accepted by ICCV2025</details>|\n", "Object detection in adverse weather conditions for autonomous vehicles using Instruct Pix2Pix": "|**2025-6-30**|**Object detection in adverse weather conditions for autonomous vehicles using Instruct Pix2Pix**|Unai Gurbindo et.al|[paper](https://arxiv.org/abs/2505.08228)|-|-|\n", "From Sight to Insight: Unleashing Eye-Tracking in Weakly Supervised Video Salient Object Detection": "|**2025-6-30**|**From Sight to Insight: Unleashing Eye-Tracking in Weakly Supervised Video Salient Object Detection**|Qi Qin et.al|[paper](https://arxiv.org/abs/2506.23519)|-|<details><summary>detail</summary>15 Pages</details>|\n", "Improve Underwater Object Detection through YOLOv12 Architecture and Physics-informed Augmentation": "|**2025-6-30**|**Improve Underwater Object Detection through YOLOv12 Architecture and Physics-informed Augmentation**|Tinh Nguyen et.al|[paper](https://arxiv.org/abs/2506.23505)|-|-|\n", "Multimodal Object Detection using Depth and Image Data for Manufacturing Parts": "|**2025-6-29**|**Multimodal Object Detection using Depth and Image Data for Manufacturing Parts**|Nazanin Mahjourian et.al|[paper](https://arxiv.org/abs/2411.09062)|-|-|\n", "Detecting What Matters: A Novel Approach for Out-of-Distribution 3D Object Detection in Autonomous Vehicles": "|**2025-6-29**|**Detecting What Matters: A Novel Approach for Out-of-Distribution 3D Object Detection in Autonomous Vehicles**|Menna Taha et.al|[paper](https://arxiv.org/abs/2506.23426)|-|-|\n", "DGE-YOLO: Dual-Branch Gathering and Attention for Accurate UAV Object Detection": "|**2025-6-29**|**DGE-YOLO: Dual-Branch Gathering and Attention for Accurate UAV Object Detection**|Kunwei Lv et.al|[paper](https://arxiv.org/abs/2506.23252)|-|-|\n", "Accelerate 3D Object Detection Models via Zero-Shot Attention Key Pruning": "|**2025-6-29**|**Accelerate 3D Object Detection Models via Zero-Shot Attention Key Pruning**|Lizhen Xu et.al|[paper](https://arxiv.org/abs/2503.08101)|[code](https://github.com/iseri27/tg_gbc.)|<details><summary>detail</summary>Accepted by ICCV2025</details>|\n", "Open World Object Detection: A Survey": "|**2025-6-28**|**Open World Object Detection: A Survey**|Yiming Li et.al|[paper](https://arxiv.org/abs/2410.11301)|[code](https://github.com/ArminLee/OWOD)|<details><summary>detail</summary>Accepted for publication in IEEE TCSVT</details>|\n", "Tracking by Detection and Query: An Efficient End-to-End Framework for Multi-Object Tracking": "|**2025-6-27**|**Tracking by Detection and Query: An Efficient End-to-End Framework for Multi-Object Tracking**|Shukun Jia et.al|[paper](https://arxiv.org/abs/2411.06197)|-|-|\n"}, "domain adaptation": {"Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning": "|**2025-6-30**|**Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning**|Harisankar Babu et.al|[paper](https://arxiv.org/abs/2506.19592)|-|<details><summary>detail</summary>IEEE CASE 2025</details>|\n", "Pruning by Block Benefit: Exploring the Properties of Vision Transformer Blocks during Domain Adaptation": "|**2025-6-30**|**Pruning by Block Benefit: Exploring the Properties of Vision Transformer Blocks during Domain Adaptation**|Patrick Glandorf et.al|[paper](https://arxiv.org/abs/2506.23675)|-|<details><summary>detail</summary>ICCV'25 Workshops</details>|\n", "HASD: Hierarchical Adaption for pathology Slide-level Domain-shift": "|**2025-6-30**|**HASD: Hierarchical Adaption for pathology Slide-level Domain-shift**|Jingsong Liu et.al|[paper](https://arxiv.org/abs/2506.23673)|-|-|\n", "Relating Events and Frames Based on Self-Supervised Learning and Uncorrelated Conditioning for Unsupervised Domain Adaptation": "|**2025-6-29**|**Relating Events and Frames Based on Self-Supervised Learning and Uncorrelated Conditioning for Unsupervised Domain Adaptation**|Mohammad Rostami et.al|[paper](https://arxiv.org/abs/2401.01042)|-|-|\n", "Boosting Domain Generalized and Adaptive Detection with Diffusion Models: Fitness, Generalization, and Transferability": "|**2025-6-27**|**Boosting Domain Generalized and Adaptive Detection with Diffusion Models: Fitness, Generalization, and Transferability**|Boyong He et.al|[paper](https://arxiv.org/abs/2506.21042)|[code](https://github.com/heboyong/Fitness-Generalization-Transferability)|<details><summary>detail</summary>Accepted by ICCV2025</details>|\n", "Multi-View Contrastive Learning for Robust Domain Adaptation in Medical Time Series Analysis": "|**2025-6-27**|**Multi-View Contrastive Learning for Robust Domain Adaptation in Medical Time Series Analysis**|YongKyung Oh et.al|[paper](https://arxiv.org/abs/2506.22393)|-|-|\n", "Weakly-Supervised Domain Adaptation with Proportion-Constrained Pseudo-Labeling": "|**2025-6-27**|**Weakly-Supervised Domain Adaptation with Proportion-Constrained Pseudo-Labeling**|Takumi Okuo et.al|[paper](https://arxiv.org/abs/2506.22301)|-|<details><summary>detail</summary>IJCNN2025</details>|\n", "Gradual Domain Adaptation for Graph Learning": "|**2025-6-27**|**Gradual Domain Adaptation for Graph Learning**|Pui Ieng Lei et.al|[paper](https://arxiv.org/abs/2501.17443)|-|-|\n", "Embodied Domain Adaptation for Object Detection": "|**2025-6-26**|**Embodied Domain Adaptation for Object Detection**|Xiangyu Shi et.al|[paper](https://arxiv.org/abs/2506.21860)|-|<details><summary>detail</summary>Accepted by IROS 2025</details>|\n", "TITAN: Query-Token based Domain Adaptive Adversarial Learning": "|**2025-6-26**|**TITAN: Query-Token based Domain Adaptive Adversarial Learning**|Tajamul Ashraf et.al|[paper](https://arxiv.org/abs/2506.21484)|-|<details><summary>detail</summary>ICCV 2025</details>|\n", "Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework": "|**2025-6-26**|**Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework**|Ismail Nejjar et.al|[paper](https://arxiv.org/abs/2411.12558)|-|<details><summary>detail</summary>TMLR 2025</details>|\n", "FreeDNA: Endowing Domain Adaptation of Diffusion-Based Dense Prediction with Training-Free Domain Noise Alignment": "|**2025-6-25**|**FreeDNA: Endowing Domain Adaptation of Diffusion-Based Dense Prediction with Training-Free Domain Noise Alignment**|Hang Xu et.al|[paper](https://arxiv.org/abs/2506.22509)|[code](https://github.com/xuhang07/FreeDNA)|<details><summary>detail</summary>ICCV2025</details>|\n", "crossMoDA Challenge: Evolution of Cross-Modality Domain Adaptation Techniques for Vestibular Schwannoma and Cochlea Segmentation from 2021 to 2023": "|**2025-6-24**|**crossMoDA Challenge: Evolution of Cross-Modality Domain Adaptation Techniques for Vestibular Schwannoma and Cochlea Segmentation from 2021 to 2023**|Navodini Wijethilake et.al|[paper](https://arxiv.org/abs/2506.12006)|-|-|\n", "M3D: Manifold-based Domain Adaptation with Dynamic Distribution for Non-Deep Transfer Learning in Cross-subject and Cross-session EEG-based Emotion Recognition": "|**2025-6-24**|**M3D: Manifold-based Domain Adaptation with Dynamic Distribution for Non-Deep Transfer Learning in Cross-subject and Cross-session EEG-based Emotion Recognition**|Ting Luo et.al|[paper](https://arxiv.org/abs/2404.15615)|-|-|\n", "Progressive Modality Cooperation for Multi-Modality Domain Adaptation": "|**2025-6-24**|**Progressive Modality Cooperation for Multi-Modality Domain Adaptation**|Weichen Zhang et.al|[paper](https://arxiv.org/abs/2506.19316)|-|-|\n"}, "domain generalization": {"DGSAM: Domain Generalization via Individual Sharpness-Aware Minimization": "|**2025-6-30**|**DGSAM: Domain Generalization via Individual Sharpness-Aware Minimization**|Youngjun Song et.al|[paper](https://arxiv.org/abs/2503.23430)|-|-|\n", "Calculation of Photocarrier Generation from Optical Absorption for Time-domain Simulation of Optoelectronic Devices": "|**2025-6-30**|**Calculation of Photocarrier Generation from Optical Absorption for Time-domain Simulation of Optoelectronic Devices**|Liang Chen et.al|[paper](https://arxiv.org/abs/2102.06702)|-|-|\n", "Generalizing vision-language models to novel domains: A comprehensive survey": "|**2025-6-30**|**Generalizing vision-language models to novel domains: A comprehensive survey**|Xinyao Li et.al|[paper](https://arxiv.org/abs/2506.18504)|-|-|\n", "Learning Time-Aware Causal Representation for Model Generalization in Evolving Domains": "|**2025-6-28**|**Learning Time-Aware Causal Representation for Model Generalization in Evolving Domains**|Zhuo He et.al|[paper](https://arxiv.org/abs/2506.17718)|-|<details><summary>detail</summary>ICML 2025</details>|\n", "Boosting Domain Generalized and Adaptive Detection with Diffusion Models: Fitness, Generalization, and Transferability": "|**2025-6-27**|**Boosting Domain Generalized and Adaptive Detection with Diffusion Models: Fitness, Generalization, and Transferability**|Boyong He et.al|[paper](https://arxiv.org/abs/2506.21042)|[code](https://github.com/heboyong/Fitness-Generalization-Transferability)|<details><summary>detail</summary>Accepted by ICCV2025</details>|\n", "Video-Guided Text-to-Music Generation Using Public Domain Movie Collections": "|**2025-6-27**|**Video-Guided Text-to-Music Generation Using Public Domain Movie Collections**|Haven Kim et.al|[paper](https://arxiv.org/abs/2506.12573)|[code](https://havenpersona.github.io/ossl-v1)|<details><summary>detail</summary>ISMIR 2025 regular paper</details>|\n", "Exploring Task-Solving Paradigm for Generalized Cross-Domain Face Anti-Spoofing via Reinforcement Fine-Tuning": "|**2025-6-27**|**Exploring Task-Solving Paradigm for Generalized Cross-Domain Face Anti-Spoofing via Reinforcement Fine-Tuning**|Fangling Jiang et.al|[paper](https://arxiv.org/abs/2506.21895)|-|-|\n", "QT-DoG: Quantization-aware Training for Domain Generalization": "|**2025-6-26**|**QT-DoG: Quantization-aware Training for Domain Generalization**|Saqib Javed et.al|[paper](https://arxiv.org/abs/2410.06020)|[code](https://saqibjaved1.github.io/QT_DoG/.)|<details><summary>detail</summary>International Conference on Machine Learning (ICML) 2025</details>|\n", "MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models": "|**2025-6-26**|**MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models**|Yifan Liu et.al|[paper](https://arxiv.org/abs/2506.21784)|[code](https://github.com/ucla-mobility/MobiVerse.)|-|\n", "FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain Generalization": "|**2025-6-25**|**FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain Generalization**|Ha Min Son et.al|[paper](https://arxiv.org/abs/2506.20841)|-|-|\n", "General Methods Make Great Domain-specific Foundation Models: A Case-study on Fetal Ultrasound": "|**2025-6-24**|**General Methods Make Great Domain-specific Foundation Models: A Case-study on Fetal Ultrasound**|Jakob Ambsdorf et.al|[paper](https://arxiv.org/abs/2506.19552)|-|<details><summary>detail</summary>Submitted version of paper accepted at MICCAI 2025</details>|\n", "RLPR: Extrapolating RLVR to General Domains without Verifiers": "|**2025-6-22**|**RLPR: Extrapolating RLVR to General Domains without Verifiers**|Tianyu Yu et.al|[paper](https://arxiv.org/abs/2506.18254)|[code](https://github.com/openbmb/RLPR)|<details><summary>detail</summary>Project Website: https://github</details>|\n", "RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation": "|**2025-6-22**|**RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation**|Tianxing Chen et.al|[paper](https://arxiv.org/abs/2506.18088)|[code](https://robotwin-platform.github.io/)|<details><summary>detail</summary>Project Page: https://robotwin-platform</details>|\n", "Domain Generalization using Action Sequences for Egocentric Action Recognition": "|**2025-6-21**|**Domain Generalization using Action Sequences for Egocentric Action Recognition**|Amirshayan Nasirimajd et.al|[paper](https://arxiv.org/abs/2506.17685)|[code](https://github.com/Ashayan97/SeqDG)|<details><summary>detail</summary>Pattern Recognition Letters</details>|\n", "When and How Does CLIP Enable Domain and Compositional Generalization?": "|**2025-6-20**|**When and How Does CLIP Enable Domain and Compositional Generalization?**|Elias Kempf et.al|[paper](https://arxiv.org/abs/2502.09507)|-|<details><summary>detail</summary>ICML 2025 (Spotlight)</details>|\n"}, "vision language": {"A Survey on Vision-Language-Action Models for Autonomous Driving": "|**2025-6-30**|**A Survey on Vision-Language-Action Models for Autonomous Driving**|Sicong Jiang et.al|[paper](https://arxiv.org/abs/2506.24044)|[code](https://github.com/JohnsonJiang1996/Awesome-VLA4AD)|-|\n", "The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models": "|**2025-6-30**|**The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models**|Lijun Sheng et.al|[paper](https://arxiv.org/abs/2506.24000)|[code](https://github.com/TomSheng21/tta-vlm)|<details><summary>detail</summary>Github link: https://github</details>|\n", "GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models": "|**2025-6-30**|**GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models**|Hamza Rasaee et.al|[paper](https://arxiv.org/abs/2506.23903)|-|-|\n", "A Closer Look at Conditional Prompt Tuning for Vision-Language Models": "|**2025-6-30**|**A Closer Look at Conditional Prompt Tuning for Vision-Language Models**|Ji Zhang et.al|[paper](https://arxiv.org/abs/2506.23856)|[code](https://github.com/Koorye/CaPT.)|-|\n", "Task Preference Optimization: Improving Multimodal Large Language Models with Vision Task Alignment": "|**2025-6-30**|**Task Preference Optimization: Improving Multimodal Large Language Models with Vision Task Alignment**|Ziang Yan et.al|[paper](https://arxiv.org/abs/2412.19326)|[code](https://github.com/OpenGVLab/TPO)|<details><summary>detail</summary>CVPR2025</details>|\n", "Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model": "|**2025-6-30**|**Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model**|Shiming Chen et.al|[paper](https://arxiv.org/abs/2506.23822)|[code](https://github.com/shiming-chen/LaZSL.)|<details><summary>detail</summary>ICCV'25</details>|\n", "Towards Vision-Language-Garment Models for Web Knowledge Garment Understanding and Generation": "|**2025-6-30**|**Towards Vision-Language-Garment Models for Web Knowledge Garment Understanding and Generation**|Jan Ackermann et.al|[paper](https://arxiv.org/abs/2506.05210)|[code](https://www.computationalimaging.org/publications/vision-language-garment-models/)|<details><summary>detail</summary>Presented at MMFM CVPRW'25</details>|\n", "On the Domain Robustness of Contrastive Vision-Language Models": "|**2025-6-30**|**On the Domain Robustness of Contrastive Vision-Language Models**|Mario Koddenbrock et.al|[paper](https://arxiv.org/abs/2506.23663)|[code](https://github.com/ml-lab-htw/deepbench)|<details><summary>detail</summary>Deepbench is available at https://github</details>|\n", "TinyAlign: Boosting Lightweight Vision-Language Models by Mitigating Modal Alignment Bottlenecks": "|**2025-6-30**|**TinyAlign: Boosting Lightweight Vision-Language Models by Mitigating Modal Alignment Bottlenecks**|Yuanze Hu et.al|[paper](https://arxiv.org/abs/2505.12884)|-|-|\n", "CAI: Caption-Sensitive Attention Intervention for Mitigating Object Hallucination in Large Vision-Language Models": "|**2025-6-30**|**CAI: Caption-Sensitive Attention Intervention for Mitigating Object Hallucination in Large Vision-Language Models**|Qiming Li et.al|[paper](https://arxiv.org/abs/2506.23590)|-|-|\n", "Dataset Distillation via Vision-Language Category Prototype": "|**2025-6-30**|**Dataset Distillation via Vision-Language Category Prototype**|Yawen Zou et.al|[paper](https://arxiv.org/abs/2506.23580)|[code](https://github.com/zou-yawen/Dataset-Distillation-via-Vision-Language-Category-Prototype/)|<details><summary>detail</summary>accepted by ICCV2025</details>|\n", "Generalizing vision-language models to novel domains: A comprehensive survey": "|**2025-6-30**|**Generalizing vision-language models to novel domains: A comprehensive survey**|Xinyao Li et.al|[paper](https://arxiv.org/abs/2506.18504)|-|-|\n", "Qwen-GUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding": "|**2025-6-29**|**Qwen-GUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding**|ZongHan Hsieh et.al|[paper](https://arxiv.org/abs/2506.23491)|[code](https://github.com/Han1018/Qwen-GUI-3B)|-|\n", "NavMorph: A Self-Evolving World Model for Vision-and-Language Navigation in Continuous Environments": "|**2025-6-29**|**NavMorph: A Self-Evolving World Model for Vision-and-Language Navigation in Continuous Environments**|Xuan Yao et.al|[paper](https://arxiv.org/abs/2506.23468)|[code](https://github.com/Feliciaxyao/NavMorph)|<details><summary>detail</summary>Accepted by ICCV 2025</details>|\n", "Sanitizing Manufacturing Dataset Labels Using Vision-Language Models": "|**2025-6-29**|**Sanitizing Manufacturing Dataset Labels Using Vision-Language Models**|Nazanin Mahjourian et.al|[paper](https://arxiv.org/abs/2506.23465)|-|-|\n"}}