{"source-free": {"Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method": "|**2025-8-8**|**Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2508.09202)|-|-|\n", "Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation": "|**2025-8-7**|**Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation**|Jianming Liu et.al|[paper](https://arxiv.org/abs/2508.05213)|[code](https://github.com/ljm198134/TVGTANet.)|-|\n", "Model Recycling Framework for Multi-Source Data-Free Supervised Transfer Learning": "|**2025-8-4**|**Model Recycling Framework for Multi-Source Data-Free Supervised Transfer Learning**|Sijia Wang et.al|[paper](https://arxiv.org/abs/2508.02039)|-|-|\n", "Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments": "|**2025-7-30**|**Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2501.02184)|-|-|\n", "Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation": "|**2025-7-28**|**Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation**|Yihong Cao et.al|[paper](https://arxiv.org/abs/2506.21198)|[code](https://github.com/yihong-97/UNLOCK.)|<details><summary>detail</summary>ICCV 2025</details>|\n", "GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning": "|**2025-7-26**|**GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning**|Sanqing Qu et.al|[paper](https://arxiv.org/abs/2403.14410)|[code](https://github.com/ispc-lab/GLC-plus.)|<details><summary>detail</summary>A substantial extension of the CVPR paper \"Upcycling Models under Domain and Category Shift\"</details>|\n", "SFUOD: Source-Free Unknown Object Detection": "|**2025-7-23**|**SFUOD: Source-Free Unknown Object Detection**|Keon-Hee Park et.al|[paper](https://arxiv.org/abs/2507.17373)|-|<details><summary>detail</summary>This paper has been accepted by ICCV 2025</details>|\n", "Text-Driven Causal Representation Learning for Source-Free Domain Generalization": "|**2025-7-14**|**Text-Driven Causal Representation Learning for Source-Free Domain Generalization**|Lihua Zhou et.al|[paper](https://arxiv.org/abs/2507.09961)|-|<details><summary>detail</summary>Under Review</details>|\n", "Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting": "|**2025-7-12**|**Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting**|Zheang Huai et.al|[paper](https://arxiv.org/abs/2505.08527)|[code](https://github.com/xmed-lab/DFG.)|<details><summary>detail</summary>Accepted in TMI 2025</details>|\n", "Source-Free Domain Adaptation via Multi-view Contrastive Learning": "|**2025-7-4**|**Source-Free Domain Adaptation via Multi-view Contrastive Learning**|Amirfarhad Farhadi et.al|[paper](https://arxiv.org/abs/2507.03321)|-|-|\n", "Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework": "|**2025-6-26**|**Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework**|Ismail Nejjar et.al|[paper](https://arxiv.org/abs/2411.12558)|-|<details><summary>detail</summary>TMLR 2025</details>|\n", "Context Aware Grounded Teacher for Source Free Object Detection": "|**2025-6-25**|**Context Aware Grounded Teacher for Source Free Object Detection**|Tajamul Ashraf et.al|[paper](https://arxiv.org/abs/2504.15404)|[code](https://github.com/Tajamul21/Grounded_Teacher.)|-|\n", "SFDLA: Source-Free Document Layout Analysis": "|**2025-6-18**|**SFDLA: Source-Free Document Layout Analysis**|Sebastian Tewes et.al|[paper](https://arxiv.org/abs/2503.18742)|[code](https://github.com/s3setewe/sfdla-DLAdapter.)|<details><summary>detail</summary>Accepted by ICDAR 2025</details>|\n", "Unified Source-Free Domain Adaptation": "|**2025-6-17**|**Unified Source-Free Domain Adaptation**|Song Tang et.al|[paper](https://arxiv.org/abs/2403.07601)|-|-|\n", "SRPL-SFDA: SAM-Guided Reliable Pseudo-Labels for Source-Free Domain Adaptation in Medical Image Segmentation": "|**2025-6-11**|**SRPL-SFDA: SAM-Guided Reliable Pseudo-Labels for Source-Free Domain Adaptation in Medical Image Segmentation**|Xinya Liu et.al|[paper](https://arxiv.org/abs/2506.09403)|[code](https://github.com/HiLab-git/SRPL-SFDA.)|-|\n"}, "object detection": {"RoHOI: Robustness Benchmark for Human-Object Interaction Detection": "|**2025-8-13**|**RoHOI: Robustness Benchmark for Human-Object Interaction Detection**|Di Wen et.al|[paper](https://arxiv.org/abs/2507.09111)|[code](https://github.com/Kratos-Wen/RoHOI.)|<details><summary>detail</summary>Benchmarks</details>|\n", "MGDFIS: Multi-scale Global-detail Feature Integration Strategy for Small Object Detection": "|**2025-8-13**|**MGDFIS: Multi-scale Global-detail Feature Integration Strategy for Small Object Detection**|Yuxiang Wang et.al|[paper](https://arxiv.org/abs/2506.12697)|-|-|\n", "Robustness analysis of Deep Sky Objects detection models on HPC": "|**2025-8-13**|**Robustness analysis of Deep Sky Objects detection models on HPC**|Olivier Parisot et.al|[paper](https://arxiv.org/abs/2508.09831)|-|-|\n", "COXNet: Cross-Layer Fusion with Adaptive Alignment and Scale Integration for RGBT Tiny Object Detection": "|**2025-8-13**|**COXNet: Cross-Layer Fusion with Adaptive Alignment and Scale Integration for RGBT Tiny Object Detection**|Peiran Peng et.al|[paper](https://arxiv.org/abs/2508.09533)|-|-|\n", "DenoDet V2: Phase-Amplitude Cross Denoising for SAR Object Detection": "|**2025-8-12**|**DenoDet V2: Phase-Amplitude Cross Denoising for SAR Object Detection**|Kang Ni et.al|[paper](https://arxiv.org/abs/2508.09392)|[code](https://github.com/GrokCV/GrokSAR.)|-|\n", "DriveIndia: An Object Detection Dataset for Diverse Indian Traffic Scenes": "|**2025-8-12**|**DriveIndia: An Object Detection Dataset for Diverse Indian Traffic Scenes**|Rishav Kumar et.al|[paper](https://arxiv.org/abs/2507.19912)|[code](https://tihan.iith.ac.in/TiAND.html)|<details><summary>detail</summary>ITSC 2025 Conference</details>|\n", "QueryCraft: Transformer-Guided Query Initialization for Enhanced Human-Object Interaction Detection": "|**2025-8-11**|**QueryCraft: Transformer-Guided Query Initialization for Enhanced Human-Object Interaction Detection**|Yuxiao Wang et.al|[paper](https://arxiv.org/abs/2508.08590)|-|-|\n", "Designing Object Detection Models for TinyML: Foundations, Comparative Analysis, Challenges, and Emerging Solutions": "|**2025-8-11**|**Designing Object Detection Models for TinyML: Foundations, Comparative Analysis, Challenges, and Emerging Solutions**|Christophe EL Zeinaty et.al|[paper](https://arxiv.org/abs/2508.08352)|[code](https://github.com/christophezei/Optimizing-Object-Detection-Models-for-TinyML-A-Comprehensive-Survey.)|-|\n", "DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection and Large Language Models": "|**2025-8-11**|**DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection and Large Language Models**|Licheng Zhang et.al|[paper](https://arxiv.org/abs/2508.07714)|-|-|\n", "Enhancing Egocentric Object Detection in Static Environments using Graph-based Spatial Anomaly Detection and Correction": "|**2025-8-11**|**Enhancing Egocentric Object Detection in Static Environments using Graph-based Spatial Anomaly Detection and Correction**|Vishakha Lall et.al|[paper](https://arxiv.org/abs/2508.07624)|-|-|\n", "GAPNet: A Lightweight Framework for Image and Video Salient Object Detection via Granularity-Aware Paradigm": "|**2025-8-10**|**GAPNet: A Lightweight Framework for Image and Video Salient Object Detection via Granularity-Aware Paradigm**|Yu-Huan Wu et.al|[paper](https://arxiv.org/abs/2508.07585)|[code](https://github.com/yuhuan-wu/GAPNet.)|-|\n", "Lightweight Multi-Scale Feature Extraction with Fully Connected LMF Layer for Salient Object Detection": "|**2025-8-10**|**Lightweight Multi-Scale Feature Extraction with Fully Connected LMF Layer for Salient Object Detection**|Yunpeng Shi et.al|[paper](https://arxiv.org/abs/2508.07170)|[code](https://github.com/Shi-Yun-peng/LMFNet)|-|\n", "ForeSight: Multi-View Streaming Joint Object Detection and Trajectory Forecasting": "|**2025-8-9**|**ForeSight: Multi-View Streaming Joint Object Detection and Trajectory Forecasting**|Sandro Papais et.al|[paper](https://arxiv.org/abs/2508.07089)|-|<details><summary>detail</summary>ICCV 2025</details>|\n", "SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection": "|**2025-8-8**|**SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection**|Yuxuan Li et.al|[paper](https://arxiv.org/abs/2403.06534)|[code](https://github.com/zcablii/SARDet_100K.)|<details><summary>detail</summary>NeurIPS 2024</details>|\n", "Distribution-Specific Learning for Joint Salient and Camouflaged Object Detection": "|**2025-8-8**|**Distribution-Specific Learning for Joint Salient and Camouflaged Object Detection**|Chao Hao et.al|[paper](https://arxiv.org/abs/2508.06063)|[code](https://github.com/linuxsino/JoNet.)|-|\n"}, "domain adaptation": {"Multiple Stochastic Prompt Tuning for Few-shot Adaptation under Extreme Domain Shift": "|**2025-8-12**|**Multiple Stochastic Prompt Tuning for Few-shot Adaptation under Extreme Domain Shift**|Debarshi Brahma et.al|[paper](https://arxiv.org/abs/2506.03926)|-|-|\n", "Unified and Semantically Grounded Domain Adaptation for Medical Image Segmentation": "|**2025-8-12**|**Unified and Semantically Grounded Domain Adaptation for Medical Image Segmentation**|Xin Wang et.al|[paper](https://arxiv.org/abs/2508.08660)|-|-|\n", "DepressLLM: Interpretable domain-adapted language model for depression detection from real-world narratives": "|**2025-8-11**|**DepressLLM: Interpretable domain-adapted language model for depression detection from real-world narratives**|Sehwan Moon et.al|[paper](https://arxiv.org/abs/2508.08591)|-|-|\n", "FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis": "|**2025-8-11**|**FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis**|Chen Shen et.al|[paper](https://arxiv.org/abs/2508.07950)|-|-|\n", "VFM-UDA++: Improving Network Architectures and Data Strategies for Unsupervised Domain Adaptive Semantic Segmentation": "|**2025-8-10**|**VFM-UDA++: Improving Network Architectures and Data Strategies for Unsupervised Domain Adaptive Semantic Segmentation**|Brun\u00f3 B. Englert et.al|[paper](https://arxiv.org/abs/2503.10685)|-|-|\n", "Statistical Inference for Autoencoder-based Anomaly Detection after Representation Learning-based Domain Adaptation": "|**2025-8-9**|**Statistical Inference for Autoencoder-based Anomaly Detection after Representation Learning-based Domain Adaptation**|Tran Tuan Kiet et.al|[paper](https://arxiv.org/abs/2508.07049)|-|-|\n", "Low-Rank Expert Merging for Multi-Source Domain Adaptation in Person Re-Identification": "|**2025-8-9**|**Low-Rank Expert Merging for Multi-Source Domain Adaptation in Person Re-Identification**|Taha Mustapha Nehdi et.al|[paper](https://arxiv.org/abs/2508.06831)|-|-|\n", "AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation": "|**2025-8-8**|**AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation**|Md. Al-Masrur Khan et.al|[paper](https://arxiv.org/abs/2507.17957)|[code](https://github.com/Masrur02/AFRDA)|-|\n", "Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method": "|**2025-8-8**|**Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2508.09202)|-|-|\n", "TRUST: Leveraging Text Robustness for Unsupervised Domain Adaptation": "|**2025-8-8**|**TRUST: Leveraging Text Robustness for Unsupervised Domain Adaptation**|Mattia Litrico et.al|[paper](https://arxiv.org/abs/2508.06452)|-|-|\n", "HASD: Hierarchical Adaption for pathology Slide-level Domain-shift": "|**2025-8-8**|**HASD: Hierarchical Adaption for pathology Slide-level Domain-shift**|Jingsong Liu et.al|[paper](https://arxiv.org/abs/2506.23673)|-|<details><summary>detail</summary>Accepted by MICCAI 2025</details>|\n", "Uncertainty-quantified Rollout Policy Adaptation for Unlabelled Cross-domain Temporal Grounding": "|**2025-8-8**|**Uncertainty-quantified Rollout Policy Adaptation for Unlabelled Cross-domain Temporal Grounding**|Jian Hu et.al|[paper](https://arxiv.org/abs/2508.06317)|-|-|\n", "Hybrid-TTA: Continual Test-time Adaptation via Dynamic Domain Shift Detection": "|**2025-8-8**|**Hybrid-TTA: Continual Test-time Adaptation via Dynamic Domain Shift Detection**|Hyewon Park et.al|[paper](https://arxiv.org/abs/2409.08566)|-|<details><summary>detail</summary>Accepted by ICCV 2025</details>|\n", "SPA++: Generalized Graph Spectral Alignment for Versatile Domain Adaptation": "|**2025-8-7**|**SPA++: Generalized Graph Spectral Alignment for Versatile Domain Adaptation**|Zhiqing Xiao et.al|[paper](https://arxiv.org/abs/2508.05182)|-|<details><summary>detail</summary>The article has been accepted by Frontiers of Computer Science (FCS)</details>|\n", "Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation": "|**2025-8-7**|**Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation**|Jianming Liu et.al|[paper](https://arxiv.org/abs/2508.05213)|[code](https://github.com/ljm198134/TVGTANet.)|-|\n"}, "domain generalization": {"Domain-Generalization to Improve Learning in Meta-Learning Algorithms": "|**2025-8-12**|**Domain-Generalization to Improve Learning in Meta-Learning Algorithms**|Usman Anjum et.al|[paper](https://arxiv.org/abs/2508.09418)|-|-|\n", "Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering": "|**2025-8-12**|**Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering**|Elman Ghazaei et.al|[paper](https://arxiv.org/abs/2508.08974)|[code](https://github.com/Elman295/TCSSM.)|-|\n", "FedSDAF: Leveraging Source Domain Awareness for Enhanced Federated Domain Generalization": "|**2025-8-11**|**FedSDAF: Leveraging Source Domain Awareness for Enhanced Federated Domain Generalization**|Hongze Li et.al|[paper](https://arxiv.org/abs/2505.02515)|[code](https://github.com/pizzareapers/FedSDAF.)|-|\n", "Domain Generalization of Pathological Image Segmentation by Patch-Level and WSI-Level Contrastive Learning": "|**2025-8-10**|**Domain Generalization of Pathological Image Segmentation by Patch-Level and WSI-Level Contrastive Learning**|Yuki Shigeyasu et.al|[paper](https://arxiv.org/abs/2508.07539)|-|-|\n", "GAITGen: Disentangled Motion-Pathology Impaired Gait Generative Model -- Bringing Motion Generation to the Clinical Domain": "|**2025-8-9**|**GAITGen: Disentangled Motion-Pathology Impaired Gait Generative Model -- Bringing Motion Generation to the Clinical Domain**|Vida Adeli et.al|[paper](https://arxiv.org/abs/2503.22397)|-|-|\n", "SPA++: Generalized Graph Spectral Alignment for Versatile Domain Adaptation": "|**2025-8-7**|**SPA++: Generalized Graph Spectral Alignment for Versatile Domain Adaptation**|Zhiqing Xiao et.al|[paper](https://arxiv.org/abs/2508.05182)|-|<details><summary>detail</summary>The article has been accepted by Frontiers of Computer Science (FCS)</details>|\n", "Generative Multi-Target Cross-Domain Recommendation": "|**2025-8-7**|**Generative Multi-Target Cross-Domain Recommendation**|Jinqiu Jin et.al|[paper](https://arxiv.org/abs/2507.12871)|-|<details><summary>detail</summary>fix some information by request</details>|\n", "HFedATM: Hierarchical Federated Domain Generalization via Optimal Transport and Regularized Mean Aggregation": "|**2025-8-7**|**HFedATM: Hierarchical Federated Domain Generalization via Optimal Transport and Regularized Mean Aggregation**|Thinh Nguyen et.al|[paper](https://arxiv.org/abs/2508.05135)|-|-|\n", "Augmentation-based Domain Generalization and Joint Training from Multiple Source Domains for Whole Heart Segmentation": "|**2025-8-6**|**Augmentation-based Domain Generalization and Joint Training from Multiple Source Domains for Whole Heart Segmentation**|Franz Thaler et.al|[paper](https://arxiv.org/abs/2508.04552)|-|<details><summary>detail</summary>Accepted for the MICCAI Challenge on Comprehensive Analysis and Computing of Real-World Medical Images 2024</details>|\n", "Cross-Domain Image Synthesis: Generating H&E from Multiplex Biomarker Imaging": "|**2025-8-5**|**Cross-Domain Image Synthesis: Generating H&E from Multiplex Biomarker Imaging**|Jillur Rahman Saurav et.al|[paper](https://arxiv.org/abs/2508.04734)|-|-|\n", "FedSemiDG: Domain Generalized Federated Semi-supervised Medical Image Segmentation": "|**2025-8-5**|**FedSemiDG: Domain Generalized Federated Semi-supervised Medical Image Segmentation**|Zhipeng Deng et.al|[paper](https://arxiv.org/abs/2501.07378)|-|-|\n", "LLM-Generated Heuristics for AI Planning: Do We Even Need Domain-Independence Anymore?": "|**2025-8-5**|**LLM-Generated Heuristics for AI Planning: Do We Even Need Domain-Independence Anymore?**|Alexander Tuisov et.al|[paper](https://arxiv.org/abs/2501.18784)|-|-|\n", "Zero Shot Domain Adaptive Semantic Segmentation by Synthetic Data Generation and Progressive Adaptation": "|**2025-8-5**|**Zero Shot Domain Adaptive Semantic Segmentation by Synthetic Data Generation and Progressive Adaptation**|Jun Luo et.al|[paper](https://arxiv.org/abs/2508.03300)|[code](https://github.com/ROUJINN/SDGPA)|<details><summary>detail</summary>IROS 2025</details>|\n", "Domain-Independent Automatic Generation of Descriptive Texts for Time-Series Data": "|**2025-8-4**|**Domain-Independent Automatic Generation of Descriptive Texts for Time-Series Data**|Kota Dohi et.al|[paper](https://arxiv.org/abs/2409.16647)|-|-|\n", "Multi-Granularity Feature Calibration via VFM for Domain Generalized Semantic Segmentation": "|**2025-8-4**|**Multi-Granularity Feature Calibration via VFM for Domain Generalized Semantic Segmentation**|Xinhui Li et.al|[paper](https://arxiv.org/abs/2508.03007)|-|-|\n"}, "vision language": {"LLMC+: Benchmarking Vision-Language Model Compression with a Plug-and-play Toolkit": "|**2025-8-13**|**LLMC+: Benchmarking Vision-Language Model Compression with a Plug-and-play Toolkit**|Chengtao Lv et.al|[paper](https://arxiv.org/abs/2508.09981)|[code](https://github.com/ModelTC/LightCompress.)|-|\n", "GeoVLA: Empowering 3D Representations in Vision-Language-Action Models": "|**2025-8-13**|**GeoVLA: Empowering 3D Representations in Vision-Language-Action Models**|Lin Sun et.al|[paper](https://arxiv.org/abs/2508.09071)|[code](https://linsun449.github.io/GeoVLA/)|<details><summary>detail</summary>The project is visible at https://linsun449</details>|\n", "CAS-IQA: Teaching Vision-Language Models for Synthetic Angiography Quality Assessment": "|**2025-8-13**|**CAS-IQA: Teaching Vision-Language Models for Synthetic Angiography Quality Assessment**|Bo Wang et.al|[paper](https://arxiv.org/abs/2505.17619)|-|<details><summary>detail</summary>Camera ready version for ICONIP 2025</details>|\n", "Transferable Model-agnostic Vision-Language Model Adaptation for Efficient Weak-to-Strong Generalization": "|**2025-8-13**|**Transferable Model-agnostic Vision-Language Model Adaptation for Efficient Weak-to-Strong Generalization**|Jihwan Park et.al|[paper](https://arxiv.org/abs/2508.08604)|-|-|\n", "Debiased Fine-Tuning for Vision-language Models by Prompt Regularization": "|**2025-8-13**|**Debiased Fine-Tuning for Vision-language Models by Prompt Regularization**|Beier Zhu et.al|[paper](https://arxiv.org/abs/2301.12429)|-|<details><summary>detail</summary>AAAI2023 accepted</details>|\n", "ViMoNet: A Multimodal Vision-Language Framework for Human Behavior Understanding from Motion and Video": "|**2025-8-13**|**ViMoNet: A Multimodal Vision-Language Framework for Human Behavior Understanding from Motion and Video**|Rajan Das Gupta et.al|[paper](https://arxiv.org/abs/2508.09818)|-|<details><summary>detail</summary>Accepted in ICCVDM '25</details>|\n", "MoIIE: Mixture of Intra- and Inter-Modality Experts for Large Vision Language Models": "|**2025-8-13**|**MoIIE: Mixture of Intra- and Inter-Modality Experts for Large Vision Language Models**|Dianyi Wang et.al|[paper](https://arxiv.org/abs/2508.09779)|[code](https://github.com/AlenjandroWang/MoIIE.)|-|\n", "The Perils of Chart Deception: How Misleading Visualizations Affect Vision-Language Models": "|**2025-8-13**|**The Perils of Chart Deception: How Misleading Visualizations Affect Vision-Language Models**|Ridwan Mahbub et.al|[paper](https://arxiv.org/abs/2508.09716)|-|<details><summary>detail</summary>IEEE VIS 2025</details>|\n", "HVL: Semi-Supervised Segmentation leveraging Hierarchical Vision-Language Synergy with Dynamic Text-Spatial Query Alignment": "|**2025-8-13**|**HVL: Semi-Supervised Segmentation leveraging Hierarchical Vision-Language Synergy with Dynamic Text-Spatial Query Alignment**|Numair Nadeem et.al|[paper](https://arxiv.org/abs/2506.13925)|-|-|\n", "Probing Mechanical Reasoning in Large Vision Language Models": "|**2025-8-13**|**Probing Mechanical Reasoning in Large Vision Language Models**|Haoran Sun et.al|[paper](https://arxiv.org/abs/2410.00318)|-|<details><summary>detail</summary>Published at the ICLR 2025 Workshop on Bidirectional Human-AI Alignment (BiAlign)</details>|\n", "Vision Language Models Know Law of Conservation without Understanding More-or-Less": "|**2025-8-13**|**Vision Language Models Know Law of Conservation without Understanding More-or-Less**|Dezhi Luo et.al|[paper](https://arxiv.org/abs/2410.00332)|-|<details><summary>detail</summary>Published at the ICLR 2025 Workshop on Bidirectional Human-AI Alignment (BiAlign)</details>|\n", "Advancing Reliable Test-Time Adaptation of Vision-Language Models under Visual Variations": "|**2025-8-13**|**Advancing Reliable Test-Time Adaptation of Vision-Language Models under Visual Variations**|Yiwen Liang et.al|[paper](https://arxiv.org/abs/2507.09500)|[code](https://github.com/Evelyn1ywliang/ReTA.)|<details><summary>detail</summary>the 33rd ACM International Conference on Multimedia(ACM MM 2025)</details>|\n", "DAgger Diffusion Navigation: DAgger Boosted Diffusion Policy for Vision-Language Navigation": "|**2025-8-12**|**DAgger Diffusion Navigation: DAgger Boosted Diffusion Policy for Vision-Language Navigation**|Haoxiang Shi et.al|[paper](https://arxiv.org/abs/2508.09444)|[code](https://github.com/Tokishx/DifNav.)|-|\n", "On the Reliability of Vision-Language Models Under Adversarial Frequency-Domain Perturbations": "|**2025-8-12**|**On the Reliability of Vision-Language Models Under Adversarial Frequency-Domain Perturbations**|Jordan Vice et.al|[paper](https://arxiv.org/abs/2507.22398)|-|<details><summary>detail</summary>Keywords: Vision-Language Models</details>|\n", "BigTokDetect: A Clinically-Informed Vision-Language Modeling Framework for Detecting Pro-Bigorexia Videos on TikTok": "|**2025-8-12**|**BigTokDetect: A Clinically-Informed Vision-Language Modeling Framework for Detecting Pro-Bigorexia Videos on TikTok**|Minh Duc Chu et.al|[paper](https://arxiv.org/abs/2508.06515)|-|-|\n"}}