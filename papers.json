{"source-free": {"VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection": "|**2025-8-26**|**VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection**|Jianhong Han et.al|[paper](https://arxiv.org/abs/2508.11167)|-|<details><summary>detail</summary>Manuscript submitted to IEEE TCSVT</details>|\n", "Towards Source-Free Machine Unlearning": "|**2025-8-20**|**Towards Source-Free Machine Unlearning**|Sk Miraj Ahmed et.al|[paper](https://arxiv.org/abs/2508.15127)|-|<details><summary>detail</summary>Accepted by CVPR 2025</details>|\n", "Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method": "|**2025-8-14**|**Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2508.09202)|-|-|\n", "Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation": "|**2025-8-7**|**Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation**|Jianming Liu et.al|[paper](https://arxiv.org/abs/2508.05213)|[code](https://github.com/ljm198134/TVGTANet.)|-|\n", "Model Recycling Framework for Multi-Source Data-Free Supervised Transfer Learning": "|**2025-8-4**|**Model Recycling Framework for Multi-Source Data-Free Supervised Transfer Learning**|Sijia Wang et.al|[paper](https://arxiv.org/abs/2508.02039)|-|-|\n", "Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments": "|**2025-7-30**|**Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2501.02184)|-|-|\n", "Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation": "|**2025-7-28**|**Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation**|Yihong Cao et.al|[paper](https://arxiv.org/abs/2506.21198)|[code](https://github.com/yihong-97/UNLOCK.)|<details><summary>detail</summary>ICCV 2025</details>|\n", "GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning": "|**2025-7-26**|**GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning**|Sanqing Qu et.al|[paper](https://arxiv.org/abs/2403.14410)|[code](https://github.com/ispc-lab/GLC-plus.)|<details><summary>detail</summary>A substantial extension of the CVPR paper \"Upcycling Models under Domain and Category Shift\"</details>|\n", "SFUOD: Source-Free Unknown Object Detection": "|**2025-7-23**|**SFUOD: Source-Free Unknown Object Detection**|Keon-Hee Park et.al|[paper](https://arxiv.org/abs/2507.17373)|-|<details><summary>detail</summary>This paper has been accepted by ICCV 2025</details>|\n", "Text-Driven Causal Representation Learning for Source-Free Domain Generalization": "|**2025-7-14**|**Text-Driven Causal Representation Learning for Source-Free Domain Generalization**|Lihua Zhou et.al|[paper](https://arxiv.org/abs/2507.09961)|-|<details><summary>detail</summary>Under Review</details>|\n", "Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting": "|**2025-7-12**|**Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting**|Zheang Huai et.al|[paper](https://arxiv.org/abs/2505.08527)|[code](https://github.com/xmed-lab/DFG.)|<details><summary>detail</summary>Accepted in TMI 2025</details>|\n", "Source-Free Domain Adaptation via Multi-view Contrastive Learning": "|**2025-7-4**|**Source-Free Domain Adaptation via Multi-view Contrastive Learning**|Amirfarhad Farhadi et.al|[paper](https://arxiv.org/abs/2507.03321)|-|-|\n", "Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework": "|**2025-6-26**|**Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework**|Ismail Nejjar et.al|[paper](https://arxiv.org/abs/2411.12558)|-|<details><summary>detail</summary>TMLR 2025</details>|\n", "Context Aware Grounded Teacher for Source Free Object Detection": "|**2025-6-25**|**Context Aware Grounded Teacher for Source Free Object Detection**|Tajamul Ashraf et.al|[paper](https://arxiv.org/abs/2504.15404)|[code](https://github.com/Tajamul21/Grounded_Teacher.)|-|\n", "SFDLA: Source-Free Document Layout Analysis": "|**2025-6-18**|**SFDLA: Source-Free Document Layout Analysis**|Sebastian Tewes et.al|[paper](https://arxiv.org/abs/2503.18742)|[code](https://github.com/s3setewe/sfdla-DLAdapter.)|<details><summary>detail</summary>Accepted by ICDAR 2025</details>|\n"}, "object detection": {"MonoCoP: Chain-of-Prediction for Monocular 3D Object Detection": "|**2025-8-26**|**MonoCoP: Chain-of-Prediction for Monocular 3D Object Detection**|Zhihao Zhang et.al|[paper](https://arxiv.org/abs/2505.04594)|-|<details><summary>detail</summary>I plan to re-format and re-write this paper</details>|\n", "Egocentric Human-Object Interaction Detection: A New Benchmark and Method": "|**2025-8-26**|**Egocentric Human-Object Interaction Detection: A New Benchmark and Method**|Kunyuan Deng et.al|[paper](https://arxiv.org/abs/2506.14189)|[code](https://dengkunyuan.github.io/EgoHOIBench/)|-|\n", "Single-Domain Generalized Object Detection by Balancing Domain Diversity and Invariance": "|**2025-8-26**|**Single-Domain Generalized Object Detection by Balancing Domain Diversity and Invariance**|Zhenwei He et.al|[paper](https://arxiv.org/abs/2502.03835)|-|-|\n", "VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection": "|**2025-8-26**|**VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection**|Jianhong Han et.al|[paper](https://arxiv.org/abs/2508.11167)|-|<details><summary>detail</summary>Manuscript submitted to IEEE TCSVT</details>|\n", "Are All Marine Species Created Equal? Performance Disparities in Underwater Object Detection": "|**2025-8-26**|**Are All Marine Species Created Equal? Performance Disparities in Underwater Object Detection**|Melanie Wille et.al|[paper](https://arxiv.org/abs/2508.18729)|-|-|\n", "DriveIndia: An Object Detection Dataset for Diverse Indian Traffic Scenes": "|**2025-8-26**|**DriveIndia: An Object Detection Dataset for Diverse Indian Traffic Scenes**|Rishav Kumar et.al|[paper](https://arxiv.org/abs/2507.19912)|[code](https://tihan.iith.ac.in/TiAND.html)|<details><summary>detail</summary>ITSC 2025 Conference</details>|\n", "BirdRecorder's AI on Sky: Safeguarding birds of prey by detection and classification of tiny objects around wind turbines": "|**2025-8-25**|**BirdRecorder's AI on Sky: Safeguarding birds of prey by detection and classification of tiny objects around wind turbines**|Nico Klar et.al|[paper](https://arxiv.org/abs/2508.18136)|-|-|\n", "V2X-R: Cooperative LiDAR-4D Radar Fusion with Denoising Diffusion for 3D Object Detection": "|**2025-8-25**|**V2X-R: Cooperative LiDAR-4D Radar Fusion with Denoising Diffusion for 3D Object Detection**|Xun Huang et.al|[paper](https://arxiv.org/abs/2411.08402)|[code](https://github.com/ylwhxht/V2X-R.)|<details><summary>detail</summary>Accepted by CVPR2025</details>|\n", "Learning to Detect Label Errors by Making Them: A Method for Segmentation and Object Detection Datasets": "|**2025-8-25**|**Learning to Detect Label Errors by Making Them: A Method for Segmentation and Object Detection Datasets**|Sarina Penquitt et.al|[paper](https://arxiv.org/abs/2508.17930)|-|-|\n", "Box-Level Class-Balanced Sampling for Active Object Detection": "|**2025-8-25**|**Box-Level Class-Balanced Sampling for Active Object Detection**|Jingyi Liao et.al|[paper](https://arxiv.org/abs/2508.17849)|-|<details><summary>detail</summary>ICIP2024</details>|\n", "SCOUT: Semi-supervised Camouflaged Object Detection by Utilizing Text and Adaptive Data Selection": "|**2025-8-25**|**SCOUT: Semi-supervised Camouflaged Object Detection by Utilizing Text and Adaptive Data Selection**|Weiqi Yan et.al|[paper](https://arxiv.org/abs/2508.17843)|[code](https://github.com/Heartfirey/SCOUT.)|<details><summary>detail</summary>Accepted by IJCAI 2025</details>|\n", "Investigating Domain Gaps for Indoor 3D Object Detection": "|**2025-8-24**|**Investigating Domain Gaps for Indoor 3D Object Detection**|Zijing Zhao et.al|[paper](https://arxiv.org/abs/2508.17439)|[code](https://jeremyzhao1998.github.io/DAVoteNet-release/.)|<details><summary>detail</summary>Accepted by ACM MM 2025</details>|\n", "BoxFusion: Reconstruction-Free Open-Vocabulary 3D Object Detection via Real-Time Multi-View Box Fusion": "|**2025-8-24**|**BoxFusion: Reconstruction-Free Open-Vocabulary 3D Object Detection via Real-Time Multi-View Box Fusion**|Yuqing Lan et.al|[paper](https://arxiv.org/abs/2506.15610)|[code](https://lanlan96.github.io/BoxFusion/)|<details><summary>detail</summary>Project page: https://lanlan96</details>|\n", "Exponentially Weighted Instance-Aware Repeat Factor Sampling for Long-Tailed Object Detection Model Training in Unmanned Aerial Vehicles Surveillance Scenarios": "|**2025-8-24**|**Exponentially Weighted Instance-Aware Repeat Factor Sampling for Long-Tailed Object Detection Model Training in Unmanned Aerial Vehicles Surveillance Scenarios**|Taufiq Ahmed et.al|[paper](https://arxiv.org/abs/2503.21893)|[code](https://github.com/futurians/E-IRFS.)|-|\n", "Spatial-Temporal Human-Object Interaction Detection": "|**2025-8-24**|**Spatial-Temporal Human-Object Interaction Detection**|Xu Sun et.al|[paper](https://arxiv.org/abs/2508.17270)|-|-|\n"}, "domain adaptation": {"PointFix: Learning to Fix Domain Bias for Robust Online Stereo Adaptation": "|**2025-8-26**|**PointFix: Learning to Fix Domain Bias for Robust Online Stereo Adaptation**|Kwonyoung Kim et.al|[paper](https://arxiv.org/abs/2207.13340)|-|<details><summary>detail</summary>ECCV 2022</details>|\n", "Feature-Space Planes Searcher: A Universal Domain Adaptation Framework for Interpretability and Computational Efficiency": "|**2025-8-26**|**Feature-Space Planes Searcher: A Universal Domain Adaptation Framework for Interpretability and Computational Efficiency**|Zhitong Cheng et.al|[paper](https://arxiv.org/abs/2508.18693)|-|-|\n", "Adapting Large Language Models to Log Analysis with Interpretable Domain Knowledge": "|**2025-8-25**|**Adapting Large Language Models to Log Analysis with Interpretable Domain Knowledge**|Yuhe Ji et.al|[paper](https://arxiv.org/abs/2412.01377)|-|<details><summary>detail</summary>Accepted by CIKM 2025</details>|\n", "Uncertainty Awareness on Unsupervised Domain Adaptation for Time Series Data": "|**2025-8-25**|**Uncertainty Awareness on Unsupervised Domain Adaptation for Time Series Data**|Weide Liu et.al|[paper](https://arxiv.org/abs/2508.18630)|-|<details><summary>detail</summary>IEEE Transactions on Multimedia</details>|\n", "Spectrum Prediction in the Fractional Fourier Domain with Adaptive Filtering": "|**2025-8-25**|**Spectrum Prediction in the Fractional Fourier Domain with Adaptive Filtering**|Yanghao Qin et.al|[paper](https://arxiv.org/abs/2508.17872)|-|<details><summary>detail</summary>Accepted by IEEE Wireless Communications Letters</details>|\n", "Federated Adversarial Domain Adaptation": "|**2025-8-24**|**Federated Adversarial Domain Adaptation**|Xingchao Peng et.al|[paper](https://arxiv.org/abs/1911.02054)|-|<details><summary>detail</summary>Published as a conference paper at ICLR 2020</details>|\n", "Addressing Annotation Scarcity in Hyperspectral Brain Image Segmentation with Unsupervised Domain Adaptation": "|**2025-8-23**|**Addressing Annotation Scarcity in Hyperspectral Brain Image Segmentation with Unsupervised Domain Adaptation**|Tim Mach et.al|[paper](https://arxiv.org/abs/2508.16934)|-|-|\n", "Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning": "|**2025-8-22**|**Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning**|Yingxu Wang et.al|[paper](https://arxiv.org/abs/2508.00716)|-|-|\n", "Domain Adaptation via Feature Refinement": "|**2025-8-22**|**Domain Adaptation via Feature Refinement**|Savvas Karatsiolis et.al|[paper](https://arxiv.org/abs/2508.16124)|-|-|\n", "Task-Generalized Adaptive Cross-Domain Learning for Multimodal Image Fusion": "|**2025-8-21**|**Task-Generalized Adaptive Cross-Domain Learning for Multimodal Image Fusion**|Mengyu Wang et.al|[paper](https://arxiv.org/abs/2508.15505)|[code](https://github.com/Zhen-yu-Liu/AdaSFFuse.)|<details><summary>detail</summary>Accepted by IEEE Transactions on Multimedia</details>|\n", "DoSReMC: Domain Shift Resilient Mammography Classification using Batch Normalization Adaptation": "|**2025-8-21**|**DoSReMC: Domain Shift Resilient Mammography Classification using Batch Normalization Adaptation**|U\u011furcan Aky\u00fcz et.al|[paper](https://arxiv.org/abs/2508.15452)|-|-|\n", "Securing Swarms: Cross-Domain Adaptation for ROS2-based CPS Anomaly Detection": "|**2025-8-20**|**Securing Swarms: Cross-Domain Adaptation for ROS2-based CPS Anomaly Detection**|Julia Boone et.al|[paper](https://arxiv.org/abs/2508.15865)|-|<details><summary>detail</summary>Accepted for publication in MILCOM 2025</details>|\n", "Adaptation and Optimization of Automatic Speech Recognition (ASR) for the Maritime Domain in the Field of VHF Communication": "|**2025-8-19**|**Adaptation and Optimization of Automatic Speech Recognition (ASR) for the Maritime Domain in the Field of VHF Communication**|Emin Cagatay Nakilcioglu et.al|[paper](https://arxiv.org/abs/2306.00614)|-|<details><summary>detail</summary>Journal ref:Proceedings of the COMPIT Conference 22 (2023) 345-354</details>|\n", "ReservoirTTA: Prolonged Test-time Adaptation for Evolving and Recurring Domains": "|**2025-8-19**|**ReservoirTTA: Prolonged Test-time Adaptation for Evolving and Recurring Domains**|Guillaume Vray et.al|[paper](https://arxiv.org/abs/2505.14511)|[code](https://github.com/LTS5/ReservoirTTA.)|-|\n", "Transfer Learning for Neutrino Scattering: Domain Adaptation with GANs": "|**2025-8-18**|**Transfer Learning for Neutrino Scattering: Domain Adaptation with GANs**|Jose L. Bonilla et.al|[paper](https://arxiv.org/abs/2508.12987)|-|-|\n"}, "domain generalization": {"Single-Domain Generalized Object Detection by Balancing Domain Diversity and Invariance": "|**2025-8-26**|**Single-Domain Generalized Object Detection by Balancing Domain Diversity and Invariance**|Zhenwei He et.al|[paper](https://arxiv.org/abs/2502.03835)|-|-|\n", "SCP-116K: A High-Quality Problem-Solution Dataset and a Generalized Pipeline for Automated Extraction in the Higher Education Science Domain": "|**2025-8-24**|**SCP-116K: A High-Quality Problem-Solution Dataset and a Generalized Pipeline for Automated Extraction in the Higher Education Science Domain**|Dakuan Lu et.al|[paper](https://arxiv.org/abs/2501.15587)|[code](https://github.com/AQA6666/SCP-116K-open.)|-|\n", "MGT-Prism: Enhancing Domain Generalization for Machine-Generated Text Detection via Spectral Alignment": "|**2025-8-24**|**MGT-Prism: Enhancing Domain Generalization for Machine-Generated Text Detection via Spectral Alignment**|Shengchao Liu et.al|[paper](https://arxiv.org/abs/2508.13768)|-|-|\n", "Preserving Domain Generalization in Fine-Tuning via Joint Parameter Selection": "|**2025-8-23**|**Preserving Domain Generalization in Fine-Tuning via Joint Parameter Selection**|Bin Pan et.al|[paper](https://arxiv.org/abs/2508.16976)|-|-|\n", "Domain-aligned generative downscaling enhances projections of extreme climate events": "|**2025-8-22**|**Domain-aligned generative downscaling enhances projections of extreme climate events**|Ruian Tie et.al|[paper](https://arxiv.org/abs/2508.16396)|-|-|\n", "Task-Generalized Adaptive Cross-Domain Learning for Multimodal Image Fusion": "|**2025-8-21**|**Task-Generalized Adaptive Cross-Domain Learning for Multimodal Image Fusion**|Mengyu Wang et.al|[paper](https://arxiv.org/abs/2508.15505)|[code](https://github.com/Zhen-yu-Liu/AdaSFFuse.)|<details><summary>detail</summary>Accepted by IEEE Transactions on Multimedia</details>|\n", "A fully-programmable integrated photonic processor for both domain-specific and general-purpose computing": "|**2025-8-19**|**A fully-programmable integrated photonic processor for both domain-specific and general-purpose computing**|Feng-Kai Han et.al|[paper](https://arxiv.org/abs/2508.13551)|-|-|\n", "Understanding the Impact of Confidence in Retrieval Augmented Generation: A Case Study in the Medical Domain": "|**2025-8-18**|**Understanding the Impact of Confidence in Retrieval Augmented Generation: A Case Study in the Medical Domain**|Shintaro Ozaki et.al|[paper](https://arxiv.org/abs/2412.20309)|-|<details><summary>detail</summary>BioNLP2025 (Workshop colocated with ACL2025)</details>|\n", "A Shift in Perspective on Causality in Domain Generalization": "|**2025-8-18**|**A Shift in Perspective on Causality in Domain Generalization**|Damian Machlanski et.al|[paper](https://arxiv.org/abs/2508.12798)|[code](https://chai-uk.github.io/ukairs25-causal-predictors/.)|-|\n", "Vision-G1: Towards General Vision Language Reasoning with Multi-Domain Data Curation": "|**2025-8-18**|**Vision-G1: Towards General Vision Language Reasoning with Multi-Domain Data Curation**|Yuheng Zha et.al|[paper](https://arxiv.org/abs/2508.12680)|[code](https://github.com/yuh-zha/Vision-G1.)|-|\n", "Domain Translation of a Soft Robotic Arm using Conditional Cycle Generative Adversarial Network": "|**2025-8-16**|**Domain Translation of a Soft Robotic Arm using Conditional Cycle Generative Adversarial Network**|Nilay Kushawaha et.al|[paper](https://arxiv.org/abs/2508.14100)|-|<details><summary>detail</summary>IEEE International Conference on Robotic Systems and Applications</details>|\n", "Subcortical Masks Generation in CT Images via Ensemble-Based Cross-Domain Label Transfer": "|**2025-8-15**|**Subcortical Masks Generation in CT Images via Ensemble-Based Cross-Domain Label Transfer**|Augustine X. W. Lee et.al|[paper](https://arxiv.org/abs/2508.11450)|[code](https://github.com/SCSE-Biomedical-Computing-Group/CT-Subcortical-Segmentation,)|-|\n", "MIDAS: Modeling Ground-Truth Distributions with Dark Knowledge for Domain Generalized Stereo Matching": "|**2025-8-14**|**MIDAS: Modeling Ground-Truth Distributions with Dark Knowledge for Domain Generalized Stereo Matching**|Peng Xu et.al|[paper](https://arxiv.org/abs/2503.04376)|-|-|\n", "Domain-Generalization to Improve Learning in Meta-Learning Algorithms": "|**2025-8-12**|**Domain-Generalization to Improve Learning in Meta-Learning Algorithms**|Usman Anjum et.al|[paper](https://arxiv.org/abs/2508.09418)|-|-|\n", "Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering": "|**2025-8-12**|**Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering**|Elman Ghazaei et.al|[paper](https://arxiv.org/abs/2508.08974)|[code](https://github.com/Elman295/TCSSM.)|-|\n"}, "vision language": {"MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation": "|**2025-8-26**|**MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation**|Hao Shi et.al|[paper](https://arxiv.org/abs/2508.19236)|[code](https://shihao1895.github.io/MemoryVLA)|<details><summary>detail</summary>The project is available at https://shihao1895</details>|\n", "Dual Enhancement on 3D Vision-Language Perception for Monocular 3D Visual Grounding": "|**2025-8-26**|**Dual Enhancement on 3D Vision-Language Perception for Monocular 3D Visual Grounding**|Yuzhen Li et.al|[paper](https://arxiv.org/abs/2508.19165)|-|-|\n", "Ask Me Again Differently: GRAS for Measuring Bias in Vision Language Models on Gender, Race, Age, and Skin Tone": "|**2025-8-26**|**Ask Me Again Differently: GRAS for Measuring Bias in Vision Language Models on Gender, Race, Age, and Skin Tone**|Shaivi Malik et.al|[paper](https://arxiv.org/abs/2508.18989)|-|-|\n", "Toward Robust Medical Fairness: Debiased Dual-Modal Alignment via Text-Guided Attribute-Disentangled Prompt Learning for Vision-Language Models": "|**2025-8-26**|**Toward Robust Medical Fairness: Debiased Dual-Modal Alignment via Text-Guided Attribute-Disentangled Prompt Learning for Vision-Language Models**|Yuexuan Xia et.al|[paper](https://arxiv.org/abs/2508.18886)|-|-|\n", "SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models": "|**2025-8-26**|**SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models**|Xiangyu Dong et.al|[paper](https://arxiv.org/abs/2507.13152)|-|-|\n", "Hidden Tail: Adversarial Image Causing Stealthy Resource Consumption in Vision-Language Models": "|**2025-8-26**|**Hidden Tail: Adversarial Image Causing Stealthy Resource Consumption in Vision-Language Models**|Rui Zhang et.al|[paper](https://arxiv.org/abs/2508.18805)|[code](https://github.com/zhangrui4041/Hidden_Tail.)|-|\n", "DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge": "|**2025-8-26**|**DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge**|Wenyao Zhang et.al|[paper](https://arxiv.org/abs/2507.04447)|-|-|\n", "Rethinking Human-Object Interaction Evaluation for both Vision-Language Models and HOI-Specific Methods": "|**2025-8-26**|**Rethinking Human-Object Interaction Evaluation for both Vision-Language Models and HOI-Specific Methods**|Qinqian Lei et.al|[paper](https://arxiv.org/abs/2508.18753)|-|-|\n", "Jigsaw-Puzzles: From Seeing to Understanding to Reasoning in Vision-Language Models": "|**2025-8-25**|**Jigsaw-Puzzles: From Seeing to Understanding to Reasoning in Vision-Language Models**|Zesen Lyu et.al|[paper](https://arxiv.org/abs/2505.20728)|[code](https://zesen01.github.io/jigsaw-puzzles.)|<details><summary>detail</summary>Accepted by EMNLP 2025 Main conference</details>|\n", "Language-Specific Layer Matters: Efficient Multilingual Enhancement for Large Vision-Language Models": "|**2025-8-25**|**Language-Specific Layer Matters: Efficient Multilingual Enhancement for Large Vision-Language Models**|Yuchun Fan et.al|[paper](https://arxiv.org/abs/2508.18381)|-|<details><summary>detail</summary>Accepted by EMNLP 2025 findings</details>|\n", "SEAM: Semantically Equivalent Across Modalities Benchmark for Vision-Language Models": "|**2025-8-25**|**SEAM: Semantically Equivalent Across Modalities Benchmark for Vision-Language Models**|Zhenwei Tang et.al|[paper](https://arxiv.org/abs/2508.18179)|-|<details><summary>detail</summary>COLM 2025</details>|\n", "Detecting Knowledge Boundary of Vision Large Language Models by Sampling-Based Inference": "|**2025-8-25**|**Detecting Knowledge Boundary of Vision Large Language Models by Sampling-Based Inference**|Zhuo Chen et.al|[paper](https://arxiv.org/abs/2502.18023)|[code](https://github.com/Chord-Chen-30/VLLM-KnowledgeBoundary)|<details><summary>detail</summary>EMNLP2025 Main Conference</details>|\n", "PoRe: Position-Reweighted Visual Token Pruning for Vision Language Models": "|**2025-8-25**|**PoRe: Position-Reweighted Visual Token Pruning for Vision Language Models**|Kai Zhao et.al|[paper](https://arxiv.org/abs/2508.17807)|-|-|\n", "Scaling Capability in Token Space: An Analysis of Large Vision Language Model": "|**2025-8-25**|**Scaling Capability in Token Space: An Analysis of Large Vision Language Model**|Tenghui Li et.al|[paper](https://arxiv.org/abs/2412.18387)|-|-|\n", "Seeing Sarcasm Through Different Eyes: Analyzing Multimodal Sarcasm Perception in Large Vision-Language Models": "|**2025-8-25**|**Seeing Sarcasm Through Different Eyes: Analyzing Multimodal Sarcasm Perception in Large Vision-Language Models**|Junjie Chen et.al|[paper](https://arxiv.org/abs/2503.12149)|[code](https://github.com/CoderChen01/LVLMSarcasmAnalysis)|-|\n"}}