{"source-free": {"Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation": "|**2025-11-19**|**Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation**|Yaxuan Song et.al|[paper](https://arxiv.org/abs/2402.06213)|[code](https://github.com/YXSong000/UAD.)|<details><summary>detail</summary>Accepted by ISBI 2024</details>|\n", "Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection": "|**2025-11-10**|**Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2511.07301)|-|<details><summary>detail</summary>AAAI 2026</details>|\n", "Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping": "|**2025-11-5**|**Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping**|Zhihang Qin et.al|[paper](https://arxiv.org/abs/2511.03691)|-|-|\n", "Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results": "|**2025-11-1**|**Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results**|Rohan Palanikumar et.al|[paper](https://arxiv.org/abs/2511.00752)|-|-|\n", "Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising": "|**2025-10-31**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|\n", "Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation": "|**2025-10-29**|**Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation**|Yuyang Huang et.al|[paper](https://arxiv.org/abs/2510.25279)|-|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|\n", "Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation": "|**2025-10-29**|**Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation**|Quang-Khai Bui-Tran et.al|[paper](https://arxiv.org/abs/2510.25227)|-|-|\n", "Training-free Source Attribution of AI-generated Images via Resynthesis": "|**2025-10-28**|**Training-free Source Attribution of AI-generated Images via Resynthesis**|Pietro Bongini et.al|[paper](https://arxiv.org/abs/2510.24278)|-|-|\n", "Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation": "|**2025-10-24**|**Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.22142)|-|-|\n", "Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces": "|**2025-10-22**|**Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces**|Osman Berke Guney et.al|[paper](https://arxiv.org/abs/2305.17403)|[code](https://github.com/osmanberke/SFDA-SSVEP-BCI)|-|\n", "Source-Free Object Detection with Detection Transformer": "|**2025-10-13**|**Source-Free Object Detection with Detection Transformer**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2510.11090)|-|<details><summary>detail</summary>IEEE Transactions on Image Processing</details>|\n", "Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning": "|**2025-10-9**|**Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning**|Ziqi Zhang et.al|[paper](https://arxiv.org/abs/2510.08393)|-|-|\n", "ESS-Flow: Training-free guidance of flow-based models as inference in source space": "|**2025-10-7**|**ESS-Flow: Training-free guidance of flow-based models as inference in source space**|Adhithyan Kalaivanan et.al|[paper](https://arxiv.org/abs/2510.05849)|-|-|\n", "A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation": "|**2025-10-6**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|\n", "Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection": "|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|\n"}, "object detection": {"Representation Space Constrained Learning with Modality Decoupling for Multimodal Object Detection": "|**2025-11-19**|**Representation Space Constrained Learning with Modality Decoupling for Multimodal Object Detection**|YiKang Shao et.al|[paper](https://arxiv.org/abs/2511.15433)|[code](https://github.com/yikangshao/RSC-MD.)|<details><summary>detail</summary>This work has been submitted to the IEEE for possible publication</details>|\n", "Class-Aware PillarMix: Can Mixed Sample Data Augmentation Enhance 3D Object Detection with Radar Point Clouds?": "|**2025-11-19**|**Class-Aware PillarMix: Can Mixed Sample Data Augmentation Enhance 3D Object Detection with Radar Point Clouds?**|Miao Zhang et.al|[paper](https://arxiv.org/abs/2503.02687)|[code](https://github.com/boschresearch/CAPMIX)|-|\n", "Fast Post-Hoc Confidence Fusion for 3-Class Open-Set Aerial Object Detection": "|**2025-11-19**|**Fast Post-Hoc Confidence Fusion for 3-Class Open-Set Aerial Object Detection**|Spyridon Loukovitis et.al|[paper](https://arxiv.org/abs/2511.15343)|-|-|\n", "A Multimodal Transformer Approach for UAV Detection and Aerial Object Recognition Using Radar, Audio, and Video Data": "|**2025-11-19**|**A Multimodal Transformer Approach for UAV Detection and Aerial Object Recognition Using Radar, Audio, and Video Data**|Mauro Larrat et.al|[paper](https://arxiv.org/abs/2511.15312)|-|-|\n", "Graph Query Networks for Object Detection with Automotive Radar": "|**2025-11-19**|**Graph Query Networks for Object Detection with Automotive Radar**|Loveneet Saini et.al|[paper](https://arxiv.org/abs/2511.15271)|-|<details><summary>detail</summary>Accepted in WACV 2026 Main Conference</details>|\n", "FQ-PETR: Fully Quantized Position Embedding Transformation for Multi-View 3D Object Detection": "|**2025-11-18**|**FQ-PETR: Fully Quantized Position Embedding Transformation for Multi-View 3D Object Detection**|Jiangyong Yu et.al|[paper](https://arxiv.org/abs/2502.15488)|-|<details><summary>detail</summary>This paper is acceptted by AAAI 2026</details>|\n", "Detecting Out-of-Distribution Objects through Class-Conditioned Inpainting": "|**2025-11-18**|**Detecting Out-of-Distribution Objects through Class-Conditioned Inpainting**|Quang-Huy Nguyen et.al|[paper](https://arxiv.org/abs/2402.03292)|-|<details><summary>detail</summary>Accepted in WACV 2026 (Algorithms track)</details>|\n", "Benchmarking Deep Learning-Based Object Detection Models on Feature Deficient Astrophotography Imagery Dataset": "|**2025-11-18**|**Benchmarking Deep Learning-Based Object Detection Models on Feature Deficient Astrophotography Imagery Dataset**|Shantanusinh Parmar et.al|[paper](https://arxiv.org/abs/2508.06537)|-|-|\n", "Online Data Curation for Object Detection via Marginal Contributions to Dataset-level Average Precision": "|**2025-11-18**|**Online Data Curation for Object Detection via Marginal Contributions to Dataset-level Average Precision**|Zitang Sun et.al|[paper](https://arxiv.org/abs/2511.14197)|-|<details><summary>detail</summary>preprint version</details>|\n", "YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection": "|**2025-11-18**|**YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection**|Ori Meiraz et.al|[paper](https://arxiv.org/abs/2511.13344)|-|<details><summary>detail</summary>1 figure</details>|\n", "Deep Learning and Machine Learning -- Object Detection and Semantic Segmentation: From Theory to Applications": "|**2025-11-18**|**Deep Learning and Machine Learning -- Object Detection and Semantic Segmentation: From Theory to Applications**|Jintao Ren et.al|[paper](https://arxiv.org/abs/2410.15584)|-|-|\n", "Efficient Fourier Filtering Network with Contrastive Learning for AAV-based Unaligned Bimodal Salient Object Detection": "|**2025-11-17**|**Efficient Fourier Filtering Network with Contrastive Learning for AAV-based Unaligned Bimodal Salient Object Detection**|Pengfei Lyu et.al|[paper](https://arxiv.org/abs/2411.03728)|[code](https://github.com/JoshuaLPF/AlignSal.)|<details><summary>detail</summary>Accepted by TGRS 2025</details>|\n", "Referring Camouflaged Object Detection With Multi-Context Overlapped Windows Cross-Attention": "|**2025-11-17**|**Referring Camouflaged Object Detection With Multi-Context Overlapped Windows Cross-Attention**|Yu Wen et.al|[paper](https://arxiv.org/abs/2511.13249)|-|-|\n", "Difficulty-Aware Label-Guided Denoising for Monocular 3D Object Detection": "|**2025-11-17**|**Difficulty-Aware Label-Guided Denoising for Monocular 3D Object Detection**|Soyul Lee et.al|[paper](https://arxiv.org/abs/2511.13195)|-|<details><summary>detail</summary>AAAI 2026 accepted</details>|\n", "WinMamba: Multi-Scale Shifted Windows in State Space Model for 3D Object Detection": "|**2025-11-17**|**WinMamba: Multi-Scale Shifted Windows in State Space Model for 3D Object Detection**|Longhui Zheng et.al|[paper](https://arxiv.org/abs/2511.13138)|-|-|\n"}, "domain adaptation": {"Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation": "|**2025-11-19**|**Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation**|Yaxuan Song et.al|[paper](https://arxiv.org/abs/2402.06213)|[code](https://github.com/YXSong000/UAD.)|<details><summary>detail</summary>Accepted by ISBI 2024</details>|\n", "Sim-to-real supervised domain adaptation for radioisotope identification": "|**2025-11-18**|**Sim-to-real supervised domain adaptation for radioisotope identification**|Peter Lalor et.al|[paper](https://arxiv.org/abs/2412.07069)|-|-|\n", "Hybrid-Domain Adaptative Representation Learning for Gaze Estimation": "|**2025-11-17**|**Hybrid-Domain Adaptative Representation Learning for Gaze Estimation**|Qida Tan et.al|[paper](https://arxiv.org/abs/2511.13222)|[code](https://github.com/da60266/HARL.)|<details><summary>detail</summary>AAAI2026</details>|\n", "Deep Joint Distribution Optimal Transport for Universal Domain Adaptation on Time Series": "|**2025-11-17**|**Deep Joint Distribution Optimal Transport for Universal Domain Adaptation on Time Series**|Romain Mussard et.al|[paper](https://arxiv.org/abs/2503.11217)|-|<details><summary>detail</summary>Journal ref:2025 International Joint Conference on Neural Networks (IJCNN)</details>|\n", "SpectralAdapt: Semi-Supervised Domain Adaptation with Spectral Priors for Human-Centered Hyperspectral Image Reconstruction": "|**2025-11-17**|**SpectralAdapt: Semi-Supervised Domain Adaptation with Spectral Priors for Human-Centered Hyperspectral Image Reconstruction**|Yufei Wen et.al|[paper](https://arxiv.org/abs/2511.13020)|-|-|\n", "Prompt-Driven Domain Adaptation for End-to-End Autonomous Driving via In-Context RL": "|**2025-11-16**|**Prompt-Driven Domain Adaptation for End-to-End Autonomous Driving via In-Context RL**|Aleesha Khurram et.al|[paper](https://arxiv.org/abs/2511.12755)|-|-|\n", "One Request, Multiple Experts: LLM Orchestrates Domain Specific Models via Adaptive Task Routing": "|**2025-11-16**|**One Request, Multiple Experts: LLM Orchestrates Domain Specific Models via Adaptive Task Routing**|Xu Yang et.al|[paper](https://arxiv.org/abs/2511.12484)|-|-|\n", "From IDs to Semantics: A Generative Framework for Cross-Domain Recommendation with Adaptive Semantic Tokenization": "|**2025-11-16**|**From IDs to Semantics: A Generative Framework for Cross-Domain Recommendation with Adaptive Semantic Tokenization**|Peiyu Hu et.al|[paper](https://arxiv.org/abs/2511.08006)|-|<details><summary>detail</summary>Accepted by AAAI 2026</details>|\n", "Global Variational Inference Enhanced Robust Domain Adaptation": "|**2025-11-15**|**Global Variational Inference Enhanced Robust Domain Adaptation**|Lingkun Luo et.al|[paper](https://arxiv.org/abs/2507.03291)|-|<details><summary>detail</summary>The current version has issues in experimental protocol and presentation</details>|\n", "Cross-View Cross-Modal Unsupervised Domain Adaptation for Driver Monitoring System": "|**2025-11-15**|**Cross-View Cross-Modal Unsupervised Domain Adaptation for Driver Monitoring System**|Aditi Bhalla et.al|[paper](https://arxiv.org/abs/2511.12196)|-|-|\n", "DoSReMC: Domain Shift Resilient Mammography Classification using Batch Normalization Adaptation": "|**2025-11-15**|**DoSReMC: Domain Shift Resilient Mammography Classification using Batch Normalization Adaptation**|U\u011furcan Aky\u00fcz et.al|[paper](https://arxiv.org/abs/2508.15452)|-|-|\n", "MUDAS: Mote-scale Unsupervised Domain Adaptation in Multi-label Sound Classification": "|**2025-11-14**|**MUDAS: Mote-scale Unsupervised Domain Adaptation in Multi-label Sound Classification**|Jihoon Yun et.al|[paper](https://arxiv.org/abs/2506.11331)|-|<details><summary>detail</summary>BuildSys 25</details>|\n", "Unsupervised Robust Domain Adaptation: Paradigm, Theory and Algorithm": "|**2025-11-14**|**Unsupervised Robust Domain Adaptation: Paradigm, Theory and Algorithm**|Fuxiang Huang et.al|[paper](https://arxiv.org/abs/2511.11009)|-|<details><summary>detail</summary>To appear in IJCV</details>|\n", "Provable Domain Adaptation for Offline Reinforcement Learning with Limited Samples": "|**2025-11-14**|**Provable Domain Adaptation for Offline Reinforcement Learning with Limited Samples**|Weiqin Chen et.al|[paper](https://arxiv.org/abs/2408.12136)|-|-|\n", "Text-to-SQL Domain Adaptation via Human-LLM Collaborative Data Annotation": "|**2025-11-13**|**Text-to-SQL Domain Adaptation via Human-LLM Collaborative Data Annotation**|Yuan Tian et.al|[paper](https://arxiv.org/abs/2502.15980)|[code](https://github.com/magic-YuanTian/SQLsynth.)|<details><summary>detail</summary>Accepted by IUI'25 Code & Demo: https://github</details>|\n"}, "domain generalization": {"Transferable Dual-Domain Feature Importance Attack against AI-Generated Image Detector": "|**2025-11-19**|**Transferable Dual-Domain Feature Importance Attack against AI-Generated Image Detector**|Weiheng Zhu et.al|[paper](https://arxiv.org/abs/2511.15571)|-|-|\n", "Insert In Style: A Zero-Shot Generative Framework for Harmonious Cross-Domain Object Composition": "|**2025-11-19**|**Insert In Style: A Zero-Shot Generative Framework for Harmonious Cross-Domain Object Composition**|Raghu Vamsi Chittersu et.al|[paper](https://arxiv.org/abs/2511.15197)|-|-|\n", "Generating Natural-Language Surgical Feedback: From Structured Representation to Domain-Grounded Evaluation": "|**2025-11-19**|**Generating Natural-Language Surgical Feedback: From Structured Representation to Domain-Grounded Evaluation**|Firdavs Nasriddinov et.al|[paper](https://arxiv.org/abs/2511.15159)|-|<details><summary>detail</summary>Accepted as proceedings paper for ML4H 2025</details>|\n", "Wonder3D++: Cross-domain Diffusion for High-fidelity 3D Generation from a Single Image": "|**2025-11-18**|**Wonder3D++: Cross-domain Diffusion for High-fidelity 3D Generation from a Single Image**|Yuxiao Yang et.al|[paper](https://arxiv.org/abs/2511.01767)|[code](https://github.com/xxlong0/Wonder3D/tree/Wonder3D_Plus.)|-|\n", "GEN3D: Generating Domain-Free 3D Scenes from a Single Image": "|**2025-11-18**|**GEN3D: Generating Domain-Free 3D Scenes from a Single Image**|Yuxin Zhang et.al|[paper](https://arxiv.org/abs/2511.14291)|-|-|\n", "Evolving Generalizable Parallel Algorithm Portfolios for Binary Optimization Problems via Domain-Agnostic Instance Generation": "|**2025-11-18**|**Evolving Generalizable Parallel Algorithm Portfolios for Binary Optimization Problems via Domain-Agnostic Instance Generation**|Zhiyuan Wang et.al|[paper](https://arxiv.org/abs/2501.02906)|-|-|\n", "KTester: Leveraging Domain and Testing Knowledge for More Effective LLM-based Test Generation": "|**2025-11-18**|**KTester: Leveraging Domain and Testing Knowledge for More Effective LLM-based Test Generation**|Anji Li et.al|[paper](https://arxiv.org/abs/2511.14224)|-|-|\n", "Temporal Realism Evaluation of Generated Videos Using Compressed-Domain Motion Vectors": "|**2025-11-17**|**Temporal Realism Evaluation of Generated Videos Using Compressed-Domain Motion Vectors**|Mert Onur Cakiroglu et.al|[paper](https://arxiv.org/abs/2511.13897)|[code](https://github.com/KurbanIntelligenceLab/Motion-Vector-Learning)|-|\n", "Evaluation of Domain-Specific Architectures for General-Purpose Applications in Apple Silicon": "|**2025-11-17**|**Evaluation of Domain-Specific Architectures for General-Purpose Applications in Apple Silicon**|\u00c1lvaro Corrochano L\u00f3pez et.al|[paper](https://arxiv.org/abs/2511.13450)|-|-|\n", "NeuroLex: A Lightweight Domain Language Model for EEG Report Understanding and Generation": "|**2025-11-16**|**NeuroLex: A Lightweight Domain Language Model for EEG Report Understanding and Generation**|Kang Yin et.al|[paper](https://arxiv.org/abs/2511.12851)|-|-|\n", "From IDs to Semantics: A Generative Framework for Cross-Domain Recommendation with Adaptive Semantic Tokenization": "|**2025-11-16**|**From IDs to Semantics: A Generative Framework for Cross-Domain Recommendation with Adaptive Semantic Tokenization**|Peiyu Hu et.al|[paper](https://arxiv.org/abs/2511.08006)|-|<details><summary>detail</summary>Accepted by AAAI 2026</details>|\n", "FGM optimization in complex domains using Gaussian process regression based profile generation algorithm": "|**2025-11-15**|**FGM optimization in complex domains using Gaussian process regression based profile generation algorithm**|Chaitanya Kumar Konda et.al|[paper](https://arxiv.org/abs/2511.12171)|-|-|\n", "M-DAIGT: A Shared Task on Multi-Domain Detection of AI-Generated Text": "|**2025-11-14**|**M-DAIGT: A Shared Task on Multi-Domain Detection of AI-Generated Text**|Salima Lamsiyah et.al|[paper](https://arxiv.org/abs/2511.11340)|-|-|\n", "Generalizing Analogical Inference from Boolean to Continuous Domains": "|**2025-11-13**|**Generalizing Analogical Inference from Boolean to Continuous Domains**|Francisco Cunha et.al|[paper](https://arxiv.org/abs/2511.10416)|-|-|\n", "FOUND: Fourier-based von Mises Distribution for Robust Single Domain Generalization in Object Detection": "|**2025-11-13**|**FOUND: Fourier-based von Mises Distribution for Robust Single Domain Generalization in Object Detection**|Mengzhu Wang et.al|[paper](https://arxiv.org/abs/2511.10352)|-|-|\n"}, "vision language": {"Euclid's Gift: Enhancing Spatial Perception and Reasoning in Vision-Language Models via Geometric Surrogate Tasks": "|**2025-11-19**|**Euclid's Gift: Enhancing Spatial Perception and Reasoning in Vision-Language Models via Geometric Surrogate Tasks**|Shijie Lian et.al|[paper](https://arxiv.org/abs/2509.24473)|[code](https://zgca-ai4edu.github.io/Euclids_Gift)|-|\n", "C2F-Space: Coarse-to-Fine Space Grounding for Spatial Instructions using Vision-Language Models": "|**2025-11-19**|**C2F-Space: Coarse-to-Fine Space Grounding for Spatial Instructions using Vision-Language Models**|Nayoung Oh et.al|[paper](https://arxiv.org/abs/2511.15333)|-|-|\n", "Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models": "|**2025-11-19**|**Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models**|Mehran Tamjidi et.al|[paper](https://arxiv.org/abs/2511.15311)|-|<details><summary>detail</summary>Accepted by AAAI 2026</details>|\n", "Causal Tracing of Object Representations in Large Vision Language Models: Mechanistic Interpretability and Hallucination Mitigation": "|**2025-11-19**|**Causal Tracing of Object Representations in Large Vision Language Models: Mechanistic Interpretability and Hallucination Mitigation**|Qiming Li et.al|[paper](https://arxiv.org/abs/2511.05923)|-|<details><summary>detail</summary>AAAI2026 Oral</details>|\n", "Conflict Adaptation in Vision-Language Models": "|**2025-11-18**|**Conflict Adaptation in Vision-Language Models**|Xiaoyang Hu et.al|[paper](https://arxiv.org/abs/2510.24804)|-|<details><summary>detail</summary>Workshop on Interpreting Cognition in Deep Learning Models at NeurIPS 2025</details>|\n", "Breaking Language Barriers or Reinforcing Bias? A Study of Gender and Racial Disparities in Multilingual Contrastive Vision Language Models": "|**2025-11-18**|**Breaking Language Barriers or Reinforcing Bias? A Study of Gender and Racial Disparities in Multilingual Contrastive Vision Language Models**|Zahraa Al Sahili et.al|[paper](https://arxiv.org/abs/2505.14160)|-|<details><summary>detail</summary>IJCNLP-AACL 2025</details>|\n", "Maestro: Orchestrating Robotics Modules with Vision-Language Models for Zero-Shot Generalist Robots": "|**2025-11-18**|**Maestro: Orchestrating Robotics Modules with Vision-Language Models for Zero-Shot Generalist Robots**|Junyao Shi et.al|[paper](https://arxiv.org/abs/2511.00917)|-|<details><summary>detail</summary>Plan to resubmit after significant revisions</details>|\n", "Vision Large Language Models Are Good Noise Handlers in Engagement Analysis": "|**2025-11-18**|**Vision Large Language Models Are Good Noise Handlers in Engagement Analysis**|Alexander Vedernikov et.al|[paper](https://arxiv.org/abs/2511.14749)|-|-|\n", "OG-VLA: Orthographic Image Generation for 3D-Aware Vision-Language Action Model": "|**2025-11-18**|**OG-VLA: Orthographic Image Generation for 3D-Aware Vision-Language Action Model**|Ishika Singh et.al|[paper](https://arxiv.org/abs/2506.01196)|[code](https://og-vla.github.io/)|-|\n", "GMAT: Grounded Multi-Agent Clinical Description Generation for Text Encoder in Vision-Language MIL for Whole Slide Image Classification": "|**2025-11-18**|**GMAT: Grounded Multi-Agent Clinical Description Generation for Text Encoder in Vision-Language MIL for Whole Slide Image Classification**|Ngoc Bui Lam Quang et.al|[paper](https://arxiv.org/abs/2508.01293)|-|<details><summary>detail</summary>Acccepted in MICCAI Workshop 2025</details>|\n", "NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards": "|**2025-11-18**|**NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards**|Chia-Yu Hung et.al|[paper](https://arxiv.org/abs/2511.14659)|[code](https://declare-lab.github.io/nora-1.5)|<details><summary>detail</summary>https://declare-lab</details>|\n", "Enhancing Agentic Autonomous Scientific Discovery with Vision-Language Model Capabilities": "|**2025-11-18**|**Enhancing Agentic Autonomous Scientific Discovery with Vision-Language Model Capabilities**|Kahaan Gandhi et.al|[paper](https://arxiv.org/abs/2511.14631)|[code](https://github.com/CMBAgents/cmbagent)|-|\n", "GenRecal: Generation after Recalibration from Large to Small Vision-Language Models": "|**2025-11-18**|**GenRecal: Generation after Recalibration from Large to Small Vision-Language Models**|Byung-Kwan Lee et.al|[paper](https://arxiv.org/abs/2506.15681)|[code](https://byungkwanlee.github.io/GenRecal-page/)|<details><summary>detail</summary>Project page: https://byungkwanlee</details>|\n", "Explaining Similarity in Vision-Language Encoders with Weighted Banzhaf Interactions": "|**2025-11-18**|**Explaining Similarity in Vision-Language Encoders with Weighted Banzhaf Interactions**|Hubert Baniecki et.al|[paper](https://arxiv.org/abs/2508.05430)|[code](https://github.com/hbaniecki/fixlip)|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "4D-VLA: Spatiotemporal Vision-Language-Action Pretraining with Cross-Scene Calibration": "|**2025-11-18**|**4D-VLA: Spatiotemporal Vision-Language-Action Pretraining with Cross-Scene Calibration**|Jiahui Zhang et.al|[paper](https://arxiv.org/abs/2506.22242)|-|-|\n"}}