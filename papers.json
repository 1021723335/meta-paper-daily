{"source-free": {"SfMamba: Efficient Source-Free Domain Adaptation via Selective Scan Modeling": "|**2026-1-13**|**SfMamba: Efficient Source-Free Domain Adaptation via Selective Scan Modeling**|Xi Chen et.al|[paper](https://arxiv.org/abs/2601.08608)|[code](https://github.com/chenxi52/SfMamba.)|-|\n", "Source-Free Domain Adaptation for Geospatial Point Cloud Semantic Segmentation": "|**2026-1-13**|**Source-Free Domain Adaptation for Geospatial Point Cloud Semantic Segmentation**|Yuan Gao et.al|[paper](https://arxiv.org/abs/2601.08375)|-|-|\n", "Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based Curriculum Learning": "|**2026-1-5**|**Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based Curriculum Learning**|Dongjie Chen et.al|[paper](https://arxiv.org/abs/2405.18376)|[code](https://github.com/Dong-Jie-Chen/RCL.)|-|\n", "Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results": "|**2025-12-28**|**Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results**|Rohan Palanikumar et.al|[paper](https://arxiv.org/abs/2511.00752)|-|-|\n", "Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection": "|**2025-12-24**|**Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection**|Sairam VCR et.al|[paper](https://arxiv.org/abs/2512.17514)|-|-|\n", "Exploiting Radio Frequency Fingerprints for Device Identification: Tackling Cross-receiver Challenges in the Source-data-free Scenario": "|**2025-12-18**|**Exploiting Radio Frequency Fingerprints for Device Identification: Tackling Cross-receiver Challenges in the Source-data-free Scenario**|Liu Yang et.al|[paper](https://arxiv.org/abs/2512.16648)|-|<details><summary>detail</summary>IEEE Transactions on Mobile Computing</details>|\n", "VocSim: A Training-free Benchmark for Zero-shot Content Identity in Single-source Audio": "|**2025-12-10**|**VocSim: A Training-free Benchmark for Zero-shot Content Identity in Single-source Audio**|Maris Basha et.al|[paper](https://arxiv.org/abs/2512.10120)|-|-|\n", "FedSCAl: Leveraging Server and Client Alignment for Unsupervised Federated Source-Free Domain Adaptation": "|**2025-12-7**|**FedSCAl: Leveraging Server and Client Alignment for Unsupervised Federated Source-Free Domain Adaptation**|M Yashwanth et.al|[paper](https://arxiv.org/abs/2512.06738)|-|<details><summary>detail</summary>Winter Conference on Applications of Computer Vision (WACV) 2026</details>|\n", "Source-free Video Domain Adaptation by Learning from Noisy Labels": "|**2025-11-28**|**Source-free Video Domain Adaptation by Learning from Noisy Labels**|Avijit Dasgupta et.al|[paper](https://arxiv.org/abs/2311.18572)|[code](https://avijit9.github.io/CleanAdapt.)|<details><summary>detail</summary>Our extended ICVGIP paper is now accepted in Pattern Recognition</details>|\n", "Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation": "|**2025-11-24**|**Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation**|Huisoo Lee et.al|[paper](https://arxiv.org/abs/2511.19147)|-|-|\n", "Unsupervised and Source-Free Ranking of Biomedical Segmentation Models": "|**2025-11-24**|**Unsupervised and Source-Free Ranking of Biomedical Segmentation Models**|Joshua Talks et.al|[paper](https://arxiv.org/abs/2503.00450)|-|-|\n", "SloMo-Fast: Slow-Momentum and Fast-Adaptive Teachers for Source-Free Continual Test-Time Adaptation": "|**2025-11-23**|**SloMo-Fast: Slow-Momentum and Fast-Adaptive Teachers for Source-Free Continual Test-Time Adaptation**|Md Akil Raihan Iftee et.al|[paper](https://arxiv.org/abs/2511.18468)|-|-|\n", "ViMix-14M: A Curated Multi-Source Video-Text Dataset with Long-Form, High-Quality Captions and Crawl-Free Access": "|**2025-11-23**|**ViMix-14M: A Curated Multi-Source Video-Text Dataset with Long-Form, High-Quality Captions and Crawl-Free Access**|Timing Yang et.al|[paper](https://arxiv.org/abs/2511.18382)|-|-|\n", "HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for Cross-Modality Medical Image Segmentation": "|**2025-11-22**|**HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for Cross-Modality Medical Image Segmentation**|Yulong Shi et.al|[paper](https://arxiv.org/abs/2511.17958)|[code](https://github.com/derekshiii/HEAL.)|<details><summary>detail</summary>Accepted by The 36th British Machine Vision Conference (BMVC 2025)</details>|\n", "Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation": "|**2025-11-19**|**Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation**|Yaxuan Song et.al|[paper](https://arxiv.org/abs/2402.06213)|[code](https://github.com/YXSong000/UAD.)|<details><summary>detail</summary>Accepted by ISBI 2024</details>|\n"}, "object detection": {"MSSF: A 4D Radar and Camera Fusion Framework With Multi-Stage Sampling for 3D Object Detection in Autonomous Driving": "|**2026-1-13**|**MSSF: A 4D Radar and Camera Fusion Framework With Multi-Stage Sampling for 3D Object Detection in Autonomous Driving**|Hongsi Liu et.al|[paper](https://arxiv.org/abs/2411.15016)|-|<details><summary>detail</summary>T-TITS accepted</details>|\n", "REXO: Indoor Multi-View Radar Object Detection via 3D Bounding Box Diffusion": "|**2026-1-12**|**REXO: Indoor Multi-View Radar Object Detection via 3D Bounding Box Diffusion**|Ryoma Yataka et.al|[paper](https://arxiv.org/abs/2511.17806)|[code](https://github.com/merlresearch/radar-bbox-diffusion.)|-|\n", "GenDet: Painting Colored Bounding Boxes on Images via Diffusion Model for Object Detection": "|**2026-1-12**|**GenDet: Painting Colored Bounding Boxes on Images via Diffusion Model for Object Detection**|Chen Min et.al|[paper](https://arxiv.org/abs/2601.07273)|-|-|\n", "SC-MII: Infrastructure LiDAR-based 3D Object Detection on Edge Devices for Split Computing with Multiple Intermediate Outputs Integration": "|**2026-1-11**|**SC-MII: Infrastructure LiDAR-based 3D Object Detection on Edge Devices for Split Computing with Multiple Intermediate Outputs Integration**|Taisuke Noguchi et.al|[paper](https://arxiv.org/abs/2601.07119)|-|-|\n", "SpecDETR: A transformer-based hyperspectral point object detection network": "|**2026-1-9**|**SpecDETR: A transformer-based hyperspectral point object detection network**|Zhaoxu Li et.al|[paper](https://arxiv.org/abs/2405.10148)|[code](https://github.com/ZhaoxuLi123/SpecDETR.)|<details><summary>detail</summary>Journal ref:ISPRS Journal of Photogrammetry and Remote Sensing</details>|\n", "STResNet & STYOLO : A New Family of Compact Classification and Object Detection Models for MCUs": "|**2026-1-8**|**STResNet & STYOLO : A New Family of Compact Classification and Object Detection Models for MCUs**|Sudhakar Sah et.al|[paper](https://arxiv.org/abs/2601.05364)|-|-|\n", "From Dataset to Real-world: General 3D Object Detection via Generalized Cross-domain Few-shot Learning": "|**2026-1-7**|**From Dataset to Real-world: General 3D Object Detection via Generalized Cross-domain Few-shot Learning**|Shuangzhi Li et.al|[paper](https://arxiv.org/abs/2503.06282)|-|<details><summary>detail</summary>The latest version refines the few-shot setting on common classes</details>|\n", "Few-Shot LoRA Adaptation of a Flow-Matching Foundation Model for Cross-Spectral Object Detection": "|**2026-1-7**|**Few-Shot LoRA Adaptation of a Flow-Matching Foundation Model for Cross-Spectral Object Detection**|Maxim Clouser et.al|[paper](https://arxiv.org/abs/2601.04381)|-|-|\n", "SortWaste: A Densely Annotated Dataset for Object Detection in Industrial Waste Sorting": "|**2026-1-7**|**SortWaste: A Densely Annotated Dataset for Object Detection in Industrial Waste Sorting**|Sara In\u00e1cio et.al|[paper](https://arxiv.org/abs/2601.02299)|-|-|\n", "Correcting Autonomous Driving Object Detection Misclassifications with Automated Commonsense Reasoning": "|**2026-1-7**|**Correcting Autonomous Driving Object Detection Misclassifications with Automated Commonsense Reasoning**|Keegan Kimbrell et.al|[paper](https://arxiv.org/abs/2601.04271)|-|<details><summary>detail</summary>In Proceedings ICLP 2025</details>|\n", "HyperCOD: The First Challenging Benchmark and Baseline for Hyperspectral Camouflaged Object Detection": "|**2026-1-7**|**HyperCOD: The First Challenging Benchmark and Baseline for Hyperspectral Camouflaged Object Detection**|Shuyan Bai et.al|[paper](https://arxiv.org/abs/2601.03736)|-|-|\n", "D^3ETOR: Debate-Enhanced Pseudo Labeling and Frequency-Aware Progressive Debiasing for Weakly-Supervised Camouflaged Object Detection with Scribble Annotations": "|**2026-1-6**|**D^3ETOR: Debate-Enhanced Pseudo Labeling and Frequency-Aware Progressive Debiasing for Weakly-Supervised Camouflaged Object Detection with Scribble Annotations**|Jiawei Ge et.al|[paper](https://arxiv.org/abs/2512.20260)|-|-|\n", "Towards Efficient 3D Object Detection for Vehicle-Infrastructure Collaboration via Risk-Intent Selection": "|**2026-1-6**|**Towards Efficient 3D Object Detection for Vehicle-Infrastructure Collaboration via Risk-Intent Selection**|Li Wang et.al|[paper](https://arxiv.org/abs/2601.03001)|-|-|\n", "DGA-Net: Enhancing SAM with Depth Prompting and Graph-Anchor Guidance for Camouflaged Object Detection": "|**2026-1-6**|**DGA-Net: Enhancing SAM with Depth Prompting and Graph-Anchor Guidance for Camouflaged Object Detection**|Yuetong Li et.al|[paper](https://arxiv.org/abs/2601.02831)|-|-|\n", "D$^3$R-DETR: DETR with Dual-Domain Density Refinement for Tiny Object Detection in Aerial Images": "|**2026-1-6**|**D$^3$R-DETR: DETR with Dual-Domain Density Refinement for Tiny Object Detection in Aerial Images**|Zixiao Wen et.al|[paper](https://arxiv.org/abs/2601.02747)|-|<details><summary>detail</summary>This work has been submitted to the IEEE for possible publication</details>|\n"}, "domain adaptation": {"ISLA: A U-Net for MRI-based acute ischemic stroke lesion segmentation with deep supervision, attention, domain adaptation, and ensemble learning": "|**2026-1-13**|**ISLA: A U-Net for MRI-based acute ischemic stroke lesion segmentation with deep supervision, attention, domain adaptation, and ensemble learning**|Vincent Roca et.al|[paper](https://arxiv.org/abs/2601.08732)|-|-|\n", "SfMamba: Efficient Source-Free Domain Adaptation via Selective Scan Modeling": "|**2026-1-13**|**SfMamba: Efficient Source-Free Domain Adaptation via Selective Scan Modeling**|Xi Chen et.al|[paper](https://arxiv.org/abs/2601.08608)|[code](https://github.com/chenxi52/SfMamba.)|-|\n", "YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation": "|**2026-1-13**|**YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation**|Abdelaziz Bounhar et.al|[paper](https://arxiv.org/abs/2601.08441)|[code](https://github.com/MBZUAI-Paris/YaPO)|-|\n", "Source-Free Domain Adaptation for Geospatial Point Cloud Semantic Segmentation": "|**2026-1-13**|**Source-Free Domain Adaptation for Geospatial Point Cloud Semantic Segmentation**|Yuan Gao et.al|[paper](https://arxiv.org/abs/2601.08375)|-|-|\n", "Towards Cross-Platform Generalization: Domain Adaptive 3D Detection with Augmentation and Pseudo-Labeling": "|**2026-1-12**|**Towards Cross-Platform Generalization: Domain Adaptive 3D Detection with Augmentation and Pseudo-Labeling**|Xiyan Feng et.al|[paper](https://arxiv.org/abs/2601.08174)|-|-|\n", "Towards Specialized Generalists: A Multi-Task MoE-LoRA Framework for Domain-Specific LLM Adaptation": "|**2026-1-12**|**Towards Specialized Generalists: A Multi-Task MoE-LoRA Framework for Domain-Specific LLM Adaptation**|Yuxin Yang et.al|[paper](https://arxiv.org/abs/2601.07935)|-|<details><summary>detail</summary>Work in Progress</details>|\n", "Improving Domain Generalization in Contrastive Learning using Adaptive Temperature Control": "|**2026-1-12**|**Improving Domain Generalization in Contrastive Learning using Adaptive Temperature Control**|Robert Lewis et.al|[paper](https://arxiv.org/abs/2601.07748)|-|<details><summary>detail</summary>NeurIPS SSL Workshop 2023</details>|\n", "Unsupervised Domain Adaptation with SAM-RefiSeR for Enhanced Brain Tumor Segmentation": "|**2026-1-11**|**Unsupervised Domain Adaptation with SAM-RefiSeR for Enhanced Brain Tumor Segmentation**|Dillan Imans et.al|[paper](https://arxiv.org/abs/2601.06882)|-|<details><summary>detail</summary>Accepted in BIBM 2025</details>|\n", "Unsupervised Domain Adaptation for Binary Classification with an Unobservable Source Subpopulation": "|**2026-1-9**|**Unsupervised Domain Adaptation for Binary Classification with an Unobservable Source Subpopulation**|Chao Ying et.al|[paper](https://arxiv.org/abs/2509.20587)|-|-|\n", "LELA: an LLM-based Entity Linking Approach with Zero-Shot Domain Adaptation": "|**2026-1-8**|**LELA: an LLM-based Entity Linking Approach with Zero-Shot Domain Adaptation**|Samy Haffoudhi et.al|[paper](https://arxiv.org/abs/2601.05192)|-|-|\n", "Towards Real-world Lens Active Alignment with Unlabeled Data via Domain Adaptation": "|**2026-1-7**|**Towards Real-world Lens Active Alignment with Unlabeled Data via Domain Adaptation**|Wenyong Li et.al|[paper](https://arxiv.org/abs/2601.03718)|-|-|\n", "Causally-Aware Information Bottleneck for Domain Adaptation": "|**2026-1-7**|**Causally-Aware Information Bottleneck for Domain Adaptation**|Mohammad Ali Javidian et.al|[paper](https://arxiv.org/abs/2601.04361)|-|<details><summary>detail</summary>An extended abstract version of this work was accepted for the Proceedings of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)</details>|\n", "Domain Adaptation of the Pyannote Diarization Pipeline for Conversational Indonesian Audio": "|**2026-1-7**|**Domain Adaptation of the Pyannote Diarization Pipeline for Conversational Indonesian Audio**|Muhammad Daffa'i Rafi Prasetyo et.al|[paper](https://arxiv.org/abs/2601.03684)|-|<details><summary>detail</summary>Experiments conducted using synthetic Indonesian conversational speech for domain adaptation</details>|\n", "An Expectation-Maximization Algorithm for Domain Adaptation in Gaussian Causal Models": "|**2026-1-6**|**An Expectation-Maximization Algorithm for Domain Adaptation in Gaussian Causal Models**|Mohammad Ali Javidian et.al|[paper](https://arxiv.org/abs/2601.03459)|-|<details><summary>detail</summary>An earlier version of this work was accepted for the Proceedings of the 2025 IEEE International Conference on Data Mining (ICDM)</details>|\n", "Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based Curriculum Learning": "|**2026-1-5**|**Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based Curriculum Learning**|Dongjie Chen et.al|[paper](https://arxiv.org/abs/2405.18376)|[code](https://github.com/Dong-Jie-Chen/RCL.)|-|\n"}, "domain generalization": {"Creativity in AI as Emergence from Domain-Limited Generative Models": "|**2026-1-13**|**Creativity in AI as Emergence from Domain-Limited Generative Models**|Corina Chutaux et.al|[paper](https://arxiv.org/abs/2601.08388)|-|-|\n", "Towards Cross-Platform Generalization: Domain Adaptive 3D Detection with Augmentation and Pseudo-Labeling": "|**2026-1-12**|**Towards Cross-Platform Generalization: Domain Adaptive 3D Detection with Augmentation and Pseudo-Labeling**|Xiyan Feng et.al|[paper](https://arxiv.org/abs/2601.08174)|-|-|\n", "Generalization Analysis and Method for Domain Generalization for a Family of Recurrent Neural Networks": "|**2026-1-12**|**Generalization Analysis and Method for Domain Generalization for a Family of Recurrent Neural Networks**|Atefeh Termehchi et.al|[paper](https://arxiv.org/abs/2601.08122)|-|-|\n", "From Prompts to Deployment: Auto-Curated Domain-Specific Dataset Generation via Diffusion Models": "|**2026-1-12**|**From Prompts to Deployment: Auto-Curated Domain-Specific Dataset Generation via Diffusion Models**|Dongsik Yoon et.al|[paper](https://arxiv.org/abs/2601.08095)|-|<details><summary>detail</summary>To appear in the Workshop on Synthetic & Adversarial ForEnsics (SAFE)</details>|\n", "Improving Domain Generalization in Contrastive Learning using Adaptive Temperature Control": "|**2026-1-12**|**Improving Domain Generalization in Contrastive Learning using Adaptive Temperature Control**|Robert Lewis et.al|[paper](https://arxiv.org/abs/2601.07748)|-|<details><summary>detail</summary>NeurIPS SSL Workshop 2023</details>|\n", "Lexicalized Constituency Parsing for Middle Dutch: Low-resource Training and Cross-Domain Generalization": "|**2026-1-11**|**Lexicalized Constituency Parsing for Middle Dutch: Low-resource Training and Cross-Domain Generalization**|Yiming Liang et.al|[paper](https://arxiv.org/abs/2601.07008)|-|-|\n", "CyberLLM-FINDS 2025: Instruction-Tuned Fine-tuning of Domain-Specific LLMs with Retrieval-Augmented Generation and Graph Integration for MITRE Evaluation": "|**2026-1-11**|**CyberLLM-FINDS 2025: Instruction-Tuned Fine-tuning of Domain-Specific LLMs with Retrieval-Augmented Generation and Graph Integration for MITRE Evaluation**|Vasanth Iyer et.al|[paper](https://arxiv.org/abs/2601.06779)|-|-|\n", "Multi-Modal Style Transfer-based Prompt Tuning for Efficient Federated Domain Generalization": "|**2026-1-9**|**Multi-Modal Style Transfer-based Prompt Tuning for Efficient Federated Domain Generalization**|Yuliang Chen et.al|[paper](https://arxiv.org/abs/2601.05955)|-|-|\n", "Higher-Order Domain Generalization in Magnetic Resonance-Based Assessment of Alzheimer's Disease": "|**2026-1-9**|**Higher-Order Domain Generalization in Magnetic Resonance-Based Assessment of Alzheimer's Disease**|Zobia Batool et.al|[paper](https://arxiv.org/abs/2601.01485)|[code](https://github.com/zobia111/Extended-Mixstyle.)|-|\n", "WaveRNet: Wavelet-Guided Frequency Learning for Multi-Source Domain-Generalized Retinal Vessel Segmentation": "|**2026-1-9**|**WaveRNet: Wavelet-Guided Frequency Learning for Multi-Source Domain-Generalized Retinal Vessel Segmentation**|Chanchan Wang et.al|[paper](https://arxiv.org/abs/2601.05942)|[code](https://github.com/Chanchan-Wang/WaveRNet.)|-|\n", "An Empirical Study on Preference Tuning Generalization and Diversity Under Domain Shift": "|**2026-1-9**|**An Empirical Study on Preference Tuning Generalization and Diversity Under Domain Shift**|Constantinos Karouzos et.al|[paper](https://arxiv.org/abs/2601.05882)|-|-|\n", "Learning from Mistakes: Negative Reasoning Samples Enhance Out-of-Domain Generalization": "|**2026-1-8**|**Learning from Mistakes: Negative Reasoning Samples Enhance Out-of-Domain Generalization**|Xueyun Tian et.al|[paper](https://arxiv.org/abs/2601.04992)|[code](https://github.com/Eureka-Maggie/GLOW)|<details><summary>detail</summary>Code and data are available at https://github</details>|\n", "RiskAtlas: Exposing Domain-Specific Risks in LLMs through Knowledge-Graph-Guided Harmful Prompt Generation": "|**2026-1-8**|**RiskAtlas: Exposing Domain-Specific Risks in LLMs through Knowledge-Graph-Guided Harmful Prompt Generation**|Huawei Zheng et.al|[paper](https://arxiv.org/abs/2601.04740)|-|-|\n", "From Dataset to Real-world: General 3D Object Detection via Generalized Cross-domain Few-shot Learning": "|**2026-1-7**|**From Dataset to Real-world: General 3D Object Detection via Generalized Cross-domain Few-shot Learning**|Shuangzhi Li et.al|[paper](https://arxiv.org/abs/2503.06282)|-|<details><summary>detail</summary>The latest version refines the few-shot setting on common classes</details>|\n", "Complex Domain Approach for Reversible Data Hiding and Homomorphic Encryption: General Framework and Application to Dispersed Data": "|**2026-1-7**|**Complex Domain Approach for Reversible Data Hiding and Homomorphic Encryption: General Framework and Application to Dispersed Data**|David Megias et.al|[paper](https://arxiv.org/abs/2510.03770)|-|-|\n"}, "vision language": {"Cascading multi-agent anomaly detection in surveillance systems via vision-language models and embedding-based classification": "|**2026-1-13**|**Cascading multi-agent anomaly detection in surveillance systems via vision-language models and embedding-based classification**|Tayyab Rehman et.al|[paper](https://arxiv.org/abs/2601.06204)|-|<details><summary>detail</summary>Author email changed</details>|\n", "DriveRX: A Vision-Language Reasoning Model for Cross-Task Autonomous Driving": "|**2026-1-13**|**DriveRX: A Vision-Language Reasoning Model for Cross-Task Autonomous Driving**|Muxi Diao et.al|[paper](https://arxiv.org/abs/2505.20665)|-|-|\n", "Cross-modal Proxy Evolving for OOD Detection with Vision-Language Models": "|**2026-1-13**|**Cross-modal Proxy Evolving for OOD Detection with Vision-Language Models**|Hao Tang et.al|[paper](https://arxiv.org/abs/2601.08476)|-|<details><summary>detail</summary>Accepted by AAAI 2026</details>|\n", "ClimateIQA: A New Dataset and Benchmark to Advance Vision-Language Models in Meteorology Anomalies Analysis": "|**2026-1-13**|**ClimateIQA: A New Dataset and Benchmark to Advance Vision-Language Models in Meteorology Anomalies Analysis**|Jian Chen et.al|[paper](https://arxiv.org/abs/2406.09838)|-|-|\n", "Zero-Shot Distracted Driver Detection via Vision Language Models with Double Decoupling": "|**2026-1-13**|**Zero-Shot Distracted Driver Detection via Vision Language Models with Double Decoupling**|Takamichi Miyata et.al|[paper](https://arxiv.org/abs/2601.08467)|-|-|\n", "CoMa: Contextual Massing Generation with Vision-Language Models": "|**2026-1-13**|**CoMa: Contextual Massing Generation with Vision-Language Models**|Evgenii Maslov et.al|[paper](https://arxiv.org/abs/2601.08464)|-|<details><summary>detail</summary>Code and dataset will be released later</details>|\n", "Semantic Misalignment in Vision-Language Models under Perceptual Degradation": "|**2026-1-13**|**Semantic Misalignment in Vision-Language Models under Perceptual Degradation**|Guo Cheng et.al|[paper](https://arxiv.org/abs/2601.08355)|-|-|\n", "ActiveVLA: Injecting Active Perception into Vision-Language-Action Models for Precise 3D Robotic Manipulation": "|**2026-1-13**|**ActiveVLA: Injecting Active Perception into Vision-Language-Action Models for Precise 3D Robotic Manipulation**|Zhenyang Liu et.al|[paper](https://arxiv.org/abs/2601.08325)|-|-|\n", "Global Compression Commander: Plug-and-Play Inference Acceleration for High-Resolution Large Vision-Language Models": "|**2026-1-13**|**Global Compression Commander: Plug-and-Play Inference Acceleration for High-Resolution Large Vision-Language Models**|Xuyang Liu et.al|[paper](https://arxiv.org/abs/2501.05179)|[code](https://github.com/xuyang-liu16/GlobalCom2)|<details><summary>detail</summary>Accepted by AAAI 2026</details>|\n", "Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems": "|**2026-1-13**|**Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems**|YuChe Hsu et.al|[paper](https://arxiv.org/abs/2512.20387)|[code](https://danielhsu2014.github.io/GDT-VLSM-project/)|-|\n", "Where Does Vision Meet Language? Understanding and Refining Visual Fusion in MLLMs via Contrastive Attention": "|**2026-1-12**|**Where Does Vision Meet Language? Understanding and Refining Visual Fusion in MLLMs via Contrastive Attention**|Shezheng Song et.al|[paper](https://arxiv.org/abs/2601.08151)|-|-|\n", "Subspace Alignment for Vision-Language Model Test-time Adaptation": "|**2026-1-12**|**Subspace Alignment for Vision-Language Model Test-time Adaptation**|Zhichen Zeng et.al|[paper](https://arxiv.org/abs/2601.08139)|-|-|\n", "Rescind: Countering Image Misconduct in Biomedical Publications with Vision-Language and State-Space Modeling": "|**2026-1-12**|**Rescind: Countering Image Misconduct in Biomedical Publications with Vision-Language and State-Space Modeling**|Soumyaroop Nandi et.al|[paper](https://arxiv.org/abs/2601.08040)|-|-|\n", "Token Reduction Should Go Beyond Efficiency in Generative Models -- From Vision, Language to Multimodality": "|**2026-1-12**|**Token Reduction Should Go Beyond Efficiency in Generative Models -- From Vision, Language to Multimodality**|Zhenglun Kong et.al|[paper](https://arxiv.org/abs/2505.18227)|[code](https://github.com/ZLKong/Awesome-Collection-Token-Reduction)|<details><summary>detail</summary>Project page: https://github</details>|\n", "VULCA-Bench: A Multicultural Vision-Language Benchmark for Evaluating Cultural Understanding": "|**2026-1-12**|**VULCA-Bench: A Multicultural Vision-Language Benchmark for Evaluating Cultural Understanding**|Haorui Yu et.al|[paper](https://arxiv.org/abs/2601.07986)|-|-|\n"}}