{"source-free": {"Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation": "|**2025-10-24**|**Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.22142)|-|-|\n", "Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces": "|**2025-10-22**|**Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces**|Osman Berke Guney et.al|[paper](https://arxiv.org/abs/2305.17403)|[code](https://github.com/osmanberke/SFDA-SSVEP-BCI)|-|\n", "Source-Free Object Detection with Detection Transformer": "|**2025-10-13**|**Source-Free Object Detection with Detection Transformer**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2510.11090)|-|<details><summary>detail</summary>IEEE Transactions on Image Processing</details>|\n", "Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning": "|**2025-10-9**|**Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning**|Ziqi Zhang et.al|[paper](https://arxiv.org/abs/2510.08393)|-|-|\n", "ESS-Flow: Training-free guidance of flow-based models as inference in source space": "|**2025-10-7**|**ESS-Flow: Training-free guidance of flow-based models as inference in source space**|Adhithyan Kalaivanan et.al|[paper](https://arxiv.org/abs/2510.05849)|-|-|\n", "Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising": "|**2025-10-7**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|\n", "A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation": "|**2025-10-6**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|\n", "Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection": "|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|\n", "Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation": "|**2025-10-3**|**Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation**|Yucheng Wang et.al|[paper](https://arxiv.org/abs/2409.19635)|-|-|\n", "OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation": "|**2025-10-2**|**OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation**|Yiming Zhang et.al|[paper](https://arxiv.org/abs/2505.11669)|-|-|\n", "Source-Free Cross-Domain Continual Learning": "|**2025-10-2**|**Source-Free Cross-Domain Continual Learning**|Muhammad Tanzil Furqon et.al|[paper](https://arxiv.org/abs/2510.01649)|-|-|\n", "Consistent Assistant Domains Transformer for Source-free Domain Adaptation": "|**2025-10-1**|**Consistent Assistant Domains Transformer for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.01559)|[code](https://github.com/RoryShao/CADTrans.git.)|-|\n", "Source-Free Domain Adaptive Object Detection with Semantics Compensation": "|**2025-9-30**|**Source-Free Domain Adaptive Object Detection with Semantics Compensation**|Song Tang et.al|[paper](https://arxiv.org/abs/2410.05557)|-|-|\n", "DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation": "|**2025-9-29**|**DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation**|Xi Chen et.al|[paper](https://arxiv.org/abs/2509.24896)|-|-|\n", "Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation": "|**2025-9-29**|**Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|\n"}, "object detection": {"AG-Fusion: adaptive gated multimodal fusion for 3d object detection in complex scenes": "|**2025-10-27**|**AG-Fusion: adaptive gated multimodal fusion for 3d object detection in complex scenes**|Sixian Liu et.al|[paper](https://arxiv.org/abs/2510.23151)|-|-|\n", "DQ3D: Depth-guided Query for Transformer-Based 3D Object Detection in Traffic Scenarios": "|**2025-10-27**|**DQ3D: Depth-guided Query for Transformer-Based 3D Object Detection in Traffic Scenarios**|Ziyu Wang et.al|[paper](https://arxiv.org/abs/2510.23144)|-|-|\n", "3D Roadway Scene Object Detection with LIDARs in Snowfall Conditions": "|**2025-10-25**|**3D Roadway Scene Object Detection with LIDARs in Snowfall Conditions**|Ghazal Farhani et.al|[paper](https://arxiv.org/abs/2510.22436)|-|<details><summary>detail</summary>2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC)</details>|\n", "S3OD: Towards Generalizable Salient Object Detection with Synthetic Data": "|**2025-10-24**|**S3OD: Towards Generalizable Salient Object Detection with Synthetic Data**|Orest Kupyn et.al|[paper](https://arxiv.org/abs/2510.21605)|-|-|\n", "LEGNet: A Lightweight Edge-Gaussian Network for Low-Quality Remote Sensing Image Object Detection": "|**2025-10-24**|**LEGNet: A Lightweight Edge-Gaussian Network for Low-Quality Remote Sensing Image Object Detection**|Wei Lu et.al|[paper](https://arxiv.org/abs/2503.14012)|[code](https://github.com/AeroVILab-AHU/LEGNet.)|-|\n", "BioDet: Boosting Industrial Object Detection with Image Preprocessing Strategies": "|**2025-10-23**|**BioDet: Boosting Industrial Object Detection with Image Preprocessing Strategies**|Jiaqi Hu et.al|[paper](https://arxiv.org/abs/2510.21000)|-|-|\n", "Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection": "|**2025-10-23**|**Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection**|Talha Ilyas et.al|[paper](https://arxiv.org/abs/2510.20214)|-|<details><summary>detail</summary>This is the preprint version of the manuscript submitted to IEEE Journal of Biomedical and Health Informatics (JBHI) for review</details>|\n", "Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models": "|**2025-10-22**|**Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models**|Peter Robicheaux et.al|[paper](https://arxiv.org/abs/2505.20612)|[code](https://github.com/roboflow/rf100-vl)|<details><summary>detail</summary>The first two authors contributed equally</details>|\n", "A Unified Detection Pipeline for Robust Object Detection in Fisheye-Based Traffic Surveillance": "|**2025-10-22**|**A Unified Detection Pipeline for Robust Object Detection in Fisheye-Based Traffic Surveillance**|Neema Jakisa Owor et.al|[paper](https://arxiv.org/abs/2510.20016)|-|<details><summary>detail</summary>The paper was accepted at ICCV 2025 and published in CVF database</details>|\n", "Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR": "|**2025-10-22**|**Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR**|Adwait Chandorkar et.al|[paper](https://arxiv.org/abs/2508.00744)|-|<details><summary>detail</summary>Best Paper Award at the Embedded Vision Workshop ICCV 2025</details>|\n", "Can You Trust What You See? Alpha Channel No-Box Attacks on Video Object Detection": "|**2025-10-22**|**Can You Trust What You See? Alpha Channel No-Box Attacks on Video Object Detection**|Ariana Yi et.al|[paper](https://arxiv.org/abs/2510.19574)|-|-|\n", "Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts": "|**2025-10-22**|**Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts**|Chen Li et.al|[paper](https://arxiv.org/abs/2510.19487)|-|-|\n", "DitHub: A Modular Framework for Incremental Open-Vocabulary Object Detection": "|**2025-10-22**|**DitHub: A Modular Framework for Incremental Open-Vocabulary Object Detection**|Chiara Cappellino et.al|[paper](https://arxiv.org/abs/2503.09271)|[code](https://aimagelab.github.io/DitHub/)|<details><summary>detail</summary>the 39th Conference on Neural Information Processing Systems (NeurIPS 2025)</details>|\n", "Space Object Detection using Multi-frame Temporal Trajectory Completion Method": "|**2025-10-22**|**Space Object Detection using Multi-frame Temporal Trajectory Completion Method**|Xiaoqing Lan et.al|[paper](https://arxiv.org/abs/2510.19220)|-|-|\n", "SFGFusion: Surface Fitting Guided 3D Object Detection with 4D Radar and Camera Fusion": "|**2025-10-21**|**SFGFusion: Surface Fitting Guided 3D Object Detection with 4D Radar and Camera Fusion**|Xiaozhi Li et.al|[paper](https://arxiv.org/abs/2510.19215)|-|<details><summary>detail</summary>Submitted to Pattern Recognition</details>|\n"}, "domain adaptation": {"DPGLA: Bridging the Gap between Synthetic and Real Data for Unsupervised Domain Adaptation in 3D LiDAR Semantic Segmentation": "|**2025-10-27**|**DPGLA: Bridging the Gap between Synthetic and Real Data for Unsupervised Domain Adaptation in 3D LiDAR Semantic Segmentation**|Wanmeng Li et.al|[paper](https://arxiv.org/abs/2510.23525)|-|<details><summary>detail</summary>This paper has been accepted for publication at the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</details>|\n", "PTPP-Aware Adaptation Scaling Laws: Predicting Domain-Adaptation Performance at Unseen Pre-Training Budgets": "|**2025-10-27**|**PTPP-Aware Adaptation Scaling Laws: Predicting Domain-Adaptation Performance at Unseen Pre-Training Budgets**|Etienne Goffinet et.al|[paper](https://arxiv.org/abs/2510.23198)|-|-|\n", "DeepSalt: Bridging Laboratory and Satellite Spectra through Domain Adaptation and Knowledge Distillation for Large-Scale Soil Salinity Estimation": "|**2025-10-27**|**DeepSalt: Bridging Laboratory and Satellite Spectra through Domain Adaptation and Knowledge Distillation for Large-Scale Soil Salinity Estimation**|Rupasree Dey et.al|[paper](https://arxiv.org/abs/2510.23124)|-|-|\n", "Progressive Multi-Source Domain Adaptation for Personalized Facial Expression Recognition": "|**2025-10-26**|**Progressive Multi-Source Domain Adaptation for Personalized Facial Expression Recognition**|Muhammad Osama Zeeshan et.al|[paper](https://arxiv.org/abs/2504.04252)|-|<details><summary>detail</summary>Transactions on Affective Computing 2025</details>|\n", "GALA: A GlobAl-LocAl Approach for Multi-Source Active Domain Adaptation": "|**2025-10-25**|**GALA: A GlobAl-LocAl Approach for Multi-Source Active Domain Adaptation**|Juepeng Zheng et.al|[paper](https://arxiv.org/abs/2510.22214)|-|-|\n", "Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation": "|**2025-10-24**|**Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.22142)|-|-|\n", "DAP-MAE: Domain-Adaptive Point Cloud Masked Autoencoder for Effective Cross-Domain Learning": "|**2025-10-24**|**DAP-MAE: Domain-Adaptive Point Cloud Masked Autoencoder for Effective Cross-Domain Learning**|Ziqi Gao et.al|[paper](https://arxiv.org/abs/2510.21635)|-|-|\n", "Video-Skill-CoT: Skill-based Chain-of-Thoughts for Domain-Adaptive Video Reasoning": "|**2025-10-24**|**Video-Skill-CoT: Skill-based Chain-of-Thoughts for Domain-Adaptive Video Reasoning**|Daeun Lee et.al|[paper](https://arxiv.org/abs/2506.03525)|[code](https://video-skill-cot.github.io/)|<details><summary>detail</summary>Project website: https://video-skill-cot</details>|\n", "Domain Adaptation-based Edge Computing for Cross-Conditions Fault Diagnosis": "|**2025-10-24**|**Domain Adaptation-based Edge Computing for Cross-Conditions Fault Diagnosis**|Yanzhi Wang et.al|[paper](https://arxiv.org/abs/2411.10340)|-|-|\n", "PINN Balls: Scaling Second-Order Methods for PINNs with Domain Decomposition and Adaptive Sampling": "|**2025-10-24**|**PINN Balls: Scaling Second-Order Methods for PINNs with Domain Decomposition and Adaptive Sampling**|Andrea Bonfanti et.al|[paper](https://arxiv.org/abs/2510.21262)|-|<details><summary>detail</summary>Accepted Conference Paper</details>|\n", "RT-DATR: Real-time Unsupervised Domain Adaptive Detection Transformer with Adversarial Feature Alignment": "|**2025-10-24**|**RT-DATR: Real-time Unsupervised Domain Adaptive Detection Transformer with Adversarial Feature Alignment**|Feng Lv et.al|[paper](https://arxiv.org/abs/2504.09196)|[code](https://github.com/Jeremy-lf/RT-DATR.)|-|\n", "How to Auto-optimize Prompts for Domain Tasks? Adaptive Prompting and Reasoning through Evolutionary Domain Knowledge Adaptation": "|**2025-10-24**|**How to Auto-optimize Prompts for Domain Tasks? Adaptive Prompting and Reasoning through Evolutionary Domain Knowledge Adaptation**|Yang Zhao et.al|[paper](https://arxiv.org/abs/2510.21148)|-|-|\n", "Graph Data Selection for Domain Adaptation: A Model-Free Approach": "|**2025-10-23**|**Graph Data Selection for Domain Adaptation: A Model-Free Approach**|Ting-Wei Li et.al|[paper](https://arxiv.org/abs/2505.17293)|-|-|\n", "Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation": "|**2025-10-23**|**Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation**|Ziyu Ye et.al|[paper](https://arxiv.org/abs/2510.20596)|-|<details><summary>detail</summary>MICCAI 2021</details>|\n", "IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation": "|**2025-10-23**|**IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation**|Tianyi Zhang et.al|[paper](https://arxiv.org/abs/2510.20377)|-|-|\n"}, "domain generalization": {"Robust Atypical Mitosis Classification with DenseNet121: Stain-Aware Augmentation and Hybrid Loss for Domain Generalization": "|**2025-10-26**|**Robust Atypical Mitosis Classification with DenseNet121: Stain-Aware Augmentation and Hybrid Loss for Domain Generalization**|Adinath Dukre et.al|[paper](https://arxiv.org/abs/2510.22630)|-|<details><summary>detail</summary>MIDOG 2025 MICCAI Workshop accepted</details>|\n", "Emotion Recognition with Minimal Wearable Sensing: Multi-domain Feature, Hybrid Feature Selection, and Personalized vs. Generalized Ensemble Model Analysis": "|**2025-10-25**|**Emotion Recognition with Minimal Wearable Sensing: Multi-domain Feature, Hybrid Feature Selection, and Personalized vs. Generalized Ensemble Model Analysis**|Muhammad Irfan et.al|[paper](https://arxiv.org/abs/2510.22498)|-|-|\n", "Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering": "|**2025-10-24**|**Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering**|Elman Ghazaei et.al|[paper](https://arxiv.org/abs/2508.08974)|[code](https://github.com/Elman295/TCSSM.)|-|\n", "How Many Domains Suffice for Domain Generalization? A Tight Characterization via the Domain Shattering Dimension": "|**2025-10-23**|**How Many Domains Suffice for Domain Generalization? A Tight Characterization via the Domain Shattering Dimension**|Cynthia Dwork et.al|[paper](https://arxiv.org/abs/2506.16704)|-|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "Towards Context-Aware Domain Generalization: Understanding the Benefits and Limits of Marginal Transfer Learning": "|**2025-10-22**|**Towards Context-Aware Domain Generalization: Understanding the Benefits and Limits of Marginal Transfer Learning**|Jens M\u00fcller et.al|[paper](https://arxiv.org/abs/2312.10107)|-|-|\n", "Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts": "|**2025-10-22**|**Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts**|Chen Li et.al|[paper](https://arxiv.org/abs/2510.19487)|-|-|\n", "Exploring Scale Shift in Crowd Localization under the Context of Domain Generalization": "|**2025-10-22**|**Exploring Scale Shift in Crowd Localization under the Context of Domain Generalization**|Juncheng Wang et.al|[paper](https://arxiv.org/abs/2510.19330)|-|-|\n", "FlexiDataGen: An Adaptive LLM Framework for Dynamic Semantic Dataset Generation in Sensitive Domains": "|**2025-10-21**|**FlexiDataGen: An Adaptive LLM Framework for Dynamic Semantic Dataset Generation in Sensitive Domains**|Hamed Jelodar et.al|[paper](https://arxiv.org/abs/2510.19025)|-|-|\n", "XGen-Q: An Explainable Domain-Adaptive LLM Framework with Retrieval-Augmented Generation for Software Security": "|**2025-10-21**|**XGen-Q: An Explainable Domain-Adaptive LLM Framework with Retrieval-Augmented Generation for Software Security**|Hamed Jelodar et.al|[paper](https://arxiv.org/abs/2510.19006)|-|-|\n", "TreeFedDG: Alleviating Global Drift in Federated Domain Generalization for Medical Image Segmentation": "|**2025-10-20**|**TreeFedDG: Alleviating Global Drift in Federated Domain Generalization for Medical Image Segmentation**|Yucheng Song et.al|[paper](https://arxiv.org/abs/2510.18268)|-|-|\n", "Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains": "|**2025-10-20**|**Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains**|Austin Xu et.al|[paper](https://arxiv.org/abs/2510.17793)|-|-|\n", "HIDISC: A Hyperbolic Framework for Domain Generalization with Generalized Category Discovery": "|**2025-10-20**|**HIDISC: A Hyperbolic Framework for Domain Generalization with Generalized Category Discovery**|Vaibhav Rathore et.al|[paper](https://arxiv.org/abs/2510.17188)|-|<details><summary>detail</summary>Accpeted at NeurIPS (2025) Main Conference</details>|\n", "UniGTE: Unified Graph-Text Encoding for Zero-Shot Generalization across Graph Tasks and Domains": "|**2025-10-19**|**UniGTE: Unified Graph-Text Encoding for Zero-Shot Generalization across Graph Tasks and Domains**|Duo Wang et.al|[paper](https://arxiv.org/abs/2510.16885)|-|<details><summary>detail</summary>Journal ref:NeurIPS 2025</details>|\n", "Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization": "|**2025-10-19**|**Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization**|Tianxin Wei et.al|[paper](https://arxiv.org/abs/2510.16704)|[code](https://github.com/weitianxin/DCCL)|<details><summary>detail</summary>Accepted by KDD 2025</details>|\n", "Humanoid-inspired Causal Representation Learning for Domain Generalization": "|**2025-10-18**|**Humanoid-inspired Causal Representation Learning for Domain Generalization**|Ze Tao et.al|[paper](https://arxiv.org/abs/2510.16382)|[code](https://github.com/lambett/HSCM.)|-|\n"}, "vision language": {"UrbanVLA: A Vision-Language-Action Model for Urban Micromobility": "|**2025-10-27**|**UrbanVLA: A Vision-Language-Action Model for Urban Micromobility**|Anqi Li et.al|[paper](https://arxiv.org/abs/2510.23576)|-|-|\n", "Dexbotic: Open-Source Vision-Language-Action Toolbox": "|**2025-10-27**|**Dexbotic: Open-Source Vision-Language-Action Toolbox**|Bin Xie et.al|[paper](https://arxiv.org/abs/2510.23511)|[code](https://dexbotic.com/.)|<details><summary>detail</summary>Authors are listed in alphabetical order</details>|\n", "VOLD: Reasoning Transfer from LLMs to Vision-Language Models via On-Policy Distillation": "|**2025-10-27**|**VOLD: Reasoning Transfer from LLMs to Vision-Language Models via On-Policy Distillation**|Walid Bousselham et.al|[paper](https://arxiv.org/abs/2510.23497)|-|<details><summary>detail</summary>www</details>|\n", "Med-R1: Reinforcement Learning for Generalizable Medical Reasoning in Vision-Language Models": "|**2025-10-27**|**Med-R1: Reinforcement Learning for Generalizable Medical Reasoning in Vision-Language Models**|Yuxiang Lai et.al|[paper](https://arxiv.org/abs/2503.13939)|-|-|\n", "GRE Suite: Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains": "|**2025-10-27**|**GRE Suite: Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains**|Chun Wang et.al|[paper](https://arxiv.org/abs/2505.18700)|[code](https://github.com/Thorin215/GRE.)|-|\n", "Accurate and Scalable Multimodal Pathology Retrieval via Attentive Vision-Language Alignment": "|**2025-10-27**|**Accurate and Scalable Multimodal Pathology Retrieval via Attentive Vision-Language Alignment**|Hongyi Wang et.al|[paper](https://arxiv.org/abs/2510.23224)|-|-|\n", "Attention! Your Vision Language Model Could Be Maliciously Manipulated": "|**2025-10-27**|**Attention! Your Vision Language Model Could Be Maliciously Manipulated**|Xiaosen Wang et.al|[paper](https://arxiv.org/abs/2505.19911)|[code](https://github.com/Trustworthy-AI-Group/VMA.)|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "Revisiting Multimodal Positional Encoding in Vision-Language Models": "|**2025-10-27**|**Revisiting Multimodal Positional Encoding in Vision-Language Models**|Jie Huang et.al|[paper](https://arxiv.org/abs/2510.23095)|[code](https://github.com/JJJYmmm/Multimodal-RoPEs.)|-|\n", "FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models": "|**2025-10-27**|**FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models**|Zijun Lin et.al|[paper](https://arxiv.org/abs/2510.01642)|[code](https://jimntu.github.io/FailSafe)|<details><summary>detail</summary>Project Page: https://jimntu</details>|\n", "HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model": "|**2025-10-27**|**HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model**|Youngwan Lee et.al|[paper](https://arxiv.org/abs/2506.04704)|[code](https://youngwanlee.github.io/holisafe)|<details><summary>detail</summary>Project page: https://youngwanlee</details>|\n", "Multi-Stage Field Extraction of Financial Documents with OCR and Compact Vision-Language Models": "|**2025-10-27**|**Multi-Stage Field Extraction of Financial Documents with OCR and Compact Vision-Language Models**|Yichao Jin et.al|[paper](https://arxiv.org/abs/2510.23066)|-|-|\n", "Refusal as Silence: Gendered Disparities in Vision-Language Model Responses": "|**2025-10-26**|**Refusal as Silence: Gendered Disparities in Vision-Language Model Responses**|Sha Luo et.al|[paper](https://arxiv.org/abs/2406.08222)|-|-|\n", "Seeing the Unseen: Towards Zero-Shot Inspection for Wind Turbine Blades using Knowledge-Augmented Vision Language Models": "|**2025-10-26**|**Seeing the Unseen: Towards Zero-Shot Inspection for Wind Turbine Blades using Knowledge-Augmented Vision Language Models**|Yang Zhang et.al|[paper](https://arxiv.org/abs/2510.22868)|-|-|\n", "Breaking Language Barriers or Reinforcing Bias? A Study of Gender and Racial Disparities in Multilingual Contrastive Vision Language Models": "|**2025-10-26**|**Breaking Language Barriers or Reinforcing Bias? A Study of Gender and Racial Disparities in Multilingual Contrastive Vision Language Models**|Zahraa Al Sahili et.al|[paper](https://arxiv.org/abs/2505.14160)|-|<details><summary>detail</summary>IJCNLP-AACL 2025</details>|\n", "Semantic-Preserving Cross-Style Visual Reasoning for Robust Multi-Modal Understanding in Large Vision-Language Models": "|**2025-10-26**|**Semantic-Preserving Cross-Style Visual Reasoning for Robust Multi-Modal Understanding in Large Vision-Language Models**|Aya Nakayama et.al|[paper](https://arxiv.org/abs/2510.22838)|-|-|\n"}}