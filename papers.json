{"source-free": {"Listen, Analyze, and Adapt to Learn New Attacks: An Exemplar-Free Class Incremental Learning Method for Audio Deepfake Source Tracing": "|**2025-5-20**|**Listen, Analyze, and Adapt to Learn New Attacks: An Exemplar-Free Class Incremental Learning Method for Audio Deepfake Source Tracing**|Yang Xiao et.al|[paper](https://arxiv.org/abs/2505.14601)|-|<details><summary>detail</summary>Accepted by Interspeech 2025</details>|\n", "DDFP: Data-dependent Frequency Prompt for Source Free Domain Adaptation of Medical Image Segmentation": "|**2025-5-14**|**DDFP: Data-dependent Frequency Prompt for Source Free Domain Adaptation of Medical Image Segmentation**|Siqi Yin et.al|[paper](https://arxiv.org/abs/2505.09927)|-|-|\n", "Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting": "|**2025-5-13**|**Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting**|Zheang Huai et.al|[paper](https://arxiv.org/abs/2505.08527)|[code](https://github.com/xmed-lab/DFG.)|-|\n", "CORSTITCH - A free, open source software for stitching and georeferencing underwater coral reef videos": "|**2025-5-1**|**CORSTITCH - A free, open source software for stitching and georeferencing underwater coral reef videos**|Julian Christopher L. Maypa et.al|[paper](https://arxiv.org/abs/2505.00462)|-|-|\n", "Energy-Based Pseudo-Label Refining for Source-free Domain Adaptation": "|**2025-4-23**|**Energy-Based Pseudo-Label Refining for Source-free Domain Adaptation**|Xinru Meng et.al|[paper](https://arxiv.org/abs/2504.16692)|[code](https://github.com/Sthen111/EBPR)|-|\n", "Context Aware Grounded Teacher for Source Free Object Detection": "|**2025-4-21**|**Context Aware Grounded Teacher for Source Free Object Detection**|Tajamul Ashraf et.al|[paper](https://arxiv.org/abs/2504.15404)|[code](https://github.com/Tajamul21/Grounded_Teacher.)|-|\n", "Learning Compositional Transferability of Time Series for Source-Free Domain Adaptation": "|**2025-4-21**|**Learning Compositional Transferability of Time Series for Source-Free Domain Adaptation**|Hankang Sun et.al|[paper](https://arxiv.org/abs/2504.14994)|-|<details><summary>detail</summary>Corresponding author: Su Yang</details>|\n", "Proxy Denoising for Source-Free Domain Adaptation": "|**2025-4-16**|**Proxy Denoising for Source-Free Domain Adaptation**|Song Tang et.al|[paper](https://arxiv.org/abs/2406.01658)|[code](https://github.com/tntek/source-free-domain-adaptation.)|<details><summary>detail</summary>This paper is accepted by ICLR 2025 (Oral</details>|\n", "Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation": "|**2025-4-16**|**Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation**|Pascal Schlachter et.al|[paper](https://arxiv.org/abs/2504.11992)|[code](https://github.com/pascalschlachter/PLAnalysis.)|<details><summary>detail</summary>Submitted to the 33rd European Signal Processing Conference (EUSIPCO 2025)</details>|\n", "Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation": "|**2025-4-15**|**Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation**|Amirhossein Dadashzadeh et.al|[paper](https://arxiv.org/abs/2504.11669)|[code](https://github.com/Plrbear/Co-Star)|-|\n", "Probability Distribution Alignment and Low-Rank Weight Decomposition for Source-Free Domain Adaptive Brain Decoding": "|**2025-4-15**|**Probability Distribution Alignment and Low-Rank Weight Decomposition for Source-Free Domain Adaptive Brain Decoding**|Ganxi Xu et.al|[paper](https://arxiv.org/abs/2504.09109)|-|-|\n", "Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data": "|**2025-4-5**|**Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2503.20771)|-|-|\n", "ElimPCL: Eliminating Noise Accumulation with Progressive Curriculum Labeling for Source-Free Domain Adaptation": "|**2025-3-31**|**ElimPCL: Eliminating Noise Accumulation with Progressive Curriculum Labeling for Source-Free Domain Adaptation**|Jie Cheng et.al|[paper](https://arxiv.org/abs/2503.23712)|-|<details><summary>detail</summary>ICME 2025 camera-ready</details>|\n", "ViLAaD: Enhancing \"Attracting and Dispersing'' Source-Free Domain Adaptation with Vision-and-Language Model": "|**2025-3-30**|**ViLAaD: Enhancing \"Attracting and Dispersing'' Source-Free Domain Adaptation with Vision-and-Language Model**|Shuhei Tarashima et.al|[paper](https://arxiv.org/abs/2503.23529)|-|-|\n", "Optimal Transport-Guided Source-Free Adaptation for Face Anti-Spoofing": "|**2025-3-29**|**Optimal Transport-Guided Source-Free Adaptation for Face Anti-Spoofing**|Zhuowei Li et.al|[paper](https://arxiv.org/abs/2503.22984)|-|-|\n"}, "object detection": {"MAFE R-CNN: Selecting More Samples to Learn Category-aware Features for Small Object Detection": "|**2025-5-22**|**MAFE R-CNN: Selecting More Samples to Learn Category-aware Features for Small Object Detection**|Yichen Li et.al|[paper](https://arxiv.org/abs/2505.16442)|-|-|\n", "AdvReal: Adversarial Patch Generation Framework with Application to Adversarial Safety Evaluation of Object Detection Systems": "|**2025-5-22**|**AdvReal: Adversarial Patch Generation Framework with Application to Adversarial Safety Evaluation of Object Detection Systems**|Yuanhao Huang et.al|[paper](https://arxiv.org/abs/2505.16402)|[code](https://github.com/Huangyh98/AdvReal.git.)|-|\n", "Efficient Feature Fusion for UAV Object Detection": "|**2025-5-22**|**Efficient Feature Fusion for UAV Object Detection**|Xudong Wang et.al|[paper](https://arxiv.org/abs/2501.17983)|-|-|\n", "Self-Classification Enhancement and Correction for Weakly Supervised Object Detection": "|**2025-5-22**|**Self-Classification Enhancement and Correction for Weakly Supervised Object Detection**|Yufei Yin et.al|[paper](https://arxiv.org/abs/2505.16294)|-|<details><summary>detail</summary>Accepted by IJCAI 2025</details>|\n", "HV-BEV: Decoupling Horizontal and Vertical Feature Sampling for Multi-View 3D Object Detection": "|**2025-5-21**|**HV-BEV: Decoupling Horizontal and Vertical Feature Sampling for Multi-View 3D Object Detection**|Di Wu et.al|[paper](https://arxiv.org/abs/2412.18884)|[code](https://github.com/Uddd821/HV-BEV.)|-|\n", "RGBX-DiffusionDet: A Framework for Multi-Modal RGB-X Object Detection Using DiffusionDet": "|**2025-5-21**|**RGBX-DiffusionDet: A Framework for Multi-Modal RGB-X Object Detection Using DiffusionDet**|Eliraz Orfaig et.al|[paper](https://arxiv.org/abs/2505.02586)|-|-|\n", "Boosting Few-Shot Open-Set Object Detection via Prompt Learning and Robust Decision Boundary": "|**2025-5-21**|**Boosting Few-Shot Open-Set Object Detection via Prompt Learning and Robust Decision Boundary**|Zhaowei Wu et.al|[paper](https://arxiv.org/abs/2406.18443)|[code](https://gitee.com/VR_NAVE/ced-food.)|<details><summary>detail</summary>IJCAI 2025</details>|\n", "A re-calibration method for object detection with multi-modal alignment bias in autonomous driving": "|**2025-5-20**|**A re-calibration method for object detection with multi-modal alignment bias in autonomous driving**|Zhihang Song et.al|[paper](https://arxiv.org/abs/2405.16848)|-|-|\n", "LED: LLM Enhanced Open-Vocabulary Object Detection without Human Curated Data Generation": "|**2025-5-20**|**LED: LLM Enhanced Open-Vocabulary Object Detection without Human Curated Data Generation**|Yang Zhou et.al|[paper](https://arxiv.org/abs/2503.13794)|-|-|\n", "Decoupling Classifier for Boosting Few-shot Object Detection and Instance Segmentation": "|**2025-5-20**|**Decoupling Classifier for Boosting Few-shot Object Detection and Instance Segmentation**|Bin-Bin Gao et.al|[paper](https://arxiv.org/abs/2505.14239)|[code](https://csgaobb.github.io/Projects/DCFS.)|<details><summary>detail</summary>Accepted by NeurIPS 2022</details>|\n", "View-Invariant Pixelwise Anomaly Detection in Multi-object Scenes with Adaptive View Synthesis": "|**2025-5-19**|**View-Invariant Pixelwise Anomaly Detection in Multi-object Scenes with Adaptive View Synthesis**|Subin Varghese et.al|[paper](https://arxiv.org/abs/2406.18012)|[code](https://drags99.github.io/OmniAD/)|-|\n", "Quantifying Context Bias in Domain Adaptation for Object Detection": "|**2025-5-19**|**Quantifying Context Bias in Domain Adaptation for Object Detection**|Hojun Son et.al|[paper](https://arxiv.org/abs/2409.14679)|-|<details><summary>detail</summary>Under review</details>|\n", "Dynamic Graph Induced Contour-aware Heat Conduction Network for Event-based Object Detection": "|**2025-5-19**|**Dynamic Graph Induced Contour-aware Heat Conduction Network for Event-based Object Detection**|Xiao Wang et.al|[paper](https://arxiv.org/abs/2505.12908)|[code](https://github.com/Event-AHU/OpenEvDET.)|-|\n", "Rethinking Features-Fused-Pyramid-Neck for Object Detection": "|**2025-5-19**|**Rethinking Features-Fused-Pyramid-Neck for Object Detection**|Hulin Li et.al|[paper](https://arxiv.org/abs/2505.12820)|[code](https://github.com/AlanLi1997/rethinking-fpn.)|<details><summary>detail</summary>ECCV 2024</details>|\n", "VLC Fusion: Vision-Language Conditioned Sensor Fusion for Robust Object Detection": "|**2025-5-19**|**VLC Fusion: Vision-Language Conditioned Sensor Fusion for Robust Object Detection**|Aditya Taparia et.al|[paper](https://arxiv.org/abs/2505.12715)|-|-|\n"}, "domain adaptation": {"GCAL: Adapting Graph Models to Evolving Domain Shifts": "|**2025-5-22**|**GCAL: Adapting Graph Models to Evolving Domain Shifts**|Ziyue Qiao et.al|[paper](https://arxiv.org/abs/2505.16860)|-|<details><summary>detail</summary>ICML 2025</details>|\n", "Transformers for molecular property prediction: Domain adaptation efficiently improves performance": "|**2025-5-22**|**Transformers for molecular property prediction: Domain adaptation efficiently improves performance**|Afnan Sultan et.al|[paper](https://arxiv.org/abs/2503.03360)|-|-|\n", "Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation": "|**2025-5-22**|**Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation**|Estelle Chigot et.al|[paper](https://arxiv.org/abs/2505.16360)|[code](https://github.com/echigot/cactif.)|<details><summary>detail</summary>Under review</details>|\n", "SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation": "|**2025-5-21**|**SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation**|Jiayue Liu et.al|[paper](https://arxiv.org/abs/2505.16080)|-|-|\n", "Domain Adaptive Skin Lesion Classification via Conformal Ensemble of Vision Transformers": "|**2025-5-21**|**Domain Adaptive Skin Lesion Classification via Conformal Ensemble of Vision Transformers**|Mehran Zoravar et.al|[paper](https://arxiv.org/abs/2505.15997)|-|-|\n", "seg_3D_by_PC2D: Multi-View Projection for Domain Generalization and Adaptation in 3D Semantic Segmentation": "|**2025-5-21**|**seg_3D_by_PC2D: Multi-View Projection for Domain Generalization and Adaptation in 3D Semantic Segmentation**|Andrew Caunes et.al|[paper](https://arxiv.org/abs/2505.15545)|[code](https://github.com/andrewcaunes/ia4markings)|-|\n", "GAMA++: Disentangled Geometric Alignment with Adaptive Contrastive Perturbation for Reliable Domain Transfer": "|**2025-5-21**|**GAMA++: Disentangled Geometric Alignment with Adaptive Contrastive Perturbation for Reliable Domain Transfer**|Kim Yun et.al|[paper](https://arxiv.org/abs/2505.15241)|-|-|\n", "GAMA: Geometry-Aware Manifold Alignment via Structured Adversarial Perturbations for Robust Domain Adaptation": "|**2025-5-21**|**GAMA: Geometry-Aware Manifold Alignment via Structured Adversarial Perturbations for Robust Domain Adaptation**|Hana Satou et.al|[paper](https://arxiv.org/abs/2505.15194)|-|-|\n", "DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware Reinforcement Learning on Imbalanced Data": "|**2025-5-20**|**DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware Reinforcement Learning on Imbalanced Data**|Yuhang Zhou et.al|[paper](https://arxiv.org/abs/2505.15074)|-|-|\n", "Feature-Weighted MMD-CORAL for Domain Adaptation in Power Transformer Fault Diagnosis": "|**2025-5-20**|**Feature-Weighted MMD-CORAL for Domain Adaptation in Power Transformer Fault Diagnosis**|Hootan Mahmoodiyan et.al|[paper](https://arxiv.org/abs/2505.14896)|-|-|\n", "ReservoirTTA: Prolonged Test-time Adaptation for Evolving and Recurring Domains": "|**2025-5-20**|**ReservoirTTA: Prolonged Test-time Adaptation for Evolving and Recurring Domains**|Guillaume Vray et.al|[paper](https://arxiv.org/abs/2505.14511)|-|-|\n", "Domain Adaptation for Multi-label Image Classification: a Discriminator-free Approach": "|**2025-5-20**|**Domain Adaptation for Multi-label Image Classification: a Discriminator-free Approach**|Inder Pal Singh et.al|[paper](https://arxiv.org/abs/2505.14333)|-|<details><summary>detail</summary>The paper is under consideration at Computer Vision and Image Understanding</details>|\n", "Does Unsupervised Domain Adaptation Improve the Robustness of Amortized Bayesian Inference? A Systematic Evaluation": "|**2025-5-20**|**Does Unsupervised Domain Adaptation Improve the Robustness of Amortized Bayesian Inference? A Systematic Evaluation**|Lasse Elsem\u00fcller et.al|[paper](https://arxiv.org/abs/2502.04949)|-|-|\n", "Cross-Domain Diffusion with Progressive Alignment for Efficient Adaptive Retrieval": "|**2025-5-20**|**Cross-Domain Diffusion with Progressive Alignment for Efficient Adaptive Retrieval**|Junyu Luo et.al|[paper](https://arxiv.org/abs/2505.13907)|-|<details><summary>detail</summary>IEEE TIP</details>|\n", "Domain Adaptation of VLM for Soccer Video Understanding": "|**2025-5-19**|**Domain Adaptation of VLM for Soccer Video Understanding**|Tiancheng Jiang et.al|[paper](https://arxiv.org/abs/2505.13860)|-|-|\n"}, "domain generalization": {"General-Reasoner: Advancing LLM Reasoning Across All Domains": "|**2025-5-22**|**General-Reasoner: Advancing LLM Reasoning Across All Domains**|Xueguang Ma et.al|[paper](https://arxiv.org/abs/2505.14652)|-|-|\n", "Single Domain Generalization for Few-Shot Counting via Universal Representation Matching": "|**2025-5-22**|**Single Domain Generalization for Few-Shot Counting via Universal Representation Matching**|Xianing Chen et.al|[paper](https://arxiv.org/abs/2505.16778)|-|<details><summary>detail</summary>CVPR 2025</details>|\n", "seg_3D_by_PC2D: Multi-View Projection for Domain Generalization and Adaptation in 3D Semantic Segmentation": "|**2025-5-21**|**seg_3D_by_PC2D: Multi-View Projection for Domain Generalization and Adaptation in 3D Semantic Segmentation**|Andrew Caunes et.al|[paper](https://arxiv.org/abs/2505.15545)|[code](https://github.com/andrewcaunes/ia4markings)|-|\n", "Domain Gating Ensemble Networks for AI-Generated Text Detection": "|**2025-5-19**|**Domain Gating Ensemble Networks for AI-Generated Text Detection**|Arihant Tripathi et.al|[paper](https://arxiv.org/abs/2505.13855)|-|<details><summary>detail</summary>Submitted to EMNLP 2025</details>|\n", "MoL for LLMs: Dual-Loss Optimization to Enhance Domain Expertise While Preserving General Capabilities": "|**2025-5-19**|**MoL for LLMs: Dual-Loss Optimization to Enhance Domain Expertise While Preserving General Capabilities**|Jingxue Chen et.al|[paper](https://arxiv.org/abs/2505.12043)|-|-|\n", "A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation": "|**2025-5-19**|**A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation**|Hao-Ran Yang et.al|[paper](https://arxiv.org/abs/2505.13043)|-|-|\n", "PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization": "|**2025-5-19**|**PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization**|Dong Kyu Cho et.al|[paper](https://arxiv.org/abs/2505.12745)|-|-|\n", "Learning Robust Spectral Dynamics for Temporal Domain Generalization": "|**2025-5-18**|**Learning Robust Spectral Dynamics for Temporal Domain Generalization**|En Yu et.al|[paper](https://arxiv.org/abs/2505.12585)|-|-|\n", "Towards Open-world Generalized Deepfake Detection: General Feature Extraction via Unsupervised Domain Adaptation": "|**2025-5-18**|**Towards Open-world Generalized Deepfake Detection: General Feature Extraction via Unsupervised Domain Adaptation**|Midou Guo et.al|[paper](https://arxiv.org/abs/2505.12339)|-|-|\n", "Learning Auxiliary Tasks Improves Reference-Free Hallucination Detection in Open-Domain Long-Form Generation": "|**2025-5-18**|**Learning Auxiliary Tasks Improves Reference-Free Hallucination Detection in Open-Domain Long-Form Generation**|Chengwei Qin et.al|[paper](https://arxiv.org/abs/2505.12265)|-|-|\n", "Continuous Domain Generalization": "|**2025-5-17**|**Continuous Domain Generalization**|Zekun Cai et.al|[paper](https://arxiv.org/abs/2505.13519)|-|-|\n", "Fault Diagnosis across Heterogeneous Domains via Self-Adaptive Temporal-Spatial Attention and Sample Generation": "|**2025-5-16**|**Fault Diagnosis across Heterogeneous Domains via Self-Adaptive Temporal-Spatial Attention and Sample Generation**|Guangqiang Li et.al|[paper](https://arxiv.org/abs/2505.11083)|[code](https://github.com/GuangqiangLi/TSA-SAN.)|-|\n", "Multi-Source Collaborative Style Augmentation and Domain-Invariant Learning for Federated Domain Generalization": "|**2025-5-15**|**Multi-Source Collaborative Style Augmentation and Domain-Invariant Learning for Federated Domain Generalization**|Yikang Wei et.al|[paper](https://arxiv.org/abs/2505.10152)|-|<details><summary>detail</summary>IJCAI 2025</details>|\n", "Denoising and Alignment: Rethinking Domain Generalization for Multimodal Face Anti-Spoofing": "|**2025-5-14**|**Denoising and Alignment: Rethinking Domain Generalization for Multimodal Face Anti-Spoofing**|Yingjie Ma et.al|[paper](https://arxiv.org/abs/2505.09484)|-|-|\n", "UVTM: Universal Vehicle Trajectory Modeling with ST Feature Domain Generation": "|**2025-5-13**|**UVTM: Universal Vehicle Trajectory Modeling with ST Feature Domain Generation**|Yan Lin et.al|[paper](https://arxiv.org/abs/2402.07232)|-|-|\n"}, "vision language": {"Interactive Post-Training for Vision-Language-Action Models": "|**2025-5-22**|**Interactive Post-Training for Vision-Language-Action Models**|Shuhan Tan et.al|[paper](https://arxiv.org/abs/2505.17016)|[code](https://ariostgx.github.io/ript_vla/)|<details><summary>detail</summary>Project page: https://ariostgx</details>|\n", "Remote Sensing Spatio-Temporal Vision-Language Models: A Comprehensive Survey": "|**2025-5-22**|**Remote Sensing Spatio-Temporal Vision-Language Models: A Comprehensive Survey**|Chenyang Liu et.al|[paper](https://arxiv.org/abs/2412.02573)|[code](https://github.com/Chen-Yang-Liu/Awesome-RS-SpatioTemporal-VLMs)|-|\n", "Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models": "|**2025-5-22**|**Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models**|Jiaqi Wang et.al|[paper](https://arxiv.org/abs/2505.16854)|[code](https://github.com/kokolerk/TON.)|-|\n", "SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving": "|**2025-5-22**|**SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving**|Xuesong Chen et.al|[paper](https://arxiv.org/abs/2505.16805)|-|<details><summary>detail</summary>Accepted by CVPR 2025</details>|\n", "InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning": "|**2025-5-22**|**InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning**|Ji Zhang et.al|[paper](https://arxiv.org/abs/2505.13888)|[code](https://Koorye.github.io/proj/Inspire.)|-|\n", "Self-Rewarding Large Vision-Language Models for Optimizing Prompts in Text-to-Image Generation": "|**2025-5-22**|**Self-Rewarding Large Vision-Language Models for Optimizing Prompts in Text-to-Image Generation**|Hongji Yang et.al|[paper](https://arxiv.org/abs/2505.16763)|-|-|\n", "Point, Detect, Count: Multi-Task Medical Image Understanding with Instruction-Tuned Vision-Language Models": "|**2025-5-22**|**Point, Detect, Count: Multi-Task Medical Image Understanding with Instruction-Tuned Vision-Language Models**|Sushant Gautam et.al|[paper](https://arxiv.org/abs/2505.16647)|[code](https://github.com/simula/PointDetectCount.)|<details><summary>detail</summary>Accepted as a full paper at the 38th IEEE International Symposium on Computer-Based Medical Systems (CBMS) 2025</details>|\n", "BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization": "|**2025-5-22**|**BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization**|Xueyang Zhou et.al|[paper](https://arxiv.org/abs/2505.16640)|[code](https://badvla-project.github.io/.)|-|\n", "AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving": "|**2025-5-22**|**AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving**|Kangan Qian et.al|[paper](https://arxiv.org/abs/2505.15298)|-|-|\n", "ManipLVM-R1: Reinforcement Learning for Reasoning in Embodied Manipulation with Large Vision-Language Models": "|**2025-5-22**|**ManipLVM-R1: Reinforcement Learning for Reasoning in Embodied Manipulation with Large Vision-Language Models**|Zirui Song et.al|[paper](https://arxiv.org/abs/2505.16517)|-|-|\n", "Transferring Textual Preferences to Vision-Language Understanding through Model Merging": "|**2025-5-22**|**Transferring Textual Preferences to Vision-Language Understanding through Model Merging**|Chen-An Li et.al|[paper](https://arxiv.org/abs/2502.13487)|-|<details><summary>detail</summary>ACL 2025 main</details>|\n", "Uncovering Cultural Representation Disparities in Vision-Language Models": "|**2025-5-22**|**Uncovering Cultural Representation Disparities in Vision-Language Models**|Ram Mohan Rao Kadiyala et.al|[paper](https://arxiv.org/abs/2505.14729)|-|-|\n", "Implicit Jailbreak Attacks via Cross-Modal Information Concealment on Vision-Language Models": "|**2025-5-22**|**Implicit Jailbreak Attacks via Cross-Modal Information Concealment on Vision-Language Models**|Zhaoxin Wang et.al|[paper](https://arxiv.org/abs/2505.16446)|-|-|\n", "Circle-RoPE: Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models": "|**2025-5-22**|**Circle-RoPE: Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models**|Chengcheng Wang et.al|[paper](https://arxiv.org/abs/2505.16416)|[code](https://github.com/lose4578/CircleRoPE](https://github.com/lose4578/CircleRoPE).)|-|\n", "Mitigating Hallucinations in Vision-Language Models through Image-Guided Head Suppression": "|**2025-5-22**|**Mitigating Hallucinations in Vision-Language Models through Image-Guided Head Suppression**|Sreetama Sarkar et.al|[paper](https://arxiv.org/abs/2505.16411)|[code](https://github.com/YUECHE77/SPIN.)|-|\n"}}