{"source-free": {"Source-Free Object Detection with Detection Transformer": "|**2025-10-13**|**Source-Free Object Detection with Detection Transformer**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2510.11090)|-|<details><summary>detail</summary>IEEE Transactions on Image Processing</details>|\n", "Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning": "|**2025-10-9**|**Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning**|Ziqi Zhang et.al|[paper](https://arxiv.org/abs/2510.08393)|-|-|\n", "ESS-Flow: Training-free guidance of flow-based models as inference in source space": "|**2025-10-7**|**ESS-Flow: Training-free guidance of flow-based models as inference in source space**|Adhithyan Kalaivanan et.al|[paper](https://arxiv.org/abs/2510.05849)|-|-|\n", "Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising": "|**2025-10-7**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|\n", "A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation": "|**2025-10-6**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|\n", "Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection": "|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|\n", "Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation": "|**2025-10-3**|**Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation**|Yucheng Wang et.al|[paper](https://arxiv.org/abs/2409.19635)|-|-|\n", "OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation": "|**2025-10-2**|**OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation**|Yiming Zhang et.al|[paper](https://arxiv.org/abs/2505.11669)|-|-|\n", "Source-Free Cross-Domain Continual Learning": "|**2025-10-2**|**Source-Free Cross-Domain Continual Learning**|Muhammad Tanzil Furqon et.al|[paper](https://arxiv.org/abs/2510.01649)|-|-|\n", "Consistent Assistant Domains Transformer for Source-free Domain Adaptation": "|**2025-10-1**|**Consistent Assistant Domains Transformer for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.01559)|[code](https://github.com/RoryShao/CADTrans.git.)|-|\n", "Source-Free Domain Adaptive Object Detection with Semantics Compensation": "|**2025-9-30**|**Source-Free Domain Adaptive Object Detection with Semantics Compensation**|Song Tang et.al|[paper](https://arxiv.org/abs/2410.05557)|-|-|\n", "DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation": "|**2025-9-29**|**DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation**|Xi Chen et.al|[paper](https://arxiv.org/abs/2509.24896)|-|-|\n", "Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation": "|**2025-9-29**|**Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|\n", "Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment": "|**2025-9-22**|**Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment**|Wenjie Liu et.al|[paper](https://arxiv.org/abs/2509.18502)|-|-|\n", "Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation": "|**2025-9-22**|**Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation**|Amirhossein Dadashzadeh et.al|[paper](https://arxiv.org/abs/2504.11669)|[code](https://github.com/Plrbear/Co-Star)|-|\n"}, "object detection": {"The Impact of Synthetic Data on Object Detection Model Performance: A Comparative Analysis with Real-World Data": "|**2025-10-14**|**The Impact of Synthetic Data on Object Detection Model Performance: A Comparative Analysis with Real-World Data**|Muammer Bay et.al|[paper](https://arxiv.org/abs/2510.12208)|[code](https://github.com/MuammerBay/omniverse-replicator-sim2real-analysis)|-|\n", "APGNet: Adaptive Prior-Guided for Underwater Camouflaged Object Detection": "|**2025-10-13**|**APGNet: Adaptive Prior-Guided for Underwater Camouflaged Object Detection**|Xinxin Huang et.al|[paper](https://arxiv.org/abs/2510.12056)|-|-|\n", "NV3D: Leveraging Spatial Shape Through Normal Vector-based 3D Object Detection": "|**2025-10-13**|**NV3D: Leveraging Spatial Shape Through Normal Vector-based 3D Object Detection**|Krittin Chaowakarn et.al|[paper](https://arxiv.org/abs/2510.11632)|-|<details><summary>detail</summary>ACM Class:I</details>|\n", "When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models": "|**2025-10-13**|**When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models**|Samer Al-Hamadani et.al|[paper](https://arxiv.org/abs/2510.11302)|-|-|\n", "Source-Free Object Detection with Detection Transformer": "|**2025-10-13**|**Source-Free Object Detection with Detection Transformer**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2510.11090)|-|<details><summary>detail</summary>IEEE Transactions on Image Processing</details>|\n", "RoHOI: Robustness Benchmark for Human-Object Interaction Detection": "|**2025-10-13**|**RoHOI: Robustness Benchmark for Human-Object Interaction Detection**|Di Wen et.al|[paper](https://arxiv.org/abs/2507.09111)|[code](https://github.com/KratosWen/RoHOI.)|<details><summary>detail</summary>Benchmarks</details>|\n", "MRS-YOLO Railroad Transmission Line Foreign Object Detection Based on Improved YOLO11 and Channel Pruning": "|**2025-10-12**|**MRS-YOLO Railroad Transmission Line Foreign Object Detection Based on Improved YOLO11 and Channel Pruning**|Siyuan Liu et.al|[paper](https://arxiv.org/abs/2510.10553)|-|-|\n", "Bridging Perspectives: Foundation Model Guided BEV Maps for 3D Object Detection and Tracking": "|**2025-10-11**|**Bridging Perspectives: Foundation Model Guided BEV Maps for 3D Object Detection and Tracking**|Markus K\u00e4ppeler et.al|[paper](https://arxiv.org/abs/2510.10287)|[code](https://dualviewdistill.cs.uni-freiburg.de)|-|\n", "TARO: Toward Semantically Rich Open-World Object Detection": "|**2025-10-10**|**TARO: Toward Semantically Rich Open-World Object Detection**|Yuchen Zhang et.al|[paper](https://arxiv.org/abs/2510.09173)|-|-|\n", "CQ-DINO: Mitigating Gradient Dilution via Category Queries for Vast Vocabulary Object Detection": "|**2025-10-10**|**CQ-DINO: Mitigating Gradient Dilution via Category Queries for Vast Vocabulary Object Detection**|Zhichao Sun et.al|[paper](https://arxiv.org/abs/2503.18430)|[code](https://github.com/FireRedTeam/CQ-DINO.)|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "SOS: Synthetic Object Segments Improve Detection, Segmentation, and Grounding": "|**2025-10-10**|**SOS: Synthetic Object Segments Improve Detection, Segmentation, and Grounding**|Weikai Huang et.al|[paper](https://arxiv.org/abs/2510.09110)|[code](https://github.com/weikaih04/SOS)|<details><summary>detail</summary>Project website: https://github</details>|\n", "Ultra-Efficient On-Device Object Detection on AI-Integrated Smart Glasses with TinyissimoYOLO": "|**2025-10-9**|**Ultra-Efficient On-Device Object Detection on AI-Integrated Smart Glasses with TinyissimoYOLO**|Julian Moosmann et.al|[paper](https://arxiv.org/abs/2311.01057)|[code](https://github.com/ETH-PBL/TinyissimoYOLO)|<details><summary>detail</summary>This paper has been accepted for publication at ECCV 2024 Workshops</details>|\n", "Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models": "|**2025-10-8**|**Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models**|Peter Robicheaux et.al|[paper](https://arxiv.org/abs/2505.20612)|[code](https://github.com/roboflow/rf100-vl)|<details><summary>detail</summary>The first two authors contributed equally</details>|\n", "SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation": "|**2025-10-7**|**SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation**|Ayush Zenith et.al|[paper](https://arxiv.org/abs/2510.06596)|[code](https://github.com/ayushzenith/SDQM)|-|\n", "Enhancing Maritime Object Detection in Real-Time with RT-DETR and Data Augmentation": "|**2025-10-7**|**Enhancing Maritime Object Detection in Real-Time with RT-DETR and Data Augmentation**|Nader Nemati et.al|[paper](https://arxiv.org/abs/2510.07346)|-|-|\n"}, "domain adaptation": {"OmniLens: Towards Universal Lens Aberration Correction via LensLib-to-Specific Domain Adaptation": "|**2025-10-14**|**OmniLens: Towards Universal Lens Aberration Correction via LensLib-to-Specific Domain Adaptation**|Qi Jiang et.al|[paper](https://arxiv.org/abs/2409.05809)|[code](https://github.com/zju-jiangqi/OmniLens.)|<details><summary>detail</summary>The code and data will be available at https://github</details>|\n", "HiLoRA: Adaptive Hierarchical LoRA Routing for Training-Free Domain Generalization": "|**2025-10-14**|**HiLoRA: Adaptive Hierarchical LoRA Routing for Training-Free Domain Generalization**|Ziyi Han et.al|[paper](https://arxiv.org/abs/2510.12266)|-|-|\n", "Class-aware Domain Knowledge Fusion and Fission for Continual Test-Time Adaptation": "|**2025-10-14**|**Class-aware Domain Knowledge Fusion and Fission for Continual Test-Time Adaptation**|Jiahuan Zhou et.al|[paper](https://arxiv.org/abs/2510.12150)|-|-|\n", "Tracing Multilingual Knowledge Acquisition Dynamics in Domain Adaptation: A Case Study of English-Japanese Biomedical Adaptation": "|**2025-10-13**|**Tracing Multilingual Knowledge Acquisition Dynamics in Domain Adaptation: A Case Study of English-Japanese Biomedical Adaptation**|Xin Zhao et.al|[paper](https://arxiv.org/abs/2510.12115)|-|<details><summary>detail</summary>22 Pages</details>|\n", "A Review on Domain Adaption and Generative Adversarial Networks(GANs)": "|**2025-10-13**|**A Review on Domain Adaption and Generative Adversarial Networks(GANs)**|Aashish Dhawan et.al|[paper](https://arxiv.org/abs/2510.12075)|-|-|\n", "Early Detection and Reduction of Memorisation for Domain Adaptation and Instruction Tuning": "|**2025-10-13**|**Early Detection and Reduction of Memorisation for Domain Adaptation and Instruction Tuning**|Dean L. Slack et.al|[paper](https://arxiv.org/abs/2510.11372)|-|<details><summary>detail</summary>Transactions of the ACL (TACL)</details>|\n", "Domain-Specific Data Generation Framework for RAG Adaptation": "|**2025-10-13**|**Domain-Specific Data Generation Framework for RAG Adaptation**|Chris Xing Tian et.al|[paper](https://arxiv.org/abs/2510.11217)|-|-|\n", "HAMUR: Hyper Adapter for Multi-Domain Recommendation": "|**2025-10-12**|**HAMUR: Hyper Adapter for Multi-Domain Recommendation**|Xiaopeng Li et.al|[paper](https://arxiv.org/abs/2309.06217)|-|<details><summary>detail</summary>Accepted by CIKM'2023</details>|\n", "Reinforced Domain Selection for Continuous Domain Adaptation": "|**2025-10-12**|**Reinforced Domain Selection for Continuous Domain Adaptation**|Hanbing Liu et.al|[paper](https://arxiv.org/abs/2510.10530)|-|<details><summary>detail</summary>Journal ref:ICASSP 2025 - 2025 IEEE International Conference on Acoustics</details>|\n", "Vicinity-Guided Discriminative Latent Diffusion for Privacy-Preserving Domain Adaptation": "|**2025-10-11**|**Vicinity-Guided Discriminative Latent Diffusion for Privacy-Preserving Domain Adaptation**|Jing Wang et.al|[paper](https://arxiv.org/abs/2510.00478)|-|<details><summary>detail</summary>39th Conference on Neural Information Processing Systems (NeurIPS 2025)</details>|\n", "Sim-to-real supervised domain adaptation for radioisotope identification": "|**2025-10-10**|**Sim-to-real supervised domain adaptation for radioisotope identification**|Peter Lalor et.al|[paper](https://arxiv.org/abs/2412.07069)|-|-|\n", "Domain-Adapted Pre-trained Language Models for Implicit Information Extraction in Crash Narratives": "|**2025-10-10**|**Domain-Adapted Pre-trained Language Models for Implicit Information Extraction in Crash Narratives**|Xixi Wang et.al|[paper](https://arxiv.org/abs/2510.09434)|-|-|\n", "The 1st Solution for CARE Liver Task Challenge 2025: Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation": "|**2025-10-10**|**The 1st Solution for CARE Liver Task Challenge 2025: Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation**|Jincan Lou et.al|[paper](https://arxiv.org/abs/2510.04243)|-|-|\n", "Unsupervised Multi-Source Federated Domain Adaptation under Domain Diversity through Group-Wise Discrepancy Minimization": "|**2025-10-10**|**Unsupervised Multi-Source Federated Domain Adaptation under Domain Diversity through Group-Wise Discrepancy Minimization**|Larissa Reichart et.al|[paper](https://arxiv.org/abs/2510.08150)|-|-|\n", "AB-PINNs: Adaptive-Basis Physics-Informed Neural Networks for Residual-Driven Domain Decomposition": "|**2025-10-9**|**AB-PINNs: Adaptive-Basis Physics-Informed Neural Networks for Residual-Driven Domain Decomposition**|Jonah Botvinick-Greenhouse et.al|[paper](https://arxiv.org/abs/2510.08924)|-|-|\n"}, "domain generalization": {"EReLiFM: Evidential Reliability-Aware Residual Flow Meta-Learning for Open-Set Domain Generalization under Noisy Labels": "|**2025-10-14**|**EReLiFM: Evidential Reliability-Aware Residual Flow Meta-Learning for Open-Set Domain Generalization under Noisy Labels**|Kunyu Peng et.al|[paper](https://arxiv.org/abs/2510.12687)|[code](https://github.com/KPeng9510/ERELIFM.)|<details><summary>detail</summary>The source code is available at https://github</details>|\n", "HiLoRA: Adaptive Hierarchical LoRA Routing for Training-Free Domain Generalization": "|**2025-10-14**|**HiLoRA: Adaptive Hierarchical LoRA Routing for Training-Free Domain Generalization**|Ziyi Han et.al|[paper](https://arxiv.org/abs/2510.12266)|-|-|\n", "A Review on Domain Adaption and Generative Adversarial Networks(GANs)": "|**2025-10-13**|**A Review on Domain Adaption and Generative Adversarial Networks(GANs)**|Aashish Dhawan et.al|[paper](https://arxiv.org/abs/2510.12075)|-|-|\n", "MEASURE: Multi-scale Minimal Sufficient Representation Learning for Domain Generalization in Sleep Staging": "|**2025-10-13**|**MEASURE: Multi-scale Minimal Sufficient Representation Learning for Domain Generalization in Sleep Staging**|Sangmin Jo et.al|[paper](https://arxiv.org/abs/2510.12070)|[code](https://github.com/ku-milab/Measure)|<details><summary>detail</summary>12 page</details>|\n", "Uncertainty-Aware ControlNet: Bridging Domain Gaps with Synthetic Image Generation": "|**2025-10-13**|**Uncertainty-Aware ControlNet: Bridging Domain Gaps with Synthetic Image Generation**|Joshua Niemeijer et.al|[paper](https://arxiv.org/abs/2510.11346)|-|<details><summary>detail</summary>Accepted for presentation at ICCV Workshops 2025</details>|\n", "Next Interest Flow: A Generative Pre-training Paradigm for Recommender Systems by Modeling All-domain Movelines": "|**2025-10-13**|**Next Interest Flow: A Generative Pre-training Paradigm for Recommender Systems by Modeling All-domain Movelines**|Chen Gao et.al|[paper](https://arxiv.org/abs/2510.11317)|-|-|\n", "Domain-Specific Data Generation Framework for RAG Adaptation": "|**2025-10-13**|**Domain-Specific Data Generation Framework for RAG Adaptation**|Chris Xing Tian et.al|[paper](https://arxiv.org/abs/2510.11217)|-|-|\n", "Can Tool-Integrated Reinforcement Learning Generalize Across Diverse Domains?": "|**2025-10-13**|**Can Tool-Integrated Reinforcement Learning Generalize Across Diverse Domains?**|Zhengyu Chen et.al|[paper](https://arxiv.org/abs/2510.11184)|-|-|\n", "Class-Invariant Test-Time Augmentation for Domain Generalization": "|**2025-10-12**|**Class-Invariant Test-Time Augmentation for Domain Generalization**|Zhicheng Lin et.al|[paper](https://arxiv.org/abs/2509.14420)|-|-|\n", "Latent Retrieval Augmented Generation of Cross-Domain Protein Binders": "|**2025-10-12**|**Latent Retrieval Augmented Generation of Cross-Domain Protein Binders**|Zishen Zhang et.al|[paper](https://arxiv.org/abs/2510.10480)|-|-|\n", "The 1st Solution for CARE Liver Task Challenge 2025: Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation": "|**2025-10-10**|**The 1st Solution for CARE Liver Task Challenge 2025: Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation**|Jincan Lou et.al|[paper](https://arxiv.org/abs/2510.04243)|-|-|\n", "Exploring Single Domain Generalization of LiDAR-based Semantic Segmentation under Imperfect Labels": "|**2025-10-10**|**Exploring Single Domain Generalization of LiDAR-based Semantic Segmentation under Imperfect Labels**|Weitong Kong et.al|[paper](https://arxiv.org/abs/2510.09035)|-|-|\n", "Mirror Flow Matching with Heavy-Tailed Priors for Generative Modeling on Convex Domains": "|**2025-10-9**|**Mirror Flow Matching with Heavy-Tailed Priors for Generative Modeling on Convex Domains**|Yunrui Guan et.al|[paper](https://arxiv.org/abs/2510.08929)|-|-|\n", "High-Rate Mixout: Revisiting Mixout for Robust Domain Generalization": "|**2025-10-9**|**High-Rate Mixout: Revisiting Mixout for Robust Domain Generalization**|Masih Aminbeidokhti et.al|[paper](https://arxiv.org/abs/2510.06955)|-|<details><summary>detail</summary>WACV 2026: Winter Conference on Applications of Computer Vision 2026</details>|\n", "Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations": "|**2025-10-8**|**Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations**|Ha Min Son et.al|[paper](https://arxiv.org/abs/2508.21769)|-|-|\n"}, "vision language": {"UniFusion: Vision-Language Model as Unified Encoder in Image Generation": "|**2025-10-14**|**UniFusion: Vision-Language Model as Unified Encoder in Image Generation**|Kevin Li et.al|[paper](https://arxiv.org/abs/2510.12789)|[code](https://thekevinli.github.io/unifusion/)|<details><summary>detail</summary>Project page at https://thekevinli</details>|\n", "BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models": "|**2025-10-14**|**BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models**|Peiyan Li et.al|[paper](https://arxiv.org/abs/2506.07961)|[code](https://bridgevla.github.io/)|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions": "|**2025-10-14**|**Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions**|Akash Ghosh et.al|[paper](https://arxiv.org/abs/2404.07214)|-|<details><summary>detail</summary>One of the first survey on Visual Language Models</details>|\n", "Towards General Urban Monitoring with Vision-Language Models: A Review, Evaluation, and a Research Agenda": "|**2025-10-14**|**Towards General Urban Monitoring with Vision-Language Models: A Review, Evaluation, and a Research Agenda**|Andr\u00e9 Torneiro et.al|[paper](https://arxiv.org/abs/2510.12400)|-|-|\n", "Aux-Think: Exploring Reasoning Strategies for Data-Efficient Vision-Language Navigation": "|**2025-10-14**|**Aux-Think: Exploring Reasoning Strategies for Data-Efficient Vision-Language Navigation**|Shuo Wang et.al|[paper](https://arxiv.org/abs/2505.11886)|-|<details><summary>detail</summary>Journal ref:NeurIPS 2025</details>|\n", "Vision Language Models Map Logos to Text via Semantic Entanglement in the Visual Projector": "|**2025-10-14**|**Vision Language Models Map Logos to Text via Semantic Entanglement in the Visual Projector**|Sifan Li et.al|[paper](https://arxiv.org/abs/2510.12287)|-|-|\n", "Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model": "|**2025-10-14**|**Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model**|Fuhao Li et.al|[paper](https://arxiv.org/abs/2510.12276)|[code](https://spatial-forcing.github.io/)|-|\n", "CoVLA: Comprehensive Vision-Language-Action Dataset for Autonomous Driving": "|**2025-10-14**|**CoVLA: Comprehensive Vision-Language-Action Dataset for Autonomous Driving**|Hidehisa Arai et.al|[paper](https://arxiv.org/abs/2408.10845)|[code](https://turingmotors.github.io/covla-ad/)|<details><summary>detail</summary>WACV 2025</details>|\n", "RoVer: Robot Reward Model as Test-Time Verifier for Vision-Language-Action Model": "|**2025-10-14**|**RoVer: Robot Reward Model as Test-Time Verifier for Vision-Language-Action Model**|Mingtong Dai et.al|[paper](https://arxiv.org/abs/2510.10975)|-|-|\n", "HoneyBee: Data Recipes for Vision-Language Reasoners": "|**2025-10-14**|**HoneyBee: Data Recipes for Vision-Language Reasoners**|Hritik Bansal et.al|[paper](https://arxiv.org/abs/2510.12225)|-|-|\n", "Hierarchical Reasoning with Vision-Language Models for Incident Reports from Dashcam Videos": "|**2025-10-14**|**Hierarchical Reasoning with Vision-Language Models for Incident Reports from Dashcam Videos**|Shingo Yokoi et.al|[paper](https://arxiv.org/abs/2510.12190)|[code](https://github.com/riron1206/kaggle-2COOOL-2nd-Place-Solution.)|<details><summary>detail</summary>2nd Place Winner</details>|\n", "EvolveNav: Empowering LLM-Based Vision-Language Navigation via Self-Improving Embodied Reasoning": "|**2025-10-13**|**EvolveNav: Empowering LLM-Based Vision-Language Navigation via Self-Improving Embodied Reasoning**|Bingqian Lin et.al|[paper](https://arxiv.org/abs/2506.01551)|[code](https://github.com/expectorlin/EvolveNav.)|-|\n", "Evaluating Open-Source Vision-Language Models for Multimodal Sarcasm Detection": "|**2025-10-13**|**Evaluating Open-Source Vision-Language Models for Multimodal Sarcasm Detection**|Saroj Basnet et.al|[paper](https://arxiv.org/abs/2510.11852)|[code](https://icdmw25mmai.github.io/)|<details><summary>detail</summary>ICDMW 2025 Workshop on Multimodal AI (MMAI)</details>|\n", "EvoCAD: Evolutionary CAD Code Generation with Vision Language Models": "|**2025-10-13**|**EvoCAD: Evolutionary CAD Code Generation with Vision Language Models**|Tobias Preintner et.al|[paper](https://arxiv.org/abs/2510.11631)|-|<details><summary>detail</summary>IEEE ICTAI 2025</details>|\n", "The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models": "|**2025-10-13**|**The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models**|Lijun Sheng et.al|[paper](https://arxiv.org/abs/2506.24000)|[code](https://github.com/TomSheng21/tta-vlm)|<details><summary>detail</summary>NeurIPS 2025 Datasets and Benchmarks Track</details>|\n"}}