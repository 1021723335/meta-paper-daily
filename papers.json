{"source-free": {"Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning": "|**2025-10-9**|**Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning**|Ziqi Zhang et.al|[paper](https://arxiv.org/abs/2510.08393)|-|-|\n", "ESS-Flow: Training-free guidance of flow-based models as inference in source space": "|**2025-10-7**|**ESS-Flow: Training-free guidance of flow-based models as inference in source space**|Adhithyan Kalaivanan et.al|[paper](https://arxiv.org/abs/2510.05849)|-|-|\n", "Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising": "|**2025-10-7**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|\n", "A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation": "|**2025-10-6**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|\n", "Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection": "|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|\n", "Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation": "|**2025-10-3**|**Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation**|Yucheng Wang et.al|[paper](https://arxiv.org/abs/2409.19635)|-|-|\n", "OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation": "|**2025-10-2**|**OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation**|Yiming Zhang et.al|[paper](https://arxiv.org/abs/2505.11669)|-|-|\n", "Source-Free Cross-Domain Continual Learning": "|**2025-10-2**|**Source-Free Cross-Domain Continual Learning**|Muhammad Tanzil Furqon et.al|[paper](https://arxiv.org/abs/2510.01649)|-|-|\n", "Consistent Assistant Domains Transformer for Source-free Domain Adaptation": "|**2025-10-1**|**Consistent Assistant Domains Transformer for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.01559)|[code](https://github.com/RoryShao/CADTrans.git.)|-|\n", "Source-Free Domain Adaptive Object Detection with Semantics Compensation": "|**2025-9-30**|**Source-Free Domain Adaptive Object Detection with Semantics Compensation**|Song Tang et.al|[paper](https://arxiv.org/abs/2410.05557)|-|-|\n", "DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation": "|**2025-9-29**|**DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation**|Xi Chen et.al|[paper](https://arxiv.org/abs/2509.24896)|-|-|\n", "Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation": "|**2025-9-29**|**Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|\n", "Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment": "|**2025-9-22**|**Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment**|Wenjie Liu et.al|[paper](https://arxiv.org/abs/2509.18502)|-|-|\n", "Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation": "|**2025-9-22**|**Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation**|Amirhossein Dadashzadeh et.al|[paper](https://arxiv.org/abs/2504.11669)|[code](https://github.com/Plrbear/Co-Star)|-|\n", "Prototype-Based Pseudo-Label Denoising for Source-Free Domain Adaptation in Remote Sensing Semantic Segmentation": "|**2025-9-21**|**Prototype-Based Pseudo-Label Denoising for Source-Free Domain Adaptation in Remote Sensing Semantic Segmentation**|Bin Wang et.al|[paper](https://arxiv.org/abs/2509.16942)|-|-|\n"}, "object detection": {"Ultra-Efficient On-Device Object Detection on AI-Integrated Smart Glasses with TinyissimoYOLO": "|**2025-10-9**|**Ultra-Efficient On-Device Object Detection on AI-Integrated Smart Glasses with TinyissimoYOLO**|Julian Moosmann et.al|[paper](https://arxiv.org/abs/2311.01057)|[code](https://github.com/ETH-PBL/TinyissimoYOLO)|<details><summary>detail</summary>This paper has been accepted for publication at ECCV 2024 Workshops</details>|\n", "Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models": "|**2025-10-8**|**Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models**|Peter Robicheaux et.al|[paper](https://arxiv.org/abs/2505.20612)|[code](https://github.com/roboflow/rf100-vl)|<details><summary>detail</summary>The first two authors contributed equally</details>|\n", "SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation": "|**2025-10-7**|**SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation**|Ayush Zenith et.al|[paper](https://arxiv.org/abs/2510.06596)|[code](https://github.com/ayushzenith/SDQM)|-|\n", "Enhancing Maritime Object Detection in Real-Time with RT-DETR and Data Augmentation": "|**2025-10-7**|**Enhancing Maritime Object Detection in Real-Time with RT-DETR and Data Augmentation**|Nader Nemati et.al|[paper](https://arxiv.org/abs/2510.07346)|-|-|\n", "Incremental Object Detection with Prompt-based Methods": "|**2025-10-7**|**Incremental Object Detection with Prompt-based Methods**|Matthias Neuwirth-Trapp et.al|[paper](https://arxiv.org/abs/2508.14599)|-|<details><summary>detail</summary>ICCV Workshops 2025: v2 update affiliation</details>|\n", "RICO: Two Realistic Benchmarks and an In-Depth Analysis for Incremental Learning in Object Detection": "|**2025-10-7**|**RICO: Two Realistic Benchmarks and an In-Depth Analysis for Incremental Learning in Object Detection**|Matthias Neuwirth-Trapp et.al|[paper](https://arxiv.org/abs/2508.13878)|-|<details><summary>detail</summary>ICCV Workshops 2025</details>|\n", "HOI-R1: Exploring the Potential of Multimodal Large Language Models for Human-Object Interaction Detection": "|**2025-10-7**|**HOI-R1: Exploring the Potential of Multimodal Large Language Models for Human-Object Interaction Detection**|Junwen Chen et.al|[paper](https://arxiv.org/abs/2510.05609)|[code](https://github.com/cjw2021/HOI-R1.)|-|\n", "Robust Object Detection for Autonomous Driving via Curriculum-Guided Group Relative Policy Optimization": "|**2025-10-6**|**Robust Object Detection for Autonomous Driving via Curriculum-Guided Group Relative Policy Optimization**|Xu Jia et.al|[paper](https://arxiv.org/abs/2509.22688)|-|-|\n", "Self-Supervised Representation Learning with Joint Embedding Predictive Architecture for Automotive LiDAR Object Detection": "|**2025-10-6**|**Self-Supervised Representation Learning with Joint Embedding Predictive Architecture for Automotive LiDAR Object Detection**|Haoran Zhu et.al|[paper](https://arxiv.org/abs/2501.04969)|-|-|\n", "Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection": "|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|\n", "SPEGNet: Synergistic Perception-Guided Network for Camouflaged Object Detection": "|**2025-10-6**|**SPEGNet: Synergistic Perception-Guided Network for Camouflaged Object Detection**|Baber Jan et.al|[paper](https://arxiv.org/abs/2510.04472)|[code](https://github.com/Baber-Jan/SPEGNet)|-|\n", "From Filters to VLMs: Benchmarking Defogging Methods through Object Detection and Segmentation Performance": "|**2025-10-4**|**From Filters to VLMs: Benchmarking Defogging Methods through Object Detection and Segmentation Performance**|Ardalan Aryashad et.al|[paper](https://arxiv.org/abs/2510.03906)|-|-|\n", "Cross-View Open-Vocabulary Object Detection in Aerial Imagery": "|**2025-10-4**|**Cross-View Open-Vocabulary Object Detection in Aerial Imagery**|Jyoti Kini et.al|[paper](https://arxiv.org/abs/2510.03858)|-|-|\n", "SAMSOD: Rethinking SAM Optimization for RGB-T Salient Object Detection": "|**2025-10-4**|**SAMSOD: Rethinking SAM Optimization for RGB-T Salient Object Detection**|Zhengyi Liu et.al|[paper](https://arxiv.org/abs/2510.03689)|-|<details><summary>detail</summary>Accepted by TMM</details>|\n", "Automated Defect Detection for Mass-Produced Electronic Components Based on YOLO Object Detection Models": "|**2025-10-3**|**Automated Defect Detection for Mass-Produced Electronic Components Based on YOLO Object Detection Models**|Wei-Lung Mao et.al|[paper](https://arxiv.org/abs/2510.01914)|-|-|\n"}, "domain adaptation": {"Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning": "|**2025-10-9**|**Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning**|Ziqi Zhang et.al|[paper](https://arxiv.org/abs/2510.08393)|-|-|\n", "Prepared mind, fast response: A temporal decoupling framework for adaptive knowledge orchestration in open-domain dialogue": "|**2025-10-9**|**Prepared mind, fast response: A temporal decoupling framework for adaptive knowledge orchestration in open-domain dialogue**|Jinling Gan et.al|[paper](https://arxiv.org/abs/2510.08175)|-|-|\n", "DACP: Domain-Adaptive Continual Pre-Training of Large Language Models for Phone Conversation Summarization": "|**2025-10-9**|**DACP: Domain-Adaptive Continual Pre-Training of Large Language Models for Phone Conversation Summarization**|Xue-Yong Fu et.al|[paper](https://arxiv.org/abs/2510.05858)|-|<details><summary>detail</summary>the NewSumm Workshop at EMNLP 2025</details>|\n", "DACIP-RC: Domain Adaptive Continual Instruction Pre-Training via Reading Comprehension on Business Conversations": "|**2025-10-9**|**DACIP-RC: Domain Adaptive Continual Instruction Pre-Training via Reading Comprehension on Business Conversations**|Elena Khasanova et.al|[paper](https://arxiv.org/abs/2510.08152)|-|<details><summary>detail</summary>the EMNLP 2025 Industry Track</details>|\n", "Unsupervised Multi-Source Federated Domain Adaptation under Domain Diversity through Group-Wise Discrepancy Minimization": "|**2025-10-9**|**Unsupervised Multi-Source Federated Domain Adaptation under Domain Diversity through Group-Wise Discrepancy Minimization**|Larissa Reichart et.al|[paper](https://arxiv.org/abs/2510.08150)|-|-|\n", "When Light Bends to the Collective Will: A Theory and Vision for Adaptive Photonic Scale-up Domains": "|**2025-10-9**|**When Light Bends to the Collective Will: A Theory and Vision for Adaptive Photonic Scale-up Domains**|Vamsi Addanki et.al|[paper](https://arxiv.org/abs/2510.08072)|-|-|\n", "LogAction: Consistent Cross-system Anomaly Detection through Logs via Active Domain Adaptation": "|**2025-10-9**|**LogAction: Consistent Cross-system Anomaly Detection through Logs via Active Domain Adaptation**|Chiming Duan et.al|[paper](https://arxiv.org/abs/2510.03288)|[code](https://logaction.github.io)|<details><summary>detail</summary>The 40th IEEE/ACM International Conference on Automated Software Engineering</details>|\n", "HySim-LLM: Embedding-Weighted Fine-Tuning Bounds and Manifold Denoising for Domain-Adapted LLMs": "|**2025-10-9**|**HySim-LLM: Embedding-Weighted Fine-Tuning Bounds and Manifold Denoising for Domain-Adapted LLMs**|Majid Jaberi-Douraki et.al|[paper](https://arxiv.org/abs/2510.07796)|-|-|\n", "From Noisy to Native: LLM-driven Graph Restoration for Test-Time Graph Domain Adaptation": "|**2025-10-9**|**From Noisy to Native: LLM-driven Graph Restoration for Test-Time Graph Domain Adaptation**|Xiangwei Lv et.al|[paper](https://arxiv.org/abs/2510.07762)|-|-|\n", "Self-Training with Dynamic Weighting for Robust Gradual Domain Adaptation": "|**2025-10-8**|**Self-Training with Dynamic Weighting for Robust Gradual Domain Adaptation**|Zixi Wang et.al|[paper](https://arxiv.org/abs/2501.19159)|[code](https://github.com/Dramwig/STDW.)|<details><summary>detail</summary>Accepted by NIPS 25</details>|\n", "Adaptive Stain Normalization for Cross-Domain Medical Histology": "|**2025-10-7**|**Adaptive Stain Normalization for Cross-Domain Medical Histology**|Tianyue Xu et.al|[paper](https://arxiv.org/abs/2510.06592)|[code](https://github.com/xutianyue/BeerLaNet.)|<details><summary>detail</summary>the 28th International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2025)</details>|\n", "Improving Artifact Robustness for CT Deep Learning Models Without Labeled Artifact Images via Domain Adaptation": "|**2025-10-7**|**Improving Artifact Robustness for CT Deep Learning Models Without Labeled Artifact Images via Domain Adaptation**|Justin Cheung et.al|[paper](https://arxiv.org/abs/2510.06584)|-|-|\n", "Contrastive Learning Using Graph Embeddings for Domain Adaptation of Language Models in the Process Industry": "|**2025-10-7**|**Contrastive Learning Using Graph Embeddings for Domain Adaptation of Language Models in the Process Industry**|Anastasia Zhukova et.al|[paper](https://arxiv.org/abs/2510.04631)|-|<details><summary>detail</summary>accepted to EMNLP 2025 (industry track)</details>|\n", "SKADA-Bench: Benchmarking Unsupervised Domain Adaptation Methods with Realistic Validation On Diverse Modalities": "|**2025-10-7**|**SKADA-Bench: Benchmarking Unsupervised Domain Adaptation Methods with Realistic Validation On Diverse Modalities**|Yanis Lalou et.al|[paper](https://arxiv.org/abs/2407.11676)|[code](https://github.com/scikit-adaptation/skada-bench.)|<details><summary>detail</summary>Published in Transactions on Machine Learning Research</details>|\n", "A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation": "|**2025-10-6**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|\n"}, "domain generalization": {"Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations": "|**2025-10-8**|**Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations**|Ha Min Son et.al|[paper](https://arxiv.org/abs/2508.21769)|-|-|\n", "Lemma Dilemma: On Lemma Generation Without Domain- or Language-Specific Training Data": "|**2025-10-8**|**Lemma Dilemma: On Lemma Generation Without Domain- or Language-Specific Training Data**|Olia Toporkov et.al|[paper](https://arxiv.org/abs/2510.07434)|[code](https://github.com/oltoporkov/lemma-dilemma)|-|\n", "Domain Generalization by Rejecting Extreme Augmentations": "|**2025-10-8**|**Domain Generalization by Rejecting Extreme Augmentations**|Masih Aminbeidokhti et.al|[paper](https://arxiv.org/abs/2310.06670)|[code](https://github.com/Masseeh/DCAug)|<details><summary>detail</summary>WACV 2024: Winter Conference on Applications of Computer Vision 2024</details>|\n", "High-Rate Mixout: Revisiting Mixout for Robust Domain Generalization": "|**2025-10-8**|**High-Rate Mixout: Revisiting Mixout for Robust Domain Generalization**|Masih Aminbeidokhti et.al|[paper](https://arxiv.org/abs/2510.06955)|-|<details><summary>detail</summary>WACV 2026: Winter Conference on Applications of Computer Vision 2026</details>|\n", "Redefining Generalization in Visual Domains: A Two-Axis Framework for Fake Image Detection with FusionDetect": "|**2025-10-7**|**Redefining Generalization in Visual Domains: A Two-Axis Framework for Fake Image Detection with FusionDetect**|Amirtaha Amanzadi et.al|[paper](https://arxiv.org/abs/2510.05740)|[code](http://github.com/amir-aman/FusionDetect)|<details><summary>detail</summary>Project code: http://github</details>|\n", "Domain Generalization: A Tale of Two ERMs": "|**2025-10-5**|**Domain Generalization: A Tale of Two ERMs**|Yilun Zhu et.al|[paper](https://arxiv.org/abs/2510.04441)|-|-|\n", "The best performance in the CARE 2025 -- Liver Task (LiSeg-Contrast): Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation": "|**2025-10-5**|**The best performance in the CARE 2025 -- Liver Task (LiSeg-Contrast): Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation**|Jincan Lou et.al|[paper](https://arxiv.org/abs/2510.04243)|-|-|\n", "GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Mechanism": "|**2025-10-4**|**GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Mechanism**|Hailong Yang et.al|[paper](https://arxiv.org/abs/2509.10018)|-|-|\n", "Complex Domain Approach for Reversible Data Hiding and Homomorphic Encryption: General Framework and Application to Dispersed Data": "|**2025-10-4**|**Complex Domain Approach for Reversible Data Hiding and Homomorphic Encryption: General Framework and Application to Dispersed Data**|David Megias et.al|[paper](https://arxiv.org/abs/2510.03770)|-|-|\n", "Domain Generalization for Semantic Segmentation: A Survey": "|**2025-10-3**|**Domain Generalization for Semantic Segmentation: A Survey**|Manuel Schwonberg et.al|[paper](https://arxiv.org/abs/2510.03540)|-|<details><summary>detail</summary>CVPR2025W</details>|\n", "Automated Constraint Specification for Job Scheduling by Regulating Generative Model with Domain-Specific Representation": "|**2025-10-2**|**Automated Constraint Specification for Job Scheduling by Regulating Generative Model with Domain-Specific Representation**|Yu-Zhe Shi et.al|[paper](https://arxiv.org/abs/2510.02679)|-|<details><summary>detail</summary>Accepted for publication in IEEE Transactions on Automation Science and Engineering</details>|\n", "DrKGC: Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph Completion across General and Biomedical Domains": "|**2025-10-2**|**DrKGC: Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph Completion across General and Biomedical Domains**|Yongkang Xiao et.al|[paper](https://arxiv.org/abs/2506.00708)|-|<details><summary>detail</summary>EMNLP 2025 Findings</details>|\n", "Finetune Once: Decoupling General & Domain Learning with Dynamic Boosted Annealing": "|**2025-9-30**|**Finetune Once: Decoupling General & Domain Learning with Dynamic Boosted Annealing**|Yang Tang et.al|[paper](https://arxiv.org/abs/2509.26242)|-|-|\n", "Scaling Up Temporal Domain Generalization via Temporal Experts Averaging": "|**2025-9-30**|**Scaling Up Temporal Domain Generalization via Temporal Experts Averaging**|Aoming Liu et.al|[paper](https://arxiv.org/abs/2509.26045)|-|<details><summary>detail</summary>Accepted by EMNLP 2025 main</details>|\n", "Think Less, Label Better: Multi-Stage Domain-Grounded Synthetic Data Generation for Fine-Tuning Large Language Models in Telecommunications": "|**2025-9-29**|**Think Less, Label Better: Multi-Stage Domain-Grounded Synthetic Data Generation for Fine-Tuning Large Language Models in Telecommunications**|Chenhua Shi et.al|[paper](https://arxiv.org/abs/2509.25736)|-|-|\n"}, "vision language": {"Dream to Recall: Imagination-Guided Experience Retrieval for Memory-Persistent Vision-and-Language Navigation": "|**2025-10-9**|**Dream to Recall: Imagination-Guided Experience Retrieval for Memory-Persistent Vision-and-Language Navigation**|Yunzhe Xu et.al|[paper](https://arxiv.org/abs/2510.08553)|[code](https://github.com/xyz9911/Memoir.)|-|\n", "SpatialLadder: Progressive Training for Spatial Reasoning in Vision-Language Models": "|**2025-10-9**|**SpatialLadder: Progressive Training for Spatial Reasoning in Vision-Language Models**|Hongxing Li et.al|[paper](https://arxiv.org/abs/2510.08531)|[code](https://zju-real.github.io/SpatialLadder/)|<details><summary>detail</summary>Project Page: https://zju-real</details>|\n", "Zebra-CoT: A Dataset for Interleaved Vision Language Reasoning": "|**2025-10-9**|**Zebra-CoT: A Dataset for Interleaved Vision Language Reasoning**|Ang Li et.al|[paper](https://arxiv.org/abs/2507.16746)|[code](https://huggingface.co/datasets/multimodal-reasoning-lab/Zebra-CoT)|<details><summary>detail</summary>dataset link: https://huggingface</details>|\n", "To Sink or Not to Sink: Visual Information Pathways in Large Vision-Language Models": "|**2025-10-9**|**To Sink or Not to Sink: Visual Information Pathways in Large Vision-Language Models**|Jiayun Luo et.al|[paper](https://arxiv.org/abs/2510.08510)|[code](https://davidhalladay.github.io/diysink_demo)|<details><summary>detail</summary>Preprint</details>|\n", "The Visual Iconicity Challenge: Evaluating Vision-Language Models on Sign Language Form-Meaning Mapping": "|**2025-10-9**|**The Visual Iconicity Challenge: Evaluating Vision-Language Models on Sign Language Form-Meaning Mapping**|Onur Kele\u015f et.al|[paper](https://arxiv.org/abs/2510.08482)|-|-|\n", "Looking to Learn: Token-wise Dynamic Gating for Low-Resource Vision-Language Modelling": "|**2025-10-9**|**Looking to Learn: Token-wise Dynamic Gating for Low-Resource Vision-Language Modelling**|Bianca-Mihaela Ganescu et.al|[paper](https://arxiv.org/abs/2510.08470)|-|<details><summary>detail</summary>the EMNLP 2025 BabyLM Workshop</details>|\n", "Evaluating Small Vision-Language Models on Distance-Dependent Traffic Perception": "|**2025-10-9**|**Evaluating Small Vision-Language Models on Distance-Dependent Traffic Perception**|Nikos Theodoridis et.al|[paper](https://arxiv.org/abs/2510.08352)|-|-|\n", "TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics": "|**2025-10-9**|**TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics**|Yi Han et.al|[paper](https://arxiv.org/abs/2510.07181)|-|-|\n", "Approximate Domain Unlearning for Vision-Language Models": "|**2025-10-9**|**Approximate Domain Unlearning for Vision-Language Models**|Kodai Kawamura et.al|[paper](https://arxiv.org/abs/2510.08132)|[code](https://kodaikawamura.github.io/Domain_Unlearning/.)|<details><summary>detail</summary>NeurIPS 2025 (Spotlight)</details>|\n", "Q-CLIP: Unleashing the Power of Vision-Language Models for Video Quality Assessment through Unified Cross-Modal Adaptation": "|**2025-10-9**|**Q-CLIP: Unleashing the Power of Vision-Language Models for Video Quality Assessment through Unified Cross-Modal Adaptation**|Yachun Mi et.al|[paper](https://arxiv.org/abs/2508.06092)|-|-|\n", "USIM and U0: A Vision-Language-Action Dataset and Model for General Underwater Robots": "|**2025-10-9**|**USIM and U0: A Vision-Language-Action Dataset and Model for General Underwater Robots**|Junwen Gu et.al|[paper](https://arxiv.org/abs/2510.07869)|-|-|\n", "The Role of Model Confidence on Bias Effects in Measured Uncertainties for Vision-Language Models": "|**2025-10-9**|**The Role of Model Confidence on Bias Effects in Measured Uncertainties for Vision-Language Models**|Xinyi Liu et.al|[paper](https://arxiv.org/abs/2506.16724)|-|<details><summary>detail</summary>EMNLP Findings</details>|\n", "Effective and Stealthy One-Shot Jailbreaks on Deployed Mobile Vision-Language Agents": "|**2025-10-9**|**Effective and Stealthy One-Shot Jailbreaks on Deployed Mobile Vision-Language Agents**|Renhua Ding et.al|[paper](https://arxiv.org/abs/2510.07809)|-|-|\n", "GTR-Bench: Evaluating Geo-Temporal Reasoning in Vision-Language Models": "|**2025-10-9**|**GTR-Bench: Evaluating Geo-Temporal Reasoning in Vision-Language Models**|Qinghongbing Xie et.al|[paper](https://arxiv.org/abs/2510.07791)|[code](https://github.com/X-Luffy/GTR-Bench.)|-|\n", "Can Vision Language Models Infer Human Gaze Direction? A Controlled Study": "|**2025-10-8**|**Can Vision Language Models Infer Human Gaze Direction? A Controlled Study**|Zory Zhang et.al|[paper](https://arxiv.org/abs/2506.05412)|[code](https://grow-ai-like-a-child.github.io/gaze/)|<details><summary>detail</summary>Manuscript under review</details>|\n"}}