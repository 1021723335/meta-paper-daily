{"source-free": {"Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces": "|**2025-10-22**|**Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces**|Osman Berke Guney et.al|[paper](https://arxiv.org/abs/2305.17403)|[code](https://github.com/osmanberke/SFDA-SSVEP-BCI)|-|\n", "Source-Free Object Detection with Detection Transformer": "|**2025-10-13**|**Source-Free Object Detection with Detection Transformer**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2510.11090)|-|<details><summary>detail</summary>IEEE Transactions on Image Processing</details>|\n", "Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning": "|**2025-10-9**|**Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning**|Ziqi Zhang et.al|[paper](https://arxiv.org/abs/2510.08393)|-|-|\n", "ESS-Flow: Training-free guidance of flow-based models as inference in source space": "|**2025-10-7**|**ESS-Flow: Training-free guidance of flow-based models as inference in source space**|Adhithyan Kalaivanan et.al|[paper](https://arxiv.org/abs/2510.05849)|-|-|\n", "Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising": "|**2025-10-7**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|\n", "A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation": "|**2025-10-6**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|\n", "Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection": "|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|\n", "Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation": "|**2025-10-3**|**Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation**|Yucheng Wang et.al|[paper](https://arxiv.org/abs/2409.19635)|-|-|\n", "OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation": "|**2025-10-2**|**OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation**|Yiming Zhang et.al|[paper](https://arxiv.org/abs/2505.11669)|-|-|\n", "Source-Free Cross-Domain Continual Learning": "|**2025-10-2**|**Source-Free Cross-Domain Continual Learning**|Muhammad Tanzil Furqon et.al|[paper](https://arxiv.org/abs/2510.01649)|-|-|\n", "Consistent Assistant Domains Transformer for Source-free Domain Adaptation": "|**2025-10-1**|**Consistent Assistant Domains Transformer for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.01559)|[code](https://github.com/RoryShao/CADTrans.git.)|-|\n", "Source-Free Domain Adaptive Object Detection with Semantics Compensation": "|**2025-9-30**|**Source-Free Domain Adaptive Object Detection with Semantics Compensation**|Song Tang et.al|[paper](https://arxiv.org/abs/2410.05557)|-|-|\n", "DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation": "|**2025-9-29**|**DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation**|Xi Chen et.al|[paper](https://arxiv.org/abs/2509.24896)|-|-|\n", "Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation": "|**2025-9-29**|**Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|\n", "Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment": "|**2025-9-22**|**Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment**|Wenjie Liu et.al|[paper](https://arxiv.org/abs/2509.18502)|-|-|\n"}, "object detection": {"Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR": "|**2025-10-22**|**Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR**|Adwait Chandorkar et.al|[paper](https://arxiv.org/abs/2508.00744)|-|<details><summary>detail</summary>Best Paper Award at the Embedded Vision Workshop ICCV 2025</details>|\n", "Can You Trust What You See? Alpha Channel No-Box Attacks on Video Object Detection": "|**2025-10-22**|**Can You Trust What You See? Alpha Channel No-Box Attacks on Video Object Detection**|Ariana Yi et.al|[paper](https://arxiv.org/abs/2510.19574)|-|-|\n", "Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts": "|**2025-10-22**|**Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts**|Chen Li et.al|[paper](https://arxiv.org/abs/2510.19487)|-|-|\n", "DitHub: A Modular Framework for Incremental Open-Vocabulary Object Detection": "|**2025-10-22**|**DitHub: A Modular Framework for Incremental Open-Vocabulary Object Detection**|Chiara Cappellino et.al|[paper](https://arxiv.org/abs/2503.09271)|[code](https://aimagelab.github.io/DitHub/)|<details><summary>detail</summary>the 39th Conference on Neural Information Processing Systems (NeurIPS 2025)</details>|\n", "Space Object Detection using Multi-frame Temporal Trajectory Completion Method": "|**2025-10-22**|**Space Object Detection using Multi-frame Temporal Trajectory Completion Method**|Xiaoqing Lan et.al|[paper](https://arxiv.org/abs/2510.19220)|-|-|\n", "SFGFusion: Surface Fitting Guided 3D Object Detection with 4D Radar and Camera Fusion": "|**2025-10-21**|**SFGFusion: Surface Fitting Guided 3D Object Detection with 4D Radar and Camera Fusion**|Xiaozhi Li et.al|[paper](https://arxiv.org/abs/2510.19215)|-|<details><summary>detail</summary>Submitted to Pattern Recognition</details>|\n", "Beyond Single Images: Retrieval Self-Augmented Unsupervised Camouflaged Object Detection": "|**2025-10-21**|**Beyond Single Images: Retrieval Self-Augmented Unsupervised Camouflaged Object Detection**|Ji Du et.al|[paper](https://arxiv.org/abs/2510.18437)|[code](https://github.com/xiaohainku/RISE.)|<details><summary>detail</summary>ICCV 2025</details>|\n", "Beyond Frequency: Scoring-Driven Debiasing for Object Detection via Blueprint-Prompted Image Synthesis": "|**2025-10-20**|**Beyond Frequency: Scoring-Driven Debiasing for Object Detection via Blueprint-Prompted Image Synthesis**|Xinhao Cai et.al|[paper](https://arxiv.org/abs/2510.18229)|-|-|\n", "Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation": "|**2025-10-20**|**Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation**|Masahiro Ogawa et.al|[paper](https://arxiv.org/abs/2507.13628)|-|-|\n", "When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models": "|**2025-10-20**|**When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models**|Samer Al-Hamadani et.al|[paper](https://arxiv.org/abs/2510.11302)|-|-|\n", "Monitoring Horses in Stalls: From Object to Event Detection": "|**2025-10-20**|**Monitoring Horses in Stalls: From Object to Event Detection**|Dmitrii Galimzianov et.al|[paper](https://arxiv.org/abs/2510.17409)|-|-|\n", "Towards a Generalizable Fusion Architecture for Multimodal Object Detection": "|**2025-10-19**|**Towards a Generalizable Fusion Architecture for Multimodal Object Detection**|Jad Berjawi et.al|[paper](https://arxiv.org/abs/2510.17078)|-|-|\n", "Enhancing Rotated Object Detection via Anisotropic Gaussian Bounding Box and Bhattacharyya Distance": "|**2025-10-18**|**Enhancing Rotated Object Detection via Anisotropic Gaussian Bounding Box and Bhattacharyya Distance**|Chien Thai et.al|[paper](https://arxiv.org/abs/2510.16445)|-|<details><summary>detail</summary>Neurocomputing</details>|\n", "ReCon: Region-Controllable Data Augmentation with Rectification and Alignment for Object Detection": "|**2025-10-17**|**ReCon: Region-Controllable Data Augmentation with Rectification and Alignment for Object Detection**|Haowei Zhu et.al|[paper](https://arxiv.org/abs/2510.15783)|[code](https://github.com/haoweiz23/ReCon)|<details><summary>detail</summary>NeurIPS 2025 (spotlight)</details>|\n", "UniMamba: Unified Spatial-Channel Representation Learning with Group-Efficient Mamba for LiDAR-based 3D Object Detection": "|**2025-10-17**|**UniMamba: Unified Spatial-Channel Representation Learning with Group-Efficient Mamba for LiDAR-based 3D Object Detection**|Xin Jin et.al|[paper](https://arxiv.org/abs/2503.12009)|-|<details><summary>detail</summary>CVPR2025</details>|\n"}, "domain adaptation": {"Training-Free Label Space Alignment for Universal Domain Adaptation": "|**2025-10-22**|**Training-Free Label Space Alignment for Universal Domain Adaptation**|Dujin Lee et.al|[paper](https://arxiv.org/abs/2509.17452)|-|-|\n", "Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces": "|**2025-10-22**|**Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces**|Osman Berke Guney et.al|[paper](https://arxiv.org/abs/2305.17403)|[code](https://github.com/osmanberke/SFDA-SSVEP-BCI)|-|\n", "Demystifying Domain-adaptive Post-training for Financial LLMs": "|**2025-10-21**|**Demystifying Domain-adaptive Post-training for Financial LLMs**|Zixuan Ke et.al|[paper](https://arxiv.org/abs/2501.04961)|-|<details><summary>detail</summary>EMNLP 2025 (Oral</details>|\n", "FlexiDataGen: An Adaptive LLM Framework for Dynamic Semantic Dataset Generation in Sensitive Domains": "|**2025-10-21**|**FlexiDataGen: An Adaptive LLM Framework for Dynamic Semantic Dataset Generation in Sensitive Domains**|Hamed Jelodar et.al|[paper](https://arxiv.org/abs/2510.19025)|-|-|\n", "XGen-Q: An Explainable Domain-Adaptive LLM Framework with Retrieval-Augmented Generation for Software Security": "|**2025-10-21**|**XGen-Q: An Explainable Domain-Adaptive LLM Framework with Retrieval-Augmented Generation for Software Security**|Hamed Jelodar et.al|[paper](https://arxiv.org/abs/2510.19006)|-|-|\n", "FedDEAP: Adaptive Dual-Prompt Tuning for Multi-Domain Federated Learning": "|**2025-10-21**|**FedDEAP: Adaptive Dual-Prompt Tuning for Multi-Domain Federated Learning**|Yubin Zheng et.al|[paper](https://arxiv.org/abs/2510.18837)|-|<details><summary>detail</summary>MM 2025</details>|\n", "SemiAdapt and SemiLoRA: Efficient Domain Adaptation for Transformer-based Low-Resource Language Translation with a Case Study on Irish": "|**2025-10-21**|**SemiAdapt and SemiLoRA: Efficient Domain Adaptation for Transformer-based Low-Resource Language Translation with a Case Study on Irish**|Josh McGiff et.al|[paper](https://arxiv.org/abs/2510.18725)|-|-|\n", "Towards Unsupervised Open-Set Graph Domain Adaptation via Dual Reprogramming": "|**2025-10-21**|**Towards Unsupervised Open-Set Graph Domain Adaptation via Dual Reprogramming**|Zhen Zhang et.al|[paper](https://arxiv.org/abs/2510.18363)|[code](https://github.com/cszhangzhen/GraphRTA.)|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|\n", "DAMSDAN: Distribution-Aware Multi-Source Domain Adaptation Network for Cross-Domain EEG-based Emotion Recognition": "|**2025-10-20**|**DAMSDAN: Distribution-Aware Multi-Source Domain Adaptation Network for Cross-Domain EEG-based Emotion Recognition**|Fo Hu et.al|[paper](https://arxiv.org/abs/2510.17475)|-|-|\n", "Robust Cross-Domain Adaptation in Texture Features Transferring for Wood Chip Moisture Content Prediction": "|**2025-10-19**|**Robust Cross-Domain Adaptation in Texture Features Transferring for Wood Chip Moisture Content Prediction**|Abdur Rahman et.al|[paper](https://arxiv.org/abs/2510.16832)|-|-|\n", "MOSAIC: Masked Objective with Selective Adaptation for In-domain Contrastive Learning": "|**2025-10-19**|**MOSAIC: Masked Objective with Selective Adaptation for In-domain Contrastive Learning**|Vera Pavlova et.al|[paper](https://arxiv.org/abs/2510.16797)|-|-|\n", "MedScore: Generalizable Factuality Evaluation of Free-Form Medical Answers by Domain-adapted Claim Decomposition and Verification": "|**2025-10-18**|**MedScore: Generalizable Factuality Evaluation of Free-Form Medical Answers by Domain-adapted Claim Decomposition and Verification**|Heyuan Huang et.al|[paper](https://arxiv.org/abs/2505.18452)|-|<details><summary>detail</summary>Added generalizability experiment and examples on non-medical free-form answer</details>|\n", "Instance-Aware Pseudo-Labeling and Class-Focused Contrastive Learning for Weakly Supervised Domain Adaptive Segmentation of Electron Microscopy": "|**2025-10-18**|**Instance-Aware Pseudo-Labeling and Class-Focused Contrastive Learning for Weakly Supervised Domain Adaptive Segmentation of Electron Microscopy**|Shan Xiong et.al|[paper](https://arxiv.org/abs/2510.16450)|-|-|\n", "Deep Learning Based Domain Adaptation Methods in Remote Sensing: A Comprehensive Survey": "|**2025-10-17**|**Deep Learning Based Domain Adaptation Methods in Remote Sensing: A Comprehensive Survey**|Shuchang Lyu et.al|[paper](https://arxiv.org/abs/2510.15615)|-|-|\n", "Geometric Moment Alignment for Domain Adaptation via Siegel Embeddings": "|**2025-10-16**|**Geometric Moment Alignment for Domain Adaptation via Siegel Embeddings**|Shayan Gharib et.al|[paper](https://arxiv.org/abs/2510.14666)|[code](https://github.com/shayangharib/GeoAdapt.)|-|\n"}, "domain generalization": {"Towards Context-Aware Domain Generalization: Understanding the Benefits and Limits of Marginal Transfer Learning": "|**2025-10-22**|**Towards Context-Aware Domain Generalization: Understanding the Benefits and Limits of Marginal Transfer Learning**|Jens M\u00fcller et.al|[paper](https://arxiv.org/abs/2312.10107)|-|-|\n", "Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts": "|**2025-10-22**|**Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts**|Chen Li et.al|[paper](https://arxiv.org/abs/2510.19487)|-|-|\n", "Exploring Scale Shift in Crowd Localization under the Context of Domain Generalization": "|**2025-10-22**|**Exploring Scale Shift in Crowd Localization under the Context of Domain Generalization**|Juncheng Wang et.al|[paper](https://arxiv.org/abs/2510.19330)|-|-|\n", "FlexiDataGen: An Adaptive LLM Framework for Dynamic Semantic Dataset Generation in Sensitive Domains": "|**2025-10-21**|**FlexiDataGen: An Adaptive LLM Framework for Dynamic Semantic Dataset Generation in Sensitive Domains**|Hamed Jelodar et.al|[paper](https://arxiv.org/abs/2510.19025)|-|-|\n", "XGen-Q: An Explainable Domain-Adaptive LLM Framework with Retrieval-Augmented Generation for Software Security": "|**2025-10-21**|**XGen-Q: An Explainable Domain-Adaptive LLM Framework with Retrieval-Augmented Generation for Software Security**|Hamed Jelodar et.al|[paper](https://arxiv.org/abs/2510.19006)|-|-|\n", "TreeFedDG: Alleviating Global Drift in Federated Domain Generalization for Medical Image Segmentation": "|**2025-10-20**|**TreeFedDG: Alleviating Global Drift in Federated Domain Generalization for Medical Image Segmentation**|Yucheng Song et.al|[paper](https://arxiv.org/abs/2510.18268)|-|-|\n", "Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains": "|**2025-10-20**|**Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains**|Austin Xu et.al|[paper](https://arxiv.org/abs/2510.17793)|-|-|\n", "HIDISC: A Hyperbolic Framework for Domain Generalization with Generalized Category Discovery": "|**2025-10-20**|**HIDISC: A Hyperbolic Framework for Domain Generalization with Generalized Category Discovery**|Vaibhav Rathore et.al|[paper](https://arxiv.org/abs/2510.17188)|-|<details><summary>detail</summary>Accpeted at NeurIPS (2025) Main Conference</details>|\n", "UniGTE: Unified Graph-Text Encoding for Zero-Shot Generalization across Graph Tasks and Domains": "|**2025-10-19**|**UniGTE: Unified Graph-Text Encoding for Zero-Shot Generalization across Graph Tasks and Domains**|Duo Wang et.al|[paper](https://arxiv.org/abs/2510.16885)|-|<details><summary>detail</summary>Journal ref:NeurIPS 2025</details>|\n", "Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization": "|**2025-10-19**|**Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization**|Tianxin Wei et.al|[paper](https://arxiv.org/abs/2510.16704)|[code](https://github.com/weitianxin/DCCL)|<details><summary>detail</summary>Accepted by KDD 2025</details>|\n", "Humanoid-inspired Causal Representation Learning for Domain Generalization": "|**2025-10-18**|**Humanoid-inspired Causal Representation Learning for Domain Generalization**|Ze Tao et.al|[paper](https://arxiv.org/abs/2510.16382)|[code](https://github.com/lambett/HSCM.)|-|\n", "Finetune Once: Decoupling General & Domain Learning with Dynamic Boosted Annealing": "|**2025-10-17**|**Finetune Once: Decoupling General & Domain Learning with Dynamic Boosted Annealing**|Yang Tang et.al|[paper](https://arxiv.org/abs/2509.26242)|-|-|\n", "Latent Retrieval Augmented Generation of Cross-Domain Protein Binders": "|**2025-10-16**|**Latent Retrieval Augmented Generation of Cross-Domain Protein Binders**|Zishen Zhang et.al|[paper](https://arxiv.org/abs/2510.10480)|-|-|\n", "Column Generation Using Domain-Independent Dynamic Programming": "|**2025-10-16**|**Column Generation Using Domain-Independent Dynamic Programming**|Ryo Kuroiwa et.al|[paper](https://arxiv.org/abs/2510.14317)|[code](https://github.com/domain-independent-dp/didp-rs/releases/tag/labeling)|<details><summary>detail</summary>Manuscript submitted to INFORMS Journal on Computing didp-rs code: https://github</details>|\n", "David vs. Goliath: A comparative study of different-sized LLMs for code generation in the domain of automotive scenario generation": "|**2025-10-15**|**David vs. Goliath: A comparative study of different-sized LLMs for code generation in the domain of automotive scenario generation**|Philipp Bauerfeind et.al|[paper](https://arxiv.org/abs/2510.14115)|-|-|\n"}, "vision language": {"Class-Aware Prototype Learning with Negative Contrast for Test-Time Adaptation of Vision-Language Models": "|**2025-10-22**|**Class-Aware Prototype Learning with Negative Contrast for Test-Time Adaptation of Vision-Language Models**|Xiaozhen Qiao et.al|[paper](https://arxiv.org/abs/2510.19802)|-|-|\n", "Learning Affordances at Inference-Time for Vision-Language-Action Models": "|**2025-10-22**|**Learning Affordances at Inference-Time for Vision-Language-Action Models**|Ameesh Shah et.al|[paper](https://arxiv.org/abs/2510.19752)|-|-|\n", "LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision Language Navigation in Continuous Environments": "|**2025-10-22**|**LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision Language Navigation in Continuous Environments**|Hongyu Ding et.al|[paper](https://arxiv.org/abs/2510.19655)|-|-|\n", "A Matter of Time: Revealing the Structure of Time in Vision-Language Models": "|**2025-10-22**|**A Matter of Time: Revealing the Structure of Time in Vision-Language Models**|Nidham Tekaya et.al|[paper](https://arxiv.org/abs/2510.19559)|[code](https://tekayanidham.github.io/timeline-page/.)|-|\n", "Uni-MuMER: Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition": "|**2025-10-22**|**Uni-MuMER: Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition**|Yu Li et.al|[paper](https://arxiv.org/abs/2505.23566)|[code](https://github.com/BFlameSwift/Uni-MuMER)|<details><summary>detail</summary>Accepted by NeurIPS 2025 as a spotlight</details>|\n", "GigaBrain-0: A World Model-Powered Vision-Language-Action Model": "|**2025-10-22**|**GigaBrain-0: A World Model-Powered Vision-Language-Action Model**| GigaBrain Team et.al|[paper](https://arxiv.org/abs/2510.19430)|[code](https://gigabrain0.github.io/)|<details><summary>detail</summary>https://gigabrain0</details>|\n", "Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes": "|**2025-10-22**|**Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes**|Zhiyuan Feng et.al|[paper](https://arxiv.org/abs/2510.19400)|[code](https://github.com/microsoft/MV-RoboBench)|<details><summary>detail</summary>The project and benchmark are publicly available at https://github</details>|\n", "Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey": "|**2025-10-22**|**Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey**|Weifan Guan et.al|[paper](https://arxiv.org/abs/2510.17111)|-|-|\n", "VLsI: Verbalized Layers-to-Interactions from Large to Small Vision Language Models": "|**2025-10-22**|**VLsI: Verbalized Layers-to-Interactions from Large to Small Vision Language Models**|Byung-Kwan Lee et.al|[paper](https://arxiv.org/abs/2412.01822)|[code](https://byungkwanlee.github.io/VLsI-page/)|<details><summary>detail</summary>CVPR 2025</details>|\n", "Unified Reinforcement and Imitation Learning for Vision-Language Models": "|**2025-10-22**|**Unified Reinforcement and Imitation Learning for Vision-Language Models**|Byung-Kwan Lee et.al|[paper](https://arxiv.org/abs/2510.19307)|[code](https://byungkwanlee.github.io/RIL-page)|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models": "|**2025-10-22**|**Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models**|Mingen Li et.al|[paper](https://arxiv.org/abs/2510.19268)|-|-|\n", "Semi-off-Policy Reinforcement Learning for Vision-Language Slow-Thinking Reasoning": "|**2025-10-22**|**Semi-off-Policy Reinforcement Learning for Vision-Language Slow-Thinking Reasoning**|Junhao Shen et.al|[paper](https://arxiv.org/abs/2507.16814)|-|-|\n", "MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning": "|**2025-10-22**|**MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning**|Wenhui Huang et.al|[paper](https://arxiv.org/abs/2510.18337)|-|-|\n", "OmniVIC: A Self-Improving Variable Impedance Controller with Vision-Language In-Context Learning for Safe Robotic Manipulation": "|**2025-10-22**|**OmniVIC: A Self-Improving Variable Impedance Controller with Vision-Language In-Context Learning for Safe Robotic Manipulation**|Heng Zhang et.al|[paper](https://arxiv.org/abs/2510.17150)|[code](https://sites.google.com/view/omni-vic)|<details><summary>detail</summary>Code</details>|\n", "Probing Perceptual Constancy in Large Vision-Language Models": "|**2025-10-21**|**Probing Perceptual Constancy in Large Vision-Language Models**|Haoran Sun et.al|[paper](https://arxiv.org/abs/2502.10273)|-|<details><summary>detail</summary>Accepted by ICML 2025 Workshop Building Physically Plausible World Models</details>|\n"}}