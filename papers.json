{"source-free": {"Source-Free Object Detection with Detection Transformer": "|**2025-10-13**|**Source-Free Object Detection with Detection Transformer**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2510.11090)|-|<details><summary>detail</summary>IEEE Transactions on Image Processing</details>|\n", "Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning": "|**2025-10-9**|**Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning**|Ziqi Zhang et.al|[paper](https://arxiv.org/abs/2510.08393)|-|-|\n", "ESS-Flow: Training-free guidance of flow-based models as inference in source space": "|**2025-10-7**|**ESS-Flow: Training-free guidance of flow-based models as inference in source space**|Adhithyan Kalaivanan et.al|[paper](https://arxiv.org/abs/2510.05849)|-|-|\n", "Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising": "|**2025-10-7**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|\n", "A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation": "|**2025-10-6**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|\n", "Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection": "|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|\n", "Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation": "|**2025-10-3**|**Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation**|Yucheng Wang et.al|[paper](https://arxiv.org/abs/2409.19635)|-|-|\n", "OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation": "|**2025-10-2**|**OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation**|Yiming Zhang et.al|[paper](https://arxiv.org/abs/2505.11669)|-|-|\n", "Source-Free Cross-Domain Continual Learning": "|**2025-10-2**|**Source-Free Cross-Domain Continual Learning**|Muhammad Tanzil Furqon et.al|[paper](https://arxiv.org/abs/2510.01649)|-|-|\n", "Consistent Assistant Domains Transformer for Source-free Domain Adaptation": "|**2025-10-1**|**Consistent Assistant Domains Transformer for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.01559)|[code](https://github.com/RoryShao/CADTrans.git.)|-|\n", "Source-Free Domain Adaptive Object Detection with Semantics Compensation": "|**2025-9-30**|**Source-Free Domain Adaptive Object Detection with Semantics Compensation**|Song Tang et.al|[paper](https://arxiv.org/abs/2410.05557)|-|-|\n", "DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation": "|**2025-9-29**|**DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation**|Xi Chen et.al|[paper](https://arxiv.org/abs/2509.24896)|-|-|\n", "Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation": "|**2025-9-29**|**Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|\n", "Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment": "|**2025-9-22**|**Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment**|Wenjie Liu et.al|[paper](https://arxiv.org/abs/2509.18502)|-|-|\n", "Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation": "|**2025-9-22**|**Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation**|Amirhossein Dadashzadeh et.al|[paper](https://arxiv.org/abs/2504.11669)|[code](https://github.com/Plrbear/Co-Star)|-|\n"}, "object detection": {"EdgeNavMamba: Mamba Optimized Object Detection for Energy Efficient Edge Devices": "|**2025-10-16**|**EdgeNavMamba: Mamba Optimized Object Detection for Energy Efficient Edge Devices**|Romina Aalishah et.al|[paper](https://arxiv.org/abs/2510.14946)|-|<details><summary>detail</summary>The 11th IEEE International Conference on Edge Computing and Scalable Cloud (IEEE EdgeCom 2025)</details>|\n", "CoT-PL: Visual Chain-of-Thought Reasoning Meets Pseudo-Labeling for Open-Vocabulary Object Detection": "|**2025-10-16**|**CoT-PL: Visual Chain-of-Thought Reasoning Meets Pseudo-Labeling for Open-Vocabulary Object Detection**|Hojun Choi et.al|[paper](https://arxiv.org/abs/2510.14792)|-|-|\n", "Cross-Layer Feature Self-Attention Module for Multi-Scale Object Detection": "|**2025-10-16**|**Cross-Layer Feature Self-Attention Module for Multi-Scale Object Detection**|Dingzhou Xie et.al|[paper](https://arxiv.org/abs/2510.14726)|-|-|\n", "Structured Universal Adversarial Attacks on Object Detection for Video Sequences": "|**2025-10-16**|**Structured Universal Adversarial Attacks on Object Detection for Video Sequences**|Sven Jacob et.al|[paper](https://arxiv.org/abs/2510.14460)|[code](https://github.com/jsve96/AO-Exp-Attack.)|<details><summary>detail</summary>GCPR 2025 (German Conference on Pattern Recognition)</details>|\n", "Beat Detection as Object Detection": "|**2025-10-16**|**Beat Detection as Object Detection**|Jaehoon Ahn et.al|[paper](https://arxiv.org/abs/2510.14391)|-|-|\n", "ELASTIC: Efficient Once For All Iterative Search for Object Detection on Microcontrollers": "|**2025-10-15**|**ELASTIC: Efficient Once For All Iterative Search for Object Detection on Microcontrollers**|Tony Tran et.al|[paper](https://arxiv.org/abs/2503.21999)|-|-|\n", "A Modular Object Detection System for Humanoid Robots Using YOLO": "|**2025-10-15**|**A Modular Object Detection System for Humanoid Robots Using YOLO**|Nicolas Pottier et.al|[paper](https://arxiv.org/abs/2510.13625)|-|<details><summary>detail</summary>7 Figures</details>|\n", "Fusion Meets Diverse Conditions: A High-diversity Benchmark and Baseline for UAV-based Multimodal Object Detection with Condition Cues": "|**2025-10-15**|**Fusion Meets Diverse Conditions: A High-diversity Benchmark and Baseline for UAV-based Multimodal Object Detection with Condition Cues**|Chen Chen et.al|[paper](https://arxiv.org/abs/2510.13620)|-|-|\n", "GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity": "|**2025-10-15**|**GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity**|Seongheon Park et.al|[paper](https://arxiv.org/abs/2508.19972)|-|<details><summary>detail</summary>NeurIPS 2025</details>|\n", "SHAN: Object-Level Privacy Detection via Inference on Scene Heterogeneous Graph": "|**2025-10-14**|**SHAN: Object-Level Privacy Detection via Inference on Scene Heterogeneous Graph**|Zhuohang Jiang et.al|[paper](https://arxiv.org/abs/2403.09172)|-|<details><summary>detail</summary>I would like to formally request the withdrawal of my manuscript from arXiv</details>|\n", "The Impact of Synthetic Data on Object Detection Model Performance: A Comparative Analysis with Real-World Data": "|**2025-10-14**|**The Impact of Synthetic Data on Object Detection Model Performance: A Comparative Analysis with Real-World Data**|Muammer Bay et.al|[paper](https://arxiv.org/abs/2510.12208)|[code](https://github.com/MuammerBay/omniverse-replicator-sim2real-analysis)|-|\n", "APGNet: Adaptive Prior-Guided for Underwater Camouflaged Object Detection": "|**2025-10-13**|**APGNet: Adaptive Prior-Guided for Underwater Camouflaged Object Detection**|Xinxin Huang et.al|[paper](https://arxiv.org/abs/2510.12056)|-|-|\n", "NV3D: Leveraging Spatial Shape Through Normal Vector-based 3D Object Detection": "|**2025-10-13**|**NV3D: Leveraging Spatial Shape Through Normal Vector-based 3D Object Detection**|Krittin Chaowakarn et.al|[paper](https://arxiv.org/abs/2510.11632)|-|<details><summary>detail</summary>ACM Class:I</details>|\n", "When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models": "|**2025-10-13**|**When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models**|Samer Al-Hamadani et.al|[paper](https://arxiv.org/abs/2510.11302)|-|-|\n", "Source-Free Object Detection with Detection Transformer": "|**2025-10-13**|**Source-Free Object Detection with Detection Transformer**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2510.11090)|-|<details><summary>detail</summary>IEEE Transactions on Image Processing</details>|\n"}, "domain adaptation": {"Geometric Moment Alignment for Domain Adaptation via Siegel Embeddings": "|**2025-10-16**|**Geometric Moment Alignment for Domain Adaptation via Siegel Embeddings**|Shayan Gharib et.al|[paper](https://arxiv.org/abs/2510.14666)|[code](https://github.com/shayangharib/GeoAdapt.)|-|\n", "Reinforcement Learning for Unsupervised Domain Adaptation in Spatio-Temporal Echocardiography Segmentation": "|**2025-10-15**|**Reinforcement Learning for Unsupervised Domain Adaptation in Spatio-Temporal Echocardiography Segmentation**|Arnaud Judge et.al|[paper](https://arxiv.org/abs/2510.14244)|[code](https://github.com/arnaudjudge/RL4Seg3D.)|-|\n", "VisCoP: Visual Probing for Video Domain Adaptation of Vision Language Models": "|**2025-10-15**|**VisCoP: Visual Probing for Video Domain Adaptation of Vision Language Models**|Dominick Reilly et.al|[paper](https://arxiv.org/abs/2510.13808)|-|-|\n", "Steerable Conditional Diffusion for Domain Adaptation in PET Image Reconstruction": "|**2025-10-15**|**Steerable Conditional Diffusion for Domain Adaptation in PET Image Reconstruction**|George Webber et.al|[paper](https://arxiv.org/abs/2510.13441)|-|<details><summary>detail</summary>Accepted for oral presentation at IEEE NSS MIC RTSD 2025 (submitted May 2025</details>|\n", "Rethinking Graph Domain Adaptation: A Spectral Contrastive Perspective": "|**2025-10-15**|**Rethinking Graph Domain Adaptation: A Spectral Contrastive Perspective**|Haoyu Zhang et.al|[paper](https://arxiv.org/abs/2510.13254)|-|<details><summary>detail</summary>This paper is accepted by ECML-PKDD 2025</details>|\n", "TMT: Cross-domain Semantic Segmentation with Region-adaptive Transferability Estimation": "|**2025-10-14**|**TMT: Cross-domain Semantic Segmentation with Region-adaptive Transferability Estimation**|Enming Zhang et.al|[paper](https://arxiv.org/abs/2504.05774)|-|-|\n", "Unsupervised Domain Adaptation via Content Alignment for Hippocampus Segmentation": "|**2025-10-14**|**Unsupervised Domain Adaptation via Content Alignment for Hippocampus Segmentation**|Hoda Kalabizadeh et.al|[paper](https://arxiv.org/abs/2510.13075)|-|-|\n", "Simulation-Based Pretraining and Domain Adaptation for Astronomical Time Series with Minimal Labeled Data": "|**2025-10-14**|**Simulation-Based Pretraining and Domain Adaptation for Astronomical Time Series with Minimal Labeled Data**|Rithwik Gupta et.al|[paper](https://arxiv.org/abs/2510.12958)|-|-|\n", "OmniLens: Towards Universal Lens Aberration Correction via LensLib-to-Specific Domain Adaptation": "|**2025-10-14**|**OmniLens: Towards Universal Lens Aberration Correction via LensLib-to-Specific Domain Adaptation**|Qi Jiang et.al|[paper](https://arxiv.org/abs/2409.05809)|[code](https://github.com/zju-jiangqi/OmniLens.)|<details><summary>detail</summary>The code and data will be available at https://github</details>|\n", "HiLoRA: Adaptive Hierarchical LoRA Routing for Training-Free Domain Generalization": "|**2025-10-14**|**HiLoRA: Adaptive Hierarchical LoRA Routing for Training-Free Domain Generalization**|Ziyi Han et.al|[paper](https://arxiv.org/abs/2510.12266)|-|-|\n", "Class-aware Domain Knowledge Fusion and Fission for Continual Test-Time Adaptation": "|**2025-10-14**|**Class-aware Domain Knowledge Fusion and Fission for Continual Test-Time Adaptation**|Jiahuan Zhou et.al|[paper](https://arxiv.org/abs/2510.12150)|-|-|\n", "Tracing Multilingual Knowledge Acquisition Dynamics in Domain Adaptation: A Case Study of English-Japanese Biomedical Adaptation": "|**2025-10-13**|**Tracing Multilingual Knowledge Acquisition Dynamics in Domain Adaptation: A Case Study of English-Japanese Biomedical Adaptation**|Xin Zhao et.al|[paper](https://arxiv.org/abs/2510.12115)|-|<details><summary>detail</summary>22 Pages</details>|\n", "A Review on Domain Adaption and Generative Adversarial Networks(GANs)": "|**2025-10-13**|**A Review on Domain Adaption and Generative Adversarial Networks(GANs)**|Aashish Dhawan et.al|[paper](https://arxiv.org/abs/2510.12075)|-|-|\n", "Early Detection and Reduction of Memorisation for Domain Adaptation and Instruction Tuning": "|**2025-10-13**|**Early Detection and Reduction of Memorisation for Domain Adaptation and Instruction Tuning**|Dean L. Slack et.al|[paper](https://arxiv.org/abs/2510.11372)|-|<details><summary>detail</summary>Transactions of the ACL (TACL)</details>|\n", "Domain-Specific Data Generation Framework for RAG Adaptation": "|**2025-10-13**|**Domain-Specific Data Generation Framework for RAG Adaptation**|Chris Xing Tian et.al|[paper](https://arxiv.org/abs/2510.11217)|-|-|\n"}, "domain generalization": {"Latent Retrieval Augmented Generation of Cross-Domain Protein Binders": "|**2025-10-16**|**Latent Retrieval Augmented Generation of Cross-Domain Protein Binders**|Zishen Zhang et.al|[paper](https://arxiv.org/abs/2510.10480)|-|-|\n", "Column Generation Using Domain-Independent Dynamic Programming": "|**2025-10-16**|**Column Generation Using Domain-Independent Dynamic Programming**|Ryo Kuroiwa et.al|[paper](https://arxiv.org/abs/2510.14317)|[code](https://github.com/domain-independent-dp/didp-rs/releases/tag/labeling)|<details><summary>detail</summary>Manuscript submitted to INFORMS Journal on Computing didp-rs code: https://github</details>|\n", "David vs. Goliath: A comparative study of different-sized LLMs for code generation in the domain of automotive scenario generation": "|**2025-10-15**|**David vs. Goliath: A comparative study of different-sized LLMs for code generation in the domain of automotive scenario generation**|Philipp Bauerfeind et.al|[paper](https://arxiv.org/abs/2510.14115)|-|-|\n", "EReLiFM: Evidential Reliability-Aware Residual Flow Meta-Learning for Open-Set Domain Generalization under Noisy Labels": "|**2025-10-14**|**EReLiFM: Evidential Reliability-Aware Residual Flow Meta-Learning for Open-Set Domain Generalization under Noisy Labels**|Kunyu Peng et.al|[paper](https://arxiv.org/abs/2510.12687)|[code](https://github.com/KPeng9510/ERELIFM.)|<details><summary>detail</summary>The source code is available at https://github</details>|\n", "HiLoRA: Adaptive Hierarchical LoRA Routing for Training-Free Domain Generalization": "|**2025-10-14**|**HiLoRA: Adaptive Hierarchical LoRA Routing for Training-Free Domain Generalization**|Ziyi Han et.al|[paper](https://arxiv.org/abs/2510.12266)|-|-|\n", "A Review on Domain Adaption and Generative Adversarial Networks(GANs)": "|**2025-10-13**|**A Review on Domain Adaption and Generative Adversarial Networks(GANs)**|Aashish Dhawan et.al|[paper](https://arxiv.org/abs/2510.12075)|-|-|\n", "MEASURE: Multi-scale Minimal Sufficient Representation Learning for Domain Generalization in Sleep Staging": "|**2025-10-13**|**MEASURE: Multi-scale Minimal Sufficient Representation Learning for Domain Generalization in Sleep Staging**|Sangmin Jo et.al|[paper](https://arxiv.org/abs/2510.12070)|[code](https://github.com/ku-milab/Measure)|<details><summary>detail</summary>12 page</details>|\n", "Uncertainty-Aware ControlNet: Bridging Domain Gaps with Synthetic Image Generation": "|**2025-10-13**|**Uncertainty-Aware ControlNet: Bridging Domain Gaps with Synthetic Image Generation**|Joshua Niemeijer et.al|[paper](https://arxiv.org/abs/2510.11346)|-|<details><summary>detail</summary>Accepted for presentation at ICCV Workshops 2025</details>|\n", "Next Interest Flow: A Generative Pre-training Paradigm for Recommender Systems by Modeling All-domain Movelines": "|**2025-10-13**|**Next Interest Flow: A Generative Pre-training Paradigm for Recommender Systems by Modeling All-domain Movelines**|Chen Gao et.al|[paper](https://arxiv.org/abs/2510.11317)|-|-|\n", "Domain-Specific Data Generation Framework for RAG Adaptation": "|**2025-10-13**|**Domain-Specific Data Generation Framework for RAG Adaptation**|Chris Xing Tian et.al|[paper](https://arxiv.org/abs/2510.11217)|-|-|\n", "Can Tool-Integrated Reinforcement Learning Generalize Across Diverse Domains?": "|**2025-10-13**|**Can Tool-Integrated Reinforcement Learning Generalize Across Diverse Domains?**|Zhengyu Chen et.al|[paper](https://arxiv.org/abs/2510.11184)|-|-|\n", "Class-Invariant Test-Time Augmentation for Domain Generalization": "|**2025-10-12**|**Class-Invariant Test-Time Augmentation for Domain Generalization**|Zhicheng Lin et.al|[paper](https://arxiv.org/abs/2509.14420)|-|-|\n", "The 1st Solution for CARE Liver Task Challenge 2025: Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation": "|**2025-10-10**|**The 1st Solution for CARE Liver Task Challenge 2025: Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation**|Jincan Lou et.al|[paper](https://arxiv.org/abs/2510.04243)|-|-|\n", "Exploring Single Domain Generalization of LiDAR-based Semantic Segmentation under Imperfect Labels": "|**2025-10-10**|**Exploring Single Domain Generalization of LiDAR-based Semantic Segmentation under Imperfect Labels**|Weitong Kong et.al|[paper](https://arxiv.org/abs/2510.09035)|-|-|\n", "Mirror Flow Matching with Heavy-Tailed Priors for Generative Modeling on Convex Domains": "|**2025-10-9**|**Mirror Flow Matching with Heavy-Tailed Priors for Generative Modeling on Convex Domains**|Yunrui Guan et.al|[paper](https://arxiv.org/abs/2510.08929)|-|-|\n"}, "vision language": {"From Pixels to Words -- Towards Native Vision-Language Primitives at Scale": "|**2025-10-16**|**From Pixels to Words -- Towards Native Vision-Language Primitives at Scale**|Haiwen Diao et.al|[paper](https://arxiv.org/abs/2510.14979)|[code](https://github.com/EvolvingLMMs-Lab/NEO.)|-|\n", "VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation": "|**2025-10-16**|**VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation**|Han Zhao et.al|[paper](https://arxiv.org/abs/2510.14902)|[code](https://vla-2.github.io.)|-|\n", "QDepth-VLA: Quantized Depth Prediction as Auxiliary Supervision for Vision-Language-Action Models": "|**2025-10-16**|**QDepth-VLA: Quantized Depth Prediction as Auxiliary Supervision for Vision-Language-Action Models**|Yixuan Li et.al|[paper](https://arxiv.org/abs/2510.14836)|-|-|\n", "PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model": "|**2025-10-16**|**PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model**|Cheng Cui et.al|[paper](https://arxiv.org/abs/2510.14528)|-|-|\n", "From Perception to Cognition: A Survey of Vision-Language Interactive Reasoning in Multimodal Large Language Models": "|**2025-10-16**|**From Perception to Cognition: A Survey of Vision-Language Interactive Reasoning in Multimodal Large Language Models**|Chenyue Zhou et.al|[paper](https://arxiv.org/abs/2509.25373)|-|-|\n", "Hi-Agent: Hierarchical Vision-Language Agents for Mobile Device Control": "|**2025-10-16**|**Hi-Agent: Hierarchical Vision-Language Agents for Mobile Device Control**|Zhe Wu et.al|[paper](https://arxiv.org/abs/2510.14388)|-|-|\n", "SUM-AgriVLN: Spatial Understanding Memory for Agricultural Vision-and-Language Navigation": "|**2025-10-16**|**SUM-AgriVLN: Spatial Understanding Memory for Agricultural Vision-and-Language Navigation**|Xiaobei Zhao et.al|[paper](https://arxiv.org/abs/2510.14357)|[code](https://github.com/AlexTraveling/SUM-AgriVLN.)|-|\n", "Falcon: A Remote Sensing Vision-Language Foundation Model (Technical Report)": "|**2025-10-16**|**Falcon: A Remote Sensing Vision-Language Foundation Model (Technical Report)**|Kelu Yao et.al|[paper](https://arxiv.org/abs/2503.11070)|[code](https://github.com/TianHuiLab/Falcon,)|-|\n", "Vision-Centric Activation and Coordination for Multimodal Large Language Models": "|**2025-10-16**|**Vision-Centric Activation and Coordination for Multimodal Large Language Models**|Yunnan Wang et.al|[paper](https://arxiv.org/abs/2510.14349)|-|<details><summary>detail</summary>Under Review</details>|\n", "Watermarking for Factuality: Guiding Vision-Language Models Toward Truth via Tri-layer Contrastive Decoding": "|**2025-10-16**|**Watermarking for Factuality: Guiding Vision-Language Models Toward Truth via Tri-layer Contrastive Decoding**|Kyungryul Back et.al|[paper](https://arxiv.org/abs/2510.14304)|[code](https://github.com/KR-0822/TCD)|<details><summary>detail</summary>EMNLP 2025 Findings</details>|\n", "Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning": "|**2025-10-16**|**Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning**|Weijie Shen et.al|[paper](https://arxiv.org/abs/2510.14300)|-|-|\n", "Mitigating Hallucinations in Vision-Language Models through Image-Guided Head Suppression": "|**2025-10-15**|**Mitigating Hallucinations in Vision-Language Models through Image-Guided Head Suppression**|Sreetama Sarkar et.al|[paper](https://arxiv.org/abs/2505.16411)|[code](https://github.com/YUECHE77/SPIN.)|-|\n", "Efficient Few-Shot Learning in Remote Sensing: Fusing Vision and Vision-Language Models": "|**2025-10-15**|**Efficient Few-Shot Learning in Remote Sensing: Fusing Vision and Vision-Language Models**|Jia Yun Chua et.al|[paper](https://arxiv.org/abs/2510.13993)|-|-|\n", "VisCoP: Visual Probing for Video Domain Adaptation of Vision Language Models": "|**2025-10-15**|**VisCoP: Visual Probing for Video Domain Adaptation of Vision Language Models**|Dominick Reilly et.al|[paper](https://arxiv.org/abs/2510.13808)|-|-|\n", "InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy": "|**2025-10-15**|**InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy**|Xinyi Chen et.al|[paper](https://arxiv.org/abs/2510.13778)|[code](https://github.com/InternRobotics/InternVLA-M1.)|<details><summary>detail</summary>Technical report</details>|\n"}}