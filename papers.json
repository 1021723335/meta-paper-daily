{"source-free": {"Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity": "|**2026-1-24**|**Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity**|Harsharaj Pathak et.al|[paper](https://arxiv.org/abs/2601.17408)|-|-|\n", "Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results": "|**2026-1-23**|**Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results**|Rohan Palanikumar et.al|[paper](https://arxiv.org/abs/2511.00752)|-|-|\n", "Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection": "|**2026-1-20**|**Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2511.07301)|-|<details><summary>detail</summary>AAAI 2026</details>|\n", "Towards Unbiased Source-Free Object Detection via Vision Foundation Models": "|**2026-1-19**|**Towards Unbiased Source-Free Object Detection via Vision Foundation Models**|Zhi Cai et.al|[paper](https://arxiv.org/abs/2601.12765)|-|-|\n", "Unified Source-Free Domain Adaptation": "|**2026-1-18**|**Unified Source-Free Domain Adaptation**|Song Tang et.al|[paper](https://arxiv.org/abs/2403.07601)|[code](https://github.com/tntek/CausalDA.)|-|\n", "GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher and Gaussian Mixture Model-Based Pseudo-Labeling": "|**2026-1-16**|**GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher and Gaussian Mixture Model-Based Pseudo-Labeling**|Pascal Schlachter et.al|[paper](https://arxiv.org/abs/2601.11161)|[code](https://github.com/pascalschlachter/GMM-COMET.)|-|\n", "SfMamba: Efficient Source-Free Domain Adaptation via Selective Scan Modeling": "|**2026-1-13**|**SfMamba: Efficient Source-Free Domain Adaptation via Selective Scan Modeling**|Xi Chen et.al|[paper](https://arxiv.org/abs/2601.08608)|[code](https://github.com/chenxi52/SfMamba.)|-|\n", "Source-Free Domain Adaptation for Geospatial Point Cloud Semantic Segmentation": "|**2026-1-13**|**Source-Free Domain Adaptation for Geospatial Point Cloud Semantic Segmentation**|Yuan Gao et.al|[paper](https://arxiv.org/abs/2601.08375)|-|-|\n", "Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based Curriculum Learning": "|**2026-1-5**|**Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based Curriculum Learning**|Dongjie Chen et.al|[paper](https://arxiv.org/abs/2405.18376)|[code](https://github.com/Dong-Jie-Chen/RCL.)|-|\n", "Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection": "|**2025-12-24**|**Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection**|Sairam VCR et.al|[paper](https://arxiv.org/abs/2512.17514)|-|-|\n", "Exploiting Radio Frequency Fingerprints for Device Identification: Tackling Cross-receiver Challenges in the Source-data-free Scenario": "|**2025-12-18**|**Exploiting Radio Frequency Fingerprints for Device Identification: Tackling Cross-receiver Challenges in the Source-data-free Scenario**|Liu Yang et.al|[paper](https://arxiv.org/abs/2512.16648)|-|<details><summary>detail</summary>IEEE Transactions on Mobile Computing</details>|\n", "VocSim: A Training-free Benchmark for Zero-shot Content Identity in Single-source Audio": "|**2025-12-10**|**VocSim: A Training-free Benchmark for Zero-shot Content Identity in Single-source Audio**|Maris Basha et.al|[paper](https://arxiv.org/abs/2512.10120)|-|-|\n", "FedSCAl: Leveraging Server and Client Alignment for Unsupervised Federated Source-Free Domain Adaptation": "|**2025-12-7**|**FedSCAl: Leveraging Server and Client Alignment for Unsupervised Federated Source-Free Domain Adaptation**|M Yashwanth et.al|[paper](https://arxiv.org/abs/2512.06738)|-|<details><summary>detail</summary>Winter Conference on Applications of Computer Vision (WACV) 2026</details>|\n", "Source-free Video Domain Adaptation by Learning from Noisy Labels": "|**2025-11-28**|**Source-free Video Domain Adaptation by Learning from Noisy Labels**|Avijit Dasgupta et.al|[paper](https://arxiv.org/abs/2311.18572)|[code](https://avijit9.github.io/CleanAdapt.)|<details><summary>detail</summary>Our extended ICVGIP paper is now accepted in Pattern Recognition</details>|\n", "Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation": "|**2025-11-24**|**Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation**|Huisoo Lee et.al|[paper](https://arxiv.org/abs/2511.19147)|-|-|\n"}, "object detection": {"EFSI-DETR: Efficient Frequency-Semantic Integration for Real-Time Small Object Detection in UAV Imagery": "|**2026-1-26**|**EFSI-DETR: Efficient Frequency-Semantic Integration for Real-Time Small Object Detection in UAV Imagery**|Yu Xia et.al|[paper](https://arxiv.org/abs/2601.18597)|-|-|\n", "From Filters to VLMs: Benchmarking Defogging Methods through Object Detection and Segmentation Performance": "|**2026-1-26**|**From Filters to VLMs: Benchmarking Defogging Methods through Object Detection and Segmentation Performance**|Ardalan Aryashad et.al|[paper](https://arxiv.org/abs/2510.03906)|[code](https://aradfir.github.io/filters-to-vlms-defogging-page/)|<details><summary>detail</summary>WACV 2026 Proceedings (Oral)</details>|\n", "Real-Time Object Detection Meets DINOv3": "|**2026-1-26**|**Real-Time Object Detection Meets DINOv3**|Shihua Huang et.al|[paper](https://arxiv.org/abs/2509.20787)|[code](https://github.com/Intellindust-AI-Lab/DEIMv2)|<details><summary>detail</summary>Source code available at https://github</details>|\n", "YOLO-DS: Fine-Grained Feature Decoupling via Dual-Statistic Synergy Operator for Object Detection": "|**2026-1-26**|**YOLO-DS: Fine-Grained Feature Decoupling via Dual-Statistic Synergy Operator for Object Detection**|Lin Huang et.al|[paper](https://arxiv.org/abs/2601.18172)|-|-|\n", "Cross-Level Sensor Fusion with Object Lists via Transformer for 3D Object Detection": "|**2026-1-25**|**Cross-Level Sensor Fusion with Object Lists via Transformer for 3D Object Detection**|Xiangzhong Liu et.al|[paper](https://arxiv.org/abs/2512.12884)|-|-|\n", "Exploiting Unlabeled Data with Multiple Expert Teachers for Open Vocabulary Aerial Object Detection and Its Orientation Adaptation": "|**2026-1-24**|**Exploiting Unlabeled Data with Multiple Expert Teachers for Open Vocabulary Aerial Object Detection and Its Orientation Adaptation**|Yan Li et.al|[paper](https://arxiv.org/abs/2411.02057)|[code](https://github.com/VisionXLab/CastDet.)|<details><summary>detail</summary>Accepted by International Journal of Computer Vision (IJCV'26)</details>|\n", "M2I2HA: Multi-modal Object Detection Based on Intra- and Inter-Modal Hypergraph Attention": "|**2026-1-24**|**M2I2HA: Multi-modal Object Detection Based on Intra- and Inter-Modal Hypergraph Attention**|Xiaofan Yang et.al|[paper](https://arxiv.org/abs/2601.14776)|-|-|\n", "UltraFlwr -- An Efficient Federated Surgical Object Detection Framework": "|**2026-1-23**|**UltraFlwr -- An Efficient Federated Surgical Object Detection Framework**|Yang Li et.al|[paper](https://arxiv.org/abs/2503.15161)|[code](https://github.com/KCL-BMEIS/UltraFlwr.)|-|\n", "Boundary and Position Information Mining for Aerial Small Object Detection": "|**2026-1-23**|**Boundary and Position Information Mining for Aerial Small Object Detection**|Rongxin Huang et.al|[paper](https://arxiv.org/abs/2601.16617)|-|-|\n", "YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection": "|**2026-1-22**|**YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection**|Ori Meiraz et.al|[paper](https://arxiv.org/abs/2511.13344)|-|<details><summary>detail</summary>1 figure</details>|\n", "Performance-guided Reinforced Active Learning for Object Detection": "|**2026-1-22**|**Performance-guided Reinforced Active Learning for Object Detection**|Zhixuan Liang et.al|[paper](https://arxiv.org/abs/2601.15688)|-|<details><summary>detail</summary>Accepted by ICASSP 2026</details>|\n", "Debate-Enhanced Pseudo Labeling and Frequency-Aware Progressive Debiasing for Weakly-Supervised Camouflaged Object Detection with Scribble Annotations": "|**2026-1-21**|**Debate-Enhanced Pseudo Labeling and Frequency-Aware Progressive Debiasing for Weakly-Supervised Camouflaged Object Detection with Scribble Annotations**|Jiawei Ge et.al|[paper](https://arxiv.org/abs/2512.20260)|-|-|\n", "A Training-Free Guess What Vision Language Model from Snippets to Open-Vocabulary Object Detection": "|**2026-1-21**|**A Training-Free Guess What Vision Language Model from Snippets to Open-Vocabulary Object Detection**|Guiying Zhu et.al|[paper](https://arxiv.org/abs/2601.11910)|-|-|\n", "A comprehensive overview of deep learning models for object detection from videos/images": "|**2026-1-21**|**A comprehensive overview of deep learning models for object detection from videos/images**|Sukana Zulfqar et.al|[paper](https://arxiv.org/abs/2601.14677)|-|<details><summary>detail</summary>N/A</details>|\n", "Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection": "|**2026-1-20**|**Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2511.07301)|-|<details><summary>detail</summary>AAAI 2026</details>|\n"}, "domain adaptation": {"Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation": "|**2026-1-26**|**Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation**|Zihao Wang et.al|[paper](https://arxiv.org/abs/2601.18623)|-|<details><summary>detail</summary>Paper accepted as a conference paper at ICLR 2026</details>|\n", "When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs": "|**2026-1-26**|**When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs**|Junyi Zou et.al|[paper](https://arxiv.org/abs/2601.18350)|-|-|\n", "Learning Fair Domain Adaptation with Virtual Label Distribution": "|**2026-1-26**|**Learning Fair Domain Adaptation with Virtual Label Distribution**|Yuguang Zhang et.al|[paper](https://arxiv.org/abs/2601.18171)|-|<details><summary>detail</summary>ICASSP 2026</details>|\n", "Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity": "|**2026-1-24**|**Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity**|Harsharaj Pathak et.al|[paper](https://arxiv.org/abs/2601.17408)|-|-|\n", "Semi-Supervised Domain Adaptation with Latent Diffusion for Pathology Image Classification": "|**2026-1-23**|**Semi-Supervised Domain Adaptation with Latent Diffusion for Pathology Image Classification**|Tengyue Zhang et.al|[paper](https://arxiv.org/abs/2601.17228)|-|-|\n", "Sim-to-Real Transfer via a Style-Identified Cycle Consistent Generative Adversarial Network: Zero-Shot Deployment on Robotic Manipulators through Visual Domain Adaptation": "|**2026-1-23**|**Sim-to-Real Transfer via a Style-Identified Cycle Consistent Generative Adversarial Network: Zero-Shot Deployment on Robotic Manipulators through Visual Domain Adaptation**|Luc\u00eda G\u00fcitta-L\u00f3pez et.al|[paper](https://arxiv.org/abs/2601.16677)|-|<details><summary>detail</summary>ACM Class:I</details>|\n", "SONAR: Self-Distilled Continual Pre-training for Domain Adaptive Audio Representation": "|**2026-1-23**|**SONAR: Self-Distilled Continual Pre-training for Domain Adaptive Audio Representation**|Yizhou Zhang et.al|[paper](https://arxiv.org/abs/2509.15703)|-|<details><summary>detail</summary>ICASSP 2026</details>|\n", "Multi-View Projection for Unsupervised Domain Adaptation in 3D Semantic Segmentation": "|**2026-1-22**|**Multi-View Projection for Unsupervised Domain Adaptation in 3D Semantic Segmentation**|Andrew Caunes et.al|[paper](https://arxiv.org/abs/2505.15545)|-|-|\n", "EfficientXpert: Efficient Domain Adaptation for Large Language Models via Propagation-Aware Pruning": "|**2026-1-21**|**EfficientXpert: Efficient Domain Adaptation for Large Language Models via Propagation-Aware Pruning**|Songlin Zhao et.al|[paper](https://arxiv.org/abs/2511.19935)|-|-|\n", "BEST-RQ-Based Self-Supervised Learning for Whisper Domain Adaptation": "|**2026-1-21**|**BEST-RQ-Based Self-Supervised Learning for Whisper Domain Adaptation**|Rapha\u00ebl Bagat et.al|[paper](https://arxiv.org/abs/2510.24570)|-|<details><summary>detail</summary>ICASSP 2026</details>|\n", "Transfer Learning from One Cancer to Another via Deep Learning Domain Adaptation": "|**2026-1-21**|**Transfer Learning from One Cancer to Another via Deep Learning Domain Adaptation**|Justin Cheung et.al|[paper](https://arxiv.org/abs/2601.14678)|-|-|\n", "Improving Artifact Robustness for CT Deep Learning Models Without Labeled Artifact Images via Domain Adaptation": "|**2026-1-20**|**Improving Artifact Robustness for CT Deep Learning Models Without Labeled Artifact Images via Domain Adaptation**|Justin Cheung et.al|[paper](https://arxiv.org/abs/2510.06584)|-|-|\n", "XD-MAP: Cross-Modal Domain Adaptation using Semantic Parametric Mapping": "|**2026-1-20**|**XD-MAP: Cross-Modal Domain Adaptation using Semantic Parametric Mapping**|Frank Bieder et.al|[paper](https://arxiv.org/abs/2601.14477)|-|-|\n", "Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law": "|**2026-1-20**|**Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law**|Ali Hamza Bashir et.al|[paper](https://arxiv.org/abs/2601.14160)|-|-|\n", "Back2Color: Domain-Adaptive Synthetic-to-Real Monocular Depth Estimation for Dynamic Traffic Scenes": "|**2026-1-20**|**Back2Color: Domain-Adaptive Synthetic-to-Real Monocular Depth Estimation for Dynamic Traffic Scenes**|Yufan Zhu et.al|[paper](https://arxiv.org/abs/2406.07741)|-|-|\n"}, "domain generalization": {"Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents": "|**2026-1-26**|**Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents**|Zhihan Liu et.al|[paper](https://arxiv.org/abs/2601.18217)|-|-|\n", "Domain Generalization with Quantum Enhancement for Medical Image Classification: A Lightweight Approach for Cross-Center Deployment": "|**2026-1-25**|**Domain Generalization with Quantum Enhancement for Medical Image Classification: A Lightweight Approach for Cross-Center Deployment**|Jingsong Xia et.al|[paper](https://arxiv.org/abs/2601.17862)|-|-|\n", "Stylizing ViT: Anatomy-Preserving Instance Style Transfer for Domain Generalization": "|**2026-1-24**|**Stylizing ViT: Anatomy-Preserving Instance Style Transfer for Domain Generalization**|Sebastian Doerrich et.al|[paper](https://arxiv.org/abs/2601.17586)|[code](https://github.com/sdoerrich97/stylizing-vit)|<details><summary>detail</summary>23rd IEEE International Symposium on Biomedical Imaging (IEEE ISBI 2026)</details>|\n", "Revisiting Invariant Learning for Out-of-Domain Generalization on Multi-Site Mammogram Datasets": "|**2026-1-24**|**Revisiting Invariant Learning for Out-of-Domain Generalization on Multi-Site Mammogram Datasets**|Hung Q. Vo et.al|[paper](https://arxiv.org/abs/2503.06759)|-|-|\n", "Sim-to-Real Transfer via a Style-Identified Cycle Consistent Generative Adversarial Network: Zero-Shot Deployment on Robotic Manipulators through Visual Domain Adaptation": "|**2026-1-23**|**Sim-to-Real Transfer via a Style-Identified Cycle Consistent Generative Adversarial Network: Zero-Shot Deployment on Robotic Manipulators through Visual Domain Adaptation**|Luc\u00eda G\u00fcitta-L\u00f3pez et.al|[paper](https://arxiv.org/abs/2601.16677)|-|<details><summary>detail</summary>ACM Class:I</details>|\n", "StealthGraph: Exposing Domain-Specific Risks in LLMs through Knowledge-Graph-Guided Harmful Prompt Generation": "|**2026-1-23**|**StealthGraph: Exposing Domain-Specific Risks in LLMs through Knowledge-Graph-Guided Harmful Prompt Generation**|Huawei Zheng et.al|[paper](https://arxiv.org/abs/2601.04740)|-|-|\n", "Experience with Single Domain Generalization in Real World Medical Imaging Deployments": "|**2026-1-22**|**Experience with Single Domain Generalization in Real World Medical Imaging Deployments**|Ayan Banerjee et.al|[paper](https://arxiv.org/abs/2601.16359)|-|<details><summary>detail</summary>AAAI 2026 Innovative Applications of Artificial Intelligence</details>|\n", "MMGRid: Navigating Temporal-aware and Cross-domain Generative Recommendation via Model Merging": "|**2026-1-22**|**MMGRid: Navigating Temporal-aware and Cross-domain Generative Recommendation via Model Merging**|Tianjun Wei et.al|[paper](https://arxiv.org/abs/2601.15930)|[code](https://github.com/Joinn99/MMGRid)|<details><summary>detail</summary>https://github</details>|\n", "Region-aware Spatiotemporal Modeling with Collaborative Domain Generalization for Cross-Subject EEG Emotion Recognition": "|**2026-1-21**|**Region-aware Spatiotemporal Modeling with Collaborative Domain Generalization for Cross-Subject EEG Emotion Recognition**|Weiwei Wu et.al|[paper](https://arxiv.org/abs/2601.15615)|[code](https://github.com/RyanLi-X/RSM-CoDG.)|-|\n", "From Canopy to Ground via ForestGen3D: Learning Cross-Domain Generation of 3D Forest Structure from Aerial-to-Terrestrial LiDAR": "|**2026-1-21**|**From Canopy to Ground via ForestGen3D: Learning Cross-Domain Generation of 3D Forest Structure from Aerial-to-Terrestrial LiDAR**|Juan Castorena et.al|[paper](https://arxiv.org/abs/2509.16346)|-|-|\n", "Reliability by design: quantifying and eliminating fabrication risk in LLMs. From generative to consultative AI: a comparative analysis in the legal domain and lessons for high-stakes knowledge bases": "|**2026-1-21**|**Reliability by design: quantifying and eliminating fabrication risk in LLMs. From generative to consultative AI: a comparative analysis in the legal domain and lessons for high-stakes knowledge bases**|Alex Dantart et.al|[paper](https://arxiv.org/abs/2601.15476)|-|-|\n", "Ego4OOD: Rethinking Egocentric Video Domain Generalization via Covariate Shift Scoring": "|**2026-1-21**|**Ego4OOD: Rethinking Egocentric Video Domain Generalization via Covariate Shift Scoring**|Zahra Vaseqi et.al|[paper](https://arxiv.org/abs/2601.17056)|-|-|\n", "Reinforcement Learning for Chain of Thought Compression with One-Domain-to-All Generalization": "|**2026-1-21**|**Reinforcement Learning for Chain of Thought Compression with One-Domain-to-All Generalization**|Hanyu Li et.al|[paper](https://arxiv.org/abs/2601.06052)|-|-|\n", "Log anomaly detection via Meta Learning and Prototypical Networks for Cross domain generalization": "|**2026-1-20**|**Log anomaly detection via Meta Learning and Prototypical Networks for Cross domain generalization**|Krishna Sharma et.al|[paper](https://arxiv.org/abs/2601.14336)|-|-|\n", "From Chains to Graphs: Self-Structured Reasoning for General-Domain LLMs": "|**2026-1-19**|**From Chains to Graphs: Self-Structured Reasoning for General-Domain LLMs**|Yingjian Chen et.al|[paper](https://arxiv.org/abs/2601.03597)|-|-|\n"}, "vision language": {"A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models": "|**2026-1-26**|**A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models**|Shihab Aaqil Ahamed et.al|[paper](https://arxiv.org/abs/2510.26441)|-|<details><summary>detail</summary>ICLR 2026</details>|\n", "Cross-Platform Scaling of Vision-Language-Action Models from Edge to Cloud GPUs": "|**2026-1-26**|**Cross-Platform Scaling of Vision-Language-Action Models from Edge to Cloud GPUs**|Amir Taherin et.al|[paper](https://arxiv.org/abs/2509.11480)|-|<details><summary>detail</summary>To appear in the Asilomar Conference on Signals</details>|\n", "DV-VLN: Dual Verification for Reliable LLM-Based Vision-and-Language Navigation": "|**2026-1-26**|**DV-VLN: Dual Verification for Reliable LLM-Based Vision-and-Language Navigation**|Zijun Li et.al|[paper](https://arxiv.org/abs/2601.18492)|[code](https://github.com/PlumJun/DV-VLN.)|-|\n", "SG-CADVLM: A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation": "|**2026-1-26**|**SG-CADVLM: A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation**|Hongyi Zhao et.al|[paper](https://arxiv.org/abs/2601.18442)|-|-|\n", "GlobalGeoTree: A Multi-Granular Vision-Language Dataset for Global Tree Species Classification": "|**2026-1-26**|**GlobalGeoTree: A Multi-Granular Vision-Language Dataset for Global Tree Species Classification**|Yang Mu et.al|[paper](https://arxiv.org/abs/2505.12513)|-|-|\n", "Ask Me Again Differently: GRAS for Measuring Bias in Vision Language Models on Gender, Race, Age, and Skin Tone": "|**2026-1-26**|**Ask Me Again Differently: GRAS for Measuring Bias in Vision Language Models on Gender, Race, Age, and Skin Tone**|Shaivi Malik et.al|[paper](https://arxiv.org/abs/2508.18989)|-|<details><summary>detail</summary>the Findings of EACL 2026</details>|\n", "ELIP: Efficient Discriminative Language-Image Pre-training with Fewer Vision Tokens": "|**2026-1-26**|**ELIP: Efficient Discriminative Language-Image Pre-training with Fewer Vision Tokens**|Yangyang Guo et.al|[paper](https://arxiv.org/abs/2309.16738)|-|-|\n", "Making medical vision-language models think causally across modalities with retrieval-augmented cross-modal reasoning": "|**2026-1-26**|**Making medical vision-language models think causally across modalities with retrieval-augmented cross-modal reasoning**|Weiqin Yang et.al|[paper](https://arxiv.org/abs/2601.18356)|-|-|\n", "Coding the Visual World: From Image to Simulation Using Vision Language Models": "|**2026-1-26**|**Coding the Visual World: From Image to Simulation Using Vision Language Models**|Sagi Eppel et.al|[paper](https://arxiv.org/abs/2601.05344)|-|-|\n", "Vision-Language-Model-Guided Differentiable Ray Tracing for Fast and Accurate Multi-Material RF Parameter Estimation": "|**2026-1-26**|**Vision-Language-Model-Guided Differentiable Ray Tracing for Fast and Accurate Multi-Material RF Parameter Estimation**|Zerui Kang et.al|[paper](https://arxiv.org/abs/2601.18242)|-|-|\n", "GeoVLMath: Enhancing Geometry Reasoning in Vision-Language Models via Cross-Modal Reward for Auxiliary Line Creation": "|**2026-1-26**|**GeoVLMath: Enhancing Geometry Reasoning in Vision-Language Models via Cross-Modal Reward for Auxiliary Line Creation**|Shasha Guo et.al|[paper](https://arxiv.org/abs/2510.11020)|-|-|\n", "\\textsc{NaVIDA}: Vision-Language Navigation with Inverse Dynamics Augmentation": "|**2026-1-26**|**\\textsc{NaVIDA}: Vision-Language Navigation with Inverse Dynamics Augmentation**|Weiye Zhu et.al|[paper](https://arxiv.org/abs/2601.18188)|-|-|\n", "Grounded Concreteness: Human-Like Concreteness Sensitivity in Vision-Language Models": "|**2026-1-25**|**Grounded Concreteness: Human-Like Concreteness Sensitivity in Vision-Language Models**|Aryan Roy et.al|[paper](https://arxiv.org/abs/2601.18065)|-|-|\n", "Benchmarking Direct Preference Optimization for Medical Large Vision-Language Models": "|**2026-1-25**|**Benchmarking Direct Preference Optimization for Medical Large Vision-Language Models**|Dain Kim et.al|[paper](https://arxiv.org/abs/2601.17918)|[code](https://github.com/dmis-lab/med-vlm-dpo.)|<details><summary>detail</summary>EACL 2026 (Findings)</details>|\n", "PEAfowl: Perception-Enhanced Multi-View Vision-Language-Action for Bimanual Manipulation": "|**2026-1-25**|**PEAfowl: Perception-Enhanced Multi-View Vision-Language-Action for Bimanual Manipulation**|Qingyu Fan et.al|[paper](https://arxiv.org/abs/2601.17885)|[code](https://peafowlvla.github.io/.)|-|\n"}}