{"source-free": {"StableSleep: Source-Free Test-Time Adaptation for Sleep Staging with Lightweight Safety Rails": "|**2025-9-2**|**StableSleep: Source-Free Test-Time Adaptation for Sleep Staging with Lightweight Safety Rails**|Hritik Arasu et.al|[paper](https://arxiv.org/abs/2509.02982)|-|<details><summary>detail</summary>5 page paper</details>|\n", "Model-Free Hovering and Source Seeking via Extremum Seeking Control: Experimental Demonstration": "|**2025-8-28**|**Model-Free Hovering and Source Seeking via Extremum Seeking Control: Experimental Demonstration**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2508.20836)|-|-|\n", "VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection": "|**2025-8-26**|**VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection**|Jianhong Han et.al|[paper](https://arxiv.org/abs/2508.11167)|-|<details><summary>detail</summary>Manuscript submitted to IEEE TCSVT</details>|\n", "Towards Source-Free Machine Unlearning": "|**2025-8-20**|**Towards Source-Free Machine Unlearning**|Sk Miraj Ahmed et.al|[paper](https://arxiv.org/abs/2508.15127)|-|<details><summary>detail</summary>Accepted by CVPR 2025</details>|\n", "Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method": "|**2025-8-14**|**Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2508.09202)|-|-|\n", "Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation": "|**2025-8-7**|**Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation**|Jianming Liu et.al|[paper](https://arxiv.org/abs/2508.05213)|[code](https://github.com/ljm198134/TVGTANet.)|-|\n", "Model Recycling Framework for Multi-Source Data-Free Supervised Transfer Learning": "|**2025-8-4**|**Model Recycling Framework for Multi-Source Data-Free Supervised Transfer Learning**|Sijia Wang et.al|[paper](https://arxiv.org/abs/2508.02039)|-|-|\n", "Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments": "|**2025-7-30**|**Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2501.02184)|-|-|\n", "Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation": "|**2025-7-28**|**Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation**|Yihong Cao et.al|[paper](https://arxiv.org/abs/2506.21198)|[code](https://github.com/yihong-97/UNLOCK.)|<details><summary>detail</summary>ICCV 2025</details>|\n", "GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning": "|**2025-7-26**|**GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning**|Sanqing Qu et.al|[paper](https://arxiv.org/abs/2403.14410)|[code](https://github.com/ispc-lab/GLC-plus.)|<details><summary>detail</summary>A substantial extension of the CVPR paper \"Upcycling Models under Domain and Category Shift\"</details>|\n", "SFUOD: Source-Free Unknown Object Detection": "|**2025-7-23**|**SFUOD: Source-Free Unknown Object Detection**|Keon-Hee Park et.al|[paper](https://arxiv.org/abs/2507.17373)|-|<details><summary>detail</summary>This paper has been accepted by ICCV 2025</details>|\n", "Text-Driven Causal Representation Learning for Source-Free Domain Generalization": "|**2025-7-14**|**Text-Driven Causal Representation Learning for Source-Free Domain Generalization**|Lihua Zhou et.al|[paper](https://arxiv.org/abs/2507.09961)|-|<details><summary>detail</summary>Under Review</details>|\n", "Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting": "|**2025-7-12**|**Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting**|Zheang Huai et.al|[paper](https://arxiv.org/abs/2505.08527)|[code](https://github.com/xmed-lab/DFG.)|<details><summary>detail</summary>Accepted in TMI 2025</details>|\n", "Source-Free Domain Adaptation via Multi-view Contrastive Learning": "|**2025-7-4**|**Source-Free Domain Adaptation via Multi-view Contrastive Learning**|Amirfarhad Farhadi et.al|[paper](https://arxiv.org/abs/2507.03321)|-|-|\n", "Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework": "|**2025-6-26**|**Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework**|Ismail Nejjar et.al|[paper](https://arxiv.org/abs/2411.12558)|-|<details><summary>detail</summary>TMLR 2025</details>|\n"}, "object detection": {"C-DiffDet+: Fusing Global Scene Context with Generative Denoising for High-Fidelity Object Detection": "|**2025-9-3**|**C-DiffDet+: Fusing Global Scene Context with Generative Denoising for High-Fidelity Object Detection**|Abdellah Zakaria Sellam et.al|[paper](https://arxiv.org/abs/2509.00578)|-|-|\n", "AutoDetect: Designing an Autoencoder-based Detection Method for Poisoning Attacks on Object Detection Applications in the Military Domain": "|**2025-9-3**|**AutoDetect: Designing an Autoencoder-based Detection Method for Poisoning Attacks on Object Detection Applications in the Military Domain**|Alma M. Liezenga et.al|[paper](https://arxiv.org/abs/2509.03179)|-|<details><summary>detail</summary>To be presented at SPIE: Sensors + Imaging</details>|\n", "A Data-Driven RetinaNet Model for Small Object Detection in Aerial Images": "|**2025-9-2**|**A Data-Driven RetinaNet Model for Small Object Detection in Aerial Images**|Zhicheng Tang et.al|[paper](https://arxiv.org/abs/2509.02928)|-|-|\n", "Explaining What Machines See: XAI Strategies in Deep Object Detection Models": "|**2025-9-2**|**Explaining What Machines See: XAI Strategies in Deep Object Detection Models**|FatemehSadat Seyedmomeni et.al|[paper](https://arxiv.org/abs/2509.01991)|-|-|\n", "Enabling Federated Object Detection for Connected Autonomous Vehicles: A Deployment-Oriented Evaluation": "|**2025-9-1**|**Enabling Federated Object Detection for Connected Autonomous Vehicles: A Deployment-Oriented Evaluation**|Komala Subramanyam Cherukuri et.al|[paper](https://arxiv.org/abs/2509.01868)|-|-|\n", "PointSlice: Accurate and Efficient Slice-Based Representation for 3D Object Detection from Point Clouds": "|**2025-9-1**|**PointSlice: Accurate and Efficient Slice-Based Representation for 3D Object Detection from Point Clouds**|Liu Qifeng et.al|[paper](https://arxiv.org/abs/2509.01487)|[code](https://github.com/qifeng22/PointSlice2.)|<details><summary>detail</summary>Manuscript submitted to PATTERN RECOGNITION</details>|\n", "Image Quality Enhancement and Detection of Small and Dense Objects in Industrial Recycling Processes": "|**2025-9-1**|**Image Quality Enhancement and Detection of Small and Dense Objects in Industrial Recycling Processes**|Oussama Messai et.al|[paper](https://arxiv.org/abs/2509.01332)|[code](https://github.com/o-messai/SDOOD,)|<details><summary>detail</summary>Event: Seventeenth International Conference on Quality Control by Artificial Vision (QCAV2025)</details>|\n", "Multi-Representation Adapter with Neural Architecture Search for Efficient Range-Doppler Radar Object Detection": "|**2025-9-1**|**Multi-Representation Adapter with Neural Architecture Search for Efficient Range-Doppler Radar Object Detection**|Zhiwei Lin et.al|[paper](https://arxiv.org/abs/2509.01280)|-|<details><summary>detail</summary>Accepted by ICANN 2025</details>|\n", "SAR-NAS: Lightweight SAR Object Detection with Neural Architecture Search": "|**2025-9-1**|**SAR-NAS: Lightweight SAR Object Detection with Neural Architecture Search**|Xinyi Yu et.al|[paper](https://arxiv.org/abs/2509.01279)|-|<details><summary>detail</summary>Accepted by PRCV 2025</details>|\n", "Investigating Domain Gaps for Indoor 3D Object Detection": "|**2025-9-1**|**Investigating Domain Gaps for Indoor 3D Object Detection**|Zijing Zhao et.al|[paper](https://arxiv.org/abs/2508.17439)|[code](https://jeremyzhao1998.github.io/DAVoteNet-release/.)|<details><summary>detail</summary>ACM MM 2025</details>|\n", "No More Sibling Rivalry: Debiasing Human-Object Interaction Detection": "|**2025-8-31**|**No More Sibling Rivalry: Debiasing Human-Object Interaction Detection**|Bin Yang et.al|[paper](https://arxiv.org/abs/2509.00760)|-|<details><summary>detail</summary>Accept to ICCV2025</details>|\n", "OA-DET3D: Embedding Object Awareness as a General Plug-in for Multi-Camera 3D Object Detection": "|**2025-8-29**|**OA-DET3D: Embedding Object Awareness as a General Plug-in for Multi-Camera 3D Object Detection**|Xiaomeng Chu et.al|[paper](https://arxiv.org/abs/2301.05711)|-|<details><summary>detail</summary>Accepted by IJCV after more than two years of reviewing</details>|\n", "FLORA: Efficient Synthetic Data Generation for Object Detection in Low-Data Regimes via finetuning Flux LoRA": "|**2025-8-29**|**FLORA: Efficient Synthetic Data Generation for Object Detection in Low-Data Regimes via finetuning Flux LoRA**|Alvaro Patricio et.al|[paper](https://arxiv.org/abs/2508.21712)|-|-|\n", "HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection": "|**2025-8-28**|**HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection**|Harris Song et.al|[paper](https://arxiv.org/abs/2508.21135)|-|-|\n", "Contrastive Learning through Auxiliary Branch for Video Object Detection": "|**2025-8-28**|**Contrastive Learning through Auxiliary Branch for Video Object Detection**|Lucas Rakotoarivony et.al|[paper](https://arxiv.org/abs/2508.20551)|-|<details><summary>detail</summary>Accepted paper for ACIVS 2025</details>|\n"}, "domain adaptation": {"Domain Adaptation of LLMs for Process Data": "|**2025-9-3**|**Domain Adaptation of LLMs for Process Data**|Rafael Seidi Oyamada et.al|[paper](https://arxiv.org/abs/2509.03161)|-|-|\n", "Uncertainty-aware Test-Time Training (UT$^3$) for Efficient On-the-fly Domain Adaptive Dense Regression": "|**2025-9-3**|**Uncertainty-aware Test-Time Training (UT$^3$) for Efficient On-the-fly Domain Adaptive Dense Regression**|Uddeshya Upadhyay et.al|[paper](https://arxiv.org/abs/2509.03012)|-|-|\n", "DExNet: Combining Observations of Domain Adapted Critics for Leaf Disease Classification with Limited Data": "|**2025-9-1**|**DExNet: Combining Observations of Domain Adapted Critics for Leaf Disease Classification with Limited Data**|Sabbir Ahmed et.al|[paper](https://arxiv.org/abs/2506.18173)|-|<details><summary>detail</summary>Accepted in 8th ACPR Springer</details>|\n", "Domain Adaptation for Big Data in Agricultural Image Analysis: A Comprehensive Review": "|**2025-8-30**|**Domain Adaptation for Big Data in Agricultural Image Analysis: A Comprehensive Review**|Xing Hu et.al|[paper](https://arxiv.org/abs/2506.05972)|-|-|\n", "Domain Adaptation-Based Crossmodal Knowledge Distillation for 3D Semantic Segmentation": "|**2025-8-30**|**Domain Adaptation-Based Crossmodal Knowledge Distillation for 3D Semantic Segmentation**|Jialiang Kang et.al|[paper](https://arxiv.org/abs/2509.00379)|-|<details><summary>detail</summary>ICRA 2025</details>|\n", "MedShift: Implicit Conditional Transport for X-Ray Domain Adaptation": "|**2025-8-29**|**MedShift: Implicit Conditional Transport for X-Ray Domain Adaptation**|Francisco Caetano et.al|[paper](https://arxiv.org/abs/2508.21435)|[code](https://caetas.github.io/medshift.html)|<details><summary>detail</summary>the ICCV 2025 AIM Workshop</details>|\n", "A Knowledge Distillation-empowered Adaptive Federated Reinforcement Learning Framework for Multi-Domain IoT Applications Scheduling": "|**2025-8-29**|**A Knowledge Distillation-empowered Adaptive Federated Reinforcement Learning Framework for Multi-Domain IoT Applications Scheduling**|Zhiyu Wang et.al|[paper](https://arxiv.org/abs/2508.21328)|-|-|\n", "ODES: Domain Adaptation with Expert Guidance for Online Medical Image Segmentation": "|**2025-8-28**|**ODES: Domain Adaptation with Expert Guidance for Online Medical Image Segmentation**|Md Shazid Islam et.al|[paper](https://arxiv.org/abs/2312.05407)|-|-|\n", "Gradual Domain Adaptation for Graph Learning": "|**2025-8-28**|**Gradual Domain Adaptation for Graph Learning**|Pui Ieng Lei et.al|[paper](https://arxiv.org/abs/2501.17443)|-|-|\n", "Adaptive Federated Distillation for Multi-Domain Non-IID Textual Data": "|**2025-8-28**|**Adaptive Federated Distillation for Multi-Domain Non-IID Textual Data**|Jiahao Xiao et.al|[paper](https://arxiv.org/abs/2508.20557)|[code](https://github.com/jiahaoxiao1228/AdaFD.)|-|\n", "Domain Adaptation Techniques for Natural and Medical Image Classification": "|**2025-8-28**|**Domain Adaptation Techniques for Natural and Medical Image Classification**|Ahmad Chaddad et.al|[paper](https://arxiv.org/abs/2508.20537)|-|<details><summary>detail</summary>Accepted in Information Sciences</details>|\n", "Learning What is Worth Learning: Active and Sequential Domain Adaptation for Multi-modal Gross Tumor Volume Segmentation": "|**2025-8-28**|**Learning What is Worth Learning: Active and Sequential Domain Adaptation for Multi-modal Gross Tumor Volume Segmentation**|Jingyun Yang et.al|[paper](https://arxiv.org/abs/2508.20528)|[code](https://github.com/Hiyoochan/mmActS)|-|\n", "Bridging Domain Gaps for Fine-Grained Moth Classification Through Expert-Informed Adaptation and Foundation Model Priors": "|**2025-8-27**|**Bridging Domain Gaps for Fine-Grained Moth Classification Through Expert-Informed Adaptation and Foundation Model Priors**|Ross J Gardiner et.al|[paper](https://arxiv.org/abs/2508.20089)|-|-|\n", "On Domain-Adaptive Post-Training for Multimodal Large Language Models": "|**2025-8-27**|**On Domain-Adaptive Post-Training for Multimodal Large Language Models**|Daixuan Cheng et.al|[paper](https://arxiv.org/abs/2411.19930)|[code](https://huggingface.co/AdaptLLM/Adapt-MLLM-to-Domains)|<details><summary>detail</summary>EMNLP 2025 Findings</details>|\n", "Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains": "|**2025-8-26**|**Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains**|Peiran Zhou et.al|[paper](https://arxiv.org/abs/2508.19357)|-|-|\n"}, "domain generalization": {"Single Domain Generalization in Diabetic Retinopathy: A Neuro-Symbolic Learning Approach": "|**2025-9-2**|**Single Domain Generalization in Diabetic Retinopathy: A Neuro-Symbolic Learning Approach**|Midhat Urooj et.al|[paper](https://arxiv.org/abs/2509.02918)|-|<details><summary>detail</summary>Accepted in ANSyA 2025: 1st International Workshop on Advanced Neuro-Symbolic Applications</details>|\n", "SynthGenNet: a self-supervised approach for test-time generalization using synthetic multi-source domain mixing of street view images": "|**2025-9-2**|**SynthGenNet: a self-supervised approach for test-time generalization using synthetic multi-source domain mixing of street view images**|Pushpendra Dhakara et.al|[paper](https://arxiv.org/abs/2509.02287)|-|-|\n", "FActBench: A Benchmark for Fine-grained Automatic Evaluation of LLM-Generated Text in the Medical Domain": "|**2025-9-2**|**FActBench: A Benchmark for Fine-grained Automatic Evaluation of LLM-Generated Text in the Medical Domain**|Anum Afzal et.al|[paper](https://arxiv.org/abs/2509.02198)|-|-|\n", "REVELIO -- Universal Multimodal Task Load Estimation for Cross-Domain Generalization": "|**2025-9-1**|**REVELIO -- Universal Multimodal Task Load Estimation for Cross-Domain Generalization**|Maximilian P. Oppelt et.al|[paper](https://arxiv.org/abs/2509.01642)|-|-|\n", "Target-Oriented Single Domain Generalization": "|**2025-8-30**|**Target-Oriented Single Domain Generalization**|Marzi Heidari et.al|[paper](https://arxiv.org/abs/2509.00351)|-|-|\n", "MorphGen: Morphology-Guided Representation Learning for Robust Single-Domain Generalization in Histopathological Cancer Classification": "|**2025-8-29**|**MorphGen: Morphology-Guided Representation Learning for Robust Single-Domain Generalization in Histopathological Cancer Classification**|Hikmat Khan et.al|[paper](https://arxiv.org/abs/2509.00311)|[code](https://github.com/hikmatkhan/MorphGen)|-|\n", "Single Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement": "|**2025-8-29**|**Single Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement**|Jia-Xuan Jiang et.al|[paper](https://arxiv.org/abs/2507.08340)|[code](https://github.com/HopkinsKwong/MCCSDG)|<details><summary>detail</summary>Accepted by ACMMM 25</details>|\n", "Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations": "|**2025-8-29**|**Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations**|Ha Min Son et.al|[paper](https://arxiv.org/abs/2508.21769)|-|-|\n", "PointDGRWKV: Generalizing RWKV-like Architecture to Unseen Domains for Point Cloud Classification": "|**2025-8-29**|**PointDGRWKV: Generalizing RWKV-like Architecture to Unseen Domains for Point Cloud Classification**|Hao Yang et.al|[paper](https://arxiv.org/abs/2508.20835)|-|-|\n", "Decentralized Domain Generalization with Style Sharing: Formal Model and Convergence Analysis": "|**2025-8-28**|**Decentralized Domain Generalization with Style Sharing: Formal Model and Convergence Analysis**|Shahryar Zehtabi et.al|[paper](https://arxiv.org/abs/2504.06235)|-|-|\n", "Pan-Cancer mitotic figures detection and domain generalization: MIDOG 2025 Challenge": "|**2025-8-28**|**Pan-Cancer mitotic figures detection and domain generalization: MIDOG 2025 Challenge**|Zhuoyan Shen et.al|[paper](https://arxiv.org/abs/2509.02585)|-|-|\n", "Evaluating Differentially Private Generation of Domain-Specific Text": "|**2025-8-28**|**Evaluating Differentially Private Generation of Domain-Specific Text**|Yidan Sun et.al|[paper](https://arxiv.org/abs/2508.20452)|-|-|\n", "RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation": "|**2025-8-27**|**RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation**|Tianxing Chen et.al|[paper](https://arxiv.org/abs/2506.18088)|[code](https://robotwin-platform.github.io/,)|<details><summary>detail</summary>Project Page: https://robotwin-platform</details>|\n", "IELDG: Suppressing Domain-Specific Noise with Inverse Evolution Layers for Domain Generalized Semantic Segmentation": "|**2025-8-27**|**IELDG: Suppressing Domain-Specific Noise with Inverse Evolution Layers for Domain Generalized Semantic Segmentation**|Qizhe Fan et.al|[paper](https://arxiv.org/abs/2508.19604)|-|-|\n", "Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains": "|**2025-8-26**|**Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains**|Peiran Zhou et.al|[paper](https://arxiv.org/abs/2508.19357)|-|-|\n"}, "vision language": {"Continuous Saudi Sign Language Recognition: A Vision Transformer Approach": "|**2025-9-3**|**Continuous Saudi Sign Language Recognition: A Vision Transformer Approach**|Soukeina Elhassen et.al|[paper](https://arxiv.org/abs/2509.03467)|-|-|\n", "Mitigating Hallucination in Large Vision-Language Models through Aligning Attention Distribution to Information Flow": "|**2025-9-3**|**Mitigating Hallucination in Large Vision-Language Models through Aligning Attention Distribution to Information Flow**|Jianfei Zhao et.al|[paper](https://arxiv.org/abs/2505.14257)|-|<details><summary>detail</summary>Findings of EMNLP 2025</details>|\n", "Unveiling the Response of Large Vision-Language Models to Visually Absent Tokens": "|**2025-9-3**|**Unveiling the Response of Large Vision-Language Models to Visually Absent Tokens**|Sohee Kim et.al|[paper](https://arxiv.org/abs/2509.03025)|-|<details><summary>detail</summary>accepted to EMNLP 2025</details>|\n", "Texture or Semantics? Vision-Language Models Get Lost in Font Recognition": "|**2025-9-3**|**Texture or Semantics? Vision-Language Models Get Lost in Font Recognition**|Zhecheng Li et.al|[paper](https://arxiv.org/abs/2503.23768)|-|<details><summary>detail</summary>COLM 2025</details>|\n", "KEPT: Knowledge-Enhanced Prediction of Trajectories from Consecutive Driving Frames with Vision-Language Models": "|**2025-9-2**|**KEPT: Knowledge-Enhanced Prediction of Trajectories from Consecutive Driving Frames with Vision-Language Models**|Yujin Wang et.al|[paper](https://arxiv.org/abs/2509.02966)|-|-|\n", "ViDDAR: Vision Language Model-Based Task-Detrimental Content Detection for Augmented Reality": "|**2025-9-2**|**ViDDAR: Vision Language Model-Based Task-Detrimental Content Detection for Augmented Reality**|Yanming Xiu et.al|[paper](https://arxiv.org/abs/2501.12553)|-|<details><summary>detail</summary>The paper has been accepted to the 2025 IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)</details>|\n", "GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models": "|**2025-9-2**|**GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models**|Hamza Rasaee et.al|[paper](https://arxiv.org/abs/2506.23903)|-|-|\n", "Challenges in Understanding Modality Conflict in Vision-Language Models": "|**2025-9-2**|**Challenges in Understanding Modality Conflict in Vision-Language Models**|Trang Nguyen et.al|[paper](https://arxiv.org/abs/2509.02805)|-|-|\n", "Planning with Reasoning using Vision Language World Model": "|**2025-9-2**|**Planning with Reasoning using Vision Language World Model**|Delong Chen et.al|[paper](https://arxiv.org/abs/2509.02722)|-|-|\n", "2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model": "|**2025-9-2**|**2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model**|Zilong Guo et.al|[paper](https://arxiv.org/abs/2509.02659)|-|<details><summary>detail</summary>2nd place in CVPR 2024 End-to-End Driving at Scale Challenge</details>|\n", "RS-OOD: A Vision-Language Augmented Framework for Out-of-Distribution Detection in Remote Sensing": "|**2025-9-2**|**RS-OOD: A Vision-Language Augmented Framework for Out-of-Distribution Detection in Remote Sensing**|Yingrui Ji et.al|[paper](https://arxiv.org/abs/2509.02273)|-|-|\n", "FedMVP: Federated Multimodal Visual Prompt Tuning for Vision-Language Models": "|**2025-9-2**|**FedMVP: Federated Multimodal Visual Prompt Tuning for Vision-Language Models**|Mainak Singha et.al|[paper](https://arxiv.org/abs/2504.20860)|[code](https://github.com/mainaksingha01/FedMVP.)|<details><summary>detail</summary>Accepted in ICCV 2025</details>|\n", "Exploring Primitive Visual Measurement Understanding and the Role of Output Format in Learning in Vision-Language Models": "|**2025-9-2**|**Exploring Primitive Visual Measurement Understanding and the Role of Output Format in Learning in Vision-Language Models**|Ankit Yadav et.al|[paper](https://arxiv.org/abs/2501.15144)|-|<details><summary>detail</summary>25 Pages Accepted in DICTA 2025</details>|\n", "Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance": "|**2025-9-2**|**Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance**|Yang Zhang et.al|[paper](https://arxiv.org/abs/2509.02055)|-|<details><summary>detail</summary>The first three authors contributed equally</details>|\n", "A Vision-Language Agent System for Compositional Reasoning with VLM-assisted Script and Executable Generation": "|**2025-9-1**|**A Vision-Language Agent System for Compositional Reasoning with VLM-assisted Script and Executable Generation**|Yichang Xu et.al|[paper](https://arxiv.org/abs/2506.07778)|-|-|\n"}}