{"source-free": {"Source Coding with Free Bits and the Multi-Way Number Partitioning Problem": "|**2026-1-29**|**Source Coding with Free Bits and the Multi-Way Number Partitioning Problem**|Niloufar Ahmadypour et.al|[paper](https://arxiv.org/abs/2009.02710)|-|-|\n", "Beyond Retraining: Training-Free Unknown Class Filtering for Source-Free Open Set Domain Adaptation of Vision-Language Models": "|**2026-1-28**|**Beyond Retraining: Training-Free Unknown Class Filtering for Source-Free Open Set Domain Adaptation of Vision-Language Models**|Yongguang Li et.al|[paper](https://arxiv.org/abs/2504.14224)|-|<details><summary>detail</summary>Core methods unchanged</details>|\n", "A Source-Free Approach for Domain Adaptation via Multiview Image Transformation and Latent Space Consistency": "|**2026-1-28**|**A Source-Free Approach for Domain Adaptation via Multiview Image Transformation and Latent Space Consistency**|Debopom Sutradhar et.al|[paper](https://arxiv.org/abs/2601.20284)|-|<details><summary>detail</summary>Manuscript under review in IEEE Transactions on Image Processing</details>|\n", "Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity": "|**2026-1-24**|**Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity**|Harsharaj Pathak et.al|[paper](https://arxiv.org/abs/2601.17408)|-|-|\n", "Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results": "|**2026-1-23**|**Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results**|Rohan Palanikumar et.al|[paper](https://arxiv.org/abs/2511.00752)|-|-|\n", "Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection": "|**2026-1-20**|**Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2511.07301)|-|<details><summary>detail</summary>AAAI 2026</details>|\n", "Towards Unbiased Source-Free Object Detection via Vision Foundation Models": "|**2026-1-19**|**Towards Unbiased Source-Free Object Detection via Vision Foundation Models**|Zhi Cai et.al|[paper](https://arxiv.org/abs/2601.12765)|-|-|\n", "Unified Source-Free Domain Adaptation": "|**2026-1-18**|**Unified Source-Free Domain Adaptation**|Song Tang et.al|[paper](https://arxiv.org/abs/2403.07601)|[code](https://github.com/tntek/CausalDA.)|-|\n", "GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher and Gaussian Mixture Model-Based Pseudo-Labeling": "|**2026-1-16**|**GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher and Gaussian Mixture Model-Based Pseudo-Labeling**|Pascal Schlachter et.al|[paper](https://arxiv.org/abs/2601.11161)|[code](https://github.com/pascalschlachter/GMM-COMET.)|-|\n", "SfMamba: Efficient Source-Free Domain Adaptation via Selective Scan Modeling": "|**2026-1-13**|**SfMamba: Efficient Source-Free Domain Adaptation via Selective Scan Modeling**|Xi Chen et.al|[paper](https://arxiv.org/abs/2601.08608)|[code](https://github.com/chenxi52/SfMamba.)|-|\n", "Source-Free Domain Adaptation for Geospatial Point Cloud Semantic Segmentation": "|**2026-1-13**|**Source-Free Domain Adaptation for Geospatial Point Cloud Semantic Segmentation**|Yuan Gao et.al|[paper](https://arxiv.org/abs/2601.08375)|-|-|\n", "Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based Curriculum Learning": "|**2026-1-5**|**Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based Curriculum Learning**|Dongjie Chen et.al|[paper](https://arxiv.org/abs/2405.18376)|[code](https://github.com/Dong-Jie-Chen/RCL.)|-|\n", "Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection": "|**2025-12-24**|**Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection**|Sairam VCR et.al|[paper](https://arxiv.org/abs/2512.17514)|-|-|\n", "Exploiting Radio Frequency Fingerprints for Device Identification: Tackling Cross-receiver Challenges in the Source-data-free Scenario": "|**2025-12-18**|**Exploiting Radio Frequency Fingerprints for Device Identification: Tackling Cross-receiver Challenges in the Source-data-free Scenario**|Liu Yang et.al|[paper](https://arxiv.org/abs/2512.16648)|-|<details><summary>detail</summary>IEEE Transactions on Mobile Computing</details>|\n", "VocSim: A Training-free Benchmark for Zero-shot Content Identity in Single-source Audio": "|**2025-12-10**|**VocSim: A Training-free Benchmark for Zero-shot Content Identity in Single-source Audio**|Maris Basha et.al|[paper](https://arxiv.org/abs/2512.10120)|-|-|\n"}, "object detection": {"SSCATeR: Sparse Scatter-Based Convolution Algorithm with Temporal Data Recycling for Real-Time 3D Object Detection in LiDAR Point Clouds": "|**2026-1-29**|**SSCATeR: Sparse Scatter-Based Convolution Algorithm with Temporal Data Recycling for Real-Time 3D Object Detection in LiDAR Point Clouds**|Alexander Dow et.al|[paper](https://arxiv.org/abs/2512.08557)|-|<details><summary>detail</summary>23 Pages</details>|\n", "Practical Insights into Semi-Supervised Object Detection Approaches": "|**2026-1-28**|**Practical Insights into Semi-Supervised Object Detection Approaches**|Chaoxin Wang et.al|[paper](https://arxiv.org/abs/2601.13380)|-|-|\n", "BadDet+: Robust Backdoor Attacks for Object Detection": "|**2026-1-28**|**BadDet+: Robust Backdoor Attacks for Object Detection**|Kealan Dunnett et.al|[paper](https://arxiv.org/abs/2601.21066)|-|-|\n", "Instance-Guided Radar Depth Estimation for 3D Object Detection": "|**2026-1-27**|**Instance-Guided Radar Depth Estimation for 3D Object Detection**|Chen-Chou Lo et.al|[paper](https://arxiv.org/abs/2601.19314)|-|<details><summary>detail</summary>IPMV2026</details>|\n", "Implicit Non-Causal Factors are Out via Dataset Splitting for Domain Generalization Object Detection": "|**2026-1-26**|**Implicit Non-Causal Factors are Out via Dataset Splitting for Domain Generalization Object Detection**|Zhilong Zhang et.al|[paper](https://arxiv.org/abs/2601.19127)|-|<details><summary>detail</summary>To appear in IJCV</details>|\n", "Synthetic Object Compositions for Scalable and Accurate Learning in Detection, Segmentation, and Grounding": "|**2026-1-26**|**Synthetic Object Compositions for Scalable and Accurate Learning in Detection, Segmentation, and Grounding**|Weikai Huang et.al|[paper](https://arxiv.org/abs/2510.09110)|[code](https://github.com/weikaih04/Synthetic-Detection-Segmentation-Grounding-Data)|<details><summary>detail</summary>Project website: https://github</details>|\n", "EFSI-DETR: Efficient Frequency-Semantic Integration for Real-Time Small Object Detection in UAV Imagery": "|**2026-1-26**|**EFSI-DETR: Efficient Frequency-Semantic Integration for Real-Time Small Object Detection in UAV Imagery**|Yu Xia et.al|[paper](https://arxiv.org/abs/2601.18597)|-|-|\n", "From Filters to VLMs: Benchmarking Defogging Methods through Object Detection and Segmentation Performance": "|**2026-1-26**|**From Filters to VLMs: Benchmarking Defogging Methods through Object Detection and Segmentation Performance**|Ardalan Aryashad et.al|[paper](https://arxiv.org/abs/2510.03906)|[code](https://aradfir.github.io/filters-to-vlms-defogging-page/)|<details><summary>detail</summary>WACV 2026 Proceedings (Oral)</details>|\n", "Real-Time Object Detection Meets DINOv3": "|**2026-1-26**|**Real-Time Object Detection Meets DINOv3**|Shihua Huang et.al|[paper](https://arxiv.org/abs/2509.20787)|[code](https://github.com/Intellindust-AI-Lab/DEIMv2)|<details><summary>detail</summary>Source code available at https://github</details>|\n", "YOLO-DS: Fine-Grained Feature Decoupling via Dual-Statistic Synergy Operator for Object Detection": "|**2026-1-26**|**YOLO-DS: Fine-Grained Feature Decoupling via Dual-Statistic Synergy Operator for Object Detection**|Lin Huang et.al|[paper](https://arxiv.org/abs/2601.18172)|-|-|\n", "Cross-Level Sensor Fusion with Object Lists via Transformer for 3D Object Detection": "|**2026-1-25**|**Cross-Level Sensor Fusion with Object Lists via Transformer for 3D Object Detection**|Xiangzhong Liu et.al|[paper](https://arxiv.org/abs/2512.12884)|-|-|\n", "Exploiting Unlabeled Data with Multiple Expert Teachers for Open Vocabulary Aerial Object Detection and Its Orientation Adaptation": "|**2026-1-24**|**Exploiting Unlabeled Data with Multiple Expert Teachers for Open Vocabulary Aerial Object Detection and Its Orientation Adaptation**|Yan Li et.al|[paper](https://arxiv.org/abs/2411.02057)|[code](https://github.com/VisionXLab/CastDet.)|<details><summary>detail</summary>Accepted by International Journal of Computer Vision (IJCV'26)</details>|\n", "M2I2HA: Multi-modal Object Detection Based on Intra- and Inter-Modal Hypergraph Attention": "|**2026-1-24**|**M2I2HA: Multi-modal Object Detection Based on Intra- and Inter-Modal Hypergraph Attention**|Xiaofan Yang et.al|[paper](https://arxiv.org/abs/2601.14776)|-|-|\n", "UltraFlwr -- An Efficient Federated Surgical Object Detection Framework": "|**2026-1-23**|**UltraFlwr -- An Efficient Federated Surgical Object Detection Framework**|Yang Li et.al|[paper](https://arxiv.org/abs/2503.15161)|[code](https://github.com/KCL-BMEIS/UltraFlwr.)|-|\n", "Boundary and Position Information Mining for Aerial Small Object Detection": "|**2026-1-23**|**Boundary and Position Information Mining for Aerial Small Object Detection**|Rongxin Huang et.al|[paper](https://arxiv.org/abs/2601.16617)|-|-|\n"}, "domain adaptation": {"OmniLens: Towards Universal Lens Aberration Correction via LensLib-to-Specific Domain Adaptation": "|**2026-1-29**|**OmniLens: Towards Universal Lens Aberration Correction via LensLib-to-Specific Domain Adaptation**|Qi Jiang et.al|[paper](https://arxiv.org/abs/2409.05809)|[code](https://github.com/zju-jiangqi/OmniLens.)|<details><summary>detail</summary>Optics & Laser Technology (JOLT)</details>|\n", "Influence Guided Sampling for Domain Adaptation of Text Retrievers": "|**2026-1-29**|**Influence Guided Sampling for Domain Adaptation of Text Retrievers**|Meet Doshi et.al|[paper](https://arxiv.org/abs/2601.21759)|-|-|\n", "Few-Shot Domain Adaptation with Temporal References and Static Priors for Glacier Calving Front Delineation": "|**2026-1-29**|**Few-Shot Domain Adaptation with Temporal References and Static Priors for Glacier Calving Front Delineation**|Marcel Dreier et.al|[paper](https://arxiv.org/abs/2601.21663)|-|-|\n", "EEG-based Graph-guided Domain Adaptation for Robust Cross-Session Emotion Recognition": "|**2026-1-29**|**EEG-based Graph-guided Domain Adaptation for Robust Cross-Session Emotion Recognition**|Maryam Mirzaei et.al|[paper](https://arxiv.org/abs/2512.23526)|-|-|\n", "MOSAIC: Masked Objective with Selective Adaptation for In-domain Contrastive Learning": "|**2026-1-29**|**MOSAIC: Masked Objective with Selective Adaptation for In-domain Contrastive Learning**|Vera Pavlova et.al|[paper](https://arxiv.org/abs/2510.16797)|-|-|\n", "Distributionally Robust Classification for Multi-source Unsupervised Domain Adaptation": "|**2026-1-29**|**Distributionally Robust Classification for Multi-source Unsupervised Domain Adaptation**|Seonghwi Kim et.al|[paper](https://arxiv.org/abs/2601.21315)|-|<details><summary>detail</summary>ICLR 2026</details>|\n", "Beyond Retraining: Training-Free Unknown Class Filtering for Source-Free Open Set Domain Adaptation of Vision-Language Models": "|**2026-1-28**|**Beyond Retraining: Training-Free Unknown Class Filtering for Source-Free Open Set Domain Adaptation of Vision-Language Models**|Yongguang Li et.al|[paper](https://arxiv.org/abs/2504.14224)|-|<details><summary>detail</summary>Core methods unchanged</details>|\n", "Rethinking Self-Training Based Cross-Subject Domain Adaptation for SSVEP Classification": "|**2026-1-28**|**Rethinking Self-Training Based Cross-Subject Domain Adaptation for SSVEP Classification**|Weiguang Wang et.al|[paper](https://arxiv.org/abs/2601.21203)|-|<details><summary>detail</summary>ICASSP 2026</details>|\n", "A Source-Free Approach for Domain Adaptation via Multiview Image Transformation and Latent Space Consistency": "|**2026-1-28**|**A Source-Free Approach for Domain Adaptation via Multiview Image Transformation and Latent Space Consistency**|Debopom Sutradhar et.al|[paper](https://arxiv.org/abs/2601.20284)|-|<details><summary>detail</summary>Manuscript under review in IEEE Transactions on Image Processing</details>|\n", "CiMRAG: Cim-Aware Domain-Adaptive and Noise-Resilient Retrieval-Augmented Generation for Edge-Based LLMs": "|**2026-1-27**|**CiMRAG: Cim-Aware Domain-Adaptive and Noise-Resilient Retrieval-Augmented Generation for Edge-Based LLMs**|Shih-Hsuan Chiu et.al|[paper](https://arxiv.org/abs/2601.20041)|-|<details><summary>detail</summary>Accepted by ICASSP 2026</details>|\n", "From Atoms to Chains: Divergence-Guided Reasoning Curriculum for Unlabeled LLM Domain Adaptation": "|**2026-1-27**|**From Atoms to Chains: Divergence-Guided Reasoning Curriculum for Unlabeled LLM Domain Adaptation**|Yongqi Wang et.al|[paper](https://arxiv.org/abs/2601.19588)|[code](https://github.com/bytedance/DGRC)|<details><summary>detail</summary>Code: https://github</details>|\n", "A Multi-View Consistency Framework with Semi-Supervised Domain Adaptation": "|**2026-1-27**|**A Multi-View Consistency Framework with Semi-Supervised Domain Adaptation**|Yuting Hong et.al|[paper](https://arxiv.org/abs/2601.19266)|-|-|\n", "SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics": "|**2026-1-26**|**SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics**|Santosh Chapagain et.al|[paper](https://arxiv.org/abs/2601.12131)|-|<details><summary>detail</summary>This is preliminary work towards a broader SolarGPT framework</details>|\n", "Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation": "|**2026-1-26**|**Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation**|Zihao Wang et.al|[paper](https://arxiv.org/abs/2601.18623)|-|<details><summary>detail</summary>Paper accepted as a conference paper at ICLR 2026</details>|\n", "When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs": "|**2026-1-26**|**When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs**|Junyi Zou et.al|[paper](https://arxiv.org/abs/2601.18350)|-|-|\n"}, "domain generalization": {"Negatives-Dominant Contrastive Learning for Generalization in Imbalanced Domains": "|**2026-1-29**|**Negatives-Dominant Contrastive Learning for Generalization in Imbalanced Domains**|Meng Cao et.al|[paper](https://arxiv.org/abs/2601.21999)|[code](https://github.com/Alrash/NDCL.)|-|\n", "MMGRid: Navigating Temporal-aware and Cross-domain Generative Recommendation via Model Merging": "|**2026-1-29**|**MMGRid: Navigating Temporal-aware and Cross-domain Generative Recommendation via Model Merging**|Tianjun Wei et.al|[paper](https://arxiv.org/abs/2601.15930)|[code](https://github.com/Joinn99/MMGRid)|<details><summary>detail</summary>https://github</details>|\n", "Panning for Gold: Expanding Domain-Specific Knowledge Graphs with General Knowledge": "|**2026-1-28**|**Panning for Gold: Expanding Domain-Specific Knowledge Graphs with General Knowledge**|Runhao Zhao et.al|[paper](https://arxiv.org/abs/2601.10485)|-|-|\n", "SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs": "|**2026-1-28**|**SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs**|Jiacheng Lin et.al|[paper](https://arxiv.org/abs/2509.20758)|-|<details><summary>detail</summary>Accepted by ICLR 2026</details>|\n", "Leveraging Generative AI for Enhancing Domain-Driven Software Design": "|**2026-1-28**|**Leveraging Generative AI for Enhancing Domain-Driven Software Design**|G\u00f6tz-Henrik Wiegand et.al|[paper](https://arxiv.org/abs/2601.20909)|-|<details><summary>detail</summary>Part of the Proceedings of the Upper-Rhine Artificial Intelligence Symposium 2024</details>|\n", "P2S: Probabilistic Process Supervision for General-Domain Reasoning Question Answering": "|**2026-1-28**|**P2S: Probabilistic Process Supervision for General-Domain Reasoning Question Answering**|Wenlin Zhong et.al|[paper](https://arxiv.org/abs/2601.20649)|-|-|\n", "Automated Benchmark Generation from Domain Guidelines Informed by Bloom's Taxonomy": "|**2026-1-28**|**Automated Benchmark Generation from Domain Guidelines Informed by Bloom's Taxonomy**|Si Chen et.al|[paper](https://arxiv.org/abs/2601.20253)|-|-|\n", "Modality-Balanced Collaborative Distillation for Multi-Modal Domain Generalization": "|**2026-1-27**|**Modality-Balanced Collaborative Distillation for Multi-Modal Domain Generalization**|Xiaohan Wang et.al|[paper](https://arxiv.org/abs/2511.20258)|-|-|\n", "CiMRAG: Cim-Aware Domain-Adaptive and Noise-Resilient Retrieval-Augmented Generation for Edge-Based LLMs": "|**2026-1-27**|**CiMRAG: Cim-Aware Domain-Adaptive and Noise-Resilient Retrieval-Augmented Generation for Edge-Based LLMs**|Shih-Hsuan Chiu et.al|[paper](https://arxiv.org/abs/2601.20041)|-|<details><summary>detail</summary>Accepted by ICASSP 2026</details>|\n", "Semantic-aware Random Convolution and Source Matching for Domain Generalization in Medical Image Segmentation": "|**2026-1-27**|**Semantic-aware Random Convolution and Source Matching for Domain Generalization in Medical Image Segmentation**|Franz Thaler et.al|[paper](https://arxiv.org/abs/2512.01510)|-|-|\n", "DSP-Reg: Domain-Sensitive Parameter Regularization for Robust Domain Generalization": "|**2026-1-27**|**DSP-Reg: Domain-Sensitive Parameter Regularization for Robust Domain Generalization**|Xudong Han et.al|[paper](https://arxiv.org/abs/2601.19394)|-|-|\n", "Federated Joint Learning for Domain and Class Generalization": "|**2026-1-27**|**Federated Joint Learning for Domain and Class Generalization**|Haoran Xu et.al|[paper](https://arxiv.org/abs/2601.12253)|-|<details><summary>detail</summary>ICASSP 2026</details>|\n", "Implicit Non-Causal Factors are Out via Dataset Splitting for Domain Generalization Object Detection": "|**2026-1-26**|**Implicit Non-Causal Factors are Out via Dataset Splitting for Domain Generalization Object Detection**|Zhilong Zhang et.al|[paper](https://arxiv.org/abs/2601.19127)|-|<details><summary>detail</summary>To appear in IJCV</details>|\n", "Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents": "|**2026-1-26**|**Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents**|Zhihan Liu et.al|[paper](https://arxiv.org/abs/2601.18217)|-|-|\n", "Domain Generalization with Quantum Enhancement for Medical Image Classification: A Lightweight Approach for Cross-Center Deployment": "|**2026-1-25**|**Domain Generalization with Quantum Enhancement for Medical Image Classification: A Lightweight Approach for Cross-Center Deployment**|Jingsong Xia et.al|[paper](https://arxiv.org/abs/2601.17862)|-|-|\n"}, "vision language": {"DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation": "|**2026-1-29**|**DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation**|Haozhe Xie et.al|[paper](https://arxiv.org/abs/2601.22153)|[code](https://www.infinitescript.com/project/dynamic-vla/)|<details><summary>detail</summary>Project Page: https://www</details>|\n", "Vision-DeepResearch: Incentivizing DeepResearch Capability in Multimodal Large Language Models": "|**2026-1-29**|**Vision-DeepResearch: Incentivizing DeepResearch Capability in Multimodal Large Language Models**|Wenxuan Huang et.al|[paper](https://arxiv.org/abs/2601.22060)|[code](https://github.com/Osilly/Vision-DeepResearch.)|-|\n", ": Online RL Fine-tuning for Flow-based Vision-Language-Action Models": "|**2026-1-29**|**: Online RL Fine-tuning for Flow-based Vision-Language-Action Models**|Kang Chen et.al|[paper](https://arxiv.org/abs/2510.25889)|-|-|\n", "Knowledge Vector Weakening: Efficient Training-free Unlearning for Large Vision-Language Models": "|**2026-1-29**|**Knowledge Vector Weakening: Efficient Training-free Unlearning for Large Vision-Language Models**|Yejin Kim et.al|[paper](https://arxiv.org/abs/2601.21794)|-|-|\n", "Dynamic Topology Awareness: Breaking the Granularity Rigidity in Vision-Language Navigation": "|**2026-1-29**|**Dynamic Topology Awareness: Breaking the Granularity Rigidity in Vision-Language Navigation**|Jiankun Peng et.al|[paper](https://arxiv.org/abs/2601.21751)|[code](https://github.com/shannanshouyin/DGNav.)|-|\n", "CoFreeVLA: Collision-Free Dual-Arm Manipulation via Vision-Language-Action Model and Risk Estimation": "|**2026-1-29**|**CoFreeVLA: Collision-Free Dual-Arm Manipulation via Vision-Language-Action Model and Risk Estimation**|Xuanran Zhai et.al|[paper](https://arxiv.org/abs/2601.21712)|-|-|\n", "OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models": "|**2026-1-29**|**OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models**|Yufeng Zhong et.al|[paper](https://arxiv.org/abs/2601.21639)|-|-|\n", "PathReasoner-R1: Instilling Structured Reasoning into Pathology Vision-Language Model via Knowledge-Guided Policy Optimization": "|**2026-1-29**|**PathReasoner-R1: Instilling Structured Reasoning into Pathology Vision-Language Model via Knowledge-Guided Policy Optimization**|Songhan Jiang et.al|[paper](https://arxiv.org/abs/2601.21617)|[code](https://github.com/cyclexfy/PathReasoner-R1.)|-|\n", "WMVLM: Evaluating Diffusion Model Image Watermarking via Vision-Language Models": "|**2026-1-29**|**WMVLM: Evaluating Diffusion Model Image Watermarking via Vision-Language Models**|Zijin Yang et.al|[paper](https://arxiv.org/abs/2601.21610)|-|-|\n", "AIR-VLA: Vision-Language-Action Systems for Aerial Manipulation": "|**2026-1-29**|**AIR-VLA: Vision-Language-Action Systems for Aerial Manipulation**|Jianli Sun et.al|[paper](https://arxiv.org/abs/2601.21602)|[code](https://anonymous.4open.science/r/AIR-VLA-dataset-B5CC/.)|-|\n", "Bring My Cup! Personalizing Vision-Language-Action Models with Visual Attentive Prompting": "|**2026-1-29**|**Bring My Cup! Personalizing Vision-Language-Action Models with Visual Attentive Prompting**|Sangoh Lee et.al|[paper](https://arxiv.org/abs/2512.20014)|[code](https://vap-project.github.io/)|<details><summary>detail</summary>Project page with videos and code: https://vap-project</details>|\n", "ViSurf: Visual Supervised-and-Reinforcement Fine-Tuning for Large Vision-and-Language Models": "|**2026-1-29**|**ViSurf: Visual Supervised-and-Reinforcement Fine-Tuning for Large Vision-and-Language Models**|Yuqi Liu et.al|[paper](https://arxiv.org/abs/2510.10606)|-|-|\n", "On the Adversarial Robustness of Large Vision-Language Models under Visual Token Compression": "|**2026-1-29**|**On the Adversarial Robustness of Large Vision-Language Models under Visual Token Compression**|Xinwei Zhang et.al|[paper](https://arxiv.org/abs/2601.21531)|-|<details><summary>detail</summary>Under Review</details>|\n", "Beyond Retraining: Training-Free Unknown Class Filtering for Source-Free Open Set Domain Adaptation of Vision-Language Models": "|**2026-1-28**|**Beyond Retraining: Training-Free Unknown Class Filtering for Source-Free Open Set Domain Adaptation of Vision-Language Models**|Yongguang Li et.al|[paper](https://arxiv.org/abs/2504.14224)|-|<details><summary>detail</summary>Core methods unchanged</details>|\n", "MARE: Multimodal Alignment and Reinforcement for Explainable Deepfake Detection via Vision-Language Models": "|**2026-1-28**|**MARE: Multimodal Alignment and Reinforcement for Explainable Deepfake Detection via Vision-Language Models**|Wenbo Xu et.al|[paper](https://arxiv.org/abs/2601.20433)|-|-|\n"}}