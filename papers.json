{"source-free": {"Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection": "|**2025-12-24**|**Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection**|Sairam VCR et.al|[paper](https://arxiv.org/abs/2512.17514)|-|-|\n", "Exploiting Radio Frequency Fingerprints for Device Identification: Tackling Cross-receiver Challenges in the Source-data-free Scenario": "|**2025-12-18**|**Exploiting Radio Frequency Fingerprints for Device Identification: Tackling Cross-receiver Challenges in the Source-data-free Scenario**|Liu Yang et.al|[paper](https://arxiv.org/abs/2512.16648)|-|<details><summary>detail</summary>IEEE Transactions on Mobile Computing</details>|\n", "VocSim: A Training-free Benchmark for Zero-shot Content Identity in Single-source Audio": "|**2025-12-10**|**VocSim: A Training-free Benchmark for Zero-shot Content Identity in Single-source Audio**|Maris Basha et.al|[paper](https://arxiv.org/abs/2512.10120)|-|-|\n", "FedSCAl: Leveraging Server and Client Alignment for Unsupervised Federated Source-Free Domain Adaptation": "|**2025-12-7**|**FedSCAl: Leveraging Server and Client Alignment for Unsupervised Federated Source-Free Domain Adaptation**|M Yashwanth et.al|[paper](https://arxiv.org/abs/2512.06738)|-|<details><summary>detail</summary>Winter Conference on Applications of Computer Vision (WACV) 2026</details>|\n", "Source-free Video Domain Adaptation by Learning from Noisy Labels": "|**2025-11-28**|**Source-free Video Domain Adaptation by Learning from Noisy Labels**|Avijit Dasgupta et.al|[paper](https://arxiv.org/abs/2311.18572)|[code](https://avijit9.github.io/CleanAdapt.)|<details><summary>detail</summary>Our extended ICVGIP paper is now accepted in Pattern Recognition</details>|\n", "Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation": "|**2025-11-24**|**Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation**|Huisoo Lee et.al|[paper](https://arxiv.org/abs/2511.19147)|-|-|\n", "Unsupervised and Source-Free Ranking of Biomedical Segmentation Models": "|**2025-11-24**|**Unsupervised and Source-Free Ranking of Biomedical Segmentation Models**|Joshua Talks et.al|[paper](https://arxiv.org/abs/2503.00450)|-|-|\n", "SloMo-Fast: Slow-Momentum and Fast-Adaptive Teachers for Source-Free Continual Test-Time Adaptation": "|**2025-11-23**|**SloMo-Fast: Slow-Momentum and Fast-Adaptive Teachers for Source-Free Continual Test-Time Adaptation**|Md Akil Raihan Iftee et.al|[paper](https://arxiv.org/abs/2511.18468)|-|-|\n", "ViMix-14M: A Curated Multi-Source Video-Text Dataset with Long-Form, High-Quality Captions and Crawl-Free Access": "|**2025-11-23**|**ViMix-14M: A Curated Multi-Source Video-Text Dataset with Long-Form, High-Quality Captions and Crawl-Free Access**|Timing Yang et.al|[paper](https://arxiv.org/abs/2511.18382)|-|-|\n", "HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for Cross-Modality Medical Image Segmentation": "|**2025-11-22**|**HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for Cross-Modality Medical Image Segmentation**|Yulong Shi et.al|[paper](https://arxiv.org/abs/2511.17958)|[code](https://github.com/derekshiii/HEAL.)|<details><summary>detail</summary>Accepted by The 36th British Machine Vision Conference (BMVC 2025)</details>|\n", "Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation": "|**2025-11-19**|**Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation**|Yaxuan Song et.al|[paper](https://arxiv.org/abs/2402.06213)|[code](https://github.com/YXSong000/UAD.)|<details><summary>detail</summary>Accepted by ISBI 2024</details>|\n", "Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection": "|**2025-11-10**|**Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2511.07301)|-|<details><summary>detail</summary>AAAI 2026</details>|\n", "Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping": "|**2025-11-5**|**Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping**|Zhihang Qin et.al|[paper](https://arxiv.org/abs/2511.03691)|-|-|\n", "Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results": "|**2025-11-1**|**Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results**|Rohan Palanikumar et.al|[paper](https://arxiv.org/abs/2511.00752)|-|-|\n", "Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising": "|**2025-10-31**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|\n"}, "object detection": {"Learning Association via Track-Detection Matching for Multi-Object Tracking": "|**2025-12-26**|**Learning Association via Track-Detection Matching for Multi-Object Tracking**|Momir Ad\u017eemovi\u0107 et.al|[paper](https://arxiv.org/abs/2512.22105)|[code](https://github.com/Robotmurlock/TDLP)|-|\n", "Breaking Alignment Barriers: TPS-Driven Semantic Correlation Learning for Alignment-Free RGB-T Salient Object Detection": "|**2025-12-25**|**Breaking Alignment Barriers: TPS-Driven Semantic Correlation Learning for Alignment-Free RGB-T Salient Object Detection**|Lupiao Hu et.al|[paper](https://arxiv.org/abs/2512.21856)|-|<details><summary>detail</summary>Accepted by AAAI2026</details>|\n", "AlignFreeNet: Is Cross-Modal Pre-Alignment Necessary? An End-to-End Alignment-Free Lightweight Network for Visible-Infrared Object Detection": "|**2025-12-24**|**AlignFreeNet: Is Cross-Modal Pre-Alignment Necessary? An End-to-End Alignment-Free Lightweight Network for Visible-Infrared Object Detection**|Dingkun Zhu et.al|[paper](https://arxiv.org/abs/2507.20146)|-|-|\n", "Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection": "|**2025-12-24**|**Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection**|Sairam VCR et.al|[paper](https://arxiv.org/abs/2512.17514)|-|-|\n", "Gaussian Process Assisted Meta-learning for Image Classification and Object Detection Models": "|**2025-12-22**|**Gaussian Process Assisted Meta-learning for Image Classification and Object Detection Models**|Anna R. Flowers et.al|[paper](https://arxiv.org/abs/2512.20021)|-|-|\n", "Rethinking Open-Set Object Detection: Issues, a New Formulation, and Taxonomy": "|**2025-12-21**|**Rethinking Open-Set Object Detection: Issues, a New Formulation, and Taxonomy**|Yusuke Hosoya et.al|[paper](https://arxiv.org/abs/2207.09775)|-|<details><summary>detail</summary>IJCV</details>|\n", "OW-Rep: Open World Object Detection with Instance Representation Learning": "|**2025-12-21**|**OW-Rep: Open World Object Detection with Instance Representation Learning**|Sunoh Lee et.al|[paper](https://arxiv.org/abs/2409.16073)|[code](https://sunohlee.github.io/OW-Rep/)|<details><summary>detail</summary>WACV 2026</details>|\n", "Building UI/UX Dataset for Dark Pattern Detection and YOLOv12x-based Real-Time Object Recognition Detection System": "|**2025-12-20**|**Building UI/UX Dataset for Dark Pattern Detection and YOLOv12x-based Real-Time Object Recognition Detection System**|Se-Young Jang et.al|[paper](https://arxiv.org/abs/2512.18269)|[code](https://github.com/B4E2/B4E2-DarkPattern-YOLO-DataSet.)|<details><summary>detail</summary>7page</details>|\n", "Spectral Discrepancy and Cross-modal Semantic Consistency Learning for Object Detection in Hyperspectral Image": "|**2025-12-20**|**Spectral Discrepancy and Cross-modal Semantic Consistency Learning for Object Detection in Hyperspectral Image**|Xiao He et.al|[paper](https://arxiv.org/abs/2512.18245)|-|-|\n", "ALIGN: Advanced Query Initialization with LiDAR-Image Guidance for Occlusion-Robust 3D Object Detection": "|**2025-12-19**|**ALIGN: Advanced Query Initialization with LiDAR-Image Guidance for Occlusion-Robust 3D Object Detection**|Janghyun Baek et.al|[paper](https://arxiv.org/abs/2512.18187)|-|-|\n", "SpikeDet: Better Firing Patterns for Accurate and Energy-Efficient Object Detection with Spiking Neural Networks": "|**2025-12-19**|**SpikeDet: Better Firing Patterns for Accurate and Energy-Efficient Object Detection with Spiking Neural Networks**|Yimeng Fan et.al|[paper](https://arxiv.org/abs/2501.15151)|-|-|\n", "SSCATeR: Sparse Scatter-Based Convolution Algorithm with Temporal Data Recycling for Real-Time 3D Object Detection in LiDAR Point Clouds": "|**2025-12-19**|**SSCATeR: Sparse Scatter-Based Convolution Algorithm with Temporal Data Recycling for Real-Time 3D Object Detection in LiDAR Point Clouds**|Alexander Dow et.al|[paper](https://arxiv.org/abs/2512.08557)|-|<details><summary>detail</summary>23 Pages</details>|\n", "Generative Human-Object Interaction Detection via Differentiable Cognitive Steering of Multi-modal LLMs": "|**2025-12-19**|**Generative Human-Object Interaction Detection via Differentiable Cognitive Steering of Multi-modal LLMs**|Zhaolin Cai et.al|[paper](https://arxiv.org/abs/2512.17640)|-|-|\n", "StereoMV2D: A Sparse Temporal Stereo-Enhanced Framework for Robust Multi-View 3D Object Detection": "|**2025-12-19**|**StereoMV2D: A Sparse Temporal Stereo-Enhanced Framework for Robust Multi-View 3D Object Detection**|Di Wu et.al|[paper](https://arxiv.org/abs/2512.17620)|[code](https://github.com/Uddd821/StereoMV2D.)|-|\n", "SceneDiff: A Benchmark and Method for Multiview Object Change Detection": "|**2025-12-18**|**SceneDiff: A Benchmark and Method for Multiview Object Change Detection**|Yuqun Wu et.al|[paper](https://arxiv.org/abs/2512.16908)|-|-|\n"}, "domain adaptation": {"When Unsupervised Domain Adaptation meets One-class Anomaly Detection: Addressing the Two-fold Unsupervised Curse by Leveraging Anomaly Scarcity": "|**2025-12-26**|**When Unsupervised Domain Adaptation meets One-class Anomaly Detection: Addressing the Two-fold Unsupervised Curse by Leveraging Anomaly Scarcity**|Nesryne Mejri et.al|[paper](https://arxiv.org/abs/2502.21022)|-|<details><summary>detail</summary>Added acknowledgments</details>|\n", "Co-Teaching for Unsupervised Domain Adaptation and Expansion": "|**2025-12-25**|**Co-Teaching for Unsupervised Domain Adaptation and Expansion**|Hailan Lin et.al|[paper](https://arxiv.org/abs/2204.01210)|-|<details><summary>detail</summary>Accepted as a long paper at MMM 2026</details>|\n", "Shared & Domain Self-Adaptive Experts with Frequency-Aware Discrimination for Continual Test-Time Adaptation": "|**2025-12-25**|**Shared & Domain Self-Adaptive Experts with Frequency-Aware Discrimination for Continual Test-Time Adaptation**|JianChao Zhao et.al|[paper](https://arxiv.org/abs/2507.00502)|[code](https://github.com/ZJC25127/Domain-Self-Adaptive-CTTA.git.)|-|\n", "Beyond Weight Adaptation: Feature-Space Domain Injection for Cross-Modal Ship Re-Identification": "|**2025-12-23**|**Beyond Weight Adaptation: Feature-Space Domain Injection for Cross-Modal Ship Re-Identification**|Tingfeng Xian et.al|[paper](https://arxiv.org/abs/2512.20892)|[code](https://github.com/TingfengXian/DRI.)|-|\n", "DATTA: Domain Diversity Aware Test-Time Adaptation for Dynamic Domain Shift Data Streams": "|**2025-12-23**|**DATTA: Domain Diversity Aware Test-Time Adaptation for Dynamic Domain Shift Data Streams**|Chuyang Ye et.al|[paper](https://arxiv.org/abs/2408.08056)|[code](https://github.com/DYW77/DATTA.)|<details><summary>detail</summary>2025 IEEE International Conference on Multimedia and Expo (ICME)</details>|\n", "Statistically-Guided Dual-Domain Meta-Learning with Adaptive Multi-Prototype Aggregation for Distributed Fiber Optic Sensing": "|**2025-12-22**|**Statistically-Guided Dual-Domain Meta-Learning with Adaptive Multi-Prototype Aggregation for Distributed Fiber Optic Sensing**|Yifan He et.al|[paper](https://arxiv.org/abs/2511.17902)|-|-|\n", "Low-Resource Domain Adaptation for Speech LLMs via Text-Only Fine-Tuning": "|**2025-12-22**|**Low-Resource Domain Adaptation for Speech LLMs via Text-Only Fine-Tuning**|Yangui Fang et.al|[paper](https://arxiv.org/abs/2506.05671)|-|<details><summary>detail</summary>This paper has been ACCEPTED for publication in ASRU</details>|\n", "Navigating the Reality Gap: Privacy-Preserving Adaptation of ASR for Challenging Low-Resource Domains": "|**2025-12-22**|**Navigating the Reality Gap: Privacy-Preserving Adaptation of ASR for Challenging Low-Resource Domains**|Darshil Chauhan et.al|[paper](https://arxiv.org/abs/2512.16401)|-|-|\n", "Low-Rank Expert Merging for Multi-Source Domain Adaptation in Person Re-Identification": "|**2025-12-21**|**Low-Rank Expert Merging for Multi-Source Domain Adaptation in Person Re-Identification**|Taha Mustapha Nehdi et.al|[paper](https://arxiv.org/abs/2508.06831)|-|-|\n", "TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in Legal and Financial Domain": "|**2025-12-20**|**TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in Legal and Financial Domain**|Yidan Sun et.al|[paper](https://arxiv.org/abs/2511.09854)|-|-|\n", "Hierarchical Bayesian Framework for Multisource Domain Adaptation": "|**2025-12-20**|**Hierarchical Bayesian Framework for Multisource Domain Adaptation**|Alexander M. Glandon et.al|[paper](https://arxiv.org/abs/2512.18553)|-|-|\n", "CTTA-T: Continual Test-Time Adaptation for Text Understanding via Teacher-Student with a Domain-aware and Generalized Teacher": "|**2025-12-20**|**CTTA-T: Continual Test-Time Adaptation for Text Understanding via Teacher-Student with a Domain-aware and Generalized Teacher**|Tianlun Liu et.al|[paper](https://arxiv.org/abs/2512.18321)|-|-|\n", "Adaptive Frequency Domain Alignment Network for Medical image segmentation": "|**2025-12-19**|**Adaptive Frequency Domain Alignment Network for Medical image segmentation**|Zhanwei Li et.al|[paper](https://arxiv.org/abs/2512.16393)|-|-|\n", "Flying in Clutter on Monocular RGB by Learning in 3D Radiance Fields with Domain Adaptation": "|**2025-12-19**|**Flying in Clutter on Monocular RGB by Learning in 3D Radiance Fields with Domain Adaptation**|Xijie Huang et.al|[paper](https://arxiv.org/abs/2512.17349)|-|-|\n", "Mitigating Hallucinations in Healthcare LLMs with Granular Fact-Checking and Domain-Specific Adaptation": "|**2025-12-19**|**Mitigating Hallucinations in Healthcare LLMs with Granular Fact-Checking and Domain-Specific Adaptation**|Musarrat Zeba et.al|[paper](https://arxiv.org/abs/2512.16189)|-|-|\n"}, "domain generalization": {"CAE-Net: Generalized Deepfake Image Detection using Convolution and Attention Mechanisms with Spatial and Frequency Domain Features": "|**2025-12-25**|**CAE-Net: Generalized Deepfake Image Detection using Convolution and Attention Mechanisms with Spatial and Frequency Domain Features**|Anindya Bhattacharjee et.al|[paper](https://arxiv.org/abs/2502.10682)|-|<details><summary>detail</summary>Published in Journal of Visual Communication and Image Representation</details>|\n", "CTTA-T: Continual Test-Time Adaptation for Text Understanding via Teacher-Student with a Domain-aware and Generalized Teacher": "|**2025-12-20**|**CTTA-T: Continual Test-Time Adaptation for Text Understanding via Teacher-Student with a Domain-aware and Generalized Teacher**|Tianlun Liu et.al|[paper](https://arxiv.org/abs/2512.18321)|-|-|\n", "Exploration of Augmentation Strategies in Multi-modal Retrieval-Augmented Generation for the Biomedical Domain: A Case Study Evaluating Question Answering in Glycobiology": "|**2025-12-18**|**Exploration of Augmentation Strategies in Multi-modal Retrieval-Augmented Generation for the Biomedical Domain: A Case Study Evaluating Question Answering in Glycobiology**|Primo\u017e Kocbek et.al|[paper](https://arxiv.org/abs/2512.16802)|-|<details><summary>detail</summary>Will be published in IEEE BigData 2025 proceedings</details>|\n", "Causal-Tune: Mining Causal Factors from Vision Foundation Models for Domain Generalized Semantic Segmentation": "|**2025-12-18**|**Causal-Tune: Mining Causal Factors from Vision Foundation Models for Domain Generalized Semantic Segmentation**|Yin Zhang et.al|[paper](https://arxiv.org/abs/2512.16567)|-|<details><summary>detail</summary>Accepted by AAAI 2026</details>|\n", "Exploiting Domain Properties in Language-Driven Domain Generalization for Semantic Segmentation": "|**2025-12-17**|**Exploiting Domain Properties in Language-Driven Domain Generalization for Semantic Segmentation**|Seogkyu Jeon et.al|[paper](https://arxiv.org/abs/2512.03508)|[code](https://github.com/jone1222/DPMFormer.)|<details><summary>detail</summary>ICCV 2025 (poster)</details>|\n", "XAI-Driven Diagnosis of Generalization Failure in State-Space Cerebrovascular Segmentation Models: A Case Study on Domain Shift Between RSNA and TopCoW Datasets": "|**2025-12-15**|**XAI-Driven Diagnosis of Generalization Failure in State-Space Cerebrovascular Segmentation Models: A Case Study on Domain Shift Between RSNA and TopCoW Datasets**|Youssef Abuzeid et.al|[paper](https://arxiv.org/abs/2512.13977)|-|-|\n", "Generating Reliable Synthetic Clinical Trial Data: The Role of Hyperparameter Optimization and Domain Constraints": "|**2025-12-15**|**Generating Reliable Synthetic Clinical Trial Data: The Role of Hyperparameter Optimization and Domain Constraints**|Waldemar Hahn et.al|[paper](https://arxiv.org/abs/2505.05019)|-|<details><summary>detail</summary>Published in Information Sciences</details>|\n", "From Imitation to Discrimination: Toward A Generalized Curriculum Advantage Mechanism Enhancing Cross-Domain Reasoning Tasks": "|**2025-12-15**|**From Imitation to Discrimination: Toward A Generalized Curriculum Advantage Mechanism Enhancing Cross-Domain Reasoning Tasks**|Changpeng Yang et.al|[paper](https://arxiv.org/abs/2512.02580)|-|<details><summary>detail</summary>Accepted by AAAI 2026</details>|\n", "The algorithmic muse and the public domain: Why copyrights legal philosophy precludes protection for generative AI outputs": "|**2025-12-15**|**The algorithmic muse and the public domain: Why copyrights legal philosophy precludes protection for generative AI outputs**|Ezieddin Elmahjub et.al|[paper](https://arxiv.org/abs/2512.13750)|-|-|\n", "Incremental Validation of Automated Driving Functions using Generic Volumes in Micro- Operational Design Domains": "|**2025-12-12**|**Incremental Validation of Automated Driving Functions using Generic Volumes in Micro- Operational Design Domains**|Steffen Sch\u00e4fer et.al|[paper](https://arxiv.org/abs/2512.11351)|-|-|\n", "The Finer the Better: Towards Granular-aware Open-set Domain Generalization": "|**2025-12-12**|**The Finer the Better: Towards Granular-aware Open-set Domain Generalization**|Yunyun Wang et.al|[paper](https://arxiv.org/abs/2511.16979)|-|-|\n", "Learning from a Generative Oracle: Domain Adaptation for Restoration": "|**2025-12-11**|**Learning from a Generative Oracle: Domain Adaptation for Restoration**|Yuyang Hu et.al|[paper](https://arxiv.org/abs/2512.11121)|-|-|\n", "Self-Ensemble Post Learning for Noisy Domain Generalization": "|**2025-12-11**|**Self-Ensemble Post Learning for Noisy Domain Generalization**|Wang Lu et.al|[paper](https://arxiv.org/abs/2512.10818)|-|-|\n", "Leveraging Depth and Language for Open-Vocabulary Domain-Generalized Semantic Segmentation": "|**2025-12-11**|**Leveraging Depth and Language for Open-Vocabulary Domain-Generalized Semantic Segmentation**|Siyu Chen et.al|[paper](https://arxiv.org/abs/2506.09881)|[code](https://github.com/anonymouse-9c53tp182bvz/Vireo.)|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|\n", "Federated Domain Generalization with Latent Space Inversion": "|**2025-12-10**|**Federated Domain Generalization with Latent Space Inversion**|Ragja Palakkadavath et.al|[paper](https://arxiv.org/abs/2512.10224)|-|<details><summary>detail</summary>ICDM 2025</details>|\n"}, "vision language": {"LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models": "|**2025-12-26**|**LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models**|Senyu Fei et.al|[paper](https://arxiv.org/abs/2510.13626)|-|-|\n", "LongFly: Long-Horizon UAV Vision-and-Language Navigation with Spatiotemporal Context Integration": "|**2025-12-26**|**LongFly: Long-Horizon UAV Vision-and-Language Navigation with Spatiotemporal Context Integration**|Wen Jiang et.al|[paper](https://arxiv.org/abs/2512.22010)|-|-|\n", "StereoVLA: Enhancing Vision-Language-Action Models with Stereo Vision": "|**2025-12-26**|**StereoVLA: Enhancing Vision-Language-Action Models with Stereo Vision**|Shengliang Deng et.al|[paper](https://arxiv.org/abs/2512.21970)|-|-|\n", "Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems": "|**2025-12-26**|**Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems**|YuChe Hsu et.al|[paper](https://arxiv.org/abs/2512.20387)|-|-|\n", "Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?": "|**2025-12-26**|**Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?**|Naen Xu et.al|[paper](https://arxiv.org/abs/2512.21871)|-|<details><summary>detail</summary>AAAI 2026 (Oral)</details>|\n", "Training-free Conditional Image Embedding Framework Leveraging Large Vision Language Models": "|**2025-12-25**|**Training-free Conditional Image Embedding Framework Leveraging Large Vision Language Models**|Masayuki Kawarada et.al|[paper](https://arxiv.org/abs/2512.21860)|-|-|\n", "Few Tokens Matter: Entropy Guided Attacks on Vision-Language Models": "|**2025-12-25**|**Few Tokens Matter: Entropy Guided Attacks on Vision-Language Models**|Mengqi He et.al|[paper](https://arxiv.org/abs/2512.21815)|-|<details><summary>detail</summary>19 Pages</details>|\n", "Scene-VLM: Multimodal Video Scene Segmentation via Vision-Language Models": "|**2025-12-25**|**Scene-VLM: Multimodal Video Scene Segmentation via Vision-Language Models**|Nimrod Berman et.al|[paper](https://arxiv.org/abs/2512.21778)|-|-|\n", "ChatENV: An Interactive Vision-Language Model for Sensor-Guided Environmental Monitoring and Scenario Simulation": "|**2025-12-25**|**ChatENV: An Interactive Vision-Language Model for Sensor-Guided Environmental Monitoring and Scenario Simulation**|Hosam Elgendy et.al|[paper](https://arxiv.org/abs/2508.10635)|-|-|\n", "A Medical Multimodal Diagnostic Framework Integrating Vision-Language Models and Logic Tree Reasoning": "|**2025-12-25**|**A Medical Multimodal Diagnostic Framework Integrating Vision-Language Models and Logic Tree Reasoning**|Zelin Zang et.al|[paper](https://arxiv.org/abs/2512.21583)|-|-|\n", "Towards Long-window Anchoring in Vision-Language Model Distillation": "|**2025-12-25**|**Towards Long-window Anchoring in Vision-Language Model Distillation**|Haoyi Zhou et.al|[paper](https://arxiv.org/abs/2512.21576)|-|<details><summary>detail</summary>Accepted by AAAI 2026</details>|\n", "Hierarchy-Aware Fine-Tuning of Vision-Language Models": "|**2025-12-25**|**Hierarchy-Aware Fine-Tuning of Vision-Language Models**|Jiayu Li et.al|[paper](https://arxiv.org/abs/2512.21529)|-|-|\n", "RLLaVA: An RL-central Framework for Language and Vision Assistants": "|**2025-12-24**|**RLLaVA: An RL-central Framework for Language and Vision Assistants**|Lei Zhao et.al|[paper](https://arxiv.org/abs/2512.21450)|[code](https://github.com/TinyLoopX/RLLaVA.)|<details><summary>detail</summary>The code is available at https://github</details>|\n", "Understanding Virality: A Rubric based Vision-Language Model Framework for Short-Form Edutainment Evaluation": "|**2025-12-24**|**Understanding Virality: A Rubric based Vision-Language Model Framework for Short-Form Edutainment Evaluation**|Arnav Gupta et.al|[paper](https://arxiv.org/abs/2512.21402)|-|<details><summary>detail</summary>Under Review</details>|\n", "Beyond Memorization: A Multi-Modal Ordinal Regression Benchmark to Expose Popularity Bias in Vision-Language Models": "|**2025-12-24**|**Beyond Memorization: A Multi-Modal Ordinal Regression Benchmark to Expose Popularity Bias in Vision-Language Models**|Li-Zhong Szu-Tu et.al|[paper](https://arxiv.org/abs/2512.21337)|[code](https://sytwu.github.io/BeyondMemo/)|<details><summary>detail</summary>Project page: https://sytwu</details>|\n"}}