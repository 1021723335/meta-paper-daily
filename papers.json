{"source-free": {"Model-Free Hovering and Source Seeking via Extremum Seeking Control: Experimental Demonstration": "|**2025-8-28**|**Model-Free Hovering and Source Seeking via Extremum Seeking Control: Experimental Demonstration**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2508.20836)|-|-|\n", "VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection": "|**2025-8-26**|**VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection**|Jianhong Han et.al|[paper](https://arxiv.org/abs/2508.11167)|-|<details><summary>detail</summary>Manuscript submitted to IEEE TCSVT</details>|\n", "Towards Source-Free Machine Unlearning": "|**2025-8-20**|**Towards Source-Free Machine Unlearning**|Sk Miraj Ahmed et.al|[paper](https://arxiv.org/abs/2508.15127)|-|<details><summary>detail</summary>Accepted by CVPR 2025</details>|\n", "Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method": "|**2025-8-14**|**Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2508.09202)|-|-|\n", "Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation": "|**2025-8-7**|**Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation**|Jianming Liu et.al|[paper](https://arxiv.org/abs/2508.05213)|[code](https://github.com/ljm198134/TVGTANet.)|-|\n", "Model Recycling Framework for Multi-Source Data-Free Supervised Transfer Learning": "|**2025-8-4**|**Model Recycling Framework for Multi-Source Data-Free Supervised Transfer Learning**|Sijia Wang et.al|[paper](https://arxiv.org/abs/2508.02039)|-|-|\n", "Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments": "|**2025-7-30**|**Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2501.02184)|-|-|\n", "Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation": "|**2025-7-28**|**Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation**|Yihong Cao et.al|[paper](https://arxiv.org/abs/2506.21198)|[code](https://github.com/yihong-97/UNLOCK.)|<details><summary>detail</summary>ICCV 2025</details>|\n", "GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning": "|**2025-7-26**|**GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning**|Sanqing Qu et.al|[paper](https://arxiv.org/abs/2403.14410)|[code](https://github.com/ispc-lab/GLC-plus.)|<details><summary>detail</summary>A substantial extension of the CVPR paper \"Upcycling Models under Domain and Category Shift\"</details>|\n", "SFUOD: Source-Free Unknown Object Detection": "|**2025-7-23**|**SFUOD: Source-Free Unknown Object Detection**|Keon-Hee Park et.al|[paper](https://arxiv.org/abs/2507.17373)|-|<details><summary>detail</summary>This paper has been accepted by ICCV 2025</details>|\n", "Text-Driven Causal Representation Learning for Source-Free Domain Generalization": "|**2025-7-14**|**Text-Driven Causal Representation Learning for Source-Free Domain Generalization**|Lihua Zhou et.al|[paper](https://arxiv.org/abs/2507.09961)|-|<details><summary>detail</summary>Under Review</details>|\n", "Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting": "|**2025-7-12**|**Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting**|Zheang Huai et.al|[paper](https://arxiv.org/abs/2505.08527)|[code](https://github.com/xmed-lab/DFG.)|<details><summary>detail</summary>Accepted in TMI 2025</details>|\n", "Source-Free Domain Adaptation via Multi-view Contrastive Learning": "|**2025-7-4**|**Source-Free Domain Adaptation via Multi-view Contrastive Learning**|Amirfarhad Farhadi et.al|[paper](https://arxiv.org/abs/2507.03321)|-|-|\n", "Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework": "|**2025-6-26**|**Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework**|Ismail Nejjar et.al|[paper](https://arxiv.org/abs/2411.12558)|-|<details><summary>detail</summary>TMLR 2025</details>|\n", "Context Aware Grounded Teacher for Source Free Object Detection": "|**2025-6-25**|**Context Aware Grounded Teacher for Source Free Object Detection**|Tajamul Ashraf et.al|[paper](https://arxiv.org/abs/2504.15404)|[code](https://github.com/Tajamul21/Grounded_Teacher.)|-|\n"}, "object detection": {"FLORA: Efficient Synthetic Data Generation for Object Detection in Low-Data Regimes via finetuning Flux LoRA": "|**2025-8-29**|**FLORA: Efficient Synthetic Data Generation for Object Detection in Low-Data Regimes via finetuning Flux LoRA**|Alvaro Patricio et.al|[paper](https://arxiv.org/abs/2508.21712)|-|-|\n", "HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection": "|**2025-8-28**|**HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection**|Harris Song et.al|[paper](https://arxiv.org/abs/2508.21135)|-|-|\n", "Contrastive Learning through Auxiliary Branch for Video Object Detection": "|**2025-8-28**|**Contrastive Learning through Auxiliary Branch for Video Object Detection**|Lucas Rakotoarivony et.al|[paper](https://arxiv.org/abs/2508.20551)|-|<details><summary>detail</summary>Accepted paper for ACIVS 2025</details>|\n", "Enhancing Pseudo-Boxes via Data-Level LiDAR-Camera Fusion for Unsupervised 3D Object Detection": "|**2025-8-28**|**Enhancing Pseudo-Boxes via Data-Level LiDAR-Camera Fusion for Unsupervised 3D Object Detection**|Mingqian Ji et.al|[paper](https://arxiv.org/abs/2508.20530)|-|<details><summary>detail</summary>Accepted by ACM MM 2025</details>|\n", "Adaptive Dual Uncertainty Optimization: Boosting Monocular 3D Object Detection under Test-Time Shifts": "|**2025-8-28**|**Adaptive Dual Uncertainty Optimization: Boosting Monocular 3D Object Detection under Test-Time Shifts**|Zixuan Hu et.al|[paper](https://arxiv.org/abs/2508.20488)|-|<details><summary>detail</summary>Accepted by ICCV 2025 (Highlight)</details>|\n", "Graph-Based Uncertainty Modeling and Multimodal Fusion for Salient Object Detection": "|**2025-8-28**|**Graph-Based Uncertainty Modeling and Multimodal Fusion for Salient Object Detection**|Yuqi Xiong et.al|[paper](https://arxiv.org/abs/2508.20415)|[code](https://github.com/YukiBear426/DUP-MCRNet.)|<details><summary>detail</summary>ICONIP 2025</details>|\n", "Ultra-Low-Latency Spiking Neural Networks with Temporal-Dependent Integrate-and-Fire Neuron Model for Objects Detection": "|**2025-8-27**|**Ultra-Low-Latency Spiking Neural Networks with Temporal-Dependent Integrate-and-Fire Neuron Model for Objects Detection**|Chengjun Zhang et.al|[paper](https://arxiv.org/abs/2508.20392)|-|-|\n", "OpenM3D: Open Vocabulary Multi-view Indoor 3D Object Detection without Human Annotations": "|**2025-8-27**|**OpenM3D: Open Vocabulary Multi-view Indoor 3D Object Detection without Human Annotations**|Peng-Hao Hsu et.al|[paper](https://arxiv.org/abs/2508.20063)|-|<details><summary>detail</summary>ICCV2025</details>|\n", "GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity": "|**2025-8-27**|**GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity**|Seongheon Park et.al|[paper](https://arxiv.org/abs/2508.19972)|-|-|\n", "Streamlining the Development of Active Learning Methods in Real-World Object Detection": "|**2025-8-27**|**Streamlining the Development of Active Learning Methods in Real-World Object Detection**|Moussa Kassem Sbeyti et.al|[paper](https://arxiv.org/abs/2508.19906)|[code](https://mos-ks.github.io/publications/.)|<details><summary>detail</summary>This work has been submitted to the IEEE for possible publication</details>|\n", "Robust Single-Stage Fully Sparse 3D Object Detection via Detachable Latent Diffusion": "|**2025-8-27**|**Robust Single-Stage Fully Sparse 3D Object Detection via Detachable Latent Diffusion**|Wentao Qu et.al|[paper](https://arxiv.org/abs/2508.03252)|-|-|\n", "SPLF-SAM: Self-Prompting Segment Anything Model for Light Field Salient Object Detection": "|**2025-8-27**|**SPLF-SAM: Self-Prompting Segment Anything Model for Light Field Salient Object Detection**|Qiyao Xu et.al|[paper](https://arxiv.org/abs/2508.19746)|[code](https://github.com/XucherCH/splfsam.)|-|\n", "Scalable Object Detection in the Car Interior With Vision Foundation Models": "|**2025-8-27**|**Scalable Object Detection in the Car Interior With Vision Foundation Models**|B\u00e1lint M\u00e9sz\u00e1ros et.al|[paper](https://arxiv.org/abs/2508.19651)|-|-|\n", "LDRFusion: A LiDAR-Dominant multimodal refinement framework for 3D object detection": "|**2025-8-27**|**LDRFusion: A LiDAR-Dominant multimodal refinement framework for 3D object detection**|Jijun Wang et.al|[paper](https://arxiv.org/abs/2507.16224)|-|-|\n", "Quantization Robustness to Input Degradations for Object Detection": "|**2025-8-27**|**Quantization Robustness to Input Degradations for Object Detection**|Toghrul Karimov et.al|[paper](https://arxiv.org/abs/2508.19600)|[code](https://github.com/AllanK24/QRID.)|-|\n"}, "domain adaptation": {"MedShift: Implicit Conditional Transport for X-Ray Domain Adaptation": "|**2025-8-29**|**MedShift: Implicit Conditional Transport for X-Ray Domain Adaptation**|Francisco Caetano et.al|[paper](https://arxiv.org/abs/2508.21435)|[code](https://caetas.github.io/medshift.html)|<details><summary>detail</summary>the ICCV 2025 AIM Workshop</details>|\n", "A Knowledge Distillation-empowered Adaptive Federated Reinforcement Learning Framework for Multi-Domain IoT Applications Scheduling": "|**2025-8-29**|**A Knowledge Distillation-empowered Adaptive Federated Reinforcement Learning Framework for Multi-Domain IoT Applications Scheduling**|Zhiyu Wang et.al|[paper](https://arxiv.org/abs/2508.21328)|-|-|\n", "ODES: Domain Adaptation with Expert Guidance for Online Medical Image Segmentation": "|**2025-8-28**|**ODES: Domain Adaptation with Expert Guidance for Online Medical Image Segmentation**|Md Shazid Islam et.al|[paper](https://arxiv.org/abs/2312.05407)|-|-|\n", "Gradual Domain Adaptation for Graph Learning": "|**2025-8-28**|**Gradual Domain Adaptation for Graph Learning**|Pui Ieng Lei et.al|[paper](https://arxiv.org/abs/2501.17443)|-|-|\n", "Adaptive Federated Distillation for Multi-Domain Non-IID Textual Data": "|**2025-8-28**|**Adaptive Federated Distillation for Multi-Domain Non-IID Textual Data**|Jiahao Xiao et.al|[paper](https://arxiv.org/abs/2508.20557)|[code](https://github.com/jiahaoxiao1228/AdaFD.)|-|\n", "Domain Adaptation Techniques for Natural and Medical Image Classification": "|**2025-8-28**|**Domain Adaptation Techniques for Natural and Medical Image Classification**|Ahmad Chaddad et.al|[paper](https://arxiv.org/abs/2508.20537)|-|<details><summary>detail</summary>Accepted in Information Sciences</details>|\n", "Learning What is Worth Learning: Active and Sequential Domain Adaptation for Multi-modal Gross Tumor Volume Segmentation": "|**2025-8-28**|**Learning What is Worth Learning: Active and Sequential Domain Adaptation for Multi-modal Gross Tumor Volume Segmentation**|Jingyun Yang et.al|[paper](https://arxiv.org/abs/2508.20528)|[code](https://github.com/Hiyoochan/mmActS)|-|\n", "Bridging Domain Gaps for Fine-Grained Moth Classification Through Expert-Informed Adaptation and Foundation Model Priors": "|**2025-8-27**|**Bridging Domain Gaps for Fine-Grained Moth Classification Through Expert-Informed Adaptation and Foundation Model Priors**|Ross J Gardiner et.al|[paper](https://arxiv.org/abs/2508.20089)|-|-|\n", "On Domain-Adaptive Post-Training for Multimodal Large Language Models": "|**2025-8-27**|**On Domain-Adaptive Post-Training for Multimodal Large Language Models**|Daixuan Cheng et.al|[paper](https://arxiv.org/abs/2411.19930)|[code](https://huggingface.co/AdaptLLM/Adapt-MLLM-to-Domains)|<details><summary>detail</summary>EMNLP 2025 Findings</details>|\n", "Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains": "|**2025-8-26**|**Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains**|Peiran Zhou et.al|[paper](https://arxiv.org/abs/2508.19357)|-|-|\n", "PointFix: Learning to Fix Domain Bias for Robust Online Stereo Adaptation": "|**2025-8-26**|**PointFix: Learning to Fix Domain Bias for Robust Online Stereo Adaptation**|Kwonyoung Kim et.al|[paper](https://arxiv.org/abs/2207.13340)|-|<details><summary>detail</summary>ECCV 2022</details>|\n", "Feature-Space Planes Searcher: A Universal Domain Adaptation Framework for Interpretability and Computational Efficiency": "|**2025-8-26**|**Feature-Space Planes Searcher: A Universal Domain Adaptation Framework for Interpretability and Computational Efficiency**|Zhitong Cheng et.al|[paper](https://arxiv.org/abs/2508.18693)|-|-|\n", "Adapting Large Language Models to Log Analysis with Interpretable Domain Knowledge": "|**2025-8-25**|**Adapting Large Language Models to Log Analysis with Interpretable Domain Knowledge**|Yuhe Ji et.al|[paper](https://arxiv.org/abs/2412.01377)|-|<details><summary>detail</summary>Accepted by CIKM 2025</details>|\n", "Uncertainty Awareness on Unsupervised Domain Adaptation for Time Series Data": "|**2025-8-25**|**Uncertainty Awareness on Unsupervised Domain Adaptation for Time Series Data**|Weide Liu et.al|[paper](https://arxiv.org/abs/2508.18630)|-|<details><summary>detail</summary>IEEE Transactions on Multimedia</details>|\n", "Spectrum Prediction in the Fractional Fourier Domain with Adaptive Filtering": "|**2025-8-25**|**Spectrum Prediction in the Fractional Fourier Domain with Adaptive Filtering**|Yanghao Qin et.al|[paper](https://arxiv.org/abs/2508.17872)|-|<details><summary>detail</summary>Accepted by IEEE Wireless Communications Letters</details>|\n"}, "domain generalization": {"Single Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement": "|**2025-8-29**|**Single Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement**|Jia-Xuan Jiang et.al|[paper](https://arxiv.org/abs/2507.08340)|[code](https://github.com/HopkinsKwong/MCCSDG)|<details><summary>detail</summary>Accepted by ACMMM 25</details>|\n", "Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations": "|**2025-8-29**|**Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations**|Ha Min Son et.al|[paper](https://arxiv.org/abs/2508.21769)|-|-|\n", "PointDGRWKV: Generalizing RWKV-like Architecture to Unseen Domains for Point Cloud Classification": "|**2025-8-29**|**PointDGRWKV: Generalizing RWKV-like Architecture to Unseen Domains for Point Cloud Classification**|Hao Yang et.al|[paper](https://arxiv.org/abs/2508.20835)|-|-|\n", "Decentralized Domain Generalization with Style Sharing: Formal Model and Convergence Analysis": "|**2025-8-28**|**Decentralized Domain Generalization with Style Sharing: Formal Model and Convergence Analysis**|Shahryar Zehtabi et.al|[paper](https://arxiv.org/abs/2504.06235)|-|-|\n", "Evaluating Differentially Private Generation of Domain-Specific Text": "|**2025-8-28**|**Evaluating Differentially Private Generation of Domain-Specific Text**|Yidan Sun et.al|[paper](https://arxiv.org/abs/2508.20452)|-|-|\n", "RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation": "|**2025-8-27**|**RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation**|Tianxing Chen et.al|[paper](https://arxiv.org/abs/2506.18088)|[code](https://robotwin-platform.github.io/,)|<details><summary>detail</summary>Project Page: https://robotwin-platform</details>|\n", "IELDG: Suppressing Domain-Specific Noise with Inverse Evolution Layers for Domain Generalized Semantic Segmentation": "|**2025-8-27**|**IELDG: Suppressing Domain-Specific Noise with Inverse Evolution Layers for Domain Generalized Semantic Segmentation**|Qizhe Fan et.al|[paper](https://arxiv.org/abs/2508.19604)|-|-|\n", "Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains": "|**2025-8-26**|**Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains**|Peiran Zhou et.al|[paper](https://arxiv.org/abs/2508.19357)|-|-|\n", "Single-Domain Generalized Object Detection by Balancing Domain Diversity and Invariance": "|**2025-8-26**|**Single-Domain Generalized Object Detection by Balancing Domain Diversity and Invariance**|Zhenwei He et.al|[paper](https://arxiv.org/abs/2502.03835)|-|-|\n", "SCP-116K: A High-Quality Problem-Solution Dataset and a Generalized Pipeline for Automated Extraction in the Higher Education Science Domain": "|**2025-8-24**|**SCP-116K: A High-Quality Problem-Solution Dataset and a Generalized Pipeline for Automated Extraction in the Higher Education Science Domain**|Dakuan Lu et.al|[paper](https://arxiv.org/abs/2501.15587)|[code](https://github.com/AQA6666/SCP-116K-open.)|-|\n", "MGT-Prism: Enhancing Domain Generalization for Machine-Generated Text Detection via Spectral Alignment": "|**2025-8-24**|**MGT-Prism: Enhancing Domain Generalization for Machine-Generated Text Detection via Spectral Alignment**|Shengchao Liu et.al|[paper](https://arxiv.org/abs/2508.13768)|-|-|\n", "Preserving Domain Generalization in Fine-Tuning via Joint Parameter Selection": "|**2025-8-23**|**Preserving Domain Generalization in Fine-Tuning via Joint Parameter Selection**|Bin Pan et.al|[paper](https://arxiv.org/abs/2508.16976)|-|-|\n", "Domain-aligned generative downscaling enhances projections of extreme climate events": "|**2025-8-22**|**Domain-aligned generative downscaling enhances projections of extreme climate events**|Ruian Tie et.al|[paper](https://arxiv.org/abs/2508.16396)|-|-|\n", "Task-Generalized Adaptive Cross-Domain Learning for Multimodal Image Fusion": "|**2025-8-21**|**Task-Generalized Adaptive Cross-Domain Learning for Multimodal Image Fusion**|Mengyu Wang et.al|[paper](https://arxiv.org/abs/2508.15505)|[code](https://github.com/Zhen-yu-Liu/AdaSFFuse.)|<details><summary>detail</summary>Accepted by IEEE Transactions on Multimedia</details>|\n", "A fully-programmable integrated photonic processor for both domain-specific and general-purpose computing": "|**2025-8-19**|**A fully-programmable integrated photonic processor for both domain-specific and general-purpose computing**|Feng-Kai Han et.al|[paper](https://arxiv.org/abs/2508.13551)|-|-|\n"}, "vision language": {"CAD2DMD-SET: Synthetic Generation Tool of Digital Measurement Device CAD Model Datasets for fine-tuning Large Vision-Language Models": "|**2025-8-29**|**CAD2DMD-SET: Synthetic Generation Tool of Digital Measurement Device CAD Model Datasets for fine-tuning Large Vision-Language Models**|Jo\u00e3o Valente et.al|[paper](https://arxiv.org/abs/2508.21732)|-|-|\n", "How Well Do Vision--Language Models Understand Cities? A Comparative Study on Spatial Reasoning from Street-View Images": "|**2025-8-29**|**How Well Do Vision--Language Models Understand Cities? A Comparative Study on Spatial Reasoning from Street-View Images**|Juneyoung Ro et.al|[paper](https://arxiv.org/abs/2508.21565)|-|<details><summary>detail</summary>ICCV Workshop 2025</details>|\n", "PlantVillageVQA: A Visual Question Answering Dataset for Benchmarking Vision-Language Models in Plant Science": "|**2025-8-28**|**PlantVillageVQA: A Visual Question Answering Dataset for Benchmarking Vision-Language Models in Plant Science**|Syed Nazmus Sakib et.al|[paper](https://arxiv.org/abs/2508.17117)|[code](https://huggingface.co/datasets/SyedNazmusSakib/PlantVillageVQA.)|-|\n", "CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification": "|**2025-8-28**|**CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification**|Wei Li et.al|[paper](https://arxiv.org/abs/2508.21046)|[code](https://github.com/JiuTian-VL/CogVLA.)|-|\n", "Estimating 2D Keypoints of Surgical Tools Using Vision-Language Models with Low-Rank Adaptation": "|**2025-8-28**|**Estimating 2D Keypoints of Surgical Tools Using Vision-Language Models with Low-Rank Adaptation**|Krit Duangprom et.al|[paper](https://arxiv.org/abs/2508.20830)|-|<details><summary>detail</summary>MICCAI 2025</details>|\n", "Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation": "|**2025-8-28**|**Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation**|Yiguo Fan et.al|[paper](https://arxiv.org/abs/2508.19958)|[code](https://long-vla.github.io)|<details><summary>detail</summary>CoRL 2025</details>|\n", "Escaping Plato's Cave: JAM for Aligning Independently Trained Vision and Language Models": "|**2025-8-28**|**Escaping Plato's Cave: JAM for Aligning Independently Trained Vision and Language Models**|Lauren Hyoseo Yoon et.al|[paper](https://arxiv.org/abs/2507.01201)|-|-|\n", "Relative Drawing Identification Complexity is Invariant to Modality in Vision-Language Models": "|**2025-8-28**|**Relative Drawing Identification Complexity is Invariant to Modality in Vision-Language Models**|Diogo Freitas et.al|[paper](https://arxiv.org/abs/2505.10583)|-|-|\n", "Visual Perturbation and Adaptive Hard Negative Contrastive Learning for Compositional Reasoning in Vision-Language Models": "|**2025-8-28**|**Visual Perturbation and Adaptive Hard Negative Contrastive Learning for Compositional Reasoning in Vision-Language Models**|Xin Huang et.al|[paper](https://arxiv.org/abs/2505.15576)|[code](https://github.com/nynu-BDAI/AHNPL.)|<details><summary>detail</summary>the International Joint Conference on Artificial Intelligence (IJCAI 2025)</details>|\n", "MedFoundationHub: A Lightweight and Secure Toolkit for Deploying Medical Vision Language Foundation Models": "|**2025-8-27**|**MedFoundationHub: A Lightweight and Secure Toolkit for Deploying Medical Vision Language Foundation Models**|Xiao Li et.al|[paper](https://arxiv.org/abs/2508.20345)|-|-|\n", "Linking heterogeneous microstructure informatics with expert characterization knowledge through customized and hybrid vision-language representations for industrial qualification": "|**2025-8-27**|**Linking heterogeneous microstructure informatics with expert characterization knowledge through customized and hybrid vision-language representations for industrial qualification**|Mutahar Safdar et.al|[paper](https://arxiv.org/abs/2508.20243)|-|-|\n", "A Novel Framework for Automated Explain Vision Model Using Vision-Language Models": "|**2025-8-27**|**A Novel Framework for Automated Explain Vision Model Using Vision-Language Models**|Phu-Vinh Nguyen et.al|[paper](https://arxiv.org/abs/2508.20227)|-|-|\n", "Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies": "|**2025-8-27**|**Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies**|Zhixuan Liang et.al|[paper](https://arxiv.org/abs/2508.20072)|-|-|\n", "Assessing the Geolocation Capabilities, Limitations and Societal Risks of Generative Vision-Language Models": "|**2025-8-27**|**Assessing the Geolocation Capabilities, Limitations and Societal Risks of Generative Vision-Language Models**|Oliver Grainge et.al|[paper](https://arxiv.org/abs/2508.19967)|-|<details><summary>detail</summary>AAAI Fall Symposium 2025 on AI Trustworthiness and Risk Assessment for Challenging Contexts (ATRACC)</details>|\n", "X-Prompt: Towards Universal In-Context Image Generation in Auto-Regressive Vision Language Foundation Models": "|**2025-8-27**|**X-Prompt: Towards Universal In-Context Image Generation in Auto-Regressive Vision Language Foundation Models**|Zeyi Sun et.al|[paper](https://arxiv.org/abs/2412.01824)|[code](https://github.com/SunzeY/X-Prompt)|<details><summary>detail</summary>code: https://github</details>|\n"}}