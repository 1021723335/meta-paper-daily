## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2025.11.19

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-10**|**Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2511.07301)|-|<details><summary>detail</summary>AAAI 2026</details>|
|**2025-11-5**|**Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping**|Zhihang Qin et.al|[paper](https://arxiv.org/abs/2511.03691)|-|-|
|**2025-11-1**|**Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results**|Rohan Palanikumar et.al|[paper](https://arxiv.org/abs/2511.00752)|-|-|
|**2025-10-31**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|
|**2025-10-29**|**Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation**|Yuyang Huang et.al|[paper](https://arxiv.org/abs/2510.25279)|-|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|
|**2025-10-29**|**Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation**|Quang-Khai Bui-Tran et.al|[paper](https://arxiv.org/abs/2510.25227)|-|-|
|**2025-10-28**|**Training-free Source Attribution of AI-generated Images via Resynthesis**|Pietro Bongini et.al|[paper](https://arxiv.org/abs/2510.24278)|-|-|
|**2025-10-24**|**Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.22142)|-|-|
|**2025-10-22**|**Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces**|Osman Berke Guney et.al|[paper](https://arxiv.org/abs/2305.17403)|[code](https://github.com/osmanberke/SFDA-SSVEP-BCI)|-|
|**2025-10-13**|**Source-Free Object Detection with Detection Transformer**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2510.11090)|-|<details><summary>detail</summary>IEEE Transactions on Image Processing</details>|
|**2025-10-9**|**Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning**|Ziqi Zhang et.al|[paper](https://arxiv.org/abs/2510.08393)|-|-|
|**2025-10-7**|**ESS-Flow: Training-free guidance of flow-based models as inference in source space**|Adhithyan Kalaivanan et.al|[paper](https://arxiv.org/abs/2510.05849)|-|-|
|**2025-10-6**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|
|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|
|**2025-10-3**|**Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation**|Yucheng Wang et.al|[paper](https://arxiv.org/abs/2409.19635)|-|-|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-18**|**Benchmarking Deep Learning-Based Object Detection Models on Feature Deficient Astrophotography Imagery Dataset**|Shantanusinh Parmar et.al|[paper](https://arxiv.org/abs/2508.06537)|-|-|
|**2025-11-18**|**Online Data Curation for Object Detection via Marginal Contributions to Dataset-level Average Precision**|Zitang Sun et.al|[paper](https://arxiv.org/abs/2511.14197)|-|<details><summary>detail</summary>preprint version</details>|
|**2025-11-18**|**YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection**|Ori Meiraz et.al|[paper](https://arxiv.org/abs/2511.13344)|-|<details><summary>detail</summary>1 figure</details>|
|**2025-11-18**|**Deep Learning and Machine Learning -- Object Detection and Semantic Segmentation: From Theory to Applications**|Jintao Ren et.al|[paper](https://arxiv.org/abs/2410.15584)|-|-|
|**2025-11-17**|**Efficient Fourier Filtering Network with Contrastive Learning for AAV-based Unaligned Bimodal Salient Object Detection**|Pengfei Lyu et.al|[paper](https://arxiv.org/abs/2411.03728)|[code](https://github.com/JoshuaLPF/AlignSal.)|<details><summary>detail</summary>Accepted by TGRS 2025</details>|
|**2025-11-17**|**Referring Camouflaged Object Detection With Multi-Context Overlapped Windows Cross-Attention**|Yu Wen et.al|[paper](https://arxiv.org/abs/2511.13249)|-|-|
|**2025-11-17**|**Difficulty-Aware Label-Guided Denoising for Monocular 3D Object Detection**|Soyul Lee et.al|[paper](https://arxiv.org/abs/2511.13195)|-|<details><summary>detail</summary>AAAI 2026 accepted</details>|
|**2025-11-17**|**WinMamba: Multi-Scale Shifted Windows in State Space Model for 3D Object Detection**|Longhui Zheng et.al|[paper](https://arxiv.org/abs/2511.13138)|-|-|
|**2025-11-16**|**MCAQ-YOLO: Morphological Complexity-Aware Quantization for Efficient Object Detection with Curriculum Learning**|Yoonjae Seo et.al|[paper](https://arxiv.org/abs/2511.12976)|-|-|
|**2025-11-16**|**InsFusion: Rethink Instance-level LiDAR-Camera Fusion for 3D Object Detection**|Zhongyu Xia et.al|[paper](https://arxiv.org/abs/2509.08374)|-|<details><summary>detail</summary>NeurIPS 2025 workshop</details>|
|**2025-11-16**|**SFFR: Spatial-Frequency Feature Reconstruction for Multispectral Aerial Object Detection**|Xin Zuo et.al|[paper](https://arxiv.org/abs/2511.06298)|[code](https://github.com/qchenyu1027/SFFR.)|-|
|**2025-11-16**|**MSRNet: A Multi-Scale Recursive Network for Camouflaged Object Detection**|Leena Alghamdi et.al|[paper](https://arxiv.org/abs/2511.12810)|[code](https://github.com/linaagh98/MSRNet)|-|
|**2025-11-16**|**C3Net: Context-Contrast Network for Camouflaged Object Detection**|Baber Jan et.al|[paper](https://arxiv.org/abs/2511.12627)|[code](https://github.com/Baber-Jan/C3Net.)|-|
|**2025-11-16**|**Temporal Object-Aware Vision Transformer for Few-Shot Video Object Detection**|Yogesh Kumar et.al|[paper](https://arxiv.org/abs/2511.13784)|[code](https://github.com/yogesh-iitj/fs-video-vit)|<details><summary>detail</summary>AAAI 2026 Main Track</details>|
|**2025-11-16**|**SFMNet: Sparse Focal Modulation for 3D Object Detection**|Oren Shrout et.al|[paper](https://arxiv.org/abs/2503.12093)|-|<details><summary>detail</summary>WACV 2026</details>|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-17**|**Hybrid-Domain Adaptative Representation Learning for Gaze Estimation**|Qida Tan et.al|[paper](https://arxiv.org/abs/2511.13222)|[code](https://github.com/da60266/HARL.)|<details><summary>detail</summary>AAAI2026</details>|
|**2025-11-17**|**Deep Joint Distribution Optimal Transport for Universal Domain Adaptation on Time Series**|Romain Mussard et.al|[paper](https://arxiv.org/abs/2503.11217)|-|<details><summary>detail</summary>Journal ref:2025 International Joint Conference on Neural Networks (IJCNN)</details>|
|**2025-11-17**|**SpectralAdapt: Semi-Supervised Domain Adaptation with Spectral Priors for Human-Centered Hyperspectral Image Reconstruction**|Yufei Wen et.al|[paper](https://arxiv.org/abs/2511.13020)|-|-|
|**2025-11-16**|**Prompt-Driven Domain Adaptation for End-to-End Autonomous Driving via In-Context RL**|Aleesha Khurram et.al|[paper](https://arxiv.org/abs/2511.12755)|-|-|
|**2025-11-16**|**One Request, Multiple Experts: LLM Orchestrates Domain Specific Models via Adaptive Task Routing**|Xu Yang et.al|[paper](https://arxiv.org/abs/2511.12484)|-|-|
|**2025-11-16**|**From IDs to Semantics: A Generative Framework for Cross-Domain Recommendation with Adaptive Semantic Tokenization**|Peiyu Hu et.al|[paper](https://arxiv.org/abs/2511.08006)|-|<details><summary>detail</summary>Accepted by AAAI 2026</details>|
|**2025-11-15**|**Global Variational Inference Enhanced Robust Domain Adaptation**|Lingkun Luo et.al|[paper](https://arxiv.org/abs/2507.03291)|-|<details><summary>detail</summary>The current version has issues in experimental protocol and presentation</details>|
|**2025-11-15**|**Cross-View Cross-Modal Unsupervised Domain Adaptation for Driver Monitoring System**|Aditi Bhalla et.al|[paper](https://arxiv.org/abs/2511.12196)|-|-|
|**2025-11-15**|**DoSReMC: Domain Shift Resilient Mammography Classification using Batch Normalization Adaptation**|Uğurcan Akyüz et.al|[paper](https://arxiv.org/abs/2508.15452)|-|-|
|**2025-11-14**|**MUDAS: Mote-scale Unsupervised Domain Adaptation in Multi-label Sound Classification**|Jihoon Yun et.al|[paper](https://arxiv.org/abs/2506.11331)|-|<details><summary>detail</summary>BuildSys 25</details>|
|**2025-11-14**|**Unsupervised Robust Domain Adaptation: Paradigm, Theory and Algorithm**|Fuxiang Huang et.al|[paper](https://arxiv.org/abs/2511.11009)|-|<details><summary>detail</summary>To appear in IJCV</details>|
|**2025-11-14**|**Provable Domain Adaptation for Offline Reinforcement Learning with Limited Samples**|Weiqin Chen et.al|[paper](https://arxiv.org/abs/2408.12136)|-|-|
|**2025-11-13**|**Text-to-SQL Domain Adaptation via Human-LLM Collaborative Data Annotation**|Yuan Tian et.al|[paper](https://arxiv.org/abs/2502.15980)|[code](https://github.com/magic-YuanTian/SQLsynth.)|<details><summary>detail</summary>Accepted by IUI'25 Code & Demo: https://github</details>|
|**2025-11-12**|**TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in Legal and Financial Domain**|Yidan Sun et.al|[paper](https://arxiv.org/abs/2511.09854)|-|-|
|**2025-11-12**|**Wi-CBR: Salient-aware Adaptive WiFi Sensing for Cross-domain Behavior Recognition**|Ruobei Zhang et.al|[paper](https://arxiv.org/abs/2506.11616)|-|-|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-18**|**GEN3D: Generating Domain-Free 3D Scenes from a Single Image**|Yuxin Zhang et.al|[paper](https://arxiv.org/abs/2511.14291)|-|-|
|**2025-11-18**|**Evolving Generalizable Parallel Algorithm Portfolios for Binary Optimization Problems via Domain-Agnostic Instance Generation**|Zhiyuan Wang et.al|[paper](https://arxiv.org/abs/2501.02906)|-|-|
|**2025-11-18**|**KTester: Leveraging Domain and Testing Knowledge for More Effective LLM-based Test Generation**|Anji Li et.al|[paper](https://arxiv.org/abs/2511.14224)|-|-|
|**2025-11-17**|**Temporal Realism Evaluation of Generated Videos Using Compressed-Domain Motion Vectors**|Mert Onur Cakiroglu et.al|[paper](https://arxiv.org/abs/2511.13897)|[code](https://github.com/KurbanIntelligenceLab/Motion-Vector-Learning)|-|
|**2025-11-17**|**Evaluation of Domain-Specific Architectures for General-Purpose Applications in Apple Silicon**|Álvaro Corrochano López et.al|[paper](https://arxiv.org/abs/2511.13450)|-|-|
|**2025-11-16**|**NeuroLex: A Lightweight Domain Language Model for EEG Report Understanding and Generation**|Kang Yin et.al|[paper](https://arxiv.org/abs/2511.12851)|-|-|
|**2025-11-16**|**From IDs to Semantics: A Generative Framework for Cross-Domain Recommendation with Adaptive Semantic Tokenization**|Peiyu Hu et.al|[paper](https://arxiv.org/abs/2511.08006)|-|<details><summary>detail</summary>Accepted by AAAI 2026</details>|
|**2025-11-15**|**FGM optimization in complex domains using Gaussian process regression based profile generation algorithm**|Chaitanya Kumar Konda et.al|[paper](https://arxiv.org/abs/2511.12171)|-|-|
|**2025-11-14**|**M-DAIGT: A Shared Task on Multi-Domain Detection of AI-Generated Text**|Salima Lamsiyah et.al|[paper](https://arxiv.org/abs/2511.11340)|-|-|
|**2025-11-13**|**Generalizing Analogical Inference from Boolean to Continuous Domains**|Francisco Cunha et.al|[paper](https://arxiv.org/abs/2511.10416)|-|-|
|**2025-11-13**|**FOUND: Fourier-based von Mises Distribution for Robust Single Domain Generalization in Object Detection**|Mengzhu Wang et.al|[paper](https://arxiv.org/abs/2511.10352)|-|-|
|**2025-11-12**|**Simulating Distribution Dynamics: Liquid Temporal Feature Evolution for Single-Domain Generalized Object Detection**|Zihao Zhang et.al|[paper](https://arxiv.org/abs/2511.09909)|[code](https://github.com/2490o/LTFE.)|-|
|**2025-11-12**|**Domain Adaptation from Generated Multi-Weather Images for Unsupervised Maritime Object Classification**|Dan Song et.al|[paper](https://arxiv.org/abs/2501.15503)|[code](https://github.com/honoria0204/AIMO.)|-|
|**2025-11-12**|**Data Fusion-Enhanced Decision Transformer for Stable Cross-Domain Generalization**|Guojian Wang et.al|[paper](https://arxiv.org/abs/2511.09173)|-|-|
|**2025-11-12**|**DG-DETR: Toward Domain Generalized Detection Transformer**|Seongmin Hwang et.al|[paper](https://arxiv.org/abs/2504.19574)|[code](https://github.com/sminhwang/DG-DETR.)|<details><summary>detail</summary>Accepted by Pattern Recognition Letters (DOI: https://doi</details>|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-18**|**NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards**|Chia-Yu Hung et.al|[paper](https://arxiv.org/abs/2511.14659)|[code](https://declare-lab.github.io/nora-1.5)|<details><summary>detail</summary>https://declare-lab</details>|
|**2025-11-18**|**Enhancing Agentic Autonomous Scientific Discovery with Vision-Language Model Capabilities**|Kahaan Gandhi et.al|[paper](https://arxiv.org/abs/2511.14631)|[code](https://github.com/CMBAgents/cmbagent)|-|
|**2025-11-18**|**GenRecal: Generation after Recalibration from Large to Small Vision-Language Models**|Byung-Kwan Lee et.al|[paper](https://arxiv.org/abs/2506.15681)|[code](https://byungkwanlee.github.io/GenRecal-page/)|<details><summary>detail</summary>Project page: https://byungkwanlee</details>|
|**2025-11-18**|**Explaining Similarity in Vision-Language Encoders with Weighted Banzhaf Interactions**|Hubert Baniecki et.al|[paper](https://arxiv.org/abs/2508.05430)|[code](https://github.com/hbaniecki/fixlip)|<details><summary>detail</summary>NeurIPS 2025</details>|
|**2025-11-18**|**4D-VLA: Spatiotemporal Vision-Language-Action Pretraining with Cross-Scene Calibration**|Jiahui Zhang et.al|[paper](https://arxiv.org/abs/2506.22242)|-|-|
|**2025-11-18**|**From Flatland to Space: Teaching Vision-Language Models to Perceive and Reason in 3D**|Jiahui Zhang et.al|[paper](https://arxiv.org/abs/2503.22976)|[code](https://fudan-zvg.github.io/spar)|<details><summary>detail</summary>Project page: https://fudan-zvg</details>|
|**2025-11-18**|**DepthVision: Enabling Robust Vision-Language Models with GAN-Based LiDAR-to-RGB Synthesis for Autonomous Driving**|Sven Kirchner et.al|[paper](https://arxiv.org/abs/2509.07463)|-|-|
|**2025-11-18**|**Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning**|Xiuxiu Qi et.al|[paper](https://arxiv.org/abs/2511.14396)|[code](https://qhemu.github.io/CCoL/)|<details><summary>detail</summary>AAAI 2026</details>|
|**2025-11-18**|**ArchMap: Arch-Flattening and Knowledge-Guided Vision Language Model for Tooth Counting and Structured Dental Understanding**|Bohan Zhang et.al|[paper](https://arxiv.org/abs/2511.14336)|-|-|
|**2025-11-18**|**Let Language Constrain Geometry: Vision-Language Models as Semantic and Spatial Critics for 3D Generation**|Weimin Bai et.al|[paper](https://arxiv.org/abs/2511.14271)|-|-|
|**2025-11-18**|**Branch, or Layer? Zeroth-Order Optimization for Continual Learning of Vision-Language Models**|Ziwei Liu et.al|[paper](https://arxiv.org/abs/2506.12409)|-|-|
|**2025-11-18**|**MonoDream: Monocular Vision-Language Navigation with Panoramic Dreaming**|Shuo Wang et.al|[paper](https://arxiv.org/abs/2508.02549)|-|-|
|**2025-11-18**|**AsyncVLA: Asynchronous Flow Matching for Vision-Language-Action Models**|Yuhua Jiang et.al|[paper](https://arxiv.org/abs/2511.14148)|[code](https://github.com/YuhuaJiang2002/AsyncVLA.)|-|
|**2025-11-17**|**Run, Ruminate, and Regulate: A Dual-process Thinking System for Vision-and-Language Navigation**|Yu Zhong et.al|[paper](https://arxiv.org/abs/2511.14131)|-|-|
|**2025-11-17**|**Multi-view Phase-aware Pedestrian-Vehicle Incident Reasoning Framework with Vision-Language Models**|Hao Zhen et.al|[paper](https://arxiv.org/abs/2511.14120)|-|-|

