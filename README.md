## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2025.09.28

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-9-24**|**Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|
|**2025-9-22**|**Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment**|Wenjie Liu et.al|[paper](https://arxiv.org/abs/2509.18502)|-|-|
|**2025-9-22**|**Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation**|Amirhossein Dadashzadeh et.al|[paper](https://arxiv.org/abs/2504.11669)|[code](https://github.com/Plrbear/Co-Star)|-|
|**2025-9-21**|**Prototype-Based Pseudo-Label Denoising for Source-Free Domain Adaptation in Remote Sensing Semantic Segmentation**|Bin Wang et.al|[paper](https://arxiv.org/abs/2509.16942)|-|-|
|**2025-9-18**|**Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2501.02184)|-|-|
|**2025-9-13**|**Step-wise Distribution Alignment Guided Style Prompt Tuning for Source-free Cross-domain Few-shot Learning**|Huali Xu et.al|[paper](https://arxiv.org/abs/2411.10070)|[code](https://github.com/xuhuali-mxj/StepSPT.)|<details><summary>detail</summary>IEEE TPAMI</details>|
|**2025-9-12**|**Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment**|Rini Smita Thakur et.al|[paper](https://arxiv.org/abs/2509.10134)|[code](https://visdomlab.github.io/GCL/.)|<details><summary>detail</summary>Accepted in BMVC 2025</details>|
|**2025-9-10**|**Rethinking the Backbone in Class Imbalanced Federated Source Free Domain Adaptation: The Utility of Vision Foundation Models**|Kosuke Kihara et.al|[paper](https://arxiv.org/abs/2509.08372)|-|<details><summary>detail</summary>Accepted by the IEEE ICIP 2025 Satellite Workshop 1: Edge Intelligence: Smart</details>|
|**2025-9-2**|**StableSleep: Source-Free Test-Time Adaptation for Sleep Staging with Lightweight Safety Rails**|Hritik Arasu et.al|[paper](https://arxiv.org/abs/2509.02982)|-|<details><summary>detail</summary>5 page paper</details>|
|**2025-8-28**|**Model-Free Hovering and Source Seeking via Extremum Seeking Control: Experimental Demonstration**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2508.20836)|-|-|
|**2025-8-26**|**VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection**|Jianhong Han et.al|[paper](https://arxiv.org/abs/2508.11167)|-|<details><summary>detail</summary>Manuscript submitted to IEEE TCSVT</details>|
|**2025-8-20**|**Towards Source-Free Machine Unlearning**|Sk Miraj Ahmed et.al|[paper](https://arxiv.org/abs/2508.15127)|-|<details><summary>detail</summary>Accepted by CVPR 2025</details>|
|**2025-8-14**|**Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2508.09202)|-|-|
|**2025-8-7**|**Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation**|Jianming Liu et.al|[paper](https://arxiv.org/abs/2508.05213)|[code](https://github.com/ljm198134/TVGTANet.)|-|
|**2025-8-4**|**Model Recycling Framework for Multi-Source Data-Free Supervised Transfer Learning**|Sijia Wang et.al|[paper](https://arxiv.org/abs/2508.02039)|-|-|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-9-25**|**SOOD++: Leveraging Unlabeled Data to Boost Oriented Object Detection**|Dingkang Liang et.al|[paper](https://arxiv.org/abs/2407.01016)|[code](https://dk-liang.github.io/SOODv2/)|<details><summary>detail</summary>Accepted by IEEE TPAMI</details>|
|**2025-9-25**|**Lightweight Modular Parameter-Efficient Tuning for Open-Vocabulary Object Detection**|Bilal Faye et.al|[paper](https://arxiv.org/abs/2408.10787)|-|-|
|**2025-9-25**|**Real-Time Object Detection Meets DINOv3**|Shihua Huang et.al|[paper](https://arxiv.org/abs/2509.20787)|-|-|
|**2025-9-25**|**Neptune-X: Active X-to-Maritime Generation for Universal Maritime Object Detection**|Yu Guo et.al|[paper](https://arxiv.org/abs/2509.20745)|[code](https://github.com/gy65896/Neptune-X.)|-|
|**2025-9-24**|**Model Agnostic Defense against Adversarial Patch Attacks on Object Detection in Unmanned Aerial Vehicles**|Saurabh Pathak et.al|[paper](https://arxiv.org/abs/2405.19179)|-|<details><summary>detail</summary>published in IROS 2024</details>|
|**2025-9-24**|**SpaRC: Sparse Radar-Camera Fusion for 3D Object Detection**|Philipp Wolters et.al|[paper](https://arxiv.org/abs/2411.19860)|[code](https://github.com/phi-wol/sparc.)|-|
|**2025-9-24**|**Adaptive Guidance Semantically Enhanced via Multimodal LLM for Edge-Cloud Object Detection**|Yunqing Hu et.al|[paper](https://arxiv.org/abs/2509.19875)|-|-|
|**2025-9-24**|**BiTAA: A Bi-Task Adversarial Attack for Object Detection and Depth Estimation via 3D Gaussian Splatting**|Yixun Zhang et.al|[paper](https://arxiv.org/abs/2509.19793)|-|<details><summary>detail</summary>Intend to submit to RA-L</details>|
|**2025-9-23**|**HyPSAM: Hybrid Prompt-driven Segment Anything Model for RGB-Thermal Salient Object Detection**|Ruichao Hou et.al|[paper](https://arxiv.org/abs/2509.18738)|[code](https://github.com/milotic233/HyPSAM.)|-|
|**2025-9-23**|**LEAF-Mamba: Local Emphatic and Adaptive Fusion State Space Model for RGB-D Salient Object Detection**|Lanhu Wu et.al|[paper](https://arxiv.org/abs/2509.18683)|-|<details><summary>detail</summary>ACM MM 2025</details>|
|**2025-9-23**|**MLF-4DRCNet: Multi-Level Fusion with 4D Radar and Camera for 3D Object Detection in Autonomous Driving**|Yuzhi Wu et.al|[paper](https://arxiv.org/abs/2509.18613)|-|-|
|**2025-9-22**|**MVP: Motion Vector Propagation for Zero-Shot Video Object Detection**|Binhua Huang et.al|[paper](https://arxiv.org/abs/2509.18388)|[code](https://github.com/microa/MVP.)|-|
|**2025-9-22**|**RCTDistill: Cross-Modal Knowledge Distillation Framework for Radar-Camera 3D Object Detection with Temporal Fusion**|Geonho Bang et.al|[paper](https://arxiv.org/abs/2509.17712)|-|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-9-22**|**Domain Adaptive Object Detection for Space Applications with Real-Time Constraints**|Samet Hicsonmez et.al|[paper](https://arxiv.org/abs/2509.17593)|-|<details><summary>detail</summary>Advanced Space Technologies in Robotics and Automation (ASTRA) 2025</details>|
|**2025-9-22**|**An Empirical Study on the Robustness of YOLO Models for Underwater Object Detection**|Edwine Nabahirwa et.al|[paper](https://arxiv.org/abs/2509.17561)|-|<details><summary>detail</summary>28 Pages</details>|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-9-25**|**ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining**|Seonwu Kim et.al|[paper](https://arxiv.org/abs/2507.06795)|-|<details><summary>detail</summary>EMNLP 2025 Industry Track</details>|
|**2025-9-25**|**Structure-Attribute Transformations with Markov Chain Boost Graph Domain Adaptation**|Zhen Liu et.al|[paper](https://arxiv.org/abs/2509.21059)|[code](https://github.com/GiantZhangYT/SATMC.)|-|
|**2025-9-25**|**Predictive Coding-based Deep Neural Network Fine-tuning for Computationally Efficient Domain Adaptation**|Matteo Cardoni et.al|[paper](https://arxiv.org/abs/2509.20269)|-|-|
|**2025-9-24**|**MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model**|Hsiao-Ying Huang et.al|[paper](https://arxiv.org/abs/2509.20706)|-|-|
|**2025-9-24**|**Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training**|Shuo Cheng et.al|[paper](https://arxiv.org/abs/2509.18631)|-|-|
|**2025-9-24**|**Unsupervised Domain Adaptation with an Unobservable Source Subpopulation**|Chao Ying et.al|[paper](https://arxiv.org/abs/2509.20587)|-|-|
|**2025-9-24**|**DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware Reinforcement Learning on Imbalanced Data**|Yuhang Zhou et.al|[paper](https://arxiv.org/abs/2505.15074)|[code](https://github.com/Tonyzhou98/disco_grpo.)|<details><summary>detail</summary>Accepted by EMNLP 2025 Findings</details>|
|**2025-9-24**|**Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|
|**2025-9-24**|**SDC-Net: A Domain Adaptation Framework with Semantic-Dynamic Consistency for Cross-Subject EEG Emotion Recognition**|Jiahao Tang et.al|[paper](https://arxiv.org/abs/2507.17524)|[code](https://github.com/XuanSuTrum/SDC-Net.)|-|
|**2025-9-23**|**Memory-Augmented Potential Field Theory: A Framework for Adaptive Control in Non-Convex Domains**|Dongzhe Zheng et.al|[paper](https://arxiv.org/abs/2509.19672)|-|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|
|**2025-9-23**|**EgoBridge: Domain Adaptation for Generalizable Imitation from Egocentric Human Data**|Ryan Punamiya et.al|[paper](https://arxiv.org/abs/2509.19626)|[code](https://ego-bridge.github.io)|<details><summary>detail</summary>39th Conference on Neural Information Processing Systems (NeurIPS 2025) and Oral at Conference on Robot Learning (CoRL 2025)</details>|
|**2025-9-23**|**Code Driven Planning with Domain-Adaptive Critic**|Zikang Tian et.al|[paper](https://arxiv.org/abs/2509.19077)|-|-|
|**2025-9-23**|**Prompt-DAS: Annotation-Efficient Prompt Learning for Domain Adaptive Semantic Segmentation of Electron Microscopy Images**|Jiabao Chen et.al|[paper](https://arxiv.org/abs/2509.18973)|-|<details><summary>detail</summary>MICCAI2025</details>|
|**2025-9-22**|**Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment**|Wenjie Liu et.al|[paper](https://arxiv.org/abs/2509.18502)|-|-|
|**2025-9-22**|**Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation**|Amirhossein Dadashzadeh et.al|[paper](https://arxiv.org/abs/2504.11669)|[code](https://github.com/Plrbear/Co-Star)|-|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-9-25**|**Technical report on label-informed logit redistribution for better domain generalization in low-shot classification with foundation models**|Behraj Khan et.al|[paper](https://arxiv.org/abs/2501.17595)|-|-|
|**2025-9-25**|**An orderly algorithm for generation of Condorcet Domains**|Bei Zhou et.al|[paper](https://arxiv.org/abs/2509.20865)|-|-|
|**2025-9-25**|**Federated Domain Generalization with Domain-specific Soft Prompts Generation**|Jianhan Wu et.al|[paper](https://arxiv.org/abs/2509.20807)|-|<details><summary>detail</summary>the IEEE/CVF International Conference on Computer Vision (ICCV 2025)</details>|
|**2025-9-25**|**Dual-supervised Asymmetric Co-training for Semi-supervised Medical Domain Generalization**|Jincai Song et.al|[paper](https://arxiv.org/abs/2509.20785)|-|-|
|**2025-9-25**|**SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs**|Jiacheng Lin et.al|[paper](https://arxiv.org/abs/2509.20758)|-|-|
|**2025-9-24**|**Embedding Domain Knowledge for Large Language Models via Reinforcement Learning from Augmented Generation**|Chaojun Nie et.al|[paper](https://arxiv.org/abs/2509.20162)|[code](https://github.com/ChaojunNie/RLAG.)|-|
|**2025-9-24**|**Minimal Semantic Sufficiency Meets Unsupervised Domain Generalization**|Tan Pan et.al|[paper](https://arxiv.org/abs/2509.15791)|-|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|
|**2025-9-22**|**Diffusion-Based Action Recognition Generalizes to Untrained Domains**|Rogerio Guimaraes et.al|[paper](https://arxiv.org/abs/2509.08908)|[code](https://www.vision.caltech.edu/actiondiff.)|<details><summary>detail</summary>Project page: https://www</details>|
|**2025-9-22**|**Unsupervised Structural-Counterfactual Generation under Domain Shift**|Krishn Vishwas Kher et.al|[paper](https://arxiv.org/abs/2502.12013)|-|<details><summary>detail</summary>Updated author ordering</details>|
|**2025-9-21**|**Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning**|Simon Ouellette et.al|[paper](https://arxiv.org/abs/2507.15877)|-|<details><summary>detail</summary>this version fixes errors in AlphaEvolve total % calculation</details>|
|**2025-9-21**|**From domain-landmark graph learning to problem-landmark graph generation**|Cristian Pérez-Corral et.al|[paper](https://arxiv.org/abs/2509.17062)|-|-|
|**2025-9-20**|**Leveraging Multilingual Training for Authorship Representation: Enhancing Generalization across Languages and Domains**|Junghwan Kim et.al|[paper](https://arxiv.org/abs/2509.16531)|-|<details><summary>detail</summary>EMNLP 2025</details>|
|**2025-9-19**|**From Canopy to Ground via ForestGen3D: Learning Cross-Domain Generation of 3D Forest Structure from Aerial-to-Terrestrial LiDAR**|Juan Castorena et.al|[paper](https://arxiv.org/abs/2509.16346)|-|-|
|**2025-9-18**|**CoDoL: Conditional Domain Prompt Learning for Out-of-Distribution Generalization**|Min Zhang et.al|[paper](https://arxiv.org/abs/2509.15330)|-|-|
|**2025-9-18**|**Trade-offs in Cross-Domain Generalization of Foundation Model Fine-Tuned for Biometric Applications**|Tahar Chettaoui et.al|[paper](https://arxiv.org/abs/2509.14921)|-|<details><summary>detail</summary>the IEEE International Joint Conference on Biometrics 2025 (IJCB 2025)</details>|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-9-25**|**Nova: Real-Time Agentic Vision-Language Model Serving with Adaptive Cross-Stage Parallelization**|Yuhang Xu et.al|[paper](https://arxiv.org/abs/2509.21301)|-|-|
|**2025-9-25**|**DisCoCLIP: A Distributional Compositional Tensor Network Encoder for Vision-Language Understanding**|Kin Ian Lo et.al|[paper](https://arxiv.org/abs/2509.21287)|-|-|
|**2025-9-25**|**IDEATOR: Jailbreaking and Benchmarking Large Vision-Language Models Using Themselves**|Ruofan Wang et.al|[paper](https://arxiv.org/abs/2411.00827)|[code](https://roywang021.github.io/VLJailbreakBench.)|-|
|**2025-9-25**|**Decipher-MR: A Vision-Language Foundation Model for 3D MRI Representations**|Zhijian Yang et.al|[paper](https://arxiv.org/abs/2509.21249)|-|-|
|**2025-9-25**|**Learning to Look: Cognitive Attention Alignment with Vision-Language Models**|Ryan L. Yang et.al|[paper](https://arxiv.org/abs/2509.21247)|-|-|
|**2025-9-25**|**RetoVLA: Reusing Register Tokens for Spatial Reasoning in Vision-Language-Action Models**|Jiyeon Koo et.al|[paper](https://arxiv.org/abs/2509.21243)|[code](https://youtu.be/2CseBR-snZg)|-|
|**2025-9-25**|**Pure Vision Language Action (VLA) Models: A Comprehensive Survey**|Dapeng Zhang et.al|[paper](https://arxiv.org/abs/2509.19012)|-|-|
|**2025-9-25**|**Mammo-CLIP Dissect: A Framework for Analysing Mammography Concepts in Vision-Language Models**|Suaiba Amina Salahuddin et.al|[paper](https://arxiv.org/abs/2509.21102)|[code](https://github.com/Suaiba/Mammo-CLIP-Dissect.)|-|
|**2025-9-25**|**villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models**|Xiaoyu Chen et.al|[paper](https://arxiv.org/abs/2507.23682)|[code](https://aka.ms/villa-x)|<details><summary>detail</summary>Project page: https://aka</details>|
|**2025-9-25**|**Seeing Through Words, Speaking Through Pixels: Deep Representational Alignment Between Vision and Language Models**|Zoe Wanying He et.al|[paper](https://arxiv.org/abs/2509.20751)|-|<details><summary>detail</summary>EMNLP 2025 (camera-ready)</details>|
|**2025-9-25**|**SLAM-Free Visual Navigation with Hierarchical Vision-Language Perception and Coarse-to-Fine Semantic Topological Planning**|Guoyang Zhao et.al|[paper](https://arxiv.org/abs/2509.20739)|-|-|
|**2025-9-24**|**LeVERB: Humanoid Whole-Body Control with Latent Vision-Language Instruction**|Haoru Xue et.al|[paper](https://arxiv.org/abs/2506.13751)|[code](https://ember-lab-berkeley.github.io/LeVERB-Website/)|<details><summary>detail</summary>https://ember-lab-berkeley</details>|
|**2025-9-24**|**Recov-Vision: Linking Street View Imagery and Vision-Language Models for Post-Disaster Recovery**|Yiming Xiao et.al|[paper](https://arxiv.org/abs/2509.20628)|-|-|
|**2025-9-24**|**Enhancing Targeted Adversarial Attacks on Large Vision-Language Models via Intermediate Projector**|Yiming Cao et.al|[paper](https://arxiv.org/abs/2508.13739)|-|-|
|**2025-9-24**|**Deciphering Functions of Neurons in Vision-Language Models**|Jiaqi Xu et.al|[paper](https://arxiv.org/abs/2502.18485)|-|<details><summary>detail</summary>Accepted by the 31st ACM International Conference on Multimedia (ACM MM 2025)</details>|

