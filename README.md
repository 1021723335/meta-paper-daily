## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2023.11.30

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2023-11-27**|**Aligning Non-Causal Factors for Transformer-Based Source-Free Domain Adaptation**|Sunandini Sanyalet.al|[paper](https://arxiv.org/abs/2311.16294)|[code](https://val.cds.iisc.ac.in/C-SFTrans/)|<details><summary>detail</summary>WACV 2024</details>|
|**2023-11-27**|**Source-Free Domain Adaptation with Frozen Multimodal Foundation Model**|Song Tanget.al|[paper](https://arxiv.org/abs/2311.16510)|-|-|
|**2023-11-23**|**Periodically Exchange Teacher-Student for Source-Free Object Detection**|Qipeng Liuet.al|[paper](https://arxiv.org/abs/2311.13930)|-|<details><summary>detail</summary>ICCV 2023</details>|
|**2023-11-21**|**Improving Source-Free Target Adaptation with Vision Transformers Leveraging Domain Representation Images**|Gauransh Sawhneyet.al|[paper](https://arxiv.org/abs/2311.12589)|-|-|
|**2023-11-20**|**Source Free Unsupervised Graph Domain Adaptation**|Haitao Maoet.al|[paper](https://arxiv.org/abs/2112.00955)|-|-|
|**2023-11-19**|**Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces**|Osman Berke Guneyet.al|[paper](https://arxiv.org/abs/2305.17403)|[code](https://github.com/osmanberke/SFDA-SSVEP-BCI)|-|
|**2023-11-7**|**Model-Free Source Seeking by a Novel Single-Integrator with Attenuating Oscillations and Better Convergence: Robotic Experiments**|Shivam Bajpaiet.al|[paper](https://arxiv.org/abs/2311.04330)|-|-|
|**2023-11-6**|**Distill-SODA: Distilling Self-Supervised Vision Transformer for Source-Free Open-Set Domain Adaptation in Computational Pathology**|Guillaume Vrayet.al|[paper](https://arxiv.org/abs/2307.04596)|-|-|
|**2023-11-2**|**FVP: Fourier Visual Prompting for Source-Free Unsupervised Domain Adaptation of Medical Image Segmentation**|Yan Wanget.al|[paper](https://arxiv.org/abs/2304.13672)|-|-|
|**2023-10-30**|**Improving Online Source-free Domain Adaptation for Object Detection by Unsupervised Data Acquisition**|Xiangyu Shiet.al|[paper](https://arxiv.org/abs/2310.19258)|-|-|
|**2023-10-27**|**A Chebyshev Confidence Guided Source-Free Domain Adaptation Framework for Medical Image Segmentation**|Jiesi Huet.al|[paper](https://arxiv.org/abs/2310.18087)|-|-|
|**2023-10-25**|**Robust Source-Free Domain Adaptation for Fundus Image Segmentation**|Lingrui Liet.al|[paper](https://arxiv.org/abs/2310.16665)|[code](https://github.com/LinGrayy/PLPB.)|-|
|**2023-10-19**|**Exploiting Low-confidence Pseudo-labels for Source-free Object Detection**|Zhihong Chenet.al|[paper](https://arxiv.org/abs/2310.12705)|-|-|
|**2023-10-18**|**Multi Task Consistency Guided Source-Free Test-Time Domain Adaptation Medical Image Segmentation**|Yanyu Yeet.al|[paper](https://arxiv.org/abs/2310.11766)|-|-|
|**2023-10-14**|**Transcending Domains through Text-to-Image Diffusion: A Source-Free Approach to Domain Adaptation**|Shivang Chopraet.al|[paper](https://arxiv.org/abs/2310.01701)|-|-|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2023-11-28**|**Unified-modal Salient Object Detection via Adaptive Prompt Learning**|Kunpeng Wanget.al|[paper](https://arxiv.org/abs/2311.16835)|-|-|
|**2023-11-28**|**Cross-level Attention with Overlapped Windows for Camouflaged Object Detection**|Jiepan Liet.al|[paper](https://arxiv.org/abs/2311.16618)|-|-|
|**2023-11-27**|**DoUnseen: Tuning-Free Class-Adaptive Object Detection of Unseen Objects for Robotic Grasping**|Anas Goudaet.al|[paper](https://arxiv.org/abs/2304.02833)|-|<details><summary>detail</summary>presented at RSS 2023 Workshop on Perception and Manipulation Challenges for Warehouse Automation</details>|
|**2023-11-26**|**Generating Human-Centric Visual Cues for Human-Object Interaction Detection via Large Vision-Language Models**|Yu-Wei Zhanet.al|[paper](https://arxiv.org/abs/2311.16475)|-|-|
|**2023-11-25**|**Semi-supervised Salient Object Detection with Effective Confidence Estimation**|Jiawei Liuet.al|[paper](https://arxiv.org/abs/2112.14019)|-|-|
|**2023-11-25**|**VSCode: General Visual Salient and Camouflaged Object Detection with 2D Prompt Learning**|Ziyang Luoet.al|[paper](https://arxiv.org/abs/2311.15011)|-|-|
|**2023-11-25**|**OpenNet: Incremental Learning for Autonomous Driving Object Detection with Balanced Loss**|Zezhou Wanget.al|[paper](https://arxiv.org/abs/2311.14939)|-|-|
|**2023-11-23**|**Onboard dynamic-object detection and tracking for autonomous robot navigation with RGB-D camera**|Zhefan Xuet.al|[paper](https://arxiv.org/abs/2303.00132)|-|-|
|**2023-11-23**|**Evaluating Object (mis)Detection from a Safety and Reliability Perspective: Discussion and Measures**|Andrea Ceccarelliet.al|[paper](https://arxiv.org/abs/2203.02205)|-|<details><summary>detail</summary>journal version</details>|
|**2023-11-23**|**Adaptive Self-Training for Object Detection**|Renaud Vandeghenet.al|[paper](https://arxiv.org/abs/2212.05911)|-|-|
|**2023-11-23**|**Point2RBox: Combine Knowledge from Synthetic Visual Patterns for End-to-end Oriented Object Detection with Single Point Supervision**|Yu Yiet.al|[paper](https://arxiv.org/abs/2311.14758)|[code](https://github.com/open-mmlab/mmrotate)|-|
|**2023-11-23**|**PointOBB: Learning Oriented Object Detection via Single Point Supervision**|Junwei Luoet.al|[paper](https://arxiv.org/abs/2311.14757)|[code](https://github.com/Luo-Z13/pointobb)|-|
|**2023-11-23**|**Periodically Exchange Teacher-Student for Source-Free Object Detection**|Qipeng Liuet.al|[paper](https://arxiv.org/abs/2311.13930)|-|<details><summary>detail</summary>ICCV 2023</details>|
|**2023-11-22**|**All in One: RGB, RGB-D, and RGB-T Salient Object Detection**|Xingzhao Jiaet.al|[paper](https://arxiv.org/abs/2311.14746)|-|-|
|**2023-11-21**|**Enhancing Novel Object Detection via Cooperative Foundational Models**|Rohit Bharadwajet.al|[paper](https://arxiv.org/abs/2311.12068)|[code](https://github.com/rohit901/cooperative-foundational-models)|<details><summary>detail</summary>Code: https://github</details>|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2023-11-27**|**MAPSeg: Unified Unsupervised Domain Adaptation for Heterogeneous Medical Image Segmentation Based on 3D Masked Autoencoding and Pseudo-Labeling**|Xuzhe Zhanget.al|[paper](https://arxiv.org/abs/2303.09373)|-|-|
|**2023-11-27**|**Aligning Non-Causal Factors for Transformer-Based Source-Free Domain Adaptation**|Sunandini Sanyalet.al|[paper](https://arxiv.org/abs/2311.16294)|[code](https://val.cds.iisc.ac.in/C-SFTrans/)|<details><summary>detail</summary>WACV 2024</details>|
|**2023-11-27**|**Continual Test-time Domain Adaptation via Dynamic Sample Selection**|Yanshuo Wanget.al|[paper](https://arxiv.org/abs/2310.03335)|-|<details><summary>detail</summary>2024 IEEE/CVF Winter Conference on Applications of Computer Vision</details>|
|**2023-11-27**|**Source-Free Domain Adaptation with Frozen Multimodal Foundation Model**|Song Tanget.al|[paper](https://arxiv.org/abs/2311.16510)|-|-|
|**2023-11-27**|**Progressive Target-Styled Feature Augmentation for Unsupervised Domain Adaptation on Point Clouds**|Zicheng Wanget.al|[paper](https://arxiv.org/abs/2311.16474)|[code](https://github.com/xiaoyao3302/PTSFA.)|-|
|**2023-11-27**|**UFDA: Universal Federated Domain Adaptation with Practical Assumptions**|Xinhui Liuet.al|[paper](https://arxiv.org/abs/2311.15570)|-|<details><summary>detail</summary>Submitted to AAAI2024</details>|
|**2023-11-25**|**Fine-Grained Unsupervised Cross-Modality Domain Adaptation for Vestibular Schwannoma Segmentation**|Luyi Hanet.al|[paper](https://arxiv.org/abs/2311.15090)|-|-|
|**2023-11-23**|**Class Balanced Dynamic Acquisition for Domain Adaptive Semantic Segmentation using Active Learning**|Marc Schachtsieket.al|[paper](https://arxiv.org/abs/2311.14146)|-|<details><summary>detail</summary>NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World</details>|
|**2023-11-23**|**Weighted Joint Maximum Mean Discrepancy Enabled Multi-Source-Multi-Target Unsupervised Domain Adaptation Fault Diagnosis**|Zixuan Wanget.al|[paper](https://arxiv.org/abs/2310.14790)|-|-|
|**2023-11-22**|**Learning Site-specific Styles for Multi-institutional Unsupervised Cross-modality Domain Adaptation**|Han Liuet.al|[paper](https://arxiv.org/abs/2311.12437)|[code](https://github.com/MedICL-VU/crossmoda2023.)|<details><summary>detail</summary>crossMoDA 2023 challenge 1st place solution</details>|
|**2023-11-22**|**DA-STC: Domain Adaptive Video Semantic Segmentation via Spatio-Temporal Consistency**|Zhe Zhanget.al|[paper](https://arxiv.org/abs/2311.13254)|[code](https://github.com/ZHE-SAPI/DA-STC)|-|
|**2023-11-22**|**GLAD: Global-Local View Alignment and Background Debiasing for Unsupervised Video Domain Adaptation with Large Domain Gap**|Hyogun Leeet.al|[paper](https://arxiv.org/abs/2311.12467)|[code](https://github.com/KHUVLL/GLAD.)|<details><summary>detail</summary>This is an accepted WACV 2024 paper</details>|
|**2023-11-21**|**Domain Adaptive Graph Neural Networks for Constraining Cosmological Parameters Across Multiple Data Sets**|Andrea Roncoliet.al|[paper](https://arxiv.org/abs/2311.01588)|-|<details><summary>detail</summary>Accepted in Machine Learning and the Physical Sciences Workshop at NeurIPS 2023</details>|
|**2023-11-21**|**Bridging Generalization Gaps in High Content Imaging Through Online Self-Supervised Domain Adaptation**|Johan Fredin Haslumet.al|[paper](https://arxiv.org/abs/2311.12623)|-|<details><summary>detail</summary>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2024)</details>|
|**2023-11-21**|**Heterogeneous Domain Adaptation with Positive and Unlabeled Data**|Junki Moriet.al|[paper](https://arxiv.org/abs/2304.07955)|-|<details><summary>detail</summary>Accepted by IEEE Big Data 2023 as a regular paper</details>|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2023-11-28**|**DomainStudio: Fine-Tuning Diffusion Models for Domain-Driven Image Generation using Limited Data**|Jingyuan Zhuet.al|[paper](https://arxiv.org/abs/2306.14153)|-|<details><summary>detail</summary>extended from DDPM-PA (arXiv:2211</details>|
|**2023-11-28**|**Towards Full-scene Domain Generalization in Multi-agent Collaborative Bird's Eye View Segmentation for Connected and Autonomous Driving**|Senkang Huet.al|[paper](https://arxiv.org/abs/2311.16754)|[code](https://github.com/DG-CAVs/DG-CoPerception.git.)|-|
|**2023-11-28**|**FIXED: Frustratingly Easy Domain Generalization with Mixup**|Wang Luet.al|[paper](https://arxiv.org/abs/2211.05228)|[code](https://github.com/jindongwang/transferlearning/tree/master/code/deep/fixed.)|<details><summary>detail</summary>First Conference on Parsimony and Learning (CPAL) 2024</details>|
|**2023-11-27**|**MetaDefa: Meta-learning based on Domain Enhancement and Feature Alignment for Single Domain Generalization**|Can Sunet.al|[paper](https://arxiv.org/abs/2311.15906)|-|-|
|**2023-11-26**|**Domain knowledge-informed Synthetic fault sample generation with Health Data Map for cross-domain Planetary Gearbox Fault Diagnosis**|Jong Moon Haet.al|[paper](https://arxiv.org/abs/2305.19569)|-|<details><summary>detail</summary>Under review / added arXiv identifier / Updated to revised version</details>|
|**2023-11-25**|**Choosing Wisely and Learning Deeply: Selective Cross-Modality Distillation via CLIP for Domain Generalization**|Jixuan Lenget.al|[paper](https://arxiv.org/abs/2311.15145)|-|-|
|**2023-11-24**|**Style-Hallucinated Dual Consistency Learning: A Unified Framework for Visual Domain Generalization**|Yuyang Zhaoet.al|[paper](https://arxiv.org/abs/2212.09068)|[code](https://github.com/HeliosZhao/SHADE-VisualDG)|<details><summary>detail</summary>Accepted by IJCV</details>|
|**2023-11-23**|**LucidDreamer: Domain-free Generation of 3D Gaussian Splatting Scenes**|Jaeyoung Chunget.al|[paper](https://arxiv.org/abs/2311.13384)|[code](https://luciddreamer-cvlab.github.io/)|<details><summary>detail</summary>Project page: https://luciddreamer-cvlab</details>|
|**2023-11-23**|**Parameter Exchange for Robust Dynamic Domain Generalization**|Luojun Linet.al|[paper](https://arxiv.org/abs/2311.13928)|[code](https://github.com/MetaVisionLab/PE)|<details><summary>detail</summary>Accepted by ACM MM 2023</details>|
|**2023-11-23**|**Fairness-Aware Domain Generalization under Covariate and Dependence Shifts**|Chen Zhaoet.al|[paper](https://arxiv.org/abs/2311.13816)|-|-|
|**2023-11-22**|**DoubleAUG: Single-domain Generalized Object Detector in Urban via Color Perturbation and Dual-style Memory**|Lei Qiet.al|[paper](https://arxiv.org/abs/2311.13198)|-|<details><summary>detail</summary>Accepted by ACM Transactions on Multimedia Computing</details>|
|**2023-11-21**|**Bridging Generalization Gaps in High Content Imaging Through Online Self-Supervised Domain Adaptation**|Johan Fredin Haslumet.al|[paper](https://arxiv.org/abs/2311.12623)|-|<details><summary>detail</summary>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2024)</details>|
|**2023-11-21**|**Randomized Adversarial Style Perturbations for Domain Generalization**|Taehoon Kimet.al|[paper](https://arxiv.org/abs/2304.01959)|-|-|
|**2023-11-20**|**Generalization of Fitness Exercise Recognition from Doppler Measurements by Domain-adaption and Few-Shot Learning**|Biying Fuet.al|[paper](https://arxiv.org/abs/2311.11910)|-|<details><summary>detail</summary>accepted at International Conference on Pattern Recognition (ICPR) workshop 2021</details>|
|**2023-11-18**|**Generalization Analogies: A Testbed for Generalizing AI Oversight to Hard-To-Measure Domains**|Joshua Clymeret.al|[paper](https://arxiv.org/abs/2311.07723)|[code](https://github.com/Joshuaclymer/GENIES)|<details><summary>detail</summary>Code: https://github</details>|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2023-11-28**|**Efficient In-Context Learning in Vision-Language Models for Egocentric Videos**|Keunwoo Peter Yuet.al|[paper](https://arxiv.org/abs/2311.17041)|[code](https://github.com/yukw777/EILEV)|-|
|**2023-11-28**|**Mitigating Object Hallucinations in Large Vision-Language Models through Visual Contrastive Decoding**|Sicong Lenget.al|[paper](https://arxiv.org/abs/2311.16922)|-|-|
|**2023-11-28**|**Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model: Explorations with GPT4-Vision and Beyond**|Liang Chenet.al|[paper](https://arxiv.org/abs/2310.02071)|[code](https://github.com/pkunlp-icler/PCA-EVAL/.)|<details><summary>detail</summary>FMDM@NeurIPS2023</details>|
|**2023-11-28**|**Large Language Models Meet Computer Vision: A Brief Survey**|Raby Hamadiet.al|[paper](https://arxiv.org/abs/2311.16673)|-|-|
|**2023-11-27**|**CLAP: Contrastive Learning with Augmented Prompts for Robustness on Pretrained Vision-Language Models**|Yichao Caiet.al|[paper](https://arxiv.org/abs/2311.16445)|-|-|
|**2023-11-27**|**Removing NSFW Concepts from Vision-and-Language Models for Text-to-Image Retrieval and Generation**|Samuele Poppiet.al|[paper](https://arxiv.org/abs/2311.16254)|[code](https://github.com/aimagelab/safe-clip.)|-|
|**2023-11-27**|**SemiVL: Semi-Supervised Semantic Segmentation with Vision-Language Guidance**|Lukas Hoyeret.al|[paper](https://arxiv.org/abs/2311.16241)|[code](https://github.com/google-research/semivl)|-|
|**2023-11-27**|**VLPrompt: Vision-Language Prompting for Panoptic Scene Graph Generation**|Zijian Zhouet.al|[paper](https://arxiv.org/abs/2311.16492)|-|-|
|**2023-11-27**|**ArGue: Attribute-Guided Prompt Tuning for Vision-Language Models**|Xinyu Tianet.al|[paper](https://arxiv.org/abs/2311.16494)|-|-|
|**2023-11-27**|**Can Vision-Language Models Think from a First-Person Perspective?**|Sijie Chenget.al|[paper](https://arxiv.org/abs/2311.15596)|-|-|
|**2023-11-27**|**Improving Adaptability and Generalizability of Efficient Transfer Learning for Vision-Language Models**|Yongjin Yanget.al|[paper](https://arxiv.org/abs/2311.15569)|-|-|
|**2023-11-27**|**Beyond Pixels: Exploring Human-Readable SVG Generation for Simple Images with Vision Language Models**|Tong Zhanget.al|[paper](https://arxiv.org/abs/2311.15543)|-|-|
|**2023-11-26**|**Active Prompt Learning in Vision Language Models**|Jihwan Banget.al|[paper](https://arxiv.org/abs/2311.11178)|-|<details><summary>detail</summary>version 1</details>|
|**2023-11-26**|**Generating Human-Centric Visual Cues for Human-Object Interaction Detection via Large Vision-Language Models**|Yu-Wei Zhanet.al|[paper](https://arxiv.org/abs/2311.16475)|-|-|
|**2023-11-25**|**Vision-Language Instruction Tuning: A Review and Analysis**|Chen Liet.al|[paper](https://arxiv.org/abs/2311.08172)|[code](https://github.com/palchenli/VL-Instruction-Tuning.)|-|

