## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2025.10.09

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-10-7**|**ESS-Flow: Training-free guidance of flow-based models as inference in source space**|Adhithyan Kalaivanan et.al|[paper](https://arxiv.org/abs/2510.05849)|-|-|
|**2025-10-7**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|
|**2025-10-6**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|
|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|
|**2025-10-3**|**Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation**|Yucheng Wang et.al|[paper](https://arxiv.org/abs/2409.19635)|-|-|
|**2025-10-2**|**OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation**|Yiming Zhang et.al|[paper](https://arxiv.org/abs/2505.11669)|-|-|
|**2025-10-2**|**Source-Free Cross-Domain Continual Learning**|Muhammad Tanzil Furqon et.al|[paper](https://arxiv.org/abs/2510.01649)|-|-|
|**2025-10-1**|**Consistent Assistant Domains Transformer for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.01559)|[code](https://github.com/RoryShao/CADTrans.git.)|-|
|**2025-9-30**|**Source-Free Domain Adaptive Object Detection with Semantics Compensation**|Song Tang et.al|[paper](https://arxiv.org/abs/2410.05557)|-|-|
|**2025-9-29**|**DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation**|Xi Chen et.al|[paper](https://arxiv.org/abs/2509.24896)|-|-|
|**2025-9-29**|**Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|
|**2025-9-22**|**Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment**|Wenjie Liu et.al|[paper](https://arxiv.org/abs/2509.18502)|-|-|
|**2025-9-22**|**Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation**|Amirhossein Dadashzadeh et.al|[paper](https://arxiv.org/abs/2504.11669)|[code](https://github.com/Plrbear/Co-Star)|-|
|**2025-9-21**|**Prototype-Based Pseudo-Label Denoising for Source-Free Domain Adaptation in Remote Sensing Semantic Segmentation**|Bin Wang et.al|[paper](https://arxiv.org/abs/2509.16942)|-|-|
|**2025-9-18**|**Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2501.02184)|-|-|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-10-8**|**Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models**|Peter Robicheaux et.al|[paper](https://arxiv.org/abs/2505.20612)|[code](https://github.com/roboflow/rf100-vl)|<details><summary>detail</summary>The first two authors contributed equally</details>|
|**2025-10-7**|**SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation**|Ayush Zenith et.al|[paper](https://arxiv.org/abs/2510.06596)|[code](https://github.com/ayushzenith/SDQM)|-|
|**2025-10-7**|**Incremental Object Detection with Prompt-based Methods**|Matthias Neuwirth-Trapp et.al|[paper](https://arxiv.org/abs/2508.14599)|-|<details><summary>detail</summary>ICCV Workshops 2025: v2 update affiliation</details>|
|**2025-10-7**|**RICO: Two Realistic Benchmarks and an In-Depth Analysis for Incremental Learning in Object Detection**|Matthias Neuwirth-Trapp et.al|[paper](https://arxiv.org/abs/2508.13878)|-|<details><summary>detail</summary>ICCV Workshops 2025</details>|
|**2025-10-7**|**HOI-R1: Exploring the Potential of Multimodal Large Language Models for Human-Object Interaction Detection**|Junwen Chen et.al|[paper](https://arxiv.org/abs/2510.05609)|[code](https://github.com/cjw2021/HOI-R1.)|-|
|**2025-10-6**|**Robust Object Detection for Autonomous Driving via Curriculum-Guided Group Relative Policy Optimization**|Xu Jia et.al|[paper](https://arxiv.org/abs/2509.22688)|-|-|
|**2025-10-6**|**Self-Supervised Representation Learning with Joint Embedding Predictive Architecture for Automotive LiDAR Object Detection**|Haoran Zhu et.al|[paper](https://arxiv.org/abs/2501.04969)|-|-|
|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|
|**2025-10-6**|**SPEGNet: Synergistic Perception-Guided Network for Camouflaged Object Detection**|Baber Jan et.al|[paper](https://arxiv.org/abs/2510.04472)|[code](https://github.com/Baber-Jan/SPEGNet)|-|
|**2025-10-4**|**From Filters to VLMs: Benchmarking Defogging Methods through Object Detection and Segmentation Performance**|Ardalan Aryashad et.al|[paper](https://arxiv.org/abs/2510.03906)|-|-|
|**2025-10-4**|**Cross-View Open-Vocabulary Object Detection in Aerial Imagery**|Jyoti Kini et.al|[paper](https://arxiv.org/abs/2510.03858)|-|-|
|**2025-10-4**|**SAMSOD: Rethinking SAM Optimization for RGB-T Salient Object Detection**|Zhengyi Liu et.al|[paper](https://arxiv.org/abs/2510.03689)|-|<details><summary>detail</summary>Accepted by TMM</details>|
|**2025-10-3**|**Automated Defect Detection for Mass-Produced Electronic Components Based on YOLO Object Detection Models**|Wei-Lung Mao et.al|[paper](https://arxiv.org/abs/2510.01914)|-|-|
|**2025-10-3**|**Neural Posterior Estimation with Autoregressive Tiling for Detecting Objects in Astronomical Images**|Jeffrey Regier et.al|[paper](https://arxiv.org/abs/2510.03074)|-|<details><summary>detail</summary>MSC Class:62P35ACM Class:G</details>|
|**2025-10-3**|**Visual Language Model as a Judge for Object Detection in Industrial Diagrams**|Sanjukta Ghosh et.al|[paper](https://arxiv.org/abs/2510.03376)|-|<details><summary>detail</summary>Pre-review version submitted to IEEE ICASSP 2026</details>|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-10-7**|**Adaptive Stain Normalization for Cross-Domain Medical Histology**|Tianyue Xu et.al|[paper](https://arxiv.org/abs/2510.06592)|[code](https://github.com/xutianyue/BeerLaNet.)|<details><summary>detail</summary>the 28th International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2025)</details>|
|**2025-10-7**|**Improving Artifact Robustness for CT Deep Learning Models Without Labeled Artifact Images via Domain Adaptation**|Justin Cheung et.al|[paper](https://arxiv.org/abs/2510.06584)|-|-|
|**2025-10-7**|**DACP: Domain-Adaptive Continual Pre-Training of Large Language Models for Phone Conversation Summarization**|Xue-Yong Fu et.al|[paper](https://arxiv.org/abs/2510.05858)|-|<details><summary>detail</summary>the NewSumm Workshop at EMNLP 2025</details>|
|**2025-10-7**|**Contrastive Learning Using Graph Embeddings for Domain Adaptation of Language Models in the Process Industry**|Anastasia Zhukova et.al|[paper](https://arxiv.org/abs/2510.04631)|-|<details><summary>detail</summary>accepted to EMNLP 2025 (industry track)</details>|
|**2025-10-7**|**SKADA-Bench: Benchmarking Unsupervised Domain Adaptation Methods with Realistic Validation On Diverse Modalities**|Yanis Lalou et.al|[paper](https://arxiv.org/abs/2407.11676)|[code](https://github.com/scikit-adaptation/skada-bench.)|<details><summary>detail</summary>Published in Transactions on Machine Learning Research</details>|
|**2025-10-6**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|
|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|
|**2025-10-5**|**VirDA: Reusing Backbone for Unsupervised Domain Adaptation with Visual Reprogramming**|Duy Nguyen et.al|[paper](https://arxiv.org/abs/2510.01660)|-|-|
|**2025-10-5**|**Adaptive Weighted Loss for Sequential Recommendations on Sparse Domains**|Akshay Mittal et.al|[paper](https://arxiv.org/abs/2510.04375)|-|-|
|**2025-10-5**|**The best performance in the CARE 2025 -- Liver Task (LiSeg-Contrast): Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation**|Jincan Lou et.al|[paper](https://arxiv.org/abs/2510.04243)|-|-|
|**2025-10-4**|**Domain-Adapted Granger Causality for Real-Time Cross-Slice Attack Attribution in 6G Networks**|Minh K. Quan et.al|[paper](https://arxiv.org/abs/2510.05165)|-|<details><summary>detail</summary>NeurIPS 2025 Workshop on CauScien: Uncovering Causality in Science</details>|
|**2025-10-3**|**Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation**|Yucheng Wang et.al|[paper](https://arxiv.org/abs/2409.19635)|-|-|
|**2025-10-3**|**Deep Domain Adaptation for Turbofan Engine Remaining Useful Life Prediction: Methodologies, Evaluation and Future Trends**|Yucheng Wang et.al|[paper](https://arxiv.org/abs/2510.03604)|-|-|
|**2025-10-3**|**Reasoning-Enhanced Domain-Adaptive Pretraining of Multimodal Large Language Models for Short Video Content Governance**|Zixuan Wang et.al|[paper](https://arxiv.org/abs/2509.21486)|-|-|
|**2025-10-2**|**Unified Domain Adaptive Semantic Segmentation**|Zhe Zhang et.al|[paper](https://arxiv.org/abs/2311.13254)|[code](https://github.com/ZHE-SAPI/UDASS.)|-|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-10-8**|**Domain Generalization by Rejecting Extreme Augmentations**|Masih Aminbeidokhti et.al|[paper](https://arxiv.org/abs/2310.06670)|[code](https://github.com/Masseeh/DCAug)|<details><summary>detail</summary>WACV 2024: Winter Conference on Applications of Computer Vision 2024</details>|
|**2025-10-8**|**High-Rate Mixout: Revisiting Mixout for Robust Domain Generalization**|Masih Aminbeidokhti et.al|[paper](https://arxiv.org/abs/2510.06955)|-|<details><summary>detail</summary>WACV 2026: Winter Conference on Applications of Computer Vision 2026</details>|
|**2025-10-7**|**Redefining Generalization in Visual Domains: A Two-Axis Framework for Fake Image Detection with FusionDetect**|Amirtaha Amanzadi et.al|[paper](https://arxiv.org/abs/2510.05740)|[code](http://github.com/amir-aman/FusionDetect)|<details><summary>detail</summary>Project code: http://github</details>|
|**2025-10-5**|**Domain Generalization: A Tale of Two ERMs**|Yilun Zhu et.al|[paper](https://arxiv.org/abs/2510.04441)|-|-|
|**2025-10-5**|**The best performance in the CARE 2025 -- Liver Task (LiSeg-Contrast): Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation**|Jincan Lou et.al|[paper](https://arxiv.org/abs/2510.04243)|-|-|
|**2025-10-4**|**GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Mechanism**|Hailong Yang et.al|[paper](https://arxiv.org/abs/2509.10018)|-|-|
|**2025-10-4**|**Complex Domain Approach for Reversible Data Hiding and Homomorphic Encryption: General Framework and Application to Dispersed Data**|David Megias et.al|[paper](https://arxiv.org/abs/2510.03770)|-|-|
|**2025-10-3**|**Domain Generalization for Semantic Segmentation: A Survey**|Manuel Schwonberg et.al|[paper](https://arxiv.org/abs/2510.03540)|-|<details><summary>detail</summary>CVPR2025W</details>|
|**2025-10-2**|**Automated Constraint Specification for Job Scheduling by Regulating Generative Model with Domain-Specific Representation**|Yu-Zhe Shi et.al|[paper](https://arxiv.org/abs/2510.02679)|-|<details><summary>detail</summary>Accepted for publication in IEEE Transactions on Automation Science and Engineering</details>|
|**2025-10-2**|**DrKGC: Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph Completion across General and Biomedical Domains**|Yongkang Xiao et.al|[paper](https://arxiv.org/abs/2506.00708)|-|<details><summary>detail</summary>EMNLP 2025 Findings</details>|
|**2025-9-30**|**Finetune Once: Decoupling General & Domain Learning with Dynamic Boosted Annealing**|Yang Tang et.al|[paper](https://arxiv.org/abs/2509.26242)|-|-|
|**2025-9-30**|**Scaling Up Temporal Domain Generalization via Temporal Experts Averaging**|Aoming Liu et.al|[paper](https://arxiv.org/abs/2509.26045)|-|<details><summary>detail</summary>Accepted by EMNLP 2025 main</details>|
|**2025-9-29**|**Think Less, Label Better: Multi-Stage Domain-Grounded Synthetic Data Generation for Fine-Tuning Large Language Models in Telecommunications**|Chenhua Shi et.al|[paper](https://arxiv.org/abs/2509.25736)|-|-|
|**2025-9-29**|**SING-SQL: A Synthetic Data Generation Framework for In-Domain Text-to-SQL Translation**|Hasan Alp CaferoÄŸlu et.al|[paper](https://arxiv.org/abs/2509.25672)|-|-|
|**2025-9-27**|**Embedding Domain Knowledge for Large Language Models via Reinforcement Learning from Augmented Generation**|Chaojun Nie et.al|[paper](https://arxiv.org/abs/2509.20162)|[code](https://github.com/ChaojunNie/RLAG.)|<details><summary>detail</summary>Corrected author name spelling</details>|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-10-8**|**TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics**|Yi Han et.al|[paper](https://arxiv.org/abs/2510.07181)|-|-|
|**2025-10-8**|**Few-Shot Adaptation Benchmark for Remote Sensing Vision-Language Models**|Karim El Khoury et.al|[paper](https://arxiv.org/abs/2510.07135)|[code](https://github.com/elkhouryk/fewshot_RSVLMs)|-|
|**2025-10-8**|**From Perception to Cognition: A Survey of Vision-Language Interactive Reasoning in Multimodal Large Language Models**|Chenyue Zhou et.al|[paper](https://arxiv.org/abs/2509.25373)|-|-|
|**2025-10-8**|**Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications**|Kento Kawaharazuka et.al|[paper](https://arxiv.org/abs/2510.07077)|[code](https://vla-survey.github.io)|<details><summary>detail</summary>IEEE Access</details>|
|**2025-10-8**|**Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models**|Peter Robicheaux et.al|[paper](https://arxiv.org/abs/2505.20612)|[code](https://github.com/roboflow/rf100-vl)|<details><summary>detail</summary>The first two authors contributed equally</details>|
|**2025-10-8**|**Efficient Discriminative Joint Encoders for Large Scale Vision-Language Reranking**|Mitchell Keren Taraday et.al|[paper](https://arxiv.org/abs/2510.06820)|-|<details><summary>detail</summary>preprint</details>|
|**2025-10-8**|**TTRV: Test-Time Reinforcement Learning for Vision Language Models**|Akshit Singh et.al|[paper](https://arxiv.org/abs/2510.06783)|-|-|
|**2025-10-8**|**Adaptive Rank, Reduced Forgetting: Knowledge Retention in Continual Learning Vision-Language Models with Dynamic Rank-Selective LoRA**|Haodong Lu et.al|[paper](https://arxiv.org/abs/2412.01004)|[code](https://github.com/jeff024/codyra.)|<details><summary>detail</summary>Preprint</details>|
|**2025-10-8**|**HoPE: Hybrid of Position Embedding for Long Context Vision-Language Models**|Haoran Li et.al|[paper](https://arxiv.org/abs/2505.20444)|[code](https://github.com/hrlics/HoPE.)|<details><summary>detail</summary>NeurIPS 2025</details>|
|**2025-10-7**|**Reasoning under Vision: Understanding Visual-Spatial Cognition in Vision-Language Models for CAPTCHA**|Python Song et.al|[paper](https://arxiv.org/abs/2510.06067)|-|-|
|**2025-10-7**|**Medical Vision Language Models as Policies for Robotic Surgery**|Akshay Muppidi et.al|[paper](https://arxiv.org/abs/2510.06064)|-|<details><summary>detail</summary>IEEE CAI 2025</details>|
|**2025-10-7**|**AgriGPT-VL: Agricultural Vision-Language Understanding Suite**|Bo Yang et.al|[paper](https://arxiv.org/abs/2510.04002)|-|-|
|**2025-10-7**|**FlowVLA: Visual Chain of Thought-based Motion Reasoning for Vision-Language-Action Models**|Zhide Zhong et.al|[paper](https://arxiv.org/abs/2508.18269)|[code](https://irpn-lab.github.io/FlowVLA/)|-|
|**2025-10-7**|**Verifier-free Test-Time Sampling for Vision Language Action Models**|Suhyeok Jang et.al|[paper](https://arxiv.org/abs/2510.05681)|-|-|
|**2025-10-6**|**Self-Evolving Vision-Language Models for Image Quality Assessment via Voting and Ranking**|Wen Wen et.al|[paper](https://arxiv.org/abs/2509.25787)|-|<details><summary>detail</summary>Technical Report</details>|

