## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2025.11.29

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-24**|**Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation**|Huisoo Lee et.al|[paper](https://arxiv.org/abs/2511.19147)|-|-|
|**2025-11-24**|**Unsupervised and Source-Free Ranking of Biomedical Segmentation Models**|Joshua Talks et.al|[paper](https://arxiv.org/abs/2503.00450)|-|-|
|**2025-11-23**|**SloMo-Fast: Slow-Momentum and Fast-Adaptive Teachers for Source-Free Continual Test-Time Adaptation**|Md Akil Raihan Iftee et.al|[paper](https://arxiv.org/abs/2511.18468)|-|-|
|**2025-11-23**|**ViMix-14M: A Curated Multi-Source Video-Text Dataset with Long-Form, High-Quality Captions and Crawl-Free Access**|Timing Yang et.al|[paper](https://arxiv.org/abs/2511.18382)|-|-|
|**2025-11-22**|**HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for Cross-Modality Medical Image Segmentation**|Yulong Shi et.al|[paper](https://arxiv.org/abs/2511.17958)|[code](https://github.com/derekshiii/HEAL.)|<details><summary>detail</summary>Accepted by The 36th British Machine Vision Conference (BMVC 2025)</details>|
|**2025-11-19**|**Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation**|Yaxuan Song et.al|[paper](https://arxiv.org/abs/2402.06213)|[code](https://github.com/YXSong000/UAD.)|<details><summary>detail</summary>Accepted by ISBI 2024</details>|
|**2025-11-10**|**Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2511.07301)|-|<details><summary>detail</summary>AAAI 2026</details>|
|**2025-11-5**|**Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping**|Zhihang Qin et.al|[paper](https://arxiv.org/abs/2511.03691)|-|-|
|**2025-11-1**|**Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results**|Rohan Palanikumar et.al|[paper](https://arxiv.org/abs/2511.00752)|-|-|
|**2025-10-31**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|
|**2025-10-29**|**Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation**|Yuyang Huang et.al|[paper](https://arxiv.org/abs/2510.25279)|-|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|
|**2025-10-29**|**Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation**|Quang-Khai Bui-Tran et.al|[paper](https://arxiv.org/abs/2510.25227)|-|-|
|**2025-10-28**|**Training-free Source Attribution of AI-generated Images via Resynthesis**|Pietro Bongini et.al|[paper](https://arxiv.org/abs/2510.24278)|-|-|
|**2025-10-24**|**Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.22142)|-|-|
|**2025-10-22**|**Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces**|Osman Berke Guney et.al|[paper](https://arxiv.org/abs/2305.17403)|[code](https://github.com/osmanberke/SFDA-SSVEP-BCI)|-|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-26**|**Adaptive Object Detection for Indoor Navigation Assistance: A Performance Evaluation of Real-Time Algorithms**|Abhinav Pratap et.al|[paper](https://arxiv.org/abs/2501.18444)|-|-|
|**2025-11-25**|**Wavefront-Constrained Passive Obscured Object Detection**|Zhiwen Zheng et.al|[paper](https://arxiv.org/abs/2511.20991)|-|-|
|**2025-11-25**|**RefOnce: Distilling References into a Prototype Memory for Referring Camouflaged Object Detection**|Yu-Huan Wu et.al|[paper](https://arxiv.org/abs/2511.20989)|[code](https://github.com/yuhuan-wu/RefOnce.)|-|
|**2025-11-25**|**Open Vocabulary Monocular 3D Object Detection**|Jin Yao et.al|[paper](https://arxiv.org/abs/2411.16833)|[code](https://cvlab.cs.virginia.edu/ovmono3d)|<details><summary>detail</summary>3DV 2026</details>|
|**2025-11-25**|**StableTrack: Stabilizing Multi-Object Tracking on Low-Frequency Detections**|Matvei Shelukhan et.al|[paper](https://arxiv.org/abs/2511.20418)|-|-|
|**2025-11-25**|**Zoo3D: Zero-Shot 3D Object Detection at Scene Level**|Andrey Lemeshko et.al|[paper](https://arxiv.org/abs/2511.20253)|[code](https://github.com/col14m/zoo3d)|-|
|**2025-11-25**|**Unleashing the Power of Chain-of-Prediction for Monocular 3D Object Detection**|Zhihao Zhang et.al|[paper](https://arxiv.org/abs/2505.04594)|-|-|
|**2025-11-24**|**Video Object Recognition in Mobile Edge Networks: Local Tracking or Edge Detection?**|Kun Guo et.al|[paper](https://arxiv.org/abs/2511.20716)|-|-|
|**2025-11-24**|**Maritime Small Object Detection from UAVs using Deep Learning with Altitude-Aware Dynamic Tiling**|Sakib Ahmed et.al|[paper](https://arxiv.org/abs/2511.19728)|-|<details><summary>detail</summary>This is the author's accepted version of an article that has been published by IEEE</details>|
|**2025-11-24**|**SAM3-Adapter: Efficient Adaptation of Segment Anything 3 for Camouflage Object Segmentation, Shadow Detection, and Medical Image Segmentation**|Tianrun Chen et.al|[paper](https://arxiv.org/abs/2511.19425)|-|-|
|**2025-11-24**|**DualGazeNet: A Biologically Inspired Dual-Gaze Query Network for Salient Object Detection**|Yu Zhang et.al|[paper](https://arxiv.org/abs/2511.18865)|-|-|
|**2025-11-24**|**StereoDETR: Stereo-based Transformer for 3D Object Detection**|Shiyi Mu et.al|[paper](https://arxiv.org/abs/2511.18788)|[code](https://github.com/shiyi-mu/StereoDETR-OPEN.)|<details><summary>detail</summary>Accepted by IEEE TCSVT</details>|
|**2025-11-23**|**DriveFlow: Rectified Flow Adaptation for Robust 3D Object Detection in Autonomous Driving**|Hongbin Lin et.al|[paper](https://arxiv.org/abs/2511.18713)|[code](https://github.com/Hongbin98/DriveFlow.)|<details><summary>detail</summary>Accepted by AAAI 2026</details>|
|**2025-11-23**|**Exploring Surround-View Fisheye Camera 3D Object Detection**|Changcai Li et.al|[paper](https://arxiv.org/abs/2511.18695)|-|-|
|**2025-11-22**|**VK-Det: Visual Knowledge Guided Prototype Learning for Open-Vocabulary Aerial Object Detection**|Jianhang Yao et.al|[paper](https://arxiv.org/abs/2511.18075)|-|-|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-26**|**HarmonicAttack: An Adaptive Cross-Domain Audio Watermark Removal**|Kexin Li et.al|[paper](https://arxiv.org/abs/2511.21577)|-|-|
|**2025-11-26**|**CrossEarth-Gate: Fisher-Guided Adaptive Tuning Engine for Efficient Adaptation of Cross-Domain Remote Sensing Semantic Segmentation**|Shilei Cao et.al|[paper](https://arxiv.org/abs/2511.20302)|-|-|
|**2025-11-26**|**Earth-Adapter: Bridge the Geospatial Domain Gaps with Mixture of Frequency Adaptation**|Xiaoxing Hu et.al|[paper](https://arxiv.org/abs/2504.06220)|[code](https://github.com/VisionXLab/Earth-Adapter.)|<details><summary>detail</summary>AAAI 2026 camera ready</details>|
|**2025-11-26**|**Disentangled Geometric Alignment with Adaptive Contrastive Perturbation for Reliable Domain Transfer**|Emma Collins et.al|[paper](https://arxiv.org/abs/2505.15241)|-|-|
|**2025-11-26**|**MortgageLLM: Domain-Adaptive Pretraining with Residual Instruction Transfer, Alignment Tuning, and Task-Specific Routing**|Manish Jain et.al|[paper](https://arxiv.org/abs/2511.21101)|-|-|
|**2025-11-25**|**DAPointMamba: Domain Adaptive Point Mamba for Point Cloud Completion**|Yinghui Li et.al|[paper](https://arxiv.org/abs/2511.20278)|-|<details><summary>detail</summary>AAAI 2026</details>|
|**2025-11-25**|**EfficientXpert: Efficient Domain Adaptation for Large Language Models via Propagation-Aware Pruning**|Songlin Zhao et.al|[paper](https://arxiv.org/abs/2511.19935)|-|-|
|**2025-11-24**|**AraFinNews: Arabic Financial Summarisation with Domain-Adapted LLMs**|Mo El-Haj et.al|[paper](https://arxiv.org/abs/2511.01265)|[code](https://github.com/ArabicNLP-uk/AraFinNews.)|-|
|**2025-11-24**|**Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation**|Huisoo Lee et.al|[paper](https://arxiv.org/abs/2511.19147)|-|-|
|**2025-11-23**|**Neural B-Frame Coding: Tackling Domain Shift Issues with Lightweight Online Motion Resolution Adaptation**|Sang NguyenQuang et.al|[paper](https://arxiv.org/abs/2511.18724)|[code](https://github.com/NYCU-MAPL/Fast-OMRA.git.)|<details><summary>detail</summary>Accepted by TCAS-II: Express Briefs</details>|
|**2025-11-23**|**Modality-Collaborative Low-Rank Decomposers for Few-Shot Video Domain Adaptation**|Yuyang Wanyan et.al|[paper](https://arxiv.org/abs/2511.18711)|-|-|
|**2025-11-23**|**From Simulations to Surveys: Domain Adaptation for Galaxy Observations**|Kaley Brauer et.al|[paper](https://arxiv.org/abs/2511.18590)|-|-|
|**2025-11-23**|**NeuroVascU-Net: A Unified Multi-Scale and Cross-Domain Adaptive Feature Fusion U-Net for Precise 3D Segmentation of Brain Vessels in Contrast-Enhanced T1 MRI**|Mohammad Jafari Vayeghan et.al|[paper](https://arxiv.org/abs/2511.18422)|-|-|
|**2025-11-22**|**HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for Cross-Modality Medical Image Segmentation**|Yulong Shi et.al|[paper](https://arxiv.org/abs/2511.17958)|[code](https://github.com/derekshiii/HEAL.)|<details><summary>detail</summary>Accepted by The 36th British Machine Vision Conference (BMVC 2025)</details>|
|**2025-11-21**|**Statistically-Guided Dual-Domain Meta-Learning with Adaptive Multi-Prototype Aggregation for Distributed Fiber Optic Sensing**|Yifan He et.al|[paper](https://arxiv.org/abs/2511.17902)|-|-|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-25**|**Modality-Balanced Collaborative Distillation for Multi-Modal Domain Generalization**|Xiaohan Wang et.al|[paper](https://arxiv.org/abs/2511.20258)|-|-|
|**2025-11-25**|**Domain Fusion Controllable Generalization for Cross-Domain Time Series Forecasting from Multi-Domain Integrated Distribution**|Xiangkai Ma et.al|[paper](https://arxiv.org/abs/2412.03068)|-|<details><summary>detail</summary>We have updated the abstract</details>|
|**2025-11-24**|**Enhancing Domain-Specific Encoder Models with LLM-Generated Data: How to Leverage Ontologies, and How to Do Without Them**|Marc Brinner et.al|[paper](https://arxiv.org/abs/2503.22006)|-|<details><summary>detail</summary>Published in the Findings of the Association for Computational Linguistics: EMNLP 2025</details>|
|**2025-11-24**|**Cross-Domain Generalization of Multimodal LLMs for Global Photovoltaic Assessment**|Muhao Guo et.al|[paper](https://arxiv.org/abs/2511.19537)|-|-|
|**2025-11-23**|**When Generative Replay Meets Evolving Deepfakes: Domain-Aware Relative Weighting for Incremental Face Forgery Detection**|Hao Shen et.al|[paper](https://arxiv.org/abs/2511.18436)|-|-|
|**2025-11-23**|**General vs Domain-Specific CNNs: Understanding Pretraining Effects on Brain MRI Tumor Classification**|Helia Abedini et.al|[paper](https://arxiv.org/abs/2511.18326)|-|-|
|**2025-11-22**|**UniFlow: Towards Zero-Shot LiDAR Scene Flow for Autonomous Vehicles via Cross-Domain Generalization**|Siyi Li et.al|[paper](https://arxiv.org/abs/2511.18254)|[code](https://lisiyi777.github.io/UniFlow/)|<details><summary>detail</summary>Project Page: https://lisiyi777</details>|
|**2025-11-22**|**Rethinking Retrieval: From Traditional Retrieval Augmented Generation to Agentic and Non-Vector Reasoning Systems in the Financial Domain for Large Language Models**|Elias Lumer et.al|[paper](https://arxiv.org/abs/2511.18177)|-|-|
|**2025-11-22**|**GROOT: General-Purpose Automatic Parameter Tuning Across Layers, Domains, and Use Cases**|Robert Krahn et.al|[paper](https://arxiv.org/abs/2511.17922)|-|<details><summary>detail</summary>International Conferences on Applied Computing 2025 and WWW/Internet 2025</details>|
|**2025-11-21**|**AngioDG: Interpretable Channel-informed Feature-modulated Single-source Domain Generalization for Coronary Vessel Segmentation in X-ray Angiography**|Mohammad Atwany et.al|[paper](https://arxiv.org/abs/2511.17724)|-|-|
|**2025-11-21**|**Open-Set Domain Generalization through Spectral-Spatial Uncertainty Disentanglement for Hyperspectral Image Classification**|Amirreza Khoshbakht et.al|[paper](https://arxiv.org/abs/2506.09460)|-|-|
|**2025-11-21**|**The Finer the Better: Towards Granular-aware Open-set Domain Generalization**|Yunyun Wang et.al|[paper](https://arxiv.org/abs/2511.16979)|-|-|
|**2025-11-20**|**L-JacobiNet and S-JacobiNet: An Analysis of Adaptive Generalization, Stabilization, and Spectral Domain Trade-offs in GNNs**|Huseyin Goksu et.al|[paper](https://arxiv.org/abs/2511.16081)|-|-|
|**2025-11-19**|**Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains**|Austin Xu et.al|[paper](https://arxiv.org/abs/2510.17793)|-|-|
|**2025-11-19**|**Transferable Dual-Domain Feature Importance Attack against AI-Generated Image Detector**|Weiheng Zhu et.al|[paper](https://arxiv.org/abs/2511.15571)|-|-|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-26**|**G$^2$VLM: Geometry Grounded Vision Language Model with Unified 3D Reconstruction and Spatial Reasoning**|Wenbo Hu et.al|[paper](https://arxiv.org/abs/2511.21688)|[code](https://github.com/InternRobotics/G2VLM)|<details><summary>detail</summary>code are released at https://github</details>|
|**2025-11-26**|**Attention-Guided Patch-Wise Sparse Adversarial Attacks on Vision-Language-Action Models**|Naifu Zhang et.al|[paper](https://arxiv.org/abs/2511.21663)|-|-|
|**2025-11-26**|**TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding**|Boshen Xu et.al|[paper](https://arxiv.org/abs/2511.16595)|[code](https://xuboshen.github.io/TimeViper;)|<details><summary>detail</summary>Project page: https://xuboshen</details>|
|**2025-11-26**|**TinyChemVL: Advancing Chemical Vision-Language Models via Efficient Visual Token Reduction and Complex Reaction Tasks**|Xuanle Zhao et.al|[paper](https://arxiv.org/abs/2511.06283)|-|<details><summary>detail</summary>Accepted by AAAI 2026</details>|
|**2025-11-26**|**Do Reasoning Vision-Language Models Inversely Scale in Test-Time Compute? A Distractor-centric Empirical Analysis**|Jiyun Bae et.al|[paper](https://arxiv.org/abs/2511.21397)|-|<details><summary>detail</summary>preprint</details>|
|**2025-11-26**|**Think Visually, Reason Textually: Vision-Language Synergy in ARC**|Beichen Zhang et.al|[paper](https://arxiv.org/abs/2511.15703)|[code](https://github.com/InternLM/ARC-VL.)|-|
|**2025-11-26**|**Co-Training Vision Language Models for Remote Sensing Multi-task Learning**|Qingyun Li et.al|[paper](https://arxiv.org/abs/2511.21272)|-|-|
|**2025-11-26**|**SARVLM: A Vision Language Foundation Model for Semantic Understanding and Target Recognition in SAR Imagery**|Qiwei Ma et.al|[paper](https://arxiv.org/abs/2510.22665)|-|-|
|**2025-11-26**|**When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models**|Hui Lu et.al|[paper](https://arxiv.org/abs/2511.21192)|-|-|
|**2025-11-26**|**Scenes as Tokens: Multi-Scale Normal Distributions Transform Tokenizer for General 3D Vision-Language Understanding**|Yutao Tang et.al|[paper](https://arxiv.org/abs/2511.21191)|-|-|
|**2025-11-26**|**EM-KD: Distilling Efficient Multimodal Large Language Model with Unbalanced Vision Tokens**|Ze Feng et.al|[paper](https://arxiv.org/abs/2511.21106)|-|<details><summary>detail</summary>accepted by AAAI 2026</details>|
|**2025-11-26**|**Multi-PA: A Multi-perspective Benchmark on Privacy Assessment for Large Vision-Language Models**|Jie Zhang et.al|[paper](https://arxiv.org/abs/2412.19496)|-|-|
|**2025-11-26**|**Agent0-VL: Exploring Self-Evolving Agent for Tool-Integrated Vision-Language Reasoning**|Jiaqi Liu et.al|[paper](https://arxiv.org/abs/2511.19900)|[code](https://github.com/aiming-lab/Agent0.)|-|
|**2025-11-25**|**Vision-Language Enhanced Foundation Model for Semi-supervised Medical Image Segmentation**|Jiaqi Guo et.al|[paper](https://arxiv.org/abs/2511.19759)|-|-|
|**2025-11-25**|**BUSTR: Breast Ultrasound Text Reporting with a Descriptor-Aware Vision-Language Model**|Rawa Mohammed et.al|[paper](https://arxiv.org/abs/2511.20956)|[code](https://github.com/AAR-UNLV/BUSTR)|-|

