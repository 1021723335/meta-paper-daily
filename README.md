## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2026.01.29

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2026-1-28**|**A Source-Free Approach for Domain Adaptation via Multiview Image Transformation and Latent Space Consistency**|Debopom Sutradhar et.al|[paper](https://arxiv.org/abs/2601.20284)|-|<details><summary>detail</summary>Manuscript under review in IEEE Transactions on Image Processing</details>|
|**2026-1-24**|**Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity**|Harsharaj Pathak et.al|[paper](https://arxiv.org/abs/2601.17408)|-|-|
|**2026-1-23**|**Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results**|Rohan Palanikumar et.al|[paper](https://arxiv.org/abs/2511.00752)|-|-|
|**2026-1-20**|**Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2511.07301)|-|<details><summary>detail</summary>AAAI 2026</details>|
|**2026-1-19**|**Towards Unbiased Source-Free Object Detection via Vision Foundation Models**|Zhi Cai et.al|[paper](https://arxiv.org/abs/2601.12765)|-|-|
|**2026-1-18**|**Unified Source-Free Domain Adaptation**|Song Tang et.al|[paper](https://arxiv.org/abs/2403.07601)|[code](https://github.com/tntek/CausalDA.)|-|
|**2026-1-16**|**GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher and Gaussian Mixture Model-Based Pseudo-Labeling**|Pascal Schlachter et.al|[paper](https://arxiv.org/abs/2601.11161)|[code](https://github.com/pascalschlachter/GMM-COMET.)|-|
|**2026-1-13**|**SfMamba: Efficient Source-Free Domain Adaptation via Selective Scan Modeling**|Xi Chen et.al|[paper](https://arxiv.org/abs/2601.08608)|[code](https://github.com/chenxi52/SfMamba.)|-|
|**2026-1-13**|**Source-Free Domain Adaptation for Geospatial Point Cloud Semantic Segmentation**|Yuan Gao et.al|[paper](https://arxiv.org/abs/2601.08375)|-|-|
|**2026-1-5**|**Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based Curriculum Learning**|Dongjie Chen et.al|[paper](https://arxiv.org/abs/2405.18376)|[code](https://github.com/Dong-Jie-Chen/RCL.)|-|
|**2025-12-24**|**Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection**|Sairam VCR et.al|[paper](https://arxiv.org/abs/2512.17514)|-|-|
|**2025-12-18**|**Exploiting Radio Frequency Fingerprints for Device Identification: Tackling Cross-receiver Challenges in the Source-data-free Scenario**|Liu Yang et.al|[paper](https://arxiv.org/abs/2512.16648)|-|<details><summary>detail</summary>IEEE Transactions on Mobile Computing</details>|
|**2025-12-10**|**VocSim: A Training-free Benchmark for Zero-shot Content Identity in Single-source Audio**|Maris Basha et.al|[paper](https://arxiv.org/abs/2512.10120)|-|-|
|**2025-12-7**|**FedSCAl: Leveraging Server and Client Alignment for Unsupervised Federated Source-Free Domain Adaptation**|M Yashwanth et.al|[paper](https://arxiv.org/abs/2512.06738)|-|<details><summary>detail</summary>Winter Conference on Applications of Computer Vision (WACV) 2026</details>|
|**2025-11-28**|**Source-free Video Domain Adaptation by Learning from Noisy Labels**|Avijit Dasgupta et.al|[paper](https://arxiv.org/abs/2311.18572)|[code](https://avijit9.github.io/CleanAdapt.)|<details><summary>detail</summary>Our extended ICVGIP paper is now accepted in Pattern Recognition</details>|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2026-1-27**|**Instance-Guided Radar Depth Estimation for 3D Object Detection**|Chen-Chou Lo et.al|[paper](https://arxiv.org/abs/2601.19314)|-|<details><summary>detail</summary>IPMV2026</details>|
|**2026-1-26**|**Implicit Non-Causal Factors are Out via Dataset Splitting for Domain Generalization Object Detection**|Zhilong Zhang et.al|[paper](https://arxiv.org/abs/2601.19127)|-|<details><summary>detail</summary>To appear in IJCV</details>|
|**2026-1-26**|**Synthetic Object Compositions for Scalable and Accurate Learning in Detection, Segmentation, and Grounding**|Weikai Huang et.al|[paper](https://arxiv.org/abs/2510.09110)|[code](https://github.com/weikaih04/Synthetic-Detection-Segmentation-Grounding-Data)|<details><summary>detail</summary>Project website: https://github</details>|
|**2026-1-26**|**EFSI-DETR: Efficient Frequency-Semantic Integration for Real-Time Small Object Detection in UAV Imagery**|Yu Xia et.al|[paper](https://arxiv.org/abs/2601.18597)|-|-|
|**2026-1-26**|**From Filters to VLMs: Benchmarking Defogging Methods through Object Detection and Segmentation Performance**|Ardalan Aryashad et.al|[paper](https://arxiv.org/abs/2510.03906)|[code](https://aradfir.github.io/filters-to-vlms-defogging-page/)|<details><summary>detail</summary>WACV 2026 Proceedings (Oral)</details>|
|**2026-1-26**|**Real-Time Object Detection Meets DINOv3**|Shihua Huang et.al|[paper](https://arxiv.org/abs/2509.20787)|[code](https://github.com/Intellindust-AI-Lab/DEIMv2)|<details><summary>detail</summary>Source code available at https://github</details>|
|**2026-1-26**|**YOLO-DS: Fine-Grained Feature Decoupling via Dual-Statistic Synergy Operator for Object Detection**|Lin Huang et.al|[paper](https://arxiv.org/abs/2601.18172)|-|-|
|**2026-1-25**|**Cross-Level Sensor Fusion with Object Lists via Transformer for 3D Object Detection**|Xiangzhong Liu et.al|[paper](https://arxiv.org/abs/2512.12884)|-|-|
|**2026-1-24**|**Exploiting Unlabeled Data with Multiple Expert Teachers for Open Vocabulary Aerial Object Detection and Its Orientation Adaptation**|Yan Li et.al|[paper](https://arxiv.org/abs/2411.02057)|[code](https://github.com/VisionXLab/CastDet.)|<details><summary>detail</summary>Accepted by International Journal of Computer Vision (IJCV'26)</details>|
|**2026-1-24**|**M2I2HA: Multi-modal Object Detection Based on Intra- and Inter-Modal Hypergraph Attention**|Xiaofan Yang et.al|[paper](https://arxiv.org/abs/2601.14776)|-|-|
|**2026-1-23**|**UltraFlwr -- An Efficient Federated Surgical Object Detection Framework**|Yang Li et.al|[paper](https://arxiv.org/abs/2503.15161)|[code](https://github.com/KCL-BMEIS/UltraFlwr.)|-|
|**2026-1-23**|**Boundary and Position Information Mining for Aerial Small Object Detection**|Rongxin Huang et.al|[paper](https://arxiv.org/abs/2601.16617)|-|-|
|**2026-1-22**|**YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection**|Ori Meiraz et.al|[paper](https://arxiv.org/abs/2511.13344)|-|<details><summary>detail</summary>1 figure</details>|
|**2026-1-22**|**Performance-guided Reinforced Active Learning for Object Detection**|Zhixuan Liang et.al|[paper](https://arxiv.org/abs/2601.15688)|-|<details><summary>detail</summary>Accepted by ICASSP 2026</details>|
|**2026-1-21**|**Debate-Enhanced Pseudo Labeling and Frequency-Aware Progressive Debiasing for Weakly-Supervised Camouflaged Object Detection with Scribble Annotations**|Jiawei Ge et.al|[paper](https://arxiv.org/abs/2512.20260)|-|-|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2026-1-28**|**A Source-Free Approach for Domain Adaptation via Multiview Image Transformation and Latent Space Consistency**|Debopom Sutradhar et.al|[paper](https://arxiv.org/abs/2601.20284)|-|<details><summary>detail</summary>Manuscript under review in IEEE Transactions on Image Processing</details>|
|**2026-1-27**|**CiMRAG: Cim-Aware Domain-Adaptive and Noise-Resilient Retrieval-Augmented Generation for Edge-Based LLMs**|Shih-Hsuan Chiu et.al|[paper](https://arxiv.org/abs/2601.20041)|-|<details><summary>detail</summary>Accepted by ICASSP 2026</details>|
|**2026-1-27**|**From Atoms to Chains: Divergence-Guided Reasoning Curriculum for Unlabeled LLM Domain Adaptation**|Yongqi Wang et.al|[paper](https://arxiv.org/abs/2601.19588)|[code](https://github.com/bytedance/DGRC)|<details><summary>detail</summary>Code: https://github</details>|
|**2026-1-27**|**A Multi-View Consistency Framework with Semi-Supervised Domain Adaptation**|Yuting Hong et.al|[paper](https://arxiv.org/abs/2601.19266)|-|-|
|**2026-1-26**|**SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics**|Santosh Chapagain et.al|[paper](https://arxiv.org/abs/2601.12131)|-|<details><summary>detail</summary>This is preliminary work towards a broader SolarGPT framework</details>|
|**2026-1-26**|**Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation**|Zihao Wang et.al|[paper](https://arxiv.org/abs/2601.18623)|-|<details><summary>detail</summary>Paper accepted as a conference paper at ICLR 2026</details>|
|**2026-1-26**|**When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs**|Junyi Zou et.al|[paper](https://arxiv.org/abs/2601.18350)|-|-|
|**2026-1-26**|**Learning Fair Domain Adaptation with Virtual Label Distribution**|Yuguang Zhang et.al|[paper](https://arxiv.org/abs/2601.18171)|-|<details><summary>detail</summary>ICASSP 2026</details>|
|**2026-1-24**|**Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity**|Harsharaj Pathak et.al|[paper](https://arxiv.org/abs/2601.17408)|-|-|
|**2026-1-23**|**Semi-Supervised Domain Adaptation with Latent Diffusion for Pathology Image Classification**|Tengyue Zhang et.al|[paper](https://arxiv.org/abs/2601.17228)|-|-|
|**2026-1-23**|**Sim-to-Real Transfer via a Style-Identified Cycle Consistent Generative Adversarial Network: Zero-Shot Deployment on Robotic Manipulators through Visual Domain Adaptation**|Lucía Güitta-López et.al|[paper](https://arxiv.org/abs/2601.16677)|-|<details><summary>detail</summary>ACM Class:I</details>|
|**2026-1-23**|**SONAR: Self-Distilled Continual Pre-training for Domain Adaptive Audio Representation**|Yizhou Zhang et.al|[paper](https://arxiv.org/abs/2509.15703)|-|<details><summary>detail</summary>ICASSP 2026</details>|
|**2026-1-22**|**Multi-View Projection for Unsupervised Domain Adaptation in 3D Semantic Segmentation**|Andrew Caunes et.al|[paper](https://arxiv.org/abs/2505.15545)|-|-|
|**2026-1-21**|**EfficientXpert: Efficient Domain Adaptation for Large Language Models via Propagation-Aware Pruning**|Songlin Zhao et.al|[paper](https://arxiv.org/abs/2511.19935)|-|-|
|**2026-1-21**|**BEST-RQ-Based Self-Supervised Learning for Whisper Domain Adaptation**|Raphaël Bagat et.al|[paper](https://arxiv.org/abs/2510.24570)|-|<details><summary>detail</summary>ICASSP 2026</details>|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2026-1-28**|**P2S: Probabilistic Process Supervision for General-Domain Reasoning Question Answering**|Wenlin Zhong et.al|[paper](https://arxiv.org/abs/2601.20649)|-|-|
|**2026-1-28**|**Automated Benchmark Generation from Domain Guidelines Informed by Bloom's Taxonomy**|Si Chen et.al|[paper](https://arxiv.org/abs/2601.20253)|-|-|
|**2026-1-27**|**Modality-Balanced Collaborative Distillation for Multi-Modal Domain Generalization**|Xiaohan Wang et.al|[paper](https://arxiv.org/abs/2511.20258)|-|-|
|**2026-1-27**|**CiMRAG: Cim-Aware Domain-Adaptive and Noise-Resilient Retrieval-Augmented Generation for Edge-Based LLMs**|Shih-Hsuan Chiu et.al|[paper](https://arxiv.org/abs/2601.20041)|-|<details><summary>detail</summary>Accepted by ICASSP 2026</details>|
|**2026-1-27**|**Semantic-aware Random Convolution and Source Matching for Domain Generalization in Medical Image Segmentation**|Franz Thaler et.al|[paper](https://arxiv.org/abs/2512.01510)|-|-|
|**2026-1-27**|**DSP-Reg: Domain-Sensitive Parameter Regularization for Robust Domain Generalization**|Xudong Han et.al|[paper](https://arxiv.org/abs/2601.19394)|-|-|
|**2026-1-27**|**Federated Joint Learning for Domain and Class Generalization**|Haoran Xu et.al|[paper](https://arxiv.org/abs/2601.12253)|-|<details><summary>detail</summary>ICASSP 2026</details>|
|**2026-1-26**|**Implicit Non-Causal Factors are Out via Dataset Splitting for Domain Generalization Object Detection**|Zhilong Zhang et.al|[paper](https://arxiv.org/abs/2601.19127)|-|<details><summary>detail</summary>To appear in IJCV</details>|
|**2026-1-26**|**Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents**|Zhihan Liu et.al|[paper](https://arxiv.org/abs/2601.18217)|-|-|
|**2026-1-25**|**Domain Generalization with Quantum Enhancement for Medical Image Classification: A Lightweight Approach for Cross-Center Deployment**|Jingsong Xia et.al|[paper](https://arxiv.org/abs/2601.17862)|-|-|
|**2026-1-24**|**Stylizing ViT: Anatomy-Preserving Instance Style Transfer for Domain Generalization**|Sebastian Doerrich et.al|[paper](https://arxiv.org/abs/2601.17586)|[code](https://github.com/sdoerrich97/stylizing-vit)|<details><summary>detail</summary>23rd IEEE International Symposium on Biomedical Imaging (IEEE ISBI 2026)</details>|
|**2026-1-24**|**Revisiting Invariant Learning for Out-of-Domain Generalization on Multi-Site Mammogram Datasets**|Hung Q. Vo et.al|[paper](https://arxiv.org/abs/2503.06759)|-|-|
|**2026-1-23**|**Sim-to-Real Transfer via a Style-Identified Cycle Consistent Generative Adversarial Network: Zero-Shot Deployment on Robotic Manipulators through Visual Domain Adaptation**|Lucía Güitta-López et.al|[paper](https://arxiv.org/abs/2601.16677)|-|<details><summary>detail</summary>ACM Class:I</details>|
|**2026-1-23**|**StealthGraph: Exposing Domain-Specific Risks in LLMs through Knowledge-Graph-Guided Harmful Prompt Generation**|Huawei Zheng et.al|[paper](https://arxiv.org/abs/2601.04740)|-|-|
|**2026-1-22**|**Experience with Single Domain Generalization in Real World Medical Imaging Deployments**|Ayan Banerjee et.al|[paper](https://arxiv.org/abs/2601.16359)|-|<details><summary>detail</summary>AAAI 2026 Innovative Applications of Artificial Intelligence</details>|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2026-1-28**|**BlindSight: Harnessing Sparsity for Efficient Vision-Language Models**|Tharun Adithya Srikrishnan et.al|[paper](https://arxiv.org/abs/2507.09071)|-|<details><summary>detail</summary>ACM Class:I</details>|
|**2026-1-28**|**bi-modal textual prompt learning for vision-language models in remote sensing**|Pankhi Kashyap et.al|[paper](https://arxiv.org/abs/2601.20675)|[code](https://github.com/ipankhi/BiMoRS.)|<details><summary>detail</summary>Accepted in ICASSP 2026</details>|
|**2026-1-28**|**Investigating the Development of Task-Oriented Communication in Vision-Language Models**|Boaz Carmeli et.al|[paper](https://arxiv.org/abs/2601.20641)|-|-|
|**2026-1-28**|**Mixing Importance with Diversity: Joint Optimization for KV Cache Compression in Large Vision-Language Models**|Xuyang Liu et.al|[paper](https://arxiv.org/abs/2510.20707)|[code](https://github.com/xuyang-liu16/MixKV.)|<details><summary>detail</summary>Accepted by ICLR 2026</details>|
|**2026-1-28**|**MARE: Multimodal Alignment and Reinforcement for Explainable Deepfake Detection via Vision-Language Models**|Wenbo Xu et.al|[paper](https://arxiv.org/abs/2601.20433)|-|-|
|**2026-1-28**|**Let's Roll a BiFTA: Bi-refinement for Fine-grained Text-visual Alignment in Vision-Language Models**|Yuhao Sun et.al|[paper](https://arxiv.org/abs/2601.20419)|-|-|
|**2026-1-28**|**NLPrompt: Noise-Label Prompt Learning for Vision-Language Models**|Bikang Pan et.al|[paper](https://arxiv.org/abs/2412.01256)|-|-|
|**2026-1-28**|**Tactile-Force Alignment in Vision-Language-Action Models for Force-aware Manipulation**|Yuzhe Huang et.al|[paper](https://arxiv.org/abs/2601.20321)|-|-|
|**2026-1-28**|**SG-CADVLM: A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation**|Hongyi Zhao et.al|[paper](https://arxiv.org/abs/2601.18442)|-|-|
|**2026-1-27**|**Feature Projection Learning for Better Vision-Language Reasoning**|Yi Zhang et.al|[paper](https://arxiv.org/abs/2601.20224)|-|<details><summary>detail</summary>ICASSP 2026</details>|
|**2026-1-27**|**Diagnosing Vision Language Models' Perception by Leveraging Human Methods for Color Vision Deficiencies**|Kazuki Hayashi et.al|[paper](https://arxiv.org/abs/2505.17461)|-|<details><summary>detail</summary>appear in the main conference of EACL 2026</details>|
|**2026-1-27**|**Youtu-VL: Unleashing Visual Potential via Unified Vision-Language Supervision**|Zhixiang Wei et.al|[paper](https://arxiv.org/abs/2601.19798)|-|-|
|**2026-1-27**|**SCoPE VLM: Selective Context Processing for Efficient Document Navigation in Vision-Language Models**|Gyubeum Lim et.al|[paper](https://arxiv.org/abs/2510.21850)|-|-|
|**2026-1-27**|**Physics-Aware Novel-View Acoustic Synthesis with Vision-Language Priors and 3D Acoustic Environment Modeling**|Congyi Fan et.al|[paper](https://arxiv.org/abs/2601.19712)|[code](https://physnvas.github.io/)|<details><summary>detail</summary>ICASSP 2026 Accept</details>|
|**2026-1-27**|**LangForce: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries**|Shijie Lian et.al|[paper](https://arxiv.org/abs/2601.15197)|-|-|

