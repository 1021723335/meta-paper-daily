## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2025.07.28

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-23**|**SFUOD: Source-Free Unknown Object Detection**|Keon-Hee Park et.al|[paper](https://arxiv.org/abs/2507.17373)|-|<details><summary>detail</summary>This paper has been accepted by ICCV 2025</details>|
|**2025-7-21**|**Model-Free and Real-Time Bioinspired Unicycle-Based Source Seeking: Differential Wheeled Robotic Experiments**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2501.02184)|-|-|
|**2025-7-14**|**Text-Driven Causal Representation Learning for Source-Free Domain Generalization**|Lihua Zhou et.al|[paper](https://arxiv.org/abs/2507.09961)|-|<details><summary>detail</summary>Under Review</details>|
|**2025-7-12**|**Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting**|Zheang Huai et.al|[paper](https://arxiv.org/abs/2505.08527)|[code](https://github.com/xmed-lab/DFG.)|<details><summary>detail</summary>Accepted in TMI 2025</details>|
|**2025-7-4**|**Source-Free Domain Adaptation via Multi-view Contrastive Learning**|Amirfarhad Farhadi et.al|[paper](https://arxiv.org/abs/2507.03321)|-|-|
|**2025-6-26**|**Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework**|Ismail Nejjar et.al|[paper](https://arxiv.org/abs/2411.12558)|-|<details><summary>detail</summary>TMLR 2025</details>|
|**2025-6-26**|**Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation**|Yihong Cao et.al|[paper](https://arxiv.org/abs/2506.21198)|[code](https://github.com/yihong-97/UNLOCK.)|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-6-25**|**Context Aware Grounded Teacher for Source Free Object Detection**|Tajamul Ashraf et.al|[paper](https://arxiv.org/abs/2504.15404)|[code](https://github.com/Tajamul21/Grounded_Teacher.)|-|
|**2025-6-18**|**SFDLA: Source-Free Document Layout Analysis**|Sebastian Tewes et.al|[paper](https://arxiv.org/abs/2503.18742)|[code](https://github.com/s3setewe/sfdla-DLAdapter.)|<details><summary>detail</summary>Accepted by ICDAR 2025</details>|
|**2025-6-17**|**Unified Source-Free Domain Adaptation**|Song Tang et.al|[paper](https://arxiv.org/abs/2403.07601)|-|-|
|**2025-6-11**|**SRPL-SFDA: SAM-Guided Reliable Pseudo-Labels for Source-Free Domain Adaptation in Medical Image Segmentation**|Xinya Liu et.al|[paper](https://arxiv.org/abs/2506.09403)|[code](https://github.com/HiLab-git/SRPL-SFDA.)|-|
|**2025-6-5**|**DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization**|Geonyoung Lee et.al|[paper](https://arxiv.org/abs/2506.02858)|[code](https://wltschmrz.github.io/DGMO/)|<details><summary>detail</summary>Interspeech 2025</details>|
|**2025-5-30**|**Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2503.20771)|-|-|
|**2025-5-30**|**Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation**|Pascal Schlachter et.al|[paper](https://arxiv.org/abs/2504.11992)|[code](https://github.com/pascalschlachter/PLAnalysis.)|<details><summary>detail</summary>the 33rd European Signal Processing Conference (EUSIPCO 2025)</details>|
|**2025-5-30**|**Shuffle PatchMix Augmentation with Confidence-Margin Weighted Pseudo-Labels for Enhanced Source-Free Domain Adaptation**|Prasanna Reddy Pulakurthi et.al|[paper](https://arxiv.org/abs/2505.24216)|[code](https://github.com/PrasannaPulakurthi/SPM)|-|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-25**|**Multistream Network for LiDAR and Camera-based 3D Object Detection in Outdoor Scenes**|Muhammad Ibrahim et.al|[paper](https://arxiv.org/abs/2507.19304)|[code](https://www.cvlibs.net/datasets/kitti/eval_object_detail.php?&result=d162ec699d6992040e34314d19ab7f5c217075e0)|<details><summary>detail</summary>This paper has been accepted by IEEE/RSJ IROS 2025 for oral presentation on 19 Oct</details>|
|**2025-7-25**|**Cross Spatial Temporal Fusion Attention for Remote Sensing Object Detection via Image Feature Matching**|Abu Sadat Mohammad Salehin Amit et.al|[paper](https://arxiv.org/abs/2507.19118)|-|-|
|**2025-7-25**|**Revisiting DETR for Small Object Detection via Noise-Resilient Query Optimization**|Xiaocheng Fang et.al|[paper](https://arxiv.org/abs/2507.19059)|-|<details><summary>detail</summary>2025 IEEE International Conference on Multimedia and Expo (ICME)</details>|
|**2025-7-25**|**Style-Adaptive Detection Transformer for Single-Source Domain Generalized Object Detection**|Jianhong Han et.al|[paper](https://arxiv.org/abs/2504.20498)|-|<details><summary>detail</summary>Manuscript submitted to IEEE Transactions on Circuits and Systems for Video Technology</details>|
|**2025-7-24**|**WiSE-OD: Benchmarking Robustness in Infrared Object Detection**|Heitor R. Medeiros et.al|[paper](https://arxiv.org/abs/2507.18925)|-|-|
|**2025-7-24**|**Synthetic-to-Real Camouflaged Object Detection**|Zhihao Luo et.al|[paper](https://arxiv.org/abs/2507.18911)|[code](https://github.com/Muscape/S2R-COD)|-|
|**2025-7-24**|**MambaNeXt-YOLO: A Hybrid State Space Model for Real-time Object Detection**|Xiaochun Lei et.al|[paper](https://arxiv.org/abs/2506.03654)|-|<details><summary>detail</summary>This paper is under consideration at Image and Vision Computing</details>|
|**2025-7-24**|**Towards Large Scale Geostatistical Methane Monitoring with Part-based Object Detection**|Adhemar de Senneville et.al|[paper](https://arxiv.org/abs/2507.18513)|-|-|
|**2025-7-24**|**Revisiting Physically Realizable Adversarial Object Attack against LiDAR-based Detection: Clarifying Problem Formulation and Experimental Protocols**|Luo Cheng et.al|[paper](https://arxiv.org/abs/2507.18457)|-|-|
|**2025-7-24**|**Boosting Multi-View Indoor 3D Object Detection via Adaptive 3D Volume Construction**|Runmin Zhang et.al|[paper](https://arxiv.org/abs/2507.18331)|[code](https://github.com/RM-Zhang/SGCDet.)|<details><summary>detail</summary>Accepted by ICCV2025</details>|
|**2025-7-24**|**LMM-Det: Make Large Multimodal Models Excel in Object Detection**|Jincheng Li et.al|[paper](https://arxiv.org/abs/2507.18300)|[code](https://github.com/360CVGroup/LMM-Det.)|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-7-24**|**Real-Time Object Detection and Classification using YOLO for Edge FPGAs**|Rashed Al Amin et.al|[paper](https://arxiv.org/abs/2507.18174)|-|<details><summary>detail</summary>This paper has been accepted for the 67th International Symposium on ELMAR 2025</details>|
|**2025-7-24**|**WaveMamba: Wavelet-Driven Mamba Fusion for RGB-Infrared Object Detection**|Haodong Zhu et.al|[paper](https://arxiv.org/abs/2507.18173)|-|<details><summary>detail</summary>Journal ref:ICCV</details>|
|**2025-7-23**|**Perspective-Invariant 3D Object Detection**|Ao Liang et.al|[paper](https://arxiv.org/abs/2507.17665)|[code](https://pi3det.github.io)|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-7-23**|**BoxFusion: Reconstruction-Free Open-Vocabulary 3D Object Detection via Real-Time Multi-View Box Fusion**|Yuqing Lan et.al|[paper](https://arxiv.org/abs/2506.15610)|[code](https://lanlan96.github.io/BoxFusion/)|<details><summary>detail</summary>Project page: https://lanlan96</details>|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-25**|**Style-Adaptive Detection Transformer for Single-Source Domain Generalized Object Detection**|Jianhong Han et.al|[paper](https://arxiv.org/abs/2504.20498)|-|<details><summary>detail</summary>Manuscript submitted to IEEE Transactions on Circuits and Systems for Video Technology</details>|
|**2025-7-24**|**SIDA: Synthetic Image Driven Zero-shot Domain Adaptation**|Ye-Chan Kim et.al|[paper](https://arxiv.org/abs/2507.18632)|-|<details><summary>detail</summary>ACM MM 2025</details>|
|**2025-7-24**|**crossMoDA Challenge: Evolution of Cross-Modality Domain Adaptation Techniques for Vestibular Schwannoma and Cochlea Segmentation from 2021 to 2023**|Navodini Wijethilake et.al|[paper](https://arxiv.org/abs/2506.12006)|-|-|
|**2025-7-24**|**Att-Adapter: A Robust and Precise Domain-Specific Multi-Attributes T2I Diffusion Adapter via Conditional Variational Autoencoder**|Wonwoong Cho et.al|[paper](https://arxiv.org/abs/2503.11937)|[code](https://tri-mac.github.io/att-adapter/)|<details><summary>detail</summary>ICCV'25 (Highlight)</details>|
|**2025-7-24**|**Unsupervised Domain Adaptation for 3D LiDAR Semantic Segmentation Using Contrastive Learning and Multi-Model Pseudo Labeling**|Abhishek Kaushik et.al|[paper](https://arxiv.org/abs/2507.18176)|-|-|
|**2025-7-23**|**AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation**|Md. Al-Masrur Khan et.al|[paper](https://arxiv.org/abs/2507.17957)|[code](https://github.com/Masrur02/AFRDA)|-|
|**2025-7-23**|**ODES: Domain Adaptation with Expert Guidance for Online Medical Image Segmentation**|Md Shazid Islam et.al|[paper](https://arxiv.org/abs/2312.05407)|-|-|
|**2025-7-23**|**SDC-Net: A Domain Adaptation Framework with Semantic-Dynamic Consistency for Cross-Subject EEG Emotion Recognition**|Jiahao Tang et.al|[paper](https://arxiv.org/abs/2507.17524)|[code](https://github.com/XuanSuTrum/SDC-Net.)|-|
|**2025-7-22**|**Towards Railway Domain Adaptation for LiDAR-based 3D Detection: Road-to-Rail and Sim-to-Real via SynDRA-BBox**|Xavier Diaz et.al|[paper](https://arxiv.org/abs/2507.16413)|[code](https://syndra.retis.santannapisa.it.)|<details><summary>detail</summary>IEEE International Conference on Intelligent Rail Transportation (ICIRT) 2025</details>|
|**2025-7-21**|**UPRE: Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement**|Xiao Zhang et.al|[paper](https://arxiv.org/abs/2507.00721)|[code](https://github.com/AMAP-ML/UPRE.)|<details><summary>detail</summary>ICCV2025</details>|
|**2025-7-21**|**MORDA: A Synthetic Dataset to Facilitate Adaptation of Object Detectors to Unseen Real-target Domain While Preserving Performance on Real-source Domain**|Hojun Lim et.al|[paper](https://arxiv.org/abs/2501.04950)|-|-|
|**2025-7-20**|**PHATNet: A Physics-guided Haze Transfer Network for Domain-adaptive Real-world Image Dehazing**|Fu-Jen Tsai et.al|[paper](https://arxiv.org/abs/2507.14826)|-|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-7-19**|**Domain-Adaptive Small Language Models for Structured Tax Code Prediction**|Souvik Nath et.al|[paper](https://arxiv.org/abs/2507.10880)|-|-|
|**2025-7-19**|**Fourier Domain Adaptation for Traffic Light Detection in Adverse Weather**|Ishaan Gakhar et.al|[paper](https://arxiv.org/abs/2411.07901)|-|<details><summary>detail</summary>the 2COOOL Workshop</details>|
|**2025-7-19**|**When few labeled target data suffice: a theory of semi-supervised domain adaptation via fine-tuning from multiple adaptive starts**|Wooseok Ha et.al|[paper](https://arxiv.org/abs/2507.14661)|-|-|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-25**|**From Continuous to Discrete: Cross-Domain Collaborative General Speech Enhancement via Hierarchical Language Models**|Zhaoxi Mu et.al|[paper](https://arxiv.org/abs/2507.19062)|-|<details><summary>detail</summary>ACMMM 2025</details>|
|**2025-7-25**|**Style-Adaptive Detection Transformer for Single-Source Domain Generalized Object Detection**|Jianhong Han et.al|[paper](https://arxiv.org/abs/2504.20498)|-|<details><summary>detail</summary>Manuscript submitted to IEEE Transactions on Circuits and Systems for Video Technology</details>|
|**2025-7-24**|**Omni-Thinker: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards**|Derek Li et.al|[paper](https://arxiv.org/abs/2507.14783)|-|-|
|**2025-7-24**|**VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks**|Juhwan Choi et.al|[paper](https://arxiv.org/abs/2407.19795)|-|<details><summary>detail</summary>ICCV 2025 Workshop on Curated Data for Efficient Learning (CDEL)</details>|
|**2025-7-23**|**Fully Automated SAM for Single-source Domain Generalization in Medical Image Segmentation**|Huanli Zhuo et.al|[paper](https://arxiv.org/abs/2507.17281)|-|<details><summary>detail</summary>This manuscript has been accepted for presentation at the IEEE International Conference on Systems</details>|
|**2025-7-21**|**Gradient-Guided Annealing for Domain Generalization**|Aristotelis Ballas et.al|[paper](https://arxiv.org/abs/2502.20162)|-|<details><summary>detail</summary>Paper accepted in CVPR2025</details>|
|**2025-7-20**|**DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation**|Bo Liu et.al|[paper](https://arxiv.org/abs/2501.03466)|-|-|
|**2025-7-19**|**Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification**|Subhendu Khatuya et.al|[paper](https://arxiv.org/abs/2506.06806)|-|<details><summary>detail</summary>This work has been accepted to appear at the Association for Computational Linguistics (ACL)</details>|
|**2025-7-17**|**Generative Multi-Target Cross-Domain Recommendation**|Jinqiu Jin et.al|[paper](https://arxiv.org/abs/2507.12871)|-|<details><summary>detail</summary>fix author information</details>|
|**2025-7-17**|**Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning**|Simon Ouellette et.al|[paper](https://arxiv.org/abs/2507.15877)|-|-|
|**2025-7-17**|**Addressing the ML Domain Adaptation Problem for Networking: Realistic and Controllable Training Data Generation with NetReplica**|Jaber Daneshamooz et.al|[paper](https://arxiv.org/abs/2507.13476)|-|-|
|**2025-7-17**|**CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings**|Daniil Orel et.al|[paper](https://arxiv.org/abs/2503.13733)|-|-|
|**2025-7-17**|**Generative AI Models for Learning Flow Maps of Stochastic Dynamical Systems in Bounded Domains**|Minglei Yang et.al|[paper](https://arxiv.org/abs/2507.15990)|-|-|
|**2025-7-17**|**A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints**|Youssef Tawfilis et.al|[paper](https://arxiv.org/abs/2507.12979)|[code](https://github.com/youssefga28/HuSCF-GAN.)|-|
|**2025-7-17**|**Simulate, Refocus and Ensemble: An Attention-Refocusing Scheme for Domain Generalization**|Ziyi Wang et.al|[paper](https://arxiv.org/abs/2507.12851)|[code](https://github.com/bitPrincy/SRE-DG.)|<details><summary>detail</summary>\c{opyright} 20XX IEEE</details>|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-25**|**SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models**|Xiangyu Dong et.al|[paper](https://arxiv.org/abs/2507.13152)|-|-|
|**2025-7-25**|**Towards Multimodal Social Conversations with Robots: Using Vision-Language Models**|Ruben Janssens et.al|[paper](https://arxiv.org/abs/2507.19196)|-|<details><summary>detail</summary>Submitted to the workshop "Human - Foundation Models Interaction: A Focus On Multimodal Information" (FoMo-HRI) at IEEE RO-MAN 2025</details>|
|**2025-7-25**|**Negation-Aware Test-Time Adaptation for Vision-Language Models**|Haochen Han et.al|[paper](https://arxiv.org/abs/2507.19064)|[code](https://github.com/hhc1997/NEAT.)|<details><summary>detail</summary>This paper will be submitted to the IEEE for possible publication</details>|
|**2025-7-24**|**FrameFusion: Combining Similarity and Importance for Video Token Reduction on Large Vision Language Models**|Tianyu Fu et.al|[paper](https://arxiv.org/abs/2501.01986)|[code](https://github.com/thu-nics/FrameFusion.)|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-7-24**|**DiagR1: A Vision-Language Model Trained via Reinforcement Learning for Digestive Pathology Diagnosis**|Minxi Ouyang et.al|[paper](https://arxiv.org/abs/2507.18433)|-|-|
|**2025-7-24**|**Personalization Toolkit: Training Free Personalization of Large Vision Language Models**|Soroush Seifi et.al|[paper](https://arxiv.org/abs/2502.02452)|-|-|
|**2025-7-24**|**Advancing Vision-based Human Action Recognition: Exploring Vision-Language CLIP Model for Generalisation in Domain-Independent Tasks**|Sanyam Jain et.al|[paper](https://arxiv.org/abs/2507.18675)|-|-|
|**2025-7-24**|**Improving Large Vision-Language Models' Understanding for Field Data**|Xiaomei Zhang et.al|[paper](https://arxiv.org/abs/2507.18311)|-|-|
|**2025-7-24**|**Aligning Vision to Language: Annotation-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning**|Junming Liu et.al|[paper](https://arxiv.org/abs/2503.12972)|[code](https://github.com/Wings-Of-Disaster/VaLiK.)|-|
|**2025-7-24**|**VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks**|Juhwan Choi et.al|[paper](https://arxiv.org/abs/2407.19795)|-|<details><summary>detail</summary>ICCV 2025 Workshop on Curated Data for Efficient Learning (CDEL)</details>|
|**2025-7-24**|**EVEv2: Improved Baselines for Encoder-Free Vision-Language Models**|Haiwen Diao et.al|[paper](https://arxiv.org/abs/2502.06788)|[code](https://github.com/baaivision/EVE.)|-|
|**2025-7-24**|**ViLU: Learning Vision-Language Uncertainties for Failure Prediction**|Marc Lafon et.al|[paper](https://arxiv.org/abs/2507.07620)|[code](https://github.com/ykrmm/ViLU.)|<details><summary>detail</summary>Journal ref:International Conference on Computer Vision</details>|
|**2025-7-24**|**When Large Vision-Language Model Meets Large Remote Sensing Imagery: Coarse-to-Fine Text-Guided Token Pruning**|Junwei Luo et.al|[paper](https://arxiv.org/abs/2503.07588)|[code](https://github.com/VisionXLab/LRS-VQA.)|-|
|**2025-7-23**|**RECALLED: An Unbounded Resource Consumption Attack on Large Vision-Language Models**|Haoran Gao et.al|[paper](https://arxiv.org/abs/2507.18053)|-|-|
|**2025-7-23**|**ViGText: Deepfake Image Detection with Vision-Language Model Explanations and Graph Neural Networks**|Ahmad ALBarqawi et.al|[paper](https://arxiv.org/abs/2507.18031)|-|-|

