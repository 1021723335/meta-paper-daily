## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2025.10.06

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-10-2**|**OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation**|Yiming Zhang et.al|[paper](https://arxiv.org/abs/2505.11669)|-|-|
|**2025-10-2**|**Source-Free Cross-Domain Continual Learning**|Muhammad Tanzil Furqon et.al|[paper](https://arxiv.org/abs/2510.01649)|-|-|
|**2025-10-1**|**Consistent Assistant Domains Transformer for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.01559)|[code](https://github.com/RoryShao/CADTrans.git.)|-|
|**2025-9-30**|**Source-Free Domain Adaptive Object Detection with Semantics Compensation**|Song Tang et.al|[paper](https://arxiv.org/abs/2410.05557)|-|-|
|**2025-9-29**|**DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation**|Xi Chen et.al|[paper](https://arxiv.org/abs/2509.24896)|-|-|
|**2025-9-29**|**Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|
|**2025-9-26**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|
|**2025-9-22**|**Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment**|Wenjie Liu et.al|[paper](https://arxiv.org/abs/2509.18502)|-|-|
|**2025-9-22**|**Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation**|Amirhossein Dadashzadeh et.al|[paper](https://arxiv.org/abs/2504.11669)|[code](https://github.com/Plrbear/Co-Star)|-|
|**2025-9-21**|**Prototype-Based Pseudo-Label Denoising for Source-Free Domain Adaptation in Remote Sensing Semantic Segmentation**|Bin Wang et.al|[paper](https://arxiv.org/abs/2509.16942)|-|-|
|**2025-9-18**|**Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2501.02184)|-|-|
|**2025-9-13**|**Step-wise Distribution Alignment Guided Style Prompt Tuning for Source-free Cross-domain Few-shot Learning**|Huali Xu et.al|[paper](https://arxiv.org/abs/2411.10070)|[code](https://github.com/xuhuali-mxj/StepSPT.)|<details><summary>detail</summary>IEEE TPAMI</details>|
|**2025-9-12**|**Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment**|Rini Smita Thakur et.al|[paper](https://arxiv.org/abs/2509.10134)|[code](https://visdomlab.github.io/GCL/.)|<details><summary>detail</summary>Accepted in BMVC 2025</details>|
|**2025-9-10**|**Rethinking the Backbone in Class Imbalanced Federated Source Free Domain Adaptation: The Utility of Vision Foundation Models**|Kosuke Kihara et.al|[paper](https://arxiv.org/abs/2509.08372)|-|<details><summary>detail</summary>Accepted by the IEEE ICIP 2025 Satellite Workshop 1: Edge Intelligence: Smart</details>|
|**2025-9-2**|**StableSleep: Source-Free Test-Time Adaptation for Sleep Staging with Lightweight Safety Rails**|Hritik Arasu et.al|[paper](https://arxiv.org/abs/2509.02982)|-|<details><summary>detail</summary>5 page paper</details>|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-10-3**|**Neural Posterior Estimation with Autoregressive Tiling for Detecting Objects in Astronomical Images**|Jeffrey Regier et.al|[paper](https://arxiv.org/abs/2510.03074)|-|<details><summary>detail</summary>MSC Class:62P35ACM Class:G</details>|
|**2025-10-3**|**Align Your Query: Representation Alignment for Multimodality Medical Object Detection**|Ara Seo et.al|[paper](https://arxiv.org/abs/2510.02789)|[code](https://araseo.github.io/alignyourquery/.)|<details><summary>detail</summary>Project page: https://araseo</details>|
|**2025-10-3**|**Contextualized Representation Learning for Effective Human-Object Interaction Detection**|Zhehao Li et.al|[paper](https://arxiv.org/abs/2509.12784)|[code](https://github.com/lzzhhh1019/CRL.)|-|
|**2025-10-3**|**Bayesian Test-time Adaptation for Object Recognition and Detection with Vision-language Models**|Lihua Zhou et.al|[paper](https://arxiv.org/abs/2510.02750)|-|<details><summary>detail</summary>Under Review</details>|
|**2025-10-2**|**Towards Size-invariant Salient Object Detection: A Generic Evaluation and Optimization Approach**|Shilong Bao et.al|[paper](https://arxiv.org/abs/2509.15573)|[code](https://github.com/Ferry-Li/SI-SOD.)|-|
|**2025-10-2**|**Automated Model Evaluation for Object Detection via Prediction Consistency and Reliability**|Seungju Yoo et.al|[paper](https://arxiv.org/abs/2508.12082)|[code](https://github.com/YonseiML/autoeval-det.)|<details><summary>detail</summary>ICCV 2025 Oral</details>|
|**2025-10-2**|**Automated Defect Detection for Mass-Produced Electronic Components Based on YOLO Object Detection Models**|Wei-Lung Mao et.al|[paper](https://arxiv.org/abs/2510.01914)|-|-|
|**2025-10-1**|**Adaptive Event Stream Slicing for Open-Vocabulary Event-Based Object Detection via Vision-Language Knowledge Distillation**|Jinchang Zhang et.al|[paper](https://arxiv.org/abs/2510.00681)|-|-|
|**2025-10-1**|**PAN: Pillars-Attention-Based Network for 3D Object Detection**|Ruan Bispo et.al|[paper](https://arxiv.org/abs/2509.15935)|-|-|
|**2025-10-1**|**DPDETR: Decoupled Position Detection Transformer for Infrared-Visible Object Detection**|Junjie Guo et.al|[paper](https://arxiv.org/abs/2408.06123)|[code](https://github.com/gjj45/DPDETR)|-|
|**2025-10-1**|**Are All Marine Species Created Equal? Performance Disparities in Underwater Object Detection**|Melanie Wille et.al|[paper](https://arxiv.org/abs/2508.18729)|-|-|
|**2025-9-30**|**Source-Free Domain Adaptive Object Detection with Semantics Compensation**|Song Tang et.al|[paper](https://arxiv.org/abs/2410.05557)|-|-|
|**2025-9-30**|**Looking Beyond the Known: Towards a Data Discovery Guided Open-World Object Detection**|Anay Majee et.al|[paper](https://arxiv.org/abs/2510.00303)|-|<details><summary>detail</summary>NeurIPS'25</details>|
|**2025-9-30**|**Adaptive Modality Balanced Online Knowledge Distillation for Brain-Eye-Computer based Dim Object Detection**|Zixing Li et.al|[paper](https://arxiv.org/abs/2407.01894)|-|-|
|**2025-9-30**|**Object Detection with Multimodal Large Vision-Language Models: An In-depth Review**|Ranjan Sapkota et.al|[paper](https://arxiv.org/abs/2508.19294)|-|<details><summary>detail</summary>First Peer Reviewed Review Paper for Object Detection with Vision-Language Models (VLMs)</details>|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-10-2**|**Unified Domain Adaptive Semantic Segmentation**|Zhe Zhang et.al|[paper](https://arxiv.org/abs/2311.13254)|[code](https://github.com/ZHE-SAPI/UDASS.)|-|
|**2025-10-2**|**VirDA: Reusing Backbone for Unsupervised Domain Adaptation with Visual Reprogramming**|Duy Nguyen et.al|[paper](https://arxiv.org/abs/2510.01660)|-|-|
|**2025-10-2**|**OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation**|Yiming Zhang et.al|[paper](https://arxiv.org/abs/2505.11669)|-|-|
|**2025-10-2**|**Diffusion Models and the Manifold Hypothesis: Log-Domain Smoothing is Geometry Adaptive**|Tyler Farghly et.al|[paper](https://arxiv.org/abs/2510.02305)|-|-|
|**2025-10-1**|**Consistent Assistant Domains Transformer for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.01559)|[code](https://github.com/RoryShao/CADTrans.git.)|-|
|**2025-10-1**|**Signal Classification Recovery Across Domains Using Unsupervised Domain Adaptation**|Mohammad Ali et.al|[paper](https://arxiv.org/abs/2510.00589)|-|-|
|**2025-10-1**|**Black-Box Time-Series Domain Adaptation via Cross-Prompt Foundation Models**|M. T. Furqon et.al|[paper](https://arxiv.org/abs/2510.00487)|-|-|
|**2025-9-30**|**Vicinity-Guided Discriminative Latent Diffusion for Privacy-Preserving Domain Adaptation**|Jing Wang et.al|[paper](https://arxiv.org/abs/2510.00478)|-|-|
|**2025-9-30**|**Source-Free Domain Adaptive Object Detection with Semantics Compensation**|Song Tang et.al|[paper](https://arxiv.org/abs/2410.05557)|-|-|
|**2025-9-30**|**MPCA-based Domain Adaptation for Transfer Learning in Ultrasonic Guided Waves**|Lucio Pinello et.al|[paper](https://arxiv.org/abs/2508.02726)|-|-|
|**2025-9-30**|**Multi-View Projection for Unsupervised Domain Adaptation in 3D Semantic Segmentation**|Andrew Caunes et.al|[paper](https://arxiv.org/abs/2505.15545)|-|-|
|**2025-9-29**|**DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation**|Xi Chen et.al|[paper](https://arxiv.org/abs/2509.24896)|-|-|
|**2025-9-28**|**A Self-Adaptive Frequency Domain Network for Continuous Intraoperative Hypotension Prediction**|Xian Zeng et.al|[paper](https://arxiv.org/abs/2509.23720)|-|<details><summary>detail</summary>ECAI 2025 main conference</details>|
|**2025-9-28**|**Efficient Domain-Adaptive Multi-Task Dense Prediction with Vision Foundation Models**|Beomseok Kang et.al|[paper](https://arxiv.org/abs/2509.23626)|-|-|
|**2025-9-27**|**Robust Multi-Modal Face Anti-Spoofing with Domain Adaptation: Tackling Missing Modalities, Noisy Pseudo-Labels, and Model Degradation**|Ming-Tsung Hsu et.al|[paper](https://arxiv.org/abs/2509.23475)|-|-|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-10-2**|**Automated Constraint Specification for Job Scheduling by Regulating Generative Model with Domain-Specific Representation**|Yu-Zhe Shi et.al|[paper](https://arxiv.org/abs/2510.02679)|-|<details><summary>detail</summary>Accepted for publication in IEEE Transactions on Automation Science and Engineering</details>|
|**2025-10-2**|**DrKGC: Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph Completion across General and Biomedical Domains**|Yongkang Xiao et.al|[paper](https://arxiv.org/abs/2506.00708)|-|<details><summary>detail</summary>EMNLP 2025 Findings</details>|
|**2025-9-30**|**Finetune Once: Decoupling General & Domain Learning with Dynamic Boosted Annealing**|Yang Tang et.al|[paper](https://arxiv.org/abs/2509.26242)|-|-|
|**2025-9-30**|**Scaling Up Temporal Domain Generalization via Temporal Experts Averaging**|Aoming Liu et.al|[paper](https://arxiv.org/abs/2509.26045)|-|<details><summary>detail</summary>Accepted by EMNLP 2025 main</details>|
|**2025-9-29**|**Think Less, Label Better: Multi-Stage Domain-Grounded Synthetic Data Generation for Fine-Tuning Large Language Models in Telecommunications**|Chenhua Shi et.al|[paper](https://arxiv.org/abs/2509.25736)|-|-|
|**2025-9-29**|**SING-SQL: A Synthetic Data Generation Framework for In-Domain Text-to-SQL Translation**|Hasan Alp Caferoğlu et.al|[paper](https://arxiv.org/abs/2509.25672)|-|-|
|**2025-9-27**|**Embedding Domain Knowledge for Large Language Models via Reinforcement Learning from Augmented Generation**|Chaojun Nie et.al|[paper](https://arxiv.org/abs/2509.20162)|[code](https://github.com/ChaojunNie/RLAG.)|<details><summary>detail</summary>Corrected author name spelling</details>|
|**2025-9-27**|**SynDoc: A Hybrid Discriminative-Generative Framework for Enhancing Synthetic Domain-Adaptive Document Key Information Extraction**|Yihao Ding et.al|[paper](https://arxiv.org/abs/2509.23273)|-|<details><summary>detail</summary>Work in progress</details>|
|**2025-9-26**|**Bézier Meets Diffusion: Robust Generation Across Domains for Medical Image Segmentation**|Chen Li et.al|[paper](https://arxiv.org/abs/2509.22476)|-|-|
|**2025-9-26**|**A Survey on LLM-based Code Generation for Low-Resource and Domain-Specific Programming Languages**|Sathvik Joel et.al|[paper](https://arxiv.org/abs/2410.03981)|-|-|
|**2025-9-25**|**Plan2Evolve: LLM Self-Evolution for Improved Planning Capability via Automated Domain Generation**|Jinbang Huang et.al|[paper](https://arxiv.org/abs/2509.21543)|-|-|
|**2025-9-25**|**Technical report on label-informed logit redistribution for better domain generalization in low-shot classification with foundation models**|Behraj Khan et.al|[paper](https://arxiv.org/abs/2501.17595)|-|-|
|**2025-9-25**|**An orderly algorithm for generation of Condorcet Domains**|Bei Zhou et.al|[paper](https://arxiv.org/abs/2509.20865)|-|-|
|**2025-9-25**|**Federated Domain Generalization with Domain-specific Soft Prompts Generation**|Jianhan Wu et.al|[paper](https://arxiv.org/abs/2509.20807)|-|<details><summary>detail</summary>the IEEE/CVF International Conference on Computer Vision (ICCV 2025)</details>|
|**2025-9-25**|**Dual-supervised Asymmetric Co-training for Semi-supervised Medical Domain Generalization**|Jincai Song et.al|[paper](https://arxiv.org/abs/2509.20785)|-|-|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-10-3**|**Less is More: Lean yet Powerful Vision-Language Model for Autonomous Driving**|Sheng Yang et.al|[paper](https://arxiv.org/abs/2510.00060)|-|-|
|**2025-10-3**|**Multimodal Carotid Risk Stratification with Large Vision-Language Models: Benchmarking, Fine-Tuning, and Clinical Insights**|Daphne Tsolissou et.al|[paper](https://arxiv.org/abs/2510.02922)|-|-|
|**2025-10-3**|**Zero-Shot Robustness of Vision Language Models Via Confidence-Aware Weighting**|Nikoo Naghavian et.al|[paper](https://arxiv.org/abs/2510.02913)|-|<details><summary>detail</summary>the NeurIPS 2025 Workshop on Reliable ML from Unreliable Data</details>|
|**2025-10-3**|**Reasoning Riddles: How Explainability Reveals Cognitive Limits in Vision-Language Models**|Prahitha Movva et.al|[paper](https://arxiv.org/abs/2510.02780)|-|<details><summary>detail</summary>Journal ref:COLM 2025: First Workshop on the Application of LLM Explainability to Reasoning and Planning</details>|
|**2025-10-3**|**Bayesian Test-time Adaptation for Object Recognition and Detection with Vision-language Models**|Lihua Zhou et.al|[paper](https://arxiv.org/abs/2510.02750)|-|<details><summary>detail</summary>Under Review</details>|
|**2025-10-2**|**CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification**|Cristiano Patrício et.al|[paper](https://arxiv.org/abs/2501.12266)|[code](https://cristianopatricio.github.io/CBVLM/.)|<details><summary>detail</summary>Accepted for publication in Computers in Biology and Medicine</details>|
|**2025-10-2**|**VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting**|Juyi Lin et.al|[paper](https://arxiv.org/abs/2507.05116)|[code](https://github.com/LukeLIN-web/VOTE.)|-|
|**2025-10-2**|**From Behavioral Performance to Internal Competence: Interpreting Vision-Language Models with VLM-Lens**|Hala Sheta et.al|[paper](https://arxiv.org/abs/2510.02292)|[code](https://github.com/compling-wat/vlm-lens)|<details><summary>detail</summary>EMNLP 2025 System Demonstration | Code: https://github</details>|
|**2025-10-2**|**Unlocking Vision-Language Models for Video Anomaly Detection via Fine-Grained Prompting**|Shu Zou et.al|[paper](https://arxiv.org/abs/2510.02155)|-|-|
|**2025-10-2**|**FRIEREN: Federated Learning with Vision-Language Regularization for Segmentation**|Ding-Ruei Shen et.al|[paper](https://arxiv.org/abs/2510.02114)|-|<details><summary>detail</summary>Master Thesis</details>|
|**2025-10-2**|**Post-hoc Probabilistic Vision-Language Models**|Anton Baumann et.al|[paper](https://arxiv.org/abs/2412.06014)|[code](https://aaltoml.github.io/BayesVLM/)|<details><summary>detail</summary>Project page: https://aaltoml</details>|
|**2025-10-2**|**Robust Prompt Tuning for Vision-Language Models with Mild Semantic Noise**|Yansheng Gao et.al|[paper](https://arxiv.org/abs/2508.04677)|-|-|
|**2025-10-2**|**More Thought, Less Accuracy? On the Dual Nature of Reasoning in Vision-Language Models**|Xinyu Tian et.al|[paper](https://arxiv.org/abs/2509.25848)|[code](https://xytian1008.github.io/VAPO/)|-|
|**2025-10-2**|**Nav-EE: Navigation-Guided Early Exiting for Efficient Vision-Language Models in Autonomous Driving**|Haibo Hu et.al|[paper](https://arxiv.org/abs/2510.01795)|[code](https://anonymous.4open.science/r/Nav-EE-BBC4)|-|
|**2025-10-2**|**HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy**|Myungkyu Koo et.al|[paper](https://arxiv.org/abs/2510.00695)|[code](https://myungkyukoo.github.io/hamlet/)|<details><summary>detail</summary>Project page: https://myungkyukoo</details>|

