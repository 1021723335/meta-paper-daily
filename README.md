## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2025.09.19

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-9-18**|**Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|
|**2025-9-13**|**Step-wise Distribution Alignment Guided Style Prompt Tuning for Source-free Cross-domain Few-shot Learning**|Huali Xu et.al|[paper](https://arxiv.org/abs/2411.10070)|[code](https://github.com/xuhuali-mxj/StepSPT.)|<details><summary>detail</summary>IEEE TPAMI</details>|
|**2025-9-12**|**Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment**|Rini Smita Thakur et.al|[paper](https://arxiv.org/abs/2509.10134)|[code](https://visdomlab.github.io/GCL/.)|<details><summary>detail</summary>Accepted in BMVC 2025</details>|
|**2025-9-10**|**Rethinking the Backbone in Class Imbalanced Federated Source Free Domain Adaptation: The Utility of Vision Foundation Models**|Kosuke Kihara et.al|[paper](https://arxiv.org/abs/2509.08372)|-|<details><summary>detail</summary>Accepted by the IEEE ICIP 2025 Satellite Workshop 1: Edge Intelligence: Smart</details>|
|**2025-9-2**|**StableSleep: Source-Free Test-Time Adaptation for Sleep Staging with Lightweight Safety Rails**|Hritik Arasu et.al|[paper](https://arxiv.org/abs/2509.02982)|-|<details><summary>detail</summary>5 page paper</details>|
|**2025-8-28**|**Model-Free Hovering and Source Seeking via Extremum Seeking Control: Experimental Demonstration**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2508.20836)|-|-|
|**2025-8-26**|**VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection**|Jianhong Han et.al|[paper](https://arxiv.org/abs/2508.11167)|-|<details><summary>detail</summary>Manuscript submitted to IEEE TCSVT</details>|
|**2025-8-20**|**Towards Source-Free Machine Unlearning**|Sk Miraj Ahmed et.al|[paper](https://arxiv.org/abs/2508.15127)|-|<details><summary>detail</summary>Accepted by CVPR 2025</details>|
|**2025-8-14**|**Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2508.09202)|-|-|
|**2025-8-7**|**Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation**|Jianming Liu et.al|[paper](https://arxiv.org/abs/2508.05213)|[code](https://github.com/ljm198134/TVGTANet.)|-|
|**2025-8-4**|**Model Recycling Framework for Multi-Source Data-Free Supervised Transfer Learning**|Sijia Wang et.al|[paper](https://arxiv.org/abs/2508.02039)|-|-|
|**2025-7-30**|**Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2501.02184)|-|-|
|**2025-7-28**|**Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation**|Yihong Cao et.al|[paper](https://arxiv.org/abs/2506.21198)|[code](https://github.com/yihong-97/UNLOCK.)|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-7-26**|**GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning**|Sanqing Qu et.al|[paper](https://arxiv.org/abs/2403.14410)|[code](https://github.com/ispc-lab/GLC-plus.)|<details><summary>detail</summary>A substantial extension of the CVPR paper "Upcycling Models under Domain and Category Shift"</details>|
|**2025-7-23**|**SFUOD: Source-Free Unknown Object Detection**|Keon-Hee Park et.al|[paper](https://arxiv.org/abs/2507.17373)|-|<details><summary>detail</summary>This paper has been accepted by ICCV 2025</details>|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-9-18**|**Synthetic-to-Real Object Detection using YOLOv11 and Domain Randomization Strategies**|Luisa Torquato Ni√±o et.al|[paper](https://arxiv.org/abs/2509.15045)|-|-|
|**2025-9-18**|**Data Augmentation via Latent Diffusion Models for Detecting Smell-Related Objects in Historical Artworks**|Ahmed Sheta et.al|[paper](https://arxiv.org/abs/2509.14755)|-|<details><summary>detail</summary>Appeared at the 4th International Workshop on Fine Art Pattern Extraction and Recognition (FAPER 2025)</details>|
|**2025-9-18**|**Deep Learning-Driven Multimodal Detection and Movement Analysis of Objects in Culinary**|Tahoshin Alam Ishat et.al|[paper](https://arxiv.org/abs/2509.00033)|-|-|
|**2025-9-17**|**BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection**|Rongyu Zhang et.al|[paper](https://arxiv.org/abs/2509.14151)|-|<details><summary>detail</summary>Accepted by IEEE TCSVT</details>|
|**2025-9-17**|**A Novel Compression Framework for YOLOv8: Achieving Real-Time Aerial Object Detection on Edge Devices via Structured Pruning and Channel-Wise Distillation**|Melika Sabaghian et.al|[paper](https://arxiv.org/abs/2509.12918)|-|-|
|**2025-9-16**|**Real-Time Detection and Tracking of Foreign Object Intrusions in Power Systems via Feature-Based Edge Intelligence**|Xinan Wang et.al|[paper](https://arxiv.org/abs/2509.13396)|-|<details><summary>detail</summary>12 page Journal paper</details>|
|**2025-9-16**|**Modeling the Multivariate Relationship with Contextualized Representations for Effective Human-Object Interaction Detection**|Zhehao Li et.al|[paper](https://arxiv.org/abs/2509.12784)|-|-|
|**2025-9-15**|**SFGNet: Semantic and Frequency Guided Network for Camouflaged Object Detection**|Dezhen Wang et.al|[paper](https://arxiv.org/abs/2509.11539)|[code](https://github.com/winter794444/SFGNetICASSP2026.)|<details><summary>detail</summary>Submitted to ICASSP 2026 by Dezhen Wang et al</details>|
|**2025-9-15**|**Explicit Multimodal Graph Modeling for Human-Object Interaction Detection**|Wenxuan Ji et.al|[paper](https://arxiv.org/abs/2509.12554)|-|-|
|**2025-9-15**|**SAM-TTT: Segment Anything Model via Reverse Parameter Configuration and Test-Time Training for Camouflaged Object Detection**|Zhenni Yu et.al|[paper](https://arxiv.org/abs/2509.11884)|[code](https://github.com/guobaoxiao/SAM-TTT.)|<details><summary>detail</summary>accepted by ACM MM 25</details>|
|**2025-9-15**|**HD-OOD3D: Supervised and Unsupervised Out-of-Distribution object detection in LiDAR data**|Louis Soum-Fontez et.al|[paper](https://arxiv.org/abs/2410.23767)|-|<details><summary>detail</summary>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</details>|
|**2025-9-15**|**Similarity-based Outlier Detection for Noisy Object Re-Identification Using Beta Mixtures**|Waqar Ahmad et.al|[paper](https://arxiv.org/abs/2509.08926)|-|-|
|**2025-9-15**|**First RAG, Second SEG: A Training-Free Paradigm for Camouflaged Object Detection**|Wutao Liu et.al|[paper](https://arxiv.org/abs/2508.15313)|[code](https://github.com/Lwt-diamond/RAG-SEG.)|-|
|**2025-9-15**|**IRDFusion: Iterative Relation-Map Difference guided Feature Fusion for Multispectral Object Detection**|Jifeng Shen et.al|[paper](https://arxiv.org/abs/2509.09085)|[code](https://github.com/61s61min/IRDFusion.git.)|-|
|**2025-9-14**|**DAOcc: 3D Object Detection Assisted Multi-Sensor Fusion for 3D Occupancy Prediction**|Zhen Yang et.al|[paper](https://arxiv.org/abs/2409.19972)|[code](https://github.com/AlphaPlusTT/DAOcc.)|<details><summary>detail</summary>TCSVT Accepted version (not the final published version)</details>|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-9-18**|**Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|
|**2025-9-18**|**SWAT: Sliding Window Adversarial Training for Gradual Domain Adaptation**|Zixi Wang et.al|[paper](https://arxiv.org/abs/2501.19155)|-|<details><summary>detail</summary>submitted to NIPS 2025</details>|
|**2025-9-18**|**Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation**|Estelle Chigot et.al|[paper](https://arxiv.org/abs/2505.16360)|[code](https://github.com/echigot/cactif.)|<details><summary>detail</summary>Published in Computer Vision and Image Understanding</details>|
|**2025-9-18**|**ReservoirTTA: Prolonged Test-time Adaptation for Evolving and Recurring Domains**|Guillaume Vray et.al|[paper](https://arxiv.org/abs/2505.14511)|[code](https://github.com/LTS5/ReservoirTTA.)|-|
|**2025-9-17**|**Domain Adaptation for Ulcerative Colitis Severity Estimation Using Patient-Level Diagnoses**|Takamasa Yamaguchi et.al|[paper](https://arxiv.org/abs/2509.14573)|-|<details><summary>detail</summary>MICCAI workshop 2025 (International conference on machine learning in medical imaging)</details>|
|**2025-9-17**|**3DS: Medical Domain Adaptation of LLMs via Decomposed Difficulty-based Data Selection**|Hongxin Ding et.al|[paper](https://arxiv.org/abs/2410.10901)|[code](https://github.com/PuppyKnightUniversity/3DS.)|<details><summary>detail</summary>EMNLP 2025 (Main Conference)</details>|
|**2025-9-17**|**BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection**|Rongyu Zhang et.al|[paper](https://arxiv.org/abs/2509.14151)|-|<details><summary>detail</summary>Accepted by IEEE TCSVT</details>|
|**2025-9-17**|**Towards Unified and Adaptive Cross-Domain Collaborative Filtering via Graph Signal Processing**|Jeongeun Lee et.al|[paper](https://arxiv.org/abs/2407.12374)|-|-|
|**2025-9-17**|**Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation**|Inder Pal Singh et.al|[paper](https://arxiv.org/abs/2509.13792)|-|-|
|**2025-9-16**|**Improving Anomalous Sound Detection with Attribute-aware Representation from Domain-adaptive Pre-training**|Xin Fang et.al|[paper](https://arxiv.org/abs/2509.12845)|-|-|
|**2025-9-15**|**Domain-Adaptive Pretraining Improves Primate Behavior Recognition**|Felix B. Mueller et.al|[paper](https://arxiv.org/abs/2509.12193)|[code](https://github.com/ecker-lab/dap-behavior)|<details><summary>detail</summary>Oral at the CVPR 2025 Workshop CV4Animals</details>|
|**2025-9-15**|**FedDAF: Federated Domain Adaptation Using Model Functional Distance**|Mrinmay Sen et.al|[paper](https://arxiv.org/abs/2509.11819)|-|-|
|**2025-9-14**|**Cross-Domain Attribute Alignment with CLIP: A Rehearsal-Free Approach for Class-Incremental Unsupervised Domain Adaptation**|Kerun Mi et.al|[paper](https://arxiv.org/abs/2509.11264)|[code](https://github.com/RyunMi/VisTA.)|<details><summary>detail</summary>ACM MM 2025</details>|
|**2025-9-14**|**Domain Adaptive SAR Wake Detection: Leveraging Similarity Filtering and Memory Guidance**|He Gao et.al|[paper](https://arxiv.org/abs/2509.12279)|-|-|
|**2025-9-12**|**Automated MCQA Benchmarking at Scale: Evaluating Reasoning Traces as Retrieval Sources for Domain Adaptation of Small Language Models**|Ozan Gokdemir et.al|[paper](https://arxiv.org/abs/2509.10744)|-|<details><summary>detail</summary>This manuscript has been accepted for publication at the Supercomputing 25 (SC '25) Conference (Frontiers in Generative AI for HPC Science and Engineering: Foundations</details>|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-9-18**|**Diffusion-Based Action Recognition Generalizes to Untrained Domains**|Rogerio Guimaraes et.al|[paper](https://arxiv.org/abs/2509.08908)|[code](https://www.vision.caltech.edu/actiondiff/)|-|
|**2025-9-18**|**Trade-offs in Cross-Domain Generalization of Foundation Model Fine-Tuned for Biometric Applications**|Tahar Chettaoui et.al|[paper](https://arxiv.org/abs/2509.14921)|-|<details><summary>detail</summary>the IEEE International Joint Conference on Biometrics 2025 (IJCB 2025)</details>|
|**2025-9-18**|**Domain Generalization for In-Orbit 6D Pose Estimation**|Antoine Legrand et.al|[paper](https://arxiv.org/abs/2406.11743)|-|-|
|**2025-9-17**|**SNaRe: Domain-aware Data Generation for Low-Resource Event Detection**|Tanmay Parekh et.al|[paper](https://arxiv.org/abs/2502.17394)|-|<details><summary>detail</summary>EMNLP 2025 Main</details>|
|**2025-9-17**|**Class-invariant Test-Time Augmentation for Domain Generalization**|Zhicheng Lin et.al|[paper](https://arxiv.org/abs/2509.14420)|-|-|
|**2025-9-17**|**CodeLSI: Leveraging Foundation Models for Automated Code Generation with Low-Rank Optimization and Domain-Specific Instruction Tuning**|Huy Le et.al|[paper](https://arxiv.org/abs/2509.14373)|-|-|
|**2025-9-17**|**SPAR: Scalable LLM-based PDDL Domain Generation for Aerial Robotics**|Songhao Huang et.al|[paper](https://arxiv.org/abs/2509.13691)|-|-|
|**2025-9-16**|**Double Helix Diffusion for Cross-Domain Anomaly Image Generation**|Linchun Wu et.al|[paper](https://arxiv.org/abs/2509.12787)|-|-|
|**2025-9-15**|**Speak-to-Structure: Evaluating LLMs in Open-domain Natural Language-Driven Molecule Generation**|Jiatong Li et.al|[paper](https://arxiv.org/abs/2412.14642)|[code](https://github.com/phenixace/TOMG-Bench)|<details><summary>detail</summary>Our codes and datasets are available through https://github</details>|
|**2025-9-15**|**DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models**|Jiachen Fu et.al|[paper](https://arxiv.org/abs/2509.14268)|[code](https://fjc2005.github.io/detectanyllm)|-|
|**2025-9-14**|**AI-Generated Content in Cross-Domain Applications: Research Trends, Challenges and Propositions**|Jianxin Li et.al|[paper](https://arxiv.org/abs/2509.11151)|-|-|
|**2025-9-13**|**Local Density-Based Anomaly Score Normalization for Domain Generalization**|Kevin Wilkinghoff et.al|[paper](https://arxiv.org/abs/2509.10951)|-|-|
|**2025-9-12**|**When and How Does CLIP Enable Domain and Compositional Generalization?**|Elias Kempf et.al|[paper](https://arxiv.org/abs/2502.09507)|-|<details><summary>detail</summary>ICML 2025 (Spotlight)</details>|
|**2025-9-12**|**GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method**|Hailong Yang et.al|[paper](https://arxiv.org/abs/2509.10018)|-|-|
|**2025-9-9**|**GTA-Crime: A Synthetic Dataset and Generation Framework for Fatal Violence Detection with Adversarial Snippet-Level Domain Adaptation**|Seongho Kim et.al|[paper](https://arxiv.org/abs/2509.08232)|[code](https://github.com/ta-ho/GTA-Crime.)|-|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-9-18**|**Calibration-Aware Prompt Learning for Medical Vision-Language Models**|Abhishek Basu et.al|[paper](https://arxiv.org/abs/2509.15226)|[code](https://github.com/iabh1shekbasu/CalibPrompt.)|<details><summary>detail</summary>Accepted in BMVC 2025</details>|
|**2025-9-18**|**Manipulation Facing Threats: Evaluating Physical Vulnerabilities in End-to-End Vision Language Action Models**|Hao Cheng et.al|[paper](https://arxiv.org/abs/2409.13174)|-|-|
|**2025-9-18**|**ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning**|Chi-Pin Huang et.al|[paper](https://arxiv.org/abs/2507.16815)|[code](https://jasper0314-huang.github.io/thinkact-vla/)|<details><summary>detail</summary>NeurIPS 2025</details>|
|**2025-9-18**|**Forecasting and Visualizing Air Quality from Sky Images with Vision-Language Models**|Mohammad Saleh Vahdatpour et.al|[paper](https://arxiv.org/abs/2509.15076)|-|<details><summary>detail</summary>Published at ICCVW 2025</details>|
|**2025-9-18**|**EchoVLM: Dynamic Mixture-of-Experts Vision-Language Model for Universal Ultrasound Intelligence**|Chaoyin She et.al|[paper](https://arxiv.org/abs/2509.14977)|[code](https://github.com/Asunatan/EchoVLM.)|-|
|**2025-9-18**|**T-araVLN: Translator for Agricultural Robotic Agents on Vision-and-Language Navigation**|Xiaobei Zhao et.al|[paper](https://arxiv.org/abs/2509.06644)|[code](https://github.com/AlexTraveling/T-araVLN.)|-|
|**2025-9-18**|**CollabVLA: Self-Reflective Vision-Language-Action Model Dreaming Together with Human**|Nan Sun et.al|[paper](https://arxiv.org/abs/2509.14889)|-|-|
|**2025-9-18**|**V-SEAM: Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models**|Qidong Wang et.al|[paper](https://arxiv.org/abs/2509.14837)|[code](https://github.com/petergit1/V-SEAM.)|<details><summary>detail</summary>EMNLP 2025 Main</details>|
|**2025-9-18**|**Frame Sampling Strategies Matter: A Benchmark for small vision language models**|Marija Brkic et.al|[paper](https://arxiv.org/abs/2509.14769)|-|-|
|**2025-9-18**|**UnifiedVisual: A Framework for Constructing Unified Vision-Language Datasets**|Pengyu Wang et.al|[paper](https://arxiv.org/abs/2509.14738)|[code](https://github.com/fnlp-vision/UnifiedVisual.)|<details><summary>detail</summary>Accepted by Findings of EMNLP2025</details>|
|**2025-9-18**|**PVLM: Parsing-Aware Vision Language Model with Dynamic Contrastive Learning for Zero-Shot Deepfake Attribution**|Yaning Zhang et.al|[paper](https://arxiv.org/abs/2504.14129)|-|-|
|**2025-9-18**|**RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI**|Cong Tai et.al|[paper](https://arxiv.org/abs/2509.14687)|[code](https://terminators2025.github.io/RealMirror.github.io)|-|
|**2025-9-18**|**Toward Embodiment Equivariant Vision-Language-Action Policy**|Anzhe Chen et.al|[paper](https://arxiv.org/abs/2509.14630)|[code](https://github.com/hhcaz/e2vla)|-|
|**2025-9-17**|**Do Vision-Language Models See Urban Scenes as People Do? An Urban Perception Benchmark**|Rashid Mushkani et.al|[paper](https://arxiv.org/abs/2509.14574)|-|-|
|**2025-9-17**|**VisMoDAl: Visual Analytics for Evaluating and Improving Corruption Robustness of Vision-Language Models**|Huanchen Wang et.al|[paper](https://arxiv.org/abs/2509.14571)|-|-|

