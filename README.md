## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2025.09.22

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-9-18**|**Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2501.02184)|-|-|
|**2025-9-18**|**Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|
|**2025-9-13**|**Step-wise Distribution Alignment Guided Style Prompt Tuning for Source-free Cross-domain Few-shot Learning**|Huali Xu et.al|[paper](https://arxiv.org/abs/2411.10070)|[code](https://github.com/xuhuali-mxj/StepSPT.)|<details><summary>detail</summary>IEEE TPAMI</details>|
|**2025-9-12**|**Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment**|Rini Smita Thakur et.al|[paper](https://arxiv.org/abs/2509.10134)|[code](https://visdomlab.github.io/GCL/.)|<details><summary>detail</summary>Accepted in BMVC 2025</details>|
|**2025-9-10**|**Rethinking the Backbone in Class Imbalanced Federated Source Free Domain Adaptation: The Utility of Vision Foundation Models**|Kosuke Kihara et.al|[paper](https://arxiv.org/abs/2509.08372)|-|<details><summary>detail</summary>Accepted by the IEEE ICIP 2025 Satellite Workshop 1: Edge Intelligence: Smart</details>|
|**2025-9-2**|**StableSleep: Source-Free Test-Time Adaptation for Sleep Staging with Lightweight Safety Rails**|Hritik Arasu et.al|[paper](https://arxiv.org/abs/2509.02982)|-|<details><summary>detail</summary>5 page paper</details>|
|**2025-8-28**|**Model-Free Hovering and Source Seeking via Extremum Seeking Control: Experimental Demonstration**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2508.20836)|-|-|
|**2025-8-26**|**VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection**|Jianhong Han et.al|[paper](https://arxiv.org/abs/2508.11167)|-|<details><summary>detail</summary>Manuscript submitted to IEEE TCSVT</details>|
|**2025-8-20**|**Towards Source-Free Machine Unlearning**|Sk Miraj Ahmed et.al|[paper](https://arxiv.org/abs/2508.15127)|-|<details><summary>detail</summary>Accepted by CVPR 2025</details>|
|**2025-8-14**|**Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2508.09202)|-|-|
|**2025-8-7**|**Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation**|Jianming Liu et.al|[paper](https://arxiv.org/abs/2508.05213)|[code](https://github.com/ljm198134/TVGTANet.)|-|
|**2025-8-4**|**Model Recycling Framework for Multi-Source Data-Free Supervised Transfer Learning**|Sijia Wang et.al|[paper](https://arxiv.org/abs/2508.02039)|-|-|
|**2025-7-28**|**Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation**|Yihong Cao et.al|[paper](https://arxiv.org/abs/2506.21198)|[code](https://github.com/yihong-97/UNLOCK.)|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-7-26**|**GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning**|Sanqing Qu et.al|[paper](https://arxiv.org/abs/2403.14410)|[code](https://github.com/ispc-lab/GLC-plus.)|<details><summary>detail</summary>A substantial extension of the CVPR paper "Upcycling Models under Domain and Category Shift"</details>|
|**2025-7-23**|**SFUOD: Source-Free Unknown Object Detection**|Keon-Hee Park et.al|[paper](https://arxiv.org/abs/2507.17373)|-|<details><summary>detail</summary>This paper has been accepted by ICCV 2025</details>|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-9-19**|**Efficient Detection of Objects Near a Robot Manipulator via Miniature Time-of-Flight Sensors**|Carter Sifferman et.al|[paper](https://arxiv.org/abs/2509.16122)|-|-|
|**2025-9-19**|**LED: LLM Enhanced Open-Vocabulary Object Detection without Human Curated Data Generation**|Yang Zhou et.al|[paper](https://arxiv.org/abs/2503.13794)|-|-|
|**2025-9-19**|**A re-calibration method for object detection with multi-modal alignment bias in autonomous driving**|Zhihang Song et.al|[paper](https://arxiv.org/abs/2405.16848)|-|<details><summary>detail</summary>Accepted for publication in IST 2025</details>|
|**2025-9-19**|**The Missing Piece: A Case for Pre-Training in 3D Medical Object Detection**|Katharina Eckstein et.al|[paper](https://arxiv.org/abs/2509.15947)|[code](https://github.com/MIC-DKFZ/nnDetection-finetuning.)|<details><summary>detail</summary>MICCAI 2025</details>|
|**2025-9-19**|**PAN: Pillars-Attention-Based Network for 3D Object Detection**|Ruan Bispo et.al|[paper](https://arxiv.org/abs/2509.15935)|-|-|
|**2025-9-19**|**MCOD: The First Challenging Benchmark for Multispectral Camouflaged Object Detection**|Yang Li et.al|[paper](https://arxiv.org/abs/2509.15753)|[code](https://github.com/yl2900260-bit/MCOD.)|-|
|**2025-9-19**|**Towards Size-invariant Salient Object Detection: A Generic Evaluation and Optimization Approach**|Shilong Bao et.al|[paper](https://arxiv.org/abs/2509.15573)|[code](https://github.com/Ferry-Li/SI-SOD.)|-|
|**2025-9-18**|**DAOcc: 3D Object Detection Assisted Multi-Sensor Fusion for 3D Occupancy Prediction**|Zhen Yang et.al|[paper](https://arxiv.org/abs/2409.19972)|[code](https://github.com/AlphaPlusTT/DAOcc.)|<details><summary>detail</summary>TCSVT Accepted version (not the final published version)</details>|
|**2025-9-18**|**Synthetic-to-Real Object Detection using YOLOv11 and Domain Randomization Strategies**|Luisa Torquato Ni√±o et.al|[paper](https://arxiv.org/abs/2509.15045)|-|-|
|**2025-9-18**|**GiAnt: A Bio-Inspired Hexapod for Adaptive Terrain Navigation and Object Detection**|Aasfee Mosharraf Bhuiyan et.al|[paper](https://arxiv.org/abs/2509.15264)|-|-|
|**2025-9-18**|**Data Augmentation via Latent Diffusion Models for Detecting Smell-Related Objects in Historical Artworks**|Ahmed Sheta et.al|[paper](https://arxiv.org/abs/2509.14755)|-|<details><summary>detail</summary>Appeared at the 4th International Workshop on Fine Art Pattern Extraction and Recognition (FAPER 2025)</details>|
|**2025-9-18**|**Deep Learning-Driven Multimodal Detection and Movement Analysis of Objects in Culinary**|Tahoshin Alam Ishat et.al|[paper](https://arxiv.org/abs/2509.00033)|-|-|
|**2025-9-17**|**BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection**|Rongyu Zhang et.al|[paper](https://arxiv.org/abs/2509.14151)|-|<details><summary>detail</summary>Accepted by IEEE TCSVT</details>|
|**2025-9-17**|**A Novel Compression Framework for YOLOv8: Achieving Real-Time Aerial Object Detection on Edge Devices via Structured Pruning and Channel-Wise Distillation**|Melika Sabaghian et.al|[paper](https://arxiv.org/abs/2509.12918)|-|-|
|**2025-9-16**|**Real-Time Detection and Tracking of Foreign Object Intrusions in Power Systems via Feature-Based Edge Intelligence**|Xinan Wang et.al|[paper](https://arxiv.org/abs/2509.13396)|-|<details><summary>detail</summary>12 page Journal paper</details>|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-9-19**|**AdaSports-Traj: Role- and Domain-Aware Adaptation for Multi-Agent Trajectory Modeling in Sports**|Yi Xu et.al|[paper](https://arxiv.org/abs/2509.16095)|-|<details><summary>detail</summary>Accepted by ICDM 2025</details>|
|**2025-9-19**|**SONAR: Self-Distilled Continual Pre-training for Domain Adaptive Audio Representation**|Yizhou Zhang et.al|[paper](https://arxiv.org/abs/2509.15703)|-|<details><summary>detail</summary>Submitted to ICASSP 2026</details>|
|**2025-9-19**|**Improving Anomalous Sound Detection with Attribute-aware Representation from Domain-adaptive Pre-training**|Xin Fang et.al|[paper](https://arxiv.org/abs/2509.12845)|-|<details><summary>detail</summary>Copyright 2026 IEEE</details>|
|**2025-9-18**|**Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation**|Silvio Mazzucco et.al|[paper](https://arxiv.org/abs/2509.15225)|[code](https://thegoodailab.org/blog/vocalign)|<details><summary>detail</summary>BMVC 2025 - Project Page: https://thegoodailab</details>|
|**2025-9-18**|**SWAT: Sliding Window Adversarial Training for Gradual Domain Adaptation**|Zixi Wang et.al|[paper](https://arxiv.org/abs/2501.19155)|-|<details><summary>detail</summary>submitted to NIPS 2025</details>|
|**2025-9-18**|**Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation**|Estelle Chigot et.al|[paper](https://arxiv.org/abs/2505.16360)|[code](https://github.com/echigot/cactif.)|<details><summary>detail</summary>Published in Computer Vision and Image Understanding</details>|
|**2025-9-18**|**ReservoirTTA: Prolonged Test-time Adaptation for Evolving and Recurring Domains**|Guillaume Vray et.al|[paper](https://arxiv.org/abs/2505.14511)|[code](https://github.com/LTS5/ReservoirTTA.)|-|
|**2025-9-17**|**Domain Adaptation for Ulcerative Colitis Severity Estimation Using Patient-Level Diagnoses**|Takamasa Yamaguchi et.al|[paper](https://arxiv.org/abs/2509.14573)|-|<details><summary>detail</summary>MICCAI workshop 2025 (International conference on machine learning in medical imaging)</details>|
|**2025-9-17**|**3DS: Medical Domain Adaptation of LLMs via Decomposed Difficulty-based Data Selection**|Hongxin Ding et.al|[paper](https://arxiv.org/abs/2410.10901)|[code](https://github.com/PuppyKnightUniversity/3DS.)|<details><summary>detail</summary>EMNLP 2025 (Main Conference)</details>|
|**2025-9-17**|**BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection**|Rongyu Zhang et.al|[paper](https://arxiv.org/abs/2509.14151)|-|<details><summary>detail</summary>Accepted by IEEE TCSVT</details>|
|**2025-9-17**|**Towards Unified and Adaptive Cross-Domain Collaborative Filtering via Graph Signal Processing**|Jeongeun Lee et.al|[paper](https://arxiv.org/abs/2407.12374)|-|-|
|**2025-9-17**|**Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation**|Inder Pal Singh et.al|[paper](https://arxiv.org/abs/2509.13792)|-|-|
|**2025-9-15**|**Domain-Adaptive Pretraining Improves Primate Behavior Recognition**|Felix B. Mueller et.al|[paper](https://arxiv.org/abs/2509.12193)|[code](https://github.com/ecker-lab/dap-behavior)|<details><summary>detail</summary>Oral at the CVPR 2025 Workshop CV4Animals</details>|
|**2025-9-15**|**FedDAF: Federated Domain Adaptation Using Model Functional Distance**|Mrinmay Sen et.al|[paper](https://arxiv.org/abs/2509.11819)|-|-|
|**2025-9-14**|**Cross-Domain Attribute Alignment with CLIP: A Rehearsal-Free Approach for Class-Incremental Unsupervised Domain Adaptation**|Kerun Mi et.al|[paper](https://arxiv.org/abs/2509.11264)|[code](https://github.com/RyunMi/VisTA.)|<details><summary>detail</summary>ACM MM 2025</details>|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-9-19**|**Minimal Semantic Sufficiency Meets Unsupervised Domain Generalization**|Tan Pan et.al|[paper](https://arxiv.org/abs/2509.15791)|-|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|
|**2025-9-18**|**CoDoL: Conditional Domain Prompt Learning for Out-of-Distribution Generalization**|Min Zhang et.al|[paper](https://arxiv.org/abs/2509.15330)|-|-|
|**2025-9-18**|**Diffusion-Based Action Recognition Generalizes to Untrained Domains**|Rogerio Guimaraes et.al|[paper](https://arxiv.org/abs/2509.08908)|[code](https://www.vision.caltech.edu/actiondiff/)|-|
|**2025-9-18**|**Trade-offs in Cross-Domain Generalization of Foundation Model Fine-Tuned for Biometric Applications**|Tahar Chettaoui et.al|[paper](https://arxiv.org/abs/2509.14921)|-|<details><summary>detail</summary>the IEEE International Joint Conference on Biometrics 2025 (IJCB 2025)</details>|
|**2025-9-18**|**Domain Generalization for In-Orbit 6D Pose Estimation**|Antoine Legrand et.al|[paper](https://arxiv.org/abs/2406.11743)|-|-|
|**2025-9-17**|**SNaRe: Domain-aware Data Generation for Low-Resource Event Detection**|Tanmay Parekh et.al|[paper](https://arxiv.org/abs/2502.17394)|-|<details><summary>detail</summary>EMNLP 2025 Main</details>|
|**2025-9-17**|**Class-invariant Test-Time Augmentation for Domain Generalization**|Zhicheng Lin et.al|[paper](https://arxiv.org/abs/2509.14420)|-|-|
|**2025-9-17**|**CodeLSI: Leveraging Foundation Models for Automated Code Generation with Low-Rank Optimization and Domain-Specific Instruction Tuning**|Huy Le et.al|[paper](https://arxiv.org/abs/2509.14373)|-|-|
|**2025-9-17**|**SPAR: Scalable LLM-based PDDL Domain Generation for Aerial Robotics**|Songhao Huang et.al|[paper](https://arxiv.org/abs/2509.13691)|-|-|
|**2025-9-16**|**Double Helix Diffusion for Cross-Domain Anomaly Image Generation**|Linchun Wu et.al|[paper](https://arxiv.org/abs/2509.12787)|-|-|
|**2025-9-15**|**Speak-to-Structure: Evaluating LLMs in Open-domain Natural Language-Driven Molecule Generation**|Jiatong Li et.al|[paper](https://arxiv.org/abs/2412.14642)|[code](https://github.com/phenixace/TOMG-Bench)|<details><summary>detail</summary>Our codes and datasets are available through https://github</details>|
|**2025-9-15**|**DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models**|Jiachen Fu et.al|[paper](https://arxiv.org/abs/2509.14268)|[code](https://fjc2005.github.io/detectanyllm)|-|
|**2025-9-14**|**AI-Generated Content in Cross-Domain Applications: Research Trends, Challenges and Propositions**|Jianxin Li et.al|[paper](https://arxiv.org/abs/2509.11151)|-|-|
|**2025-9-13**|**Local Density-Based Anomaly Score Normalization for Domain Generalization**|Kevin Wilkinghoff et.al|[paper](https://arxiv.org/abs/2509.10951)|-|-|
|**2025-9-12**|**When and How Does CLIP Enable Domain and Compositional Generalization?**|Elias Kempf et.al|[paper](https://arxiv.org/abs/2502.09507)|-|<details><summary>detail</summary>ICML 2025 (Spotlight)</details>|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-9-19**|**Cache-of-Thought: Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning**|Mingyuan Wu et.al|[paper](https://arxiv.org/abs/2502.20587)|[code](https://github.com/UIUC-MONET/Cache-of-Thoughts)|<details><summary>detail</summary>EMNLP 2025 Main Conference</details>|
|**2025-9-19**|**Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks**|Het Patel et.al|[paper](https://arxiv.org/abs/2509.16163)|-|<details><summary>detail</summary>To be presented as a poster at the Workshop on Safe and Trustworthy Multimodal AI Systems (SafeMM-AI)</details>|
|**2025-9-19**|**Towards deployment-centric multimodal AI beyond vision and language**|Xianyuan Liu et.al|[paper](https://arxiv.org/abs/2504.03603)|-|-|
|**2025-9-19**|**Randomized Smoothing Meets Vision-Language Models**|Emmanouil Seferis et.al|[paper](https://arxiv.org/abs/2509.16088)|-|<details><summary>detail</summary>EMNLP'25 full version</details>|
|**2025-9-19**|**I-FailSense: Towards General Robotic Failure Detection with Vision-Language Models**|Clemence Grislain et.al|[paper](https://arxiv.org/abs/2509.16072)|[code](https://clemgris.github.io/I-FailSense/).)|-|
|**2025-9-19**|**Understanding AI Evaluation Patterns: How Different GPT Models Assess Vision-Language Descriptions**|Sajjad Abdoli et.al|[paper](https://arxiv.org/abs/2509.10707)|-|-|
|**2025-9-19**|**Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study**|DongGeon Lee et.al|[paper](https://arxiv.org/abs/2505.15389)|[code](https://github.com/oneonlee/Meme-Safety-Bench.)|<details><summary>detail</summary>EMNLP 2025</details>|
|**2025-9-19**|**CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation**|Marc Lafon et.al|[paper](https://arxiv.org/abs/2507.14312)|-|<details><summary>detail</summary>Journal ref:39th Conference on Neural Information Processing Systems</details>|
|**2025-9-19**|**A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning**|Shaopeng Zhai et.al|[paper](https://arxiv.org/abs/2509.15937)|-|-|
|**2025-9-19**|**ViLU: Learning Vision-Language Uncertainties for Failure Prediction**|Marc Lafon et.al|[paper](https://arxiv.org/abs/2507.07620)|[code](https://github.com/ykrmm/ViLU.)|<details><summary>detail</summary>Journal ref:International Conference on Computer Vision</details>|
|**2025-9-19**|**Vision-Language Models as Differentiable Semantic and Spatial Rewards for Text-to-3D Generation**|Weimin Bai et.al|[paper](https://arxiv.org/abs/2509.15772)|-|-|
|**2025-9-19**|**Quality-Driven Curation of Remote Sensing Vision-Language Data via Learned Scoring Models**|Dilxat Muhtar et.al|[paper](https://arxiv.org/abs/2503.00743)|-|-|
|**2025-9-19**|**Training-Free Pyramid Token Pruning for Efficient Large Vision-Language Models via Region, Token, and Instruction-Guided Importance**|Yuxuan Liang et.al|[paper](https://arxiv.org/abs/2509.15704)|-|-|
|**2025-9-19**|**ORIC: Benchmarking Object Recognition in Incongruous Context for Large Vision-Language Models**|Zhaoyang Li et.al|[paper](https://arxiv.org/abs/2509.15695)|-|-|
|**2025-9-19**|**VLA-Mark: A cross modal watermark for large vision-language alignment model**|Shuliang Liu et.al|[paper](https://arxiv.org/abs/2507.14067)|-|<details><summary>detail</summary>Accepted by the main conference</details>|

