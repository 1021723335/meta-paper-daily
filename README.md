## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2024.08.26

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2024-8-22**|**Rank and Align: Towards Effective Source-free Graph Domain Adaptation**|Junyu Luo et.al|[paper](https://arxiv.org/abs/2408.12185)|-|<details><summary>detail</summary>Published in IJCAI2024</details>|
|**2024-8-21**|**Source-Free Domain Adaptation Guided by Vision and Vision-Language Pre-Training**|Wenyu Zhang et.al|[paper](https://arxiv.org/abs/2405.02954)|-|<details><summary>detail</summary>Extension of ICCV paper arXiv:2212</details>|
|**2024-8-18**|**Source-Free Test-Time Adaptation For Online Surface-Defect Detection**|Yiran Song et.al|[paper](https://arxiv.org/abs/2408.09494)|-|<details><summary>detail</summary>ICPR 2024</details>|
|**2024-8-14**|**Evidential Graph Contrastive Alignment for Source-Free Blending-Target Domain Adaptation**|Juepeng Zheng et.al|[paper](https://arxiv.org/abs/2408.07527)|-|-|
|**2024-8-6**|**Source-Free Domain-Invariant Performance Prediction**|Ekaterina Khramtsova et.al|[paper](https://arxiv.org/abs/2408.02209)|-|<details><summary>detail</summary>Accepted in ECCV 2024</details>|
|**2024-7-26**|**Learn from the Learnt: Source-Free Active Domain Adaptation via Contrastive Sampling and Visual Persistence**|Mengyao Lyu et.al|[paper](https://arxiv.org/abs/2407.18899)|[code](https://github.com/lyumengyao/lftl.)|<details><summary>detail</summary>ECCV 2024</details>|
|**2024-7-23**|**Dynamic Retraining-Updating Mean Teacher for Source-Free Object Detection**|Trinh Le Ba Khanh et.al|[paper](https://arxiv.org/abs/2407.16497)|[code](https://github.com/lbktrinh/DRU)|<details><summary>detail</summary>ECCV 2024</details>|
|**2024-7-22**|**Harmonizing Flows: Leveraging normalizing flows for unsupervised and source-free MRI harmonization**|Farzad Beizaee et.al|[paper](https://arxiv.org/abs/2407.15717)|[code](https://github.com/farzad-bz/Harmonizing-Flows)|-|
|**2024-7-19**|**A Curriculum-style Self-training Approach for Source-Free Semantic Segmentation**|Yuxi Wang et.al|[paper](https://arxiv.org/abs/2106.11653)|[code](https://github.com/yxiwang/ATP)|<details><summary>detail</summary>This paper is accepted by TPAMI2024</details>|
|**2024-7-19**|**Memory-Efficient Pseudo-Labeling for Online Source-Free Universal Domain Adaptation using a Gaussian Mixture Model**|Pascal Schlachter et.al|[paper](https://arxiv.org/abs/2407.14208)|[code](https://github.com/pascalschlachter/GMM.)|<details><summary>detail</summary>Submitted at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2025</details>|
|**2024-7-18**|**Enhancing Source-Free Domain Adaptive Object Detection with Low-confidence Pseudo Label Distillation**|Ilhoon Yoon et.al|[paper](https://arxiv.org/abs/2407.13524)|[code](https://github.com/junia3/LPLD.)|<details><summary>detail</summary>ECCV 2024</details>|
|**2024-7-14**|**DPStyler: Dynamic PromptStyler for Source-Free Domain Generalization**|Yunlong Tang et.al|[paper](https://arxiv.org/abs/2403.16697)|-|<details><summary>detail</summary>Accepted by IEEE TMM</details>|
|**2024-7-12**|**FastImpute: A Baseline for Open-source, Reference-Free Genotype Imputation Methods -- A Case Study in PRS313**|Aaron Ge et.al|[paper](https://arxiv.org/abs/2407.09355)|[code](https://aaronge-2020.github.io/DeepImpute/)|-|
|**2024-7-10**|**Simplifying Source-Free Domain Adaptation for Object Detection: Effective Self-Training Strategies and Performance Insights**|Yan Hao et.al|[paper](https://arxiv.org/abs/2407.07586)|[code](https://github.com/EPFL-IMOS/simple-SFOD.)|<details><summary>detail</summary>ECCV 2024</details>|
|**2024-7-5**|**A Reference-free Metric for Language-Queried Audio Source Separation using Contrastive Language-Audio Pretraining**|Feiyang Xiao et.al|[paper](https://arxiv.org/abs/2407.04936)|-|<details><summary>detail</summary>Submitted to DCASE 2024 Workshop</details>|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2024-8-23**|**DeTPP: Leveraging Object Detection for Robust Long-Horizon Event Prediction**|Ivan Karpukhin et.al|[paper](https://arxiv.org/abs/2408.13131)|-|-|
|**2024-8-23**|**BoostTrack++: using tracklet information to detect more objects in multiple object tracking**|Vukašin Stanojević et.al|[paper](https://arxiv.org/abs/2408.13003)|[code](https://github.com/vukasin-stanojevic/BoostTrack)|-|
|**2024-8-22**|**CatFree3D: Category-agnostic 3D Object Detection with Diffusion**|Wenjing Bian et.al|[paper](https://arxiv.org/abs/2408.12747)|[code](https://bianwenjing.github.io/CatFree3D)|<details><summary>detail</summary>Project page: https://bianwenjing</details>|
|**2024-8-22**|**Revisiting Cross-Domain Problem for LiDAR-based 3D Object Detection**|Ruixiao Zhang et.al|[paper](https://arxiv.org/abs/2408.12708)|-|<details><summary>detail</summary>Accepted by the ICONIP 2024</details>|
|**2024-8-22**|**StreamLTS: Query-based Temporal-Spatial LiDAR Fusion for Cooperative Object Detection**|Yunshuang Yuan et.al|[paper](https://arxiv.org/abs/2407.03825)|[code](https://github.com/YuanYunshuang/CoSense3D)|-|
|**2024-8-22**|**Class-balanced Open-set Semi-supervised Object Detection for Medical Images**|Zhanyun Lu et.al|[paper](https://arxiv.org/abs/2408.12355)|-|-|
|**2024-8-22**|**OVA-DETR: Open Vocabulary Aerial Object Detection Using Image-Text Alignment and Fusion**|Guoting Wei et.al|[paper](https://arxiv.org/abs/2408.12246)|[code](https://github.com/GT-Wei/OVA-DETR.)|-|
|**2024-8-21**|**CARLA Drone: Monocular 3D Object Detection from a Different Perspective**|Johannes Meier et.al|[paper](https://arxiv.org/abs/2408.11958)|-|-|
|**2024-8-21**|**Domain-invariant Progressive Knowledge Distillation for UAV-based Object Detection**|Liang Yao et.al|[paper](https://arxiv.org/abs/2408.11407)|-|-|
|**2024-8-20**|**S$^3$-MonoDETR: Supervised Shape&Scale-perceptive Deformable Transformer for Monocular 3D Object Detection**|Xuan He et.al|[paper](https://arxiv.org/abs/2309.00928)|[code](https://github.com/mikasa3lili/S3-MonoDETR.)|<details><summary>detail</summary>The source code will be made publicly available at https://github</details>|
|**2024-8-20**|**On the Potential of Open-Vocabulary Models for Object Detection in Unusual Street Scenes**|Sadia Ilyas et.al|[paper](https://arxiv.org/abs/2408.11221)|-|-|
|**2024-8-20**|**Domain Adaptation based Object Detection for Autonomous Driving in Foggy and Rainy Weather**|Jinlong Li et.al|[paper](https://arxiv.org/abs/2307.09676)|-|<details><summary>detail</summary>the final version</details>|
|**2024-8-20**|**Quantum Inverse Contextual Vision Transformers (Q-ICVT): A New Frontier in 3D Object Detection for AVs**|Sanjay Bhargav Dharavath et.al|[paper](https://arxiv.org/abs/2408.11207)|[code](https://github.com/sanjay-810/Qicvt)|<details><summary>detail</summary>The paper has been accepted as a short paper at CIKM '24</details>|
|**2024-8-20**|**Weakly Supervised 3D Object Detection via Multi-Level Visual Guidance**|Kuan-Chih Huang et.al|[paper](https://arxiv.org/abs/2312.07530)|[code](https://github.com/kuanchihhuang/VG-W3D.)|<details><summary>detail</summary>Accepted by ECCV'24</details>|
|**2024-8-20**|**A Closer Look at Data Augmentation Strategies for Finetuning-Based Low/Few-Shot Object Detection**|Vladislav Li et.al|[paper](https://arxiv.org/abs/2408.10940)|-|-|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2024-8-22**|**Cross-Domain Foundation Model Adaptation: Pioneering Computer Vision Models for Geophysical Data Analysis**|Zhixiang Guo et.al|[paper](https://arxiv.org/abs/2408.12396)|-|-|
|**2024-8-22**|**A Personalized Zero-Shot ECG Arrhythmia Monitoring System: From Sparse Representation Based Domain Adaption to Energy Efficient Abnormal Beat Detection for Practical ECG Surveillance**|Mehmet Yamaç et.al|[paper](https://arxiv.org/abs/2207.07089)|[code](https://github.com/MertDuman/Zero-Shot-ECG)|<details><summary>detail</summary>Software implementation: https://github</details>|
|**2024-8-22**|**Rank and Align: Towards Effective Source-free Graph Domain Adaptation**|Junyu Luo et.al|[paper](https://arxiv.org/abs/2408.12185)|-|<details><summary>detail</summary>Published in IJCAI2024</details>|
|**2024-8-22**|**Domain Adaptation for Offline Reinforcement Learning with Limited Samples**|Weiqin Chen et.al|[paper](https://arxiv.org/abs/2408.12136)|-|-|
|**2024-8-21**|**Source-Free Domain Adaptation Guided by Vision and Vision-Language Pre-Training**|Wenyu Zhang et.al|[paper](https://arxiv.org/abs/2405.02954)|-|<details><summary>detail</summary>Extension of ICCV paper arXiv:2212</details>|
|**2024-8-21**|**Lighter, Better, Faster Multi-Source Domain Adaptation with Gaussian Mixture Models and Optimal Transport**|Eduardo Fernandes Montesuma et.al|[paper](https://arxiv.org/abs/2404.10261)|[code](https://github.com/eddardd/gmm_msda)|-|
|**2024-8-20**|**Domain Adaptation based Object Detection for Autonomous Driving in Foggy and Rainy Weather**|Jinlong Li et.al|[paper](https://arxiv.org/abs/2307.09676)|-|<details><summary>detail</summary>the final version</details>|
|**2024-8-20**|**Unified Domain Adaptive Semantic Segmentation**|Zhe Zhang et.al|[paper](https://arxiv.org/abs/2311.13254)|[code](https://github.com/ZHE-SAPI/UDASS)|-|
|**2024-8-19**|**Collaborative Multi-source Domain Adaptation Through Optimal Transport**|Omar Ghannou et.al|[paper](https://arxiv.org/abs/2404.06599)|-|-|
|**2024-8-19**|**DomainForensics: Exposing Face Forgery across Domains via Bi-directional Adaptation**|Qingxuan Lv et.al|[paper](https://arxiv.org/abs/2312.10680)|-|<details><summary>detail</summary>TIFS 2024</details>|
|**2024-8-18**|**Adversarial Attacked Teacher for Unsupervised Domain Adaptive Object Detection**|Kaiwen Wang et.al|[paper](https://arxiv.org/abs/2408.09431)|-|-|
|**2024-8-17**|**SA-GDA: Spectral Augmentation for Graph Domain Adaptation**|Jinhui Pang et.al|[paper](https://arxiv.org/abs/2408.09189)|-|-|
|**2024-8-15**|**Get Your Embedding Space in Order: Domain-Adaptive Regression for Forest Monitoring**|Sizhuo Li et.al|[paper](https://arxiv.org/abs/2405.00514)|-|<details><summary>detail</summary>Updated with review comments</details>|
|**2024-8-14**|**Evidential Graph Contrastive Alignment for Source-Free Blending-Target Domain Adaptation**|Juepeng Zheng et.al|[paper](https://arxiv.org/abs/2408.07527)|-|-|
|**2024-8-14**|**MLoRA: Multi-Domain Low-Rank Adaptive Network for CTR Prediction**|Zhiming Yang et.al|[paper](https://arxiv.org/abs/2408.08913)|-|-|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2024-8-23**|**DOMAINEVAL: An Auto-Constructed Benchmark for Multi-Domain Code Generation**|Qiming Zhu et.al|[paper](https://arxiv.org/abs/2408.13204)|[code](https://domaineval.github.io/.)|-|
|**2024-8-22**|**Domain Generalization through Meta-Learning: A Survey**|Arsham Gholamzadeh Khoee et.al|[paper](https://arxiv.org/abs/2404.02785)|-|-|
|**2024-8-22**|**Mixstyle-Entropy: Domain Generalization with Causal Intervention and Perturbation**|Luyao Tang et.al|[paper](https://arxiv.org/abs/2408.03608)|-|<details><summary>detail</summary>Accepted by BMVC2024</details>|
|**2024-8-21**|**DGMamba: Domain Generalization via Generalized State Space Model**|Shaocong Long et.al|[paper](https://arxiv.org/abs/2404.07794)|[code](https://github.com/longshaocong/DGMamba.)|<details><summary>detail</summary>ACM MM 2024</details>|
|**2024-8-21**|**PermitQA: A Benchmark for Retrieval Augmented Generation in Wind Siting and Permitting domain**|Rounak Meyur et.al|[paper](https://arxiv.org/abs/2408.11800)|-|-|
|**2024-8-21**|**NuSegDG: Integration of Heterogeneous Space and Gaussian Kernel for Domain-Generalized Nuclei Segmentation**|Zhenye Lou et.al|[paper](https://arxiv.org/abs/2408.11787)|[code](https://github.com/xq141839/NuSegDG.)|<details><summary>detail</summary>Under Reivew</details>|
|**2024-8-19**|**LegalBench-RAG: A Benchmark for Retrieval-Augmented Generation in the Legal Domain**|Nicholas Pipitone et.al|[paper](https://arxiv.org/abs/2408.10343)|[code](https://github.com/zeroentropy-cc/legalbenchrag.)|-|
|**2024-8-19**|**Less but Better: Enabling Generalized Zero-shot Learning Towards Unseen Domains by Intrinsic Learning from Redundant LLM Semantics**|Jiaqi Yue et.al|[paper](https://arxiv.org/abs/2403.14362)|-|<details><summary>detail</summary>This work has been submitted to the IEEE for possible publication</details>|
|**2024-8-17**|**ESP-MedSAM: Efficient Self-Prompting SAM for Universal Domain-Generalized Medical Image Segmentation**|Qing Xu et.al|[paper](https://arxiv.org/abs/2407.14153)|[code](https://github.com/xq141839/ESP-MedSAM.)|<details><summary>detail</summary>Under Review</details>|
|**2024-8-17**|**StylePrompter: Enhancing Domain Generalization with Test-Time Style Priors**|Jiao Zhang et.al|[paper](https://arxiv.org/abs/2408.09138)|-|-|
|**2024-8-14**|**Model Attribution in LLM-Generated Disinformation: A Domain Generalization Approach with Supervised Contrastive Learning**|Alimohammad Beigi et.al|[paper](https://arxiv.org/abs/2407.21264)|-|-|
|**2024-8-11**|**Robust Domain Generalization for Multi-modal Object Recognition**|Yuxin Qiao et.al|[paper](https://arxiv.org/abs/2408.05831)|-|-|
|**2024-8-11**|**Moment&Cross: Next-Generation Real-Time Cross-Domain CTR Prediction for Live-Streaming Recommendation at Kuaishou**|Jiangxia Cao et.al|[paper](https://arxiv.org/abs/2408.05709)|-|<details><summary>detail</summary>Work in progress</details>|
|**2024-8-9**|**Generalizing Few Data to Unseen Domains Flexibly Based on Label Smoothing Integrated with Distributionally Robust Optimization**|Yangdi Wang et.al|[paper](https://arxiv.org/abs/2408.05082)|-|-|
|**2024-8-8**|**HiLo: A Learning Framework for Generalized Category Discovery Robust to Domain Shifts**|Hongjun Wang et.al|[paper](https://arxiv.org/abs/2408.04591)|-|-|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2024-8-23**|**Foundational Model for Electron Micrograph Analysis: Instruction-Tuning Small-Scale Language-and-Vision Assistant for Enterprise Adoption**|Sakhinana Sagar Srinivas et.al|[paper](https://arxiv.org/abs/2408.13248)|-|<details><summary>detail</summary>Our paper is published at ICML 2024 Workshop ML for Life and Material Science: From Theory to Industry Applications</details>|
|**2024-8-23**|**Solving Robotics Problems in Zero-Shot with Vision-Language Models**|Zidan Wang et.al|[paper](https://arxiv.org/abs/2407.19094)|-|<details><summary>detail</summary>aka Wonderful Team</details>|
|**2024-8-23**|**ParGo: Bridging Vision-Language with Partial and Global Views**|An-Lan Wang et.al|[paper](https://arxiv.org/abs/2408.12928)|-|-|
|**2024-8-23**|**SPARK: Multi-Vision Sensor Perception and Reasoning Benchmark for Large-scale Vision-Language Models**|Youngjoon Yu et.al|[paper](https://arxiv.org/abs/2408.12114)|[code](https://github.com/top-yun/SPARK)|<details><summary>detail</summary>Codes and data are available at https://github</details>|
|**2024-8-23**|**LLaVA-VSD: Large Language-and-Vision Assistant for Visual Spatial Description**|Yizhang Jin et.al|[paper](https://arxiv.org/abs/2408.04957)|-|-|
|**2024-8-22**|**Building and better understanding vision-language models: insights and future directions**|Hugo Laurençon et.al|[paper](https://arxiv.org/abs/2408.12637)|-|-|
|**2024-8-21**|**Video-to-Text Pedestrian Monitoring (VTPM): Leveraging Computer Vision and Large Language Models for Privacy-Preserve Pedestrian Activity Monitoring at Intersections**|Ahmed S. Abdelrahman et.al|[paper](https://arxiv.org/abs/2408.11649)|-|-|
|**2024-8-21**|**Source-Free Domain Adaptation Guided by Vision and Vision-Language Pre-Training**|Wenyu Zhang et.al|[paper](https://arxiv.org/abs/2405.02954)|-|<details><summary>detail</summary>Extension of ICCV paper arXiv:2212</details>|
|**2024-8-21**|**AntifakePrompt: Prompt-Tuned Vision-Language Models are Fake Image Detectors**|You-Ming Chang et.al|[paper](https://arxiv.org/abs/2310.17419)|[code](https://github.com/nctu-eva-lab/AntifakePrompt.)|-|
|**2024-8-21**|**Reflex-Based Open-Vocabulary Navigation without Prior Knowledge Using Omnidirectional Camera and Multiple Vision-Language Models**|Kento Kawaharazuka et.al|[paper](https://arxiv.org/abs/2408.11380)|[code](https://haraduka.github.io/omnidirectional-vlm/)|<details><summary>detail</summary>Advanced Robotics</details>|
|**2024-8-20**|**Swarm Intelligence in Geo-Localization: A Multi-Agent Large Vision-Language Model Collaborative Framework**|Xiao Han et.al|[paper](https://arxiv.org/abs/2408.11312)|-|-|
|**2024-8-20**|**UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation**|Xiangyu Zhao et.al|[paper](https://arxiv.org/abs/2408.11305)|[code](https://github.com/xiangyu-mm/UniFashion.)|-|
|**2024-8-20**|**Making Large Vision Language Models to be Good Few-shot Learners**|Fan Liu et.al|[paper](https://arxiv.org/abs/2408.11297)|-|-|
|**2024-8-20**|**Towards Analyzing and Mitigating Sycophancy in Large Vision-Language Models**|Yunpu Zhao et.al|[paper](https://arxiv.org/abs/2408.11261)|-|-|
|**2024-8-20**|**Creative Problem Solving in Large Language and Vision Models -- What Would it Take?**|Lakshmi Nair et.al|[paper](https://arxiv.org/abs/2405.01453)|[code](https://github.com/lnairGT/creative-problem-solving-LLMs)|-|

