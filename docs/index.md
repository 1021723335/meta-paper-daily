## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2025.11.13

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-10**|**Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2511.07301)|-|<details><summary>detail</summary>AAAI 2026</details>|
|**2025-11-5**|**Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping**|Zhihang Qin et.al|[paper](https://arxiv.org/abs/2511.03691)|-|-|
|**2025-11-1**|**Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results**|Rohan Palanikumar et.al|[paper](https://arxiv.org/abs/2511.00752)|-|-|
|**2025-10-31**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|
|**2025-10-29**|**Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation**|Yuyang Huang et.al|[paper](https://arxiv.org/abs/2510.25279)|-|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|
|**2025-10-29**|**Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation**|Quang-Khai Bui-Tran et.al|[paper](https://arxiv.org/abs/2510.25227)|-|-|
|**2025-10-28**|**Training-free Source Attribution of AI-generated Images via Resynthesis**|Pietro Bongini et.al|[paper](https://arxiv.org/abs/2510.24278)|-|-|
|**2025-10-24**|**Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.22142)|-|-|
|**2025-10-22**|**Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces**|Osman Berke Guney et.al|[paper](https://arxiv.org/abs/2305.17403)|[code](https://github.com/osmanberke/SFDA-SSVEP-BCI)|-|
|**2025-10-13**|**Source-Free Object Detection with Detection Transformer**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2510.11090)|-|<details><summary>detail</summary>IEEE Transactions on Image Processing</details>|
|**2025-10-9**|**Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning**|Ziqi Zhang et.al|[paper](https://arxiv.org/abs/2510.08393)|-|-|
|**2025-10-7**|**ESS-Flow: Training-free guidance of flow-based models as inference in source space**|Adhithyan Kalaivanan et.al|[paper](https://arxiv.org/abs/2510.05849)|-|-|
|**2025-10-6**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|
|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|
|**2025-10-3**|**Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation**|Yucheng Wang et.al|[paper](https://arxiv.org/abs/2409.19635)|-|-|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-12**|**FQ-PETR: Fully Quantized Position Embedding Transformation for Multi-View 3D Object Detection**|Jiangyong Yu et.al|[paper](https://arxiv.org/abs/2511.09347)|-|-|
|**2025-11-12**|**T-Rex-Omni: Integrating Negative Visual Prompt in Generic Object Detection**|Jiazhou Zhou et.al|[paper](https://arxiv.org/abs/2511.08997)|-|<details><summary>detail</summary>Accepted by AAAI 2026</details>|
|**2025-11-11**|**SFFR: Spatial-Frequency Feature Reconstruction for Multispectral Aerial Object Detection**|Xin Zuo et.al|[paper](https://arxiv.org/abs/2511.06298)|[code](https://github.com/qchenyu1027/SFFR.)|-|
|**2025-11-11**|**DMAT: An End-to-End Framework for Joint Atmospheric Turbulence Mitigation and Object Detection**|Paul Hill et.al|[paper](https://arxiv.org/abs/2507.04323)|-|<details><summary>detail</summary>WACV2026</details>|
|**2025-11-11**|**Toward Autonomous and Efficient Cybersecurity: A Multi-Objective AutoML-based Intrusion Detection System**|Li Yang et.al|[paper](https://arxiv.org/abs/2511.08491)|[code](https://github.com/Western-OC2-Lab/Multi-Objective-Optimization-AutoML-based-Intrusion-Detection-System)|<details><summary>detail</summary>Accepted and To Appear in IEEE Transactions on Machine Learning in Communications and Networking (TMLCN)</details>|
|**2025-11-11**|**Pixel-level Quality Assessment for Oriented Object Detection**|Yunhui Zhu et.al|[paper](https://arxiv.org/abs/2511.08186)|-|-|
|**2025-11-11**|**PEOD: A Pixel-Aligned Event-RGB Benchmark for Object Detection under Challenging Conditions**|Luoping Cui et.al|[paper](https://arxiv.org/abs/2511.08140)|-|-|
|**2025-11-11**|**High-Quality Proposal Encoding and Cascade Denoising for Imaginary Supervised Object Detection**|Zhiyuan Chen et.al|[paper](https://arxiv.org/abs/2511.08018)|-|<details><summary>detail</summary>This work has been submitted to Pattern Recognition for possible publication</details>|
|**2025-11-11**|**MMCL: Correcting Content Query Distributions for Improved Anti-Overlapping X-Ray Object Detection**|Mingyuan Li et.al|[paper](https://arxiv.org/abs/2406.03176)|-|-|
|**2025-11-11**|**Multi-Modal Assistance for Unsupervised Domain Adaptation on Point Cloud 3D Object Detection**|Shenao Zhao et.al|[paper](https://arxiv.org/abs/2511.07966)|[code](https://github.com/liangp/MMAssist.)|<details><summary>detail</summary>AAAI-26</details>|
|**2025-11-11**|**MonoCLUE : Object-Aware Clustering Enhances Monocular 3D Object Detection**|Sunghun Yang et.al|[paper](https://arxiv.org/abs/2511.07862)|-|<details><summary>detail</summary>AAAI 2026</details>|
|**2025-11-10**|**Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2511.07301)|-|<details><summary>detail</summary>AAAI 2026</details>|
|**2025-11-10**|**SM3Det: A Unified Model for Multi-Modal Remote Sensing Object Detection**|Yuxuan Li et.al|[paper](https://arxiv.org/abs/2412.20665)|[code](https://github.com/zcablii/SM3Det.)|<details><summary>detail</summary>Accepted as Oral in AAAI 2026</details>|
|**2025-11-9**|**SPAN: Spatial-Projection Alignment for Monocular 3D Object Detection**|Yifan Wang et.al|[paper](https://arxiv.org/abs/2511.06702)|-|-|
|**2025-11-9**|**On Modality Incomplete Infrared-Visible Object Detection: An Architecture Compatibility Perspective**|Shuo Yang et.al|[paper](https://arxiv.org/abs/2511.06406)|[code](https://github.com/YinghuiXing/Scarf-DETR.)|-|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-11**|**Vicinity-Guided Discriminative Latent Diffusion for Privacy-Preserving Domain Adaptation**|Jing Wang et.al|[paper](https://arxiv.org/abs/2510.00478)|-|<details><summary>detail</summary>39th Conference on Neural Information Processing Systems (NeurIPS 2025)</details>|
|**2025-11-11**|**RAFT - A Domain Adaptation Framework for RGB & LiDAR Semantic Segmentation**|Edward Humes et.al|[paper](https://arxiv.org/abs/2505.04529)|-|<details><summary>detail</summary>Submitted to RA-L</details>|
|**2025-11-11**|**FS-DAG: Few Shot Domain Adapting Graph Networks for Visually Rich Document Understanding**|Amit Agarwal et.al|[paper](https://arxiv.org/abs/2505.17330)|[code](https://github.com/oracle-samples/fs-dag)|<details><summary>detail</summary>Proceedings of the 31st International Conference on Computational Linguistics (COLING 2025)</details>|
|**2025-11-11**|**Boomda: Balanced Multi-objective Optimization for Multimodal Domain Adaptation**|Jun Sun et.al|[paper](https://arxiv.org/abs/2511.08152)|[code](https://github.com/sunjunaimer/Boomda.git.)|-|
|**2025-11-11**|**Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems**|Georgios Kamaras et.al|[paper](https://arxiv.org/abs/2510.26656)|-|-|
|**2025-11-11**|**From IDs to Semantics: A Generative Framework for Cross-Domain Recommendation with Adaptive Semantic Tokenization**|Peiyu Hu et.al|[paper](https://arxiv.org/abs/2511.08006)|-|-|
|**2025-11-11**|**Multi-Modal Assistance for Unsupervised Domain Adaptation on Point Cloud 3D Object Detection**|Shenao Zhao et.al|[paper](https://arxiv.org/abs/2511.07966)|[code](https://github.com/liangp/MMAssist.)|<details><summary>detail</summary>AAAI-26</details>|
|**2025-11-11**|**Reasoning-Enhanced Domain-Adaptive Pretraining of Multimodal Large Language Models for Short Video Content Governance**|Zixuan Wang et.al|[paper](https://arxiv.org/abs/2509.21486)|-|<details><summary>detail</summary>Camera Ready for EMNLP 2025</details>|
|**2025-11-10**|**Data Trajectory Alignment for LLM Domain Adaptation: A Two-Phase Synthesis Framework for Telecommunications Mathematics**|Zhicheng Zhou et.al|[paper](https://arxiv.org/abs/2511.06776)|-|-|
|**2025-11-7**|**TCSA-UDA: Text-Driven Cross-Semantic Alignment for Unsupervised Domain Adaptation in Medical Image Segmentation**|Lalit Maurya et.al|[paper](https://arxiv.org/abs/2511.05782)|-|-|
|**2025-11-7**|**NMIXX: Domain-Adapted Neural Embeddings for Cross-Lingual eXploration of Finance**|Hanwool Lee et.al|[paper](https://arxiv.org/abs/2507.09601)|-|<details><summary>detail</summary>FinAI@CIKM 2025</details>|
|**2025-11-6**|**FunOTTA: On-the-Fly Adaptation on Cross-Domain Fundus Image via Stable Test-time Training**|Qian Zeng et.al|[paper](https://arxiv.org/abs/2407.04396)|[code](https://github.com/Casperqian/FunOTTA.)|-|
|**2025-11-6**|**Vision Foundation Models in Agriculture: Toward Domain-Specific Adaptation for Weed Herbicide Trials Assessment**|Leire Benito-Del-Valle et.al|[paper](https://arxiv.org/abs/2511.04288)|-|-|
|**2025-11-6**|**Active Domain Adaptation for mmWave-based HAR via Renyi Entropy-based Uncertainty Estimation**|Mingzhi Lin et.al|[paper](https://arxiv.org/abs/2511.04219)|-|-|
|**2025-11-4**|**Domain-Adaptive Transformer for Data-Efficient Glioma Segmentation in Sub-Saharan MRI**|Ilerioluwakiiye Abolade et.al|[paper](https://arxiv.org/abs/2511.02928)|-|-|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-12**|**Data Fusion-Enhanced Decision Transformer for Stable Cross-Domain Generalization**|Guojian Wang et.al|[paper](https://arxiv.org/abs/2511.09173)|-|-|
|**2025-11-12**|**DG-DETR: Toward Domain Generalized Detection Transformer**|Seongmin Hwang et.al|[paper](https://arxiv.org/abs/2504.19574)|[code](https://github.com/sminhwang/DG-DETR.)|<details><summary>detail</summary>Accepted by Pattern Recognition Letters (DOI: https://doi</details>|
|**2025-11-11**|**GAITGen: Disentangled Motion-Pathology Impaired Gait Generative Model -- Bringing Motion Generation to the Clinical Domain**|Vida Adeli et.al|[paper](https://arxiv.org/abs/2503.22397)|-|<details><summary>detail</summary>the IEEE/CVF winter conference on applications of computer vision (WACV 2026)</details>|
|**2025-11-11**|**Benchmarking Domain Generalization Algorithms in Computational Pathology**|Neda Zamanitajeddin et.al|[paper](https://arxiv.org/abs/2409.17063)|-|-|
|**2025-11-11**|**From IDs to Semantics: A Generative Framework for Cross-Domain Recommendation with Adaptive Semantic Tokenization**|Peiyu Hu et.al|[paper](https://arxiv.org/abs/2511.08006)|-|-|
|**2025-11-10**|**Free-T2M: Robust Text-to-Motion Generation for Humanoid Robots via Frequency-Domain**|Wenshuo Chen et.al|[paper](https://arxiv.org/abs/2501.18232)|-|-|
|**2025-11-10**|**DrKGC: Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph Completion across General and Biomedical Domains**|Yongkang Xiao et.al|[paper](https://arxiv.org/abs/2506.00708)|-|<details><summary>detail</summary>EMNLP 2025 Findings</details>|
|**2025-11-9**|**Retrieval-Augmented Feature Generation for Domain-Specific Classification**|Xinhao Zhang et.al|[paper](https://arxiv.org/abs/2406.11177)|-|<details><summary>detail</summary>Accepted by ICDM 2025</details>|
|**2025-11-5**|**GNN-MoE: Context-Aware Patch Routing using GNNs for Parameter-Efficient Domain Generalization**|Mahmoud Soliman et.al|[paper](https://arxiv.org/abs/2511.04008)|-|-|
|**2025-11-4**|**ORANGE: An Online Reflection ANd GEneration framework with Domain Knowledge for Text-to-SQL**|Yiwen Jiao et.al|[paper](https://arxiv.org/abs/2511.00985)|-|-|
|**2025-11-3**|**Wonder3D++: Cross-domain Diffusion for High-fidelity 3D Generation from a Single Image**|Yuxiao Yang et.al|[paper](https://arxiv.org/abs/2511.01767)|[code](https://github.com/xxlong0/Wonder3D/tree/Wonder3D_Plus.)|-|
|**2025-11-2**|**OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting**|Tingyue Pan et.al|[paper](https://arxiv.org/abs/2510.24028)|-|-|
|**2025-11-2**|**SynthTextEval: Synthetic Text Data Generation and Evaluation for High-Stakes Domains**|Krithika Ramesh et.al|[paper](https://arxiv.org/abs/2507.07229)|-|<details><summary>detail</summary>EMNLP 2025 System Demonstration</details>|
|**2025-11-1**|**Generalized Category Discovery under Domain Shift: A Frequency Domain Perspective**|Wei Feng et.al|[paper](https://arxiv.org/abs/2511.00573)|-|-|
|**2025-11-1**|**Robust Atypical Mitosis Classification with DenseNet121: Stain-Aware Augmentation and Hybrid Loss for Domain Generalization**|Adinath Dukre et.al|[paper](https://arxiv.org/abs/2510.22630)|-|<details><summary>detail</summary>MIDOG 2025 MICCAI Workshop accepted</details>|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-12**|**MAP-VLA: Memory-Augmented Prompting for Vision-Language-Action Model in Robotic Manipulation**|Runhao Li et.al|[paper](https://arxiv.org/abs/2511.09516)|-|-|
|**2025-11-12**|**WMPO: World Model-based Policy Optimization for Vision-Language-Action Models**|Fangqi Zhu et.al|[paper](https://arxiv.org/abs/2511.09515)|[code](https://wm-po.github.io)|<details><summary>detail</summary>project website: https://wm-po</details>|
|**2025-11-12**|**CrochetBench: Can Vision-Language Models Move from Describing to Doing in Crochet Domain?**|Peiyu Li et.al|[paper](https://arxiv.org/abs/2511.09483)|[code](https://github.com/Peiyu-Georgia-Li/crochetBench.)|<details><summary>detail</summary>code available at https://github</details>|
|**2025-11-12**|**Radio Astronomy in the Era of Vision-Language Models: Prompt Sensitivity and Adaptation**|Mariia Drozdova et.al|[paper](https://arxiv.org/abs/2509.02615)|-|<details><summary>detail</summary>Machine Learning and the Physical Sciences Workshop</details>|
|**2025-11-12**|**mmJEE-Eval: A Bilingual Multimodal Benchmark for Evaluating Scientific Reasoning in Vision-Language Models**|Arka Mukherjee et.al|[paper](https://arxiv.org/abs/2511.09339)|[code](https://mmjee-eval.github.io)|<details><summary>detail</summary>IJCNLP-AACL Findings 2025</details>|
|**2025-11-12**|**PET2Rep: Towards Vision-Language Model-Drived Automated Radiology Report Generation for Positron Emission Tomography**|Yichi Zhang et.al|[paper](https://arxiv.org/abs/2508.04062)|-|<details><summary>detail</summary>Accepted by AAAI 2026</details>|
|**2025-11-12**|**Raw Data Matters: Enhancing Prompt Tuning by Internal Augmentation on Vision-Language Models**|Haoyang Li et.al|[paper](https://arxiv.org/abs/2508.02671)|[code](https://github.com/JREion/AugPT)|-|
|**2025-11-12**|**PISA-Bench: The PISA Index as a Multilingual and Multimodal Metric for the Evaluation of Vision-Language Models**|Patrick Haller et.al|[paper](https://arxiv.org/abs/2510.24792)|-|-|
|**2025-11-12**|**Multimodal Adversarial Defense for Vision-Language Models by Leveraging One-To-Many Relationships**|Futa Waseda et.al|[paper](https://arxiv.org/abs/2405.18770)|-|<details><summary>detail</summary>WACV 2026 Accepted</details>|
|**2025-11-12**|**Ultra-Light Test-Time Adaptation for Vision--Language Models**|Byunghyun Kim et.al|[paper](https://arxiv.org/abs/2511.09101)|-|-|
|**2025-11-12**|**Prompt-OT: An Optimal Transport Regularization Paradigm for Knowledge Preservation in Vision-Language Model Adaptation**|Xiwen Chen et.al|[paper](https://arxiv.org/abs/2503.08906)|[code](https://github.com/ChongQingNoSubway/Prompt-OT)|<details><summary>detail</summary>WACV 2026</details>|
|**2025-11-11**|**Spatio-Temporal Data Enhanced Vision-Language Model for Traffic Scene Understanding**|Jingtian Ma et.al|[paper](https://arxiv.org/abs/2511.08978)|-|-|
|**2025-11-11**|**CHOICE: Benchmarking the Remote Sensing Capabilities of Large Vision-Language Models**|Xiao An et.al|[paper](https://arxiv.org/abs/2411.18145)|[code](https://github.com/ShawnAn-WHU/CHOICE).)|<details><summary>detail</summary>Accepted by NeurIPS 2025 Track on Datasets and Benchmarks</details>|
|**2025-11-11**|**Synth-Align: Improving Trustworthiness in Vision-Language Model with Synthetic Preference Data Alignment**|Robert Wijaya et.al|[paper](https://arxiv.org/abs/2412.17417)|-|-|
|**2025-11-11**|**Survey of Vision-Language-Action Models for Embodied Manipulation**|Haoran Li et.al|[paper](https://arxiv.org/abs/2508.15201)|-|<details><summary>detail</summary>in Chinese language</details>|

