## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2025.05.23

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-5-20**|**Listen, Analyze, and Adapt to Learn New Attacks: An Exemplar-Free Class Incremental Learning Method for Audio Deepfake Source Tracing**|Yang Xiao et.al|[paper](https://arxiv.org/abs/2505.14601)|-|<details><summary>detail</summary>Accepted by Interspeech 2025</details>|
|**2025-5-14**|**DDFP: Data-dependent Frequency Prompt for Source Free Domain Adaptation of Medical Image Segmentation**|Siqi Yin et.al|[paper](https://arxiv.org/abs/2505.09927)|-|-|
|**2025-5-13**|**Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting**|Zheang Huai et.al|[paper](https://arxiv.org/abs/2505.08527)|[code](https://github.com/xmed-lab/DFG.)|-|
|**2025-5-1**|**CORSTITCH - A free, open source software for stitching and georeferencing underwater coral reef videos**|Julian Christopher L. Maypa et.al|[paper](https://arxiv.org/abs/2505.00462)|-|-|
|**2025-4-23**|**Energy-Based Pseudo-Label Refining for Source-free Domain Adaptation**|Xinru Meng et.al|[paper](https://arxiv.org/abs/2504.16692)|[code](https://github.com/Sthen111/EBPR)|-|
|**2025-4-21**|**Context Aware Grounded Teacher for Source Free Object Detection**|Tajamul Ashraf et.al|[paper](https://arxiv.org/abs/2504.15404)|[code](https://github.com/Tajamul21/Grounded_Teacher.)|-|
|**2025-4-21**|**Learning Compositional Transferability of Time Series for Source-Free Domain Adaptation**|Hankang Sun et.al|[paper](https://arxiv.org/abs/2504.14994)|-|<details><summary>detail</summary>Corresponding author: Su Yang</details>|
|**2025-4-16**|**Proxy Denoising for Source-Free Domain Adaptation**|Song Tang et.al|[paper](https://arxiv.org/abs/2406.01658)|[code](https://github.com/tntek/source-free-domain-adaptation.)|<details><summary>detail</summary>This paper is accepted by ICLR 2025 (Oral</details>|
|**2025-4-16**|**Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation**|Pascal Schlachter et.al|[paper](https://arxiv.org/abs/2504.11992)|[code](https://github.com/pascalschlachter/PLAnalysis.)|<details><summary>detail</summary>Submitted to the 33rd European Signal Processing Conference (EUSIPCO 2025)</details>|
|**2025-4-15**|**Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation**|Amirhossein Dadashzadeh et.al|[paper](https://arxiv.org/abs/2504.11669)|[code](https://github.com/Plrbear/Co-Star)|-|
|**2025-4-15**|**Probability Distribution Alignment and Low-Rank Weight Decomposition for Source-Free Domain Adaptive Brain Decoding**|Ganxi Xu et.al|[paper](https://arxiv.org/abs/2504.09109)|-|-|
|**2025-4-5**|**Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2503.20771)|-|-|
|**2025-3-31**|**ElimPCL: Eliminating Noise Accumulation with Progressive Curriculum Labeling for Source-Free Domain Adaptation**|Jie Cheng et.al|[paper](https://arxiv.org/abs/2503.23712)|-|<details><summary>detail</summary>ICME 2025 camera-ready</details>|
|**2025-3-30**|**ViLAaD: Enhancing "Attracting and Dispersing'' Source-Free Domain Adaptation with Vision-and-Language Model**|Shuhei Tarashima et.al|[paper](https://arxiv.org/abs/2503.23529)|-|-|
|**2025-3-29**|**Optimal Transport-Guided Source-Free Adaptation for Face Anti-Spoofing**|Zhuowei Li et.al|[paper](https://arxiv.org/abs/2503.22984)|-|-|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-5-22**|**MAFE R-CNN: Selecting More Samples to Learn Category-aware Features for Small Object Detection**|Yichen Li et.al|[paper](https://arxiv.org/abs/2505.16442)|-|-|
|**2025-5-22**|**AdvReal: Adversarial Patch Generation Framework with Application to Adversarial Safety Evaluation of Object Detection Systems**|Yuanhao Huang et.al|[paper](https://arxiv.org/abs/2505.16402)|[code](https://github.com/Huangyh98/AdvReal.git.)|-|
|**2025-5-22**|**Efficient Feature Fusion for UAV Object Detection**|Xudong Wang et.al|[paper](https://arxiv.org/abs/2501.17983)|-|-|
|**2025-5-22**|**Self-Classification Enhancement and Correction for Weakly Supervised Object Detection**|Yufei Yin et.al|[paper](https://arxiv.org/abs/2505.16294)|-|<details><summary>detail</summary>Accepted by IJCAI 2025</details>|
|**2025-5-21**|**HV-BEV: Decoupling Horizontal and Vertical Feature Sampling for Multi-View 3D Object Detection**|Di Wu et.al|[paper](https://arxiv.org/abs/2412.18884)|[code](https://github.com/Uddd821/HV-BEV.)|-|
|**2025-5-21**|**RGBX-DiffusionDet: A Framework for Multi-Modal RGB-X Object Detection Using DiffusionDet**|Eliraz Orfaig et.al|[paper](https://arxiv.org/abs/2505.02586)|-|-|
|**2025-5-21**|**Boosting Few-Shot Open-Set Object Detection via Prompt Learning and Robust Decision Boundary**|Zhaowei Wu et.al|[paper](https://arxiv.org/abs/2406.18443)|[code](https://gitee.com/VR_NAVE/ced-food.)|<details><summary>detail</summary>IJCAI 2025</details>|
|**2025-5-20**|**A re-calibration method for object detection with multi-modal alignment bias in autonomous driving**|Zhihang Song et.al|[paper](https://arxiv.org/abs/2405.16848)|-|-|
|**2025-5-20**|**LED: LLM Enhanced Open-Vocabulary Object Detection without Human Curated Data Generation**|Yang Zhou et.al|[paper](https://arxiv.org/abs/2503.13794)|-|-|
|**2025-5-20**|**Decoupling Classifier for Boosting Few-shot Object Detection and Instance Segmentation**|Bin-Bin Gao et.al|[paper](https://arxiv.org/abs/2505.14239)|[code](https://csgaobb.github.io/Projects/DCFS.)|<details><summary>detail</summary>Accepted by NeurIPS 2022</details>|
|**2025-5-19**|**View-Invariant Pixelwise Anomaly Detection in Multi-object Scenes with Adaptive View Synthesis**|Subin Varghese et.al|[paper](https://arxiv.org/abs/2406.18012)|[code](https://drags99.github.io/OmniAD/)|-|
|**2025-5-19**|**Quantifying Context Bias in Domain Adaptation for Object Detection**|Hojun Son et.al|[paper](https://arxiv.org/abs/2409.14679)|-|<details><summary>detail</summary>Under review</details>|
|**2025-5-19**|**Dynamic Graph Induced Contour-aware Heat Conduction Network for Event-based Object Detection**|Xiao Wang et.al|[paper](https://arxiv.org/abs/2505.12908)|[code](https://github.com/Event-AHU/OpenEvDET.)|-|
|**2025-5-19**|**Rethinking Features-Fused-Pyramid-Neck for Object Detection**|Hulin Li et.al|[paper](https://arxiv.org/abs/2505.12820)|[code](https://github.com/AlanLi1997/rethinking-fpn.)|<details><summary>detail</summary>ECCV 2024</details>|
|**2025-5-19**|**VLC Fusion: Vision-Language Conditioned Sensor Fusion for Robust Object Detection**|Aditya Taparia et.al|[paper](https://arxiv.org/abs/2505.12715)|-|-|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-5-22**|**GCAL: Adapting Graph Models to Evolving Domain Shifts**|Ziyue Qiao et.al|[paper](https://arxiv.org/abs/2505.16860)|-|<details><summary>detail</summary>ICML 2025</details>|
|**2025-5-22**|**Transformers for molecular property prediction: Domain adaptation efficiently improves performance**|Afnan Sultan et.al|[paper](https://arxiv.org/abs/2503.03360)|-|-|
|**2025-5-22**|**Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation**|Estelle Chigot et.al|[paper](https://arxiv.org/abs/2505.16360)|[code](https://github.com/echigot/cactif.)|<details><summary>detail</summary>Under review</details>|
|**2025-5-21**|**SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation**|Jiayue Liu et.al|[paper](https://arxiv.org/abs/2505.16080)|-|-|
|**2025-5-21**|**Domain Adaptive Skin Lesion Classification via Conformal Ensemble of Vision Transformers**|Mehran Zoravar et.al|[paper](https://arxiv.org/abs/2505.15997)|-|-|
|**2025-5-21**|**seg_3D_by_PC2D: Multi-View Projection for Domain Generalization and Adaptation in 3D Semantic Segmentation**|Andrew Caunes et.al|[paper](https://arxiv.org/abs/2505.15545)|[code](https://github.com/andrewcaunes/ia4markings)|-|
|**2025-5-21**|**GAMA++: Disentangled Geometric Alignment with Adaptive Contrastive Perturbation for Reliable Domain Transfer**|Kim Yun et.al|[paper](https://arxiv.org/abs/2505.15241)|-|-|
|**2025-5-21**|**GAMA: Geometry-Aware Manifold Alignment via Structured Adversarial Perturbations for Robust Domain Adaptation**|Hana Satou et.al|[paper](https://arxiv.org/abs/2505.15194)|-|-|
|**2025-5-20**|**DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware Reinforcement Learning on Imbalanced Data**|Yuhang Zhou et.al|[paper](https://arxiv.org/abs/2505.15074)|-|-|
|**2025-5-20**|**Feature-Weighted MMD-CORAL for Domain Adaptation in Power Transformer Fault Diagnosis**|Hootan Mahmoodiyan et.al|[paper](https://arxiv.org/abs/2505.14896)|-|-|
|**2025-5-20**|**ReservoirTTA: Prolonged Test-time Adaptation for Evolving and Recurring Domains**|Guillaume Vray et.al|[paper](https://arxiv.org/abs/2505.14511)|-|-|
|**2025-5-20**|**Domain Adaptation for Multi-label Image Classification: a Discriminator-free Approach**|Inder Pal Singh et.al|[paper](https://arxiv.org/abs/2505.14333)|-|<details><summary>detail</summary>The paper is under consideration at Computer Vision and Image Understanding</details>|
|**2025-5-20**|**Does Unsupervised Domain Adaptation Improve the Robustness of Amortized Bayesian Inference? A Systematic Evaluation**|Lasse Elsem√ºller et.al|[paper](https://arxiv.org/abs/2502.04949)|-|-|
|**2025-5-20**|**Cross-Domain Diffusion with Progressive Alignment for Efficient Adaptive Retrieval**|Junyu Luo et.al|[paper](https://arxiv.org/abs/2505.13907)|-|<details><summary>detail</summary>IEEE TIP</details>|
|**2025-5-19**|**Domain Adaptation of VLM for Soccer Video Understanding**|Tiancheng Jiang et.al|[paper](https://arxiv.org/abs/2505.13860)|-|-|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-5-22**|**General-Reasoner: Advancing LLM Reasoning Across All Domains**|Xueguang Ma et.al|[paper](https://arxiv.org/abs/2505.14652)|-|-|
|**2025-5-22**|**Single Domain Generalization for Few-Shot Counting via Universal Representation Matching**|Xianing Chen et.al|[paper](https://arxiv.org/abs/2505.16778)|-|<details><summary>detail</summary>CVPR 2025</details>|
|**2025-5-21**|**seg_3D_by_PC2D: Multi-View Projection for Domain Generalization and Adaptation in 3D Semantic Segmentation**|Andrew Caunes et.al|[paper](https://arxiv.org/abs/2505.15545)|[code](https://github.com/andrewcaunes/ia4markings)|-|
|**2025-5-19**|**Domain Gating Ensemble Networks for AI-Generated Text Detection**|Arihant Tripathi et.al|[paper](https://arxiv.org/abs/2505.13855)|-|<details><summary>detail</summary>Submitted to EMNLP 2025</details>|
|**2025-5-19**|**MoL for LLMs: Dual-Loss Optimization to Enhance Domain Expertise While Preserving General Capabilities**|Jingxue Chen et.al|[paper](https://arxiv.org/abs/2505.12043)|-|-|
|**2025-5-19**|**A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation**|Hao-Ran Yang et.al|[paper](https://arxiv.org/abs/2505.13043)|-|-|
|**2025-5-19**|**PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization**|Dong Kyu Cho et.al|[paper](https://arxiv.org/abs/2505.12745)|-|-|
|**2025-5-18**|**Learning Robust Spectral Dynamics for Temporal Domain Generalization**|En Yu et.al|[paper](https://arxiv.org/abs/2505.12585)|-|-|
|**2025-5-18**|**Towards Open-world Generalized Deepfake Detection: General Feature Extraction via Unsupervised Domain Adaptation**|Midou Guo et.al|[paper](https://arxiv.org/abs/2505.12339)|-|-|
|**2025-5-18**|**Learning Auxiliary Tasks Improves Reference-Free Hallucination Detection in Open-Domain Long-Form Generation**|Chengwei Qin et.al|[paper](https://arxiv.org/abs/2505.12265)|-|-|
|**2025-5-17**|**Continuous Domain Generalization**|Zekun Cai et.al|[paper](https://arxiv.org/abs/2505.13519)|-|-|
|**2025-5-16**|**Fault Diagnosis across Heterogeneous Domains via Self-Adaptive Temporal-Spatial Attention and Sample Generation**|Guangqiang Li et.al|[paper](https://arxiv.org/abs/2505.11083)|[code](https://github.com/GuangqiangLi/TSA-SAN.)|-|
|**2025-5-15**|**Multi-Source Collaborative Style Augmentation and Domain-Invariant Learning for Federated Domain Generalization**|Yikang Wei et.al|[paper](https://arxiv.org/abs/2505.10152)|-|<details><summary>detail</summary>IJCAI 2025</details>|
|**2025-5-14**|**Denoising and Alignment: Rethinking Domain Generalization for Multimodal Face Anti-Spoofing**|Yingjie Ma et.al|[paper](https://arxiv.org/abs/2505.09484)|-|-|
|**2025-5-13**|**UVTM: Universal Vehicle Trajectory Modeling with ST Feature Domain Generation**|Yan Lin et.al|[paper](https://arxiv.org/abs/2402.07232)|-|-|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-5-22**|**Interactive Post-Training for Vision-Language-Action Models**|Shuhan Tan et.al|[paper](https://arxiv.org/abs/2505.17016)|[code](https://ariostgx.github.io/ript_vla/)|<details><summary>detail</summary>Project page: https://ariostgx</details>|
|**2025-5-22**|**Remote Sensing Spatio-Temporal Vision-Language Models: A Comprehensive Survey**|Chenyang Liu et.al|[paper](https://arxiv.org/abs/2412.02573)|[code](https://github.com/Chen-Yang-Liu/Awesome-RS-SpatioTemporal-VLMs)|-|
|**2025-5-22**|**Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models**|Jiaqi Wang et.al|[paper](https://arxiv.org/abs/2505.16854)|[code](https://github.com/kokolerk/TON.)|-|
|**2025-5-22**|**SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving**|Xuesong Chen et.al|[paper](https://arxiv.org/abs/2505.16805)|-|<details><summary>detail</summary>Accepted by CVPR 2025</details>|
|**2025-5-22**|**InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning**|Ji Zhang et.al|[paper](https://arxiv.org/abs/2505.13888)|[code](https://Koorye.github.io/proj/Inspire.)|-|
|**2025-5-22**|**Self-Rewarding Large Vision-Language Models for Optimizing Prompts in Text-to-Image Generation**|Hongji Yang et.al|[paper](https://arxiv.org/abs/2505.16763)|-|-|
|**2025-5-22**|**Point, Detect, Count: Multi-Task Medical Image Understanding with Instruction-Tuned Vision-Language Models**|Sushant Gautam et.al|[paper](https://arxiv.org/abs/2505.16647)|[code](https://github.com/simula/PointDetectCount.)|<details><summary>detail</summary>Accepted as a full paper at the 38th IEEE International Symposium on Computer-Based Medical Systems (CBMS) 2025</details>|
|**2025-5-22**|**BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization**|Xueyang Zhou et.al|[paper](https://arxiv.org/abs/2505.16640)|[code](https://badvla-project.github.io/.)|-|
|**2025-5-22**|**AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving**|Kangan Qian et.al|[paper](https://arxiv.org/abs/2505.15298)|-|-|
|**2025-5-22**|**ManipLVM-R1: Reinforcement Learning for Reasoning in Embodied Manipulation with Large Vision-Language Models**|Zirui Song et.al|[paper](https://arxiv.org/abs/2505.16517)|-|-|
|**2025-5-22**|**Transferring Textual Preferences to Vision-Language Understanding through Model Merging**|Chen-An Li et.al|[paper](https://arxiv.org/abs/2502.13487)|-|<details><summary>detail</summary>ACL 2025 main</details>|
|**2025-5-22**|**Uncovering Cultural Representation Disparities in Vision-Language Models**|Ram Mohan Rao Kadiyala et.al|[paper](https://arxiv.org/abs/2505.14729)|-|-|
|**2025-5-22**|**Implicit Jailbreak Attacks via Cross-Modal Information Concealment on Vision-Language Models**|Zhaoxin Wang et.al|[paper](https://arxiv.org/abs/2505.16446)|-|-|
|**2025-5-22**|**Circle-RoPE: Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models**|Chengcheng Wang et.al|[paper](https://arxiv.org/abs/2505.16416)|[code](https://github.com/lose4578/CircleRoPE](https://github.com/lose4578/CircleRoPE).)|-|
|**2025-5-22**|**Mitigating Hallucinations in Vision-Language Models through Image-Guided Head Suppression**|Sreetama Sarkar et.al|[paper](https://arxiv.org/abs/2505.16411)|[code](https://github.com/YUECHE77/SPIN.)|-|

