## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2025.07.23

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-21**|**Model-Free and Real-Time Bioinspired Unicycle-Based Source Seeking: Differential Wheeled Robotic Experiments**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2501.02184)|-|-|
|**2025-7-14**|**Text-Driven Causal Representation Learning for Source-Free Domain Generalization**|Lihua Zhou et.al|[paper](https://arxiv.org/abs/2507.09961)|-|<details><summary>detail</summary>Under Review</details>|
|**2025-7-12**|**Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting**|Zheang Huai et.al|[paper](https://arxiv.org/abs/2505.08527)|[code](https://github.com/xmed-lab/DFG.)|<details><summary>detail</summary>Accepted in TMI 2025</details>|
|**2025-7-4**|**Source-Free Domain Adaptation via Multi-view Contrastive Learning**|Amirfarhad Farhadi et.al|[paper](https://arxiv.org/abs/2507.03321)|-|-|
|**2025-6-26**|**Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework**|Ismail Nejjar et.al|[paper](https://arxiv.org/abs/2411.12558)|-|<details><summary>detail</summary>TMLR 2025</details>|
|**2025-6-26**|**Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation**|Yihong Cao et.al|[paper](https://arxiv.org/abs/2506.21198)|[code](https://github.com/yihong-97/UNLOCK.)|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-6-25**|**Context Aware Grounded Teacher for Source Free Object Detection**|Tajamul Ashraf et.al|[paper](https://arxiv.org/abs/2504.15404)|[code](https://github.com/Tajamul21/Grounded_Teacher.)|-|
|**2025-6-18**|**SFDLA: Source-Free Document Layout Analysis**|Sebastian Tewes et.al|[paper](https://arxiv.org/abs/2503.18742)|[code](https://github.com/s3setewe/sfdla-DLAdapter.)|<details><summary>detail</summary>Accepted by ICDAR 2025</details>|
|**2025-6-17**|**Unified Source-Free Domain Adaptation**|Song Tang et.al|[paper](https://arxiv.org/abs/2403.07601)|-|-|
|**2025-6-11**|**SRPL-SFDA: SAM-Guided Reliable Pseudo-Labels for Source-Free Domain Adaptation in Medical Image Segmentation**|Xinya Liu et.al|[paper](https://arxiv.org/abs/2506.09403)|[code](https://github.com/HiLab-git/SRPL-SFDA.)|-|
|**2025-6-5**|**DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization**|Geonyoung Lee et.al|[paper](https://arxiv.org/abs/2506.02858)|[code](https://wltschmrz.github.io/DGMO/)|<details><summary>detail</summary>Interspeech 2025</details>|
|**2025-5-30**|**Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2503.20771)|-|-|
|**2025-5-30**|**Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation**|Pascal Schlachter et.al|[paper](https://arxiv.org/abs/2504.11992)|[code](https://github.com/pascalschlachter/PLAnalysis.)|<details><summary>detail</summary>the 33rd European Signal Processing Conference (EUSIPCO 2025)</details>|
|**2025-5-30**|**Shuffle PatchMix Augmentation with Confidence-Margin Weighted Pseudo-Labels for Enhanced Source-Free Domain Adaptation**|Prasanna Reddy Pulakurthi et.al|[paper](https://arxiv.org/abs/2505.24216)|[code](https://github.com/PrasannaPulakurthi/SPM)|-|
|**2025-5-27**|**Multi-Granularity Class Prototype Topology Distillation for Class-Incremental Source-Free Unsupervised Domain Adaptation**|Peihua Deng et.al|[paper](https://arxiv.org/abs/2411.16064)|[code](https://github.com/dengpeihua/GROTO.)|<details><summary>detail</summary>Accepted by CVPR 2025</details>|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-22**|**Task-Specific Zero-shot Quantization-Aware Training for Object Detection**|Changhao Li et.al|[paper](https://arxiv.org/abs/2507.16782)|[code](https://github.com/DFQ-Dojo/dfq-toolkit)|<details><summary>detail</summary>Accepted by ICCV 2025</details>|
|**2025-7-22**|**PlantSAM: An Object Detection-Driven Segmentation Pipeline for Herbarium Specimens**|Youcef Sklab et.al|[paper](https://arxiv.org/abs/2507.16506)|-|-|
|**2025-7-22**|**Edge-case Synthesis for Fisheye Object Detection: A Data-centric Perspective**|Seunghyeon Kim et.al|[paper](https://arxiv.org/abs/2507.16254)|-|-|
|**2025-7-22**|**LDRFusion: A LiDAR-Dominant multimodal refinement framework for 3D object detection**|Jijun Wang et.al|[paper](https://arxiv.org/abs/2507.16224)|-|-|
|**2025-7-21**|**Towards Accurate and Efficient 3D Object Detection for Autonomous Driving: A Mixture of Experts Computing System on Edge**|Linshen Liu et.al|[paper](https://arxiv.org/abs/2507.04123)|[code](https://github.com/LinshenLiu622/EMC2.)|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-7-21**|**UPRE: Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement**|Xiao Zhang et.al|[paper](https://arxiv.org/abs/2507.00721)|[code](https://github.com/AMAP-ML/UPRE.)|<details><summary>detail</summary>ICCV2025</details>|
|**2025-7-21**|**Few-Shot Object Detection via Spatial-Channel State Space Model**|Zhimeng Xin et.al|[paper](https://arxiv.org/abs/2507.15308)|-|-|
|**2025-7-20**|**Event-based Graph Representation with Spatial and Motion Vectors for Asynchronous Object Detection**|Aayush Atul Verma et.al|[paper](https://arxiv.org/abs/2507.15150)|-|-|
|**2025-7-20**|**Beyond RGB: Adaptive Parallel Processing for RAW Object Detection**|Shani Gamrian et.al|[paper](https://arxiv.org/abs/2503.13163)|-|-|
|**2025-7-20**|**An Uncertainty-aware DETR Enhancement Framework for Object Detection**|Xingshu Chen et.al|[paper](https://arxiv.org/abs/2507.14855)|[code](https://github.com/ParadiseforAndaChen/An-Uncertainty-aware-DETR-Enhancement-Framework-for-Object-Detection.)|-|
|**2025-7-19**|**Multispectral State-Space Feature Fusion: Bridging Shared and Cross-Parametric Interactions for Object Detection**|Jifeng Shen et.al|[paper](https://arxiv.org/abs/2507.14643)|[code](https://github.com/61s61min/MS2Fusion.git.)|<details><summary>detail</summary>submitted on 30/4/2025</details>|
|**2025-7-19**|**Clutter Detection and Removal by Multi-Objective Analysis for Photographic Guidance**|Xiaoran Wu et.al|[paper](https://arxiv.org/abs/2507.14553)|-|-|
|**2025-7-18**|**ZS-VCOS: Zero-Shot Video Camouflaged Object Segmentation By Optical Flow and Open Vocabulary Object Detection**|Wenqi Guo et.al|[paper](https://arxiv.org/abs/2505.01431)|[code](https://github.com/weathon/vcos.)|-|
|**2025-7-18**|**OD-VIRAT: A Large-Scale Benchmark for Object Detection in Realistic Surveillance Environments**|Hayat Ullah et.al|[paper](https://arxiv.org/abs/2507.12396)|-|-|
|**2025-7-18**|**Enhancing LiDAR Point Features with Foundation Model Priors for 3D Object Detection**|Yujian Mo et.al|[paper](https://arxiv.org/abs/2507.13899)|-|-|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-22**|**Towards Railway Domain Adaptation for LiDAR-based 3D Detection: Road-to-Rail and Sim-to-Real via SynDRA-BBox**|Xavier Diaz et.al|[paper](https://arxiv.org/abs/2507.16413)|[code](https://syndra.retis.santannapisa.it.)|<details><summary>detail</summary>IEEE International Conference on Intelligent Rail Transportation (ICIRT) 2025</details>|
|**2025-7-21**|**UPRE: Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement**|Xiao Zhang et.al|[paper](https://arxiv.org/abs/2507.00721)|[code](https://github.com/AMAP-ML/UPRE.)|<details><summary>detail</summary>ICCV2025</details>|
|**2025-7-21**|**MORDA: A Synthetic Dataset to Facilitate Adaptation of Object Detectors to Unseen Real-target Domain While Preserving Performance on Real-source Domain**|Hojun Lim et.al|[paper](https://arxiv.org/abs/2501.04950)|-|-|
|**2025-7-21**|**Confidence sharing adaptation for out-of-domain human pose and shape estimation**|T Yue et.al|[paper](https://www.sciencedirect.com/science/article/pii/S1077314224001322)|-|<details><summary>detail</summary>Computer Vision and Image…, 2024 Elsevier</details>|
|**2025-7-20**|**PHATNet: A Physics-guided Haze Transfer Network for Domain-adaptive Real-world Image Dehazing**|Fu-Jen Tsai et.al|[paper](https://arxiv.org/abs/2507.14826)|-|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-7-20**|**…Carbon Content and Temperature in Bof Steelmaking Based on Adaptive Balanced Joint Distribution Alignment Domain Adaptation with Variational Autoencoder**|Z Liu et.al|[paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4863841)|-|<details><summary>detail</summary>Available at SSRN 4863841 papers.ssrn.com</details>|
|**2025-7-20**|**POND: Multi-Source Time Series Domain Adaptation with Information-Aware Prompt Tuning**|J Wang et.al|[paper](https://www.researchgate.net/profile/Junxiang-Wang-3/publication/381225385_POND_Multi-Source_Time_Series_Domain_Adaptation_with_Information-Aware_Prompt_Tuning/links/6663974e85a4ee7261ae011e/POND-Multi-Source-Time-Series-Domain-Adaptation-with-Information-Aware-Prompt-Tuning.pdf)|[code](https://paperswithcode.com/paper/prompt-based-domain-discrimination-for-multi)|<details><summary>detail</summary>2024 researchgate.net</details>|
|**2025-7-20**|**Continuous Test-time Domain Adaptation for Efficient Fault Detection under Evolving Operating Conditions**|H Sun et.al|[paper](https://ui.adsabs.harvard.edu/abs/2024arXiv240606607S/abstract)|[code](https://paperswithcode.com/paper/continuous-test-time-domain-adaptation-for)|-|
|**2025-7-20**|**Source-Free Domain Adaptation for Speaker Verification in Data-Scarce Languages and Noisy Channels**|S Salo Elia et.al|[paper](https://ui.adsabs.harvard.edu/abs/2024arXiv240605863S/abstract)|[code](https://paperswithcode.com/paper/source-free-domain-adaptation-for-speaker)|-|
|**2025-7-20**|**Cross-Domain Classification Based on Frequency Component Adaptation for Remote Sensing Images**|P Zhu et.al|[paper](https://www.mdpi.com/2072-4292/16/12/2134)|-|<details><summary>detail</summary>Remote Sensing, 2024 mdpi.com</details>|
|**2025-7-20**|**TSFAN: Tensorized spatial-frequency attention network with domain adaptation for cross-session EEG-based biometric recognition**|X Jin et.al|[paper](https://automatedtest.iopscience.iop.org/article/10.1088/1741-2552/ad5761)|-|<details><summary>detail</summary>Journal of…, 2024 automatedtest.iopscience.iop.org</details>|
|**2025-7-20**|**SE/BN Adapter: Parametric Efficient Domain Adaptation for Speaker Recognition**|T Wang et.al|[paper](https://arxiv.org/abs/2406.07832)|-|-|
|**2025-7-19**|**Domain-Adaptive Small Language Models for Structured Tax Code Prediction**|Souvik Nath et.al|[paper](https://arxiv.org/abs/2507.10880)|-|-|
|**2025-7-19**|**Fourier Domain Adaptation for Traffic Light Detection in Adverse Weather**|Ishaan Gakhar et.al|[paper](https://arxiv.org/abs/2411.07901)|-|<details><summary>detail</summary>the 2COOOL Workshop</details>|
|**2025-7-19**|**When few labeled target data suffice: a theory of semi-supervised domain adaptation via fine-tuning from multiple adaptive starts**|Wooseok Ha et.al|[paper](https://arxiv.org/abs/2507.14661)|-|-|
|**2025-7-19**|**Novel Deep Learning Domain Adaptation Approach for Object Detection Using Semi-Self Building Dataset and Modified YOLOv4**|A Gomaa et.al|[paper](https://www.mdpi.com/2032-6653/15/6/255)|-|<details><summary>detail</summary>World Electric Vehicle Journal, 2024 mdpi.com</details>|
|**2025-7-19**|**Global self-sustaining and local inheritance for source-free unsupervised domain adaptation**|L Peng et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0031320324004308)|-|<details><summary>detail</summary>Pattern Recognition, 2024 Elsevier</details>|
|**2025-7-18**|**SuperCM: Improving Semi-Supervised Learning and Domain Adaptation through differentiable clustering**|Durgesh Singh et.al|[paper](https://arxiv.org/abs/2507.13779)|-|<details><summary>detail</summary>Journal ref:Pattern Recognition 2025</details>|
|**2025-7-17**|**Addressing the ML Domain Adaptation Problem for Networking: Realistic and Controllable Training Data Generation with NetReplica**|Jaber Daneshamooz et.al|[paper](https://arxiv.org/abs/2507.13476)|-|-|
|**2025-7-17**|**SIDDA: SInkhorn Dynamic Domain Adaptation for Image Classification with Equivariant Neural Networks**|Sneh Pandya et.al|[paper](https://arxiv.org/abs/2501.14048)|[code](https://github.com/deepskies/SIDDA)|-|
|**2025-7-16**|**A Privacy-Preserving Semantic-Segmentation Method Using Domain-Adaptation Technique**|Homare Sueyoshi et.al|[paper](https://arxiv.org/abs/2507.12730)|-|-|
|**2025-7-16**|**Prominent Roles of Conditionally Invariant Components in Domain Adaptation: Theory and Algorithms**|Keru Wu et.al|[paper](https://arxiv.org/abs/2309.10301)|-|-|
|**2025-7-16**|**SS-DC: Spatial-Spectral Decoupling and Coupling Across Visible-Infrared Gap for Domain Adaptive Object Detection**|Xiwei Zhang et.al|[paper](https://arxiv.org/abs/2507.12017)|-|-|
|**2025-7-16**|**Dual form Complementary Masking for Domain-Adaptive Image Segmentation**|Jiawen Wang et.al|[paper](https://arxiv.org/abs/2507.12008)|-|<details><summary>detail</summary>Accepted by ICML 2025</details>|
|**2025-7-15**|**Few-Shot Radar Signal Recognition through Self-Supervised Learning and Radio Frequency Domain Adaptation**|Zi Huang et.al|[paper](https://arxiv.org/abs/2501.03461)|-|-|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-21**|**Gradient-Guided Annealing for Domain Generalization**|Aristotelis Ballas et.al|[paper](https://arxiv.org/abs/2502.20162)|-|<details><summary>detail</summary>Paper accepted in CVPR2025</details>|
|**2025-7-21**|**Entity-centric multi-domain transformer for improving generalization in fake news detection**|P Bazmi et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0306457324001663)|-|<details><summary>detail</summary>Information Processing &…, 2024 Elsevier</details>|
|**2025-7-20**|**DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation**|Bo Liu et.al|[paper](https://arxiv.org/abs/2501.03466)|-|-|
|**2025-7-20**|**Fine-Grained Domain Generalization with Feature Structuralization**|W Yu et.al|[paper](https://arxiv.org/abs/2406.09166)|[code](https://github.com/yuwlong666/fsdg)|-|
|**2025-7-19**|**Omni-Think: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards**|Derek Li et.al|[paper](https://arxiv.org/abs/2507.14783)|-|-|
|**2025-7-19**|**Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification**|Subhendu Khatuya et.al|[paper](https://arxiv.org/abs/2506.06806)|-|<details><summary>detail</summary>This work has been accepted to appear at the Association for Computational Linguistics (ACL)</details>|
|**2025-7-18**|**Leveraging Vision-Language Models for Improving Domain Generalization in Image Classification**|S Addepalli et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Addepalli_Leveraging_Vision-Language_Models_for_Improving_Domain_Generalization_in_Image_Classification_CVPR_2024_paper.html)|[code](https://github.com/val-iisc/VL2V-ADiP)|<details><summary>detail</summary>Proceedings of the…, 2024 openaccess.thecvf.com</details>|
|**2025-7-18**|**Disentangled Prompt Representation for Domain Generalization**|D Cheng et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_Disentangled_Prompt_Representation_for_Domain_Generalization_CVPR_2024_paper.html)|[code](https://github.com/henry123-boy/SpaTracker)|<details><summary>detail</summary>Proceedings of the…, 2024 openaccess.thecvf.com</details>|
|**2025-7-18**|**Supplementary Materials: Unknown Prompt, the only Lacuna: Unveiling CLIP's Potential in Open Domain Generalization**|M Singha et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/supplemental/Singha_Unknown_Prompt_the_CVPR_2024_supplemental.pdf)|-|<details><summary>detail</summary>openaccess.thecvf.com</details>|
|**2025-7-18**|**Supplementary Material for DiPrompT: Disentangled Prompt Tuning for Multiple Latent Domain Generalization in Federated Learning**|B Dataset - openaccess.thecvf.com et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/supplemental/Bai_DiPrompT_Disentangled_Prompt_CVPR_2024_supplemental.pdf)|-|<details><summary>detail</summary>openaccess.thecvf.com</details>|
|**2025-7-18**|**Supplementary Material for Efficiently Assemble Normalization Layers and Regularization for Federated Domain Generalization**|K Le et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/supplemental/Le_Efficiently_Assemble_Normalization_CVPR_2024_supplemental.pdf)|-|<details><summary>detail</summary>Phuoc, KS Wong openaccess.thecvf.com</details>|
|**2025-7-18**|**Domain Generalization for Crop Segmentation with Standardized Ensemble Knowledge Distillation**|S Angarano et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Angarano_Domain_Generalization_for_Crop_Segmentation_with_Standardized_Ensemble_Knowledge_Distillation_CVPRW_2024_paper.html)|[code](https://github.com/pic4ser/agriseg)|<details><summary>detail</summary>Proceedings of the…, 2024 openaccess.thecvf.com</details>|
|**2025-7-18**|**MixStyle-Based Contrastive Test-Time Adaptation: Pathway to Domain Generalization**|K Yamashita et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024W/MAT/html/Yamashita_MixStyle-Based_Contrastive_Test-Time_Adaptation_Pathway_to_Domain_Generalization_CVPRW_2024_paper.html)|-|<details><summary>detail</summary>…of the IEEE/CVF Conference on…, 2024 openaccess.thecvf.com</details>|
|**2025-7-18**|**Fault vibration model driven fault-aware domain generalization framework for bearing fault diagnosis**|B Pang et.al|[paper](https://www.sciencedirect.com/science/article/pii/S1474034624002684)|-|<details><summary>detail</summary>Advanced Engineering…, 2024 Elsevier</details>|
|**2025-7-17**|**Generative Multi-Target Cross-Domain Recommendation**|Jinqiu Jin et.al|[paper](https://arxiv.org/abs/2507.12871)|-|<details><summary>detail</summary>fix author information</details>|
|**2025-7-17**|**Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning**|Simon Ouellette et.al|[paper](https://arxiv.org/abs/2507.15877)|-|-|
|**2025-7-17**|**Addressing the ML Domain Adaptation Problem for Networking: Realistic and Controllable Training Data Generation with NetReplica**|Jaber Daneshamooz et.al|[paper](https://arxiv.org/abs/2507.13476)|-|-|
|**2025-7-17**|**CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings**|Daniil Orel et.al|[paper](https://arxiv.org/abs/2503.13733)|-|-|
|**2025-7-17**|**Generative AI Models for Learning Flow Maps of Stochastic Dynamical Systems in Bounded Domains**|Minglei Yang et.al|[paper](https://arxiv.org/abs/2507.15990)|-|-|
|**2025-7-17**|**A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints**|Youssef Tawfilis et.al|[paper](https://arxiv.org/abs/2507.12979)|[code](https://github.com/youssefga28/HuSCF-GAN.)|-|
|**2025-7-17**|**Simulate, Refocus and Ensemble: An Attention-Refocusing Scheme for Domain Generalization**|Ziyi Wang et.al|[paper](https://arxiv.org/abs/2507.12851)|[code](https://github.com/bitPrincy/SRE-DG.)|<details><summary>detail</summary>\c{opyright} 20XX IEEE</details>|
|**2025-7-16**|**Domain Generalization via Pareto Optimal Gradient Matching**|Khoi Do et.al|[paper](https://arxiv.org/abs/2507.14227)|-|-|
|**2025-7-15**|**Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation**|Siyu Chen et.al|[paper](https://arxiv.org/abs/2504.12753)|[code](https://github.com/anonymouse-xzrptkvyqc/DepthForge.)|<details><summary>detail</summary>Accepted by ICCV 2025</details>|
|**2025-7-14**|**Text-Driven Causal Representation Learning for Source-Free Domain Generalization**|Lihua Zhou et.al|[paper](https://arxiv.org/abs/2507.09961)|-|<details><summary>detail</summary>Under Review</details>|
|**2025-7-13**|**Fair Domain Generalization: An Information-Theoretic View**|Tangzheng Lian et.al|[paper](https://arxiv.org/abs/2507.05823)|-|-|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-22**|**ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning**|Chi-Pin Huang et.al|[paper](https://arxiv.org/abs/2507.16815)|[code](https://jasper0314-huang.github.io/thinkact-vla/)|<details><summary>detail</summary>Project page: https://jasper0314-huang</details>|
|**2025-7-22**|**Semi-off-Policy Reinforcement Learning for Vision-Language Slow-thinking Reasoning**|Junhao Shen et.al|[paper](https://arxiv.org/abs/2507.16814)|-|-|
|**2025-7-22**|**Cooling Matters: Benchmarking Large Language Models and Vision-Language Models on Liquid-Cooled Versus Air-Cooled H100 GPU Systems**|Imran Latif et.al|[paper](https://arxiv.org/abs/2507.16781)|-|-|
|**2025-7-22**|**RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment**|Difei Gu et.al|[paper](https://arxiv.org/abs/2501.07525)|[code](https://github.com/difeigu/RadAlign.)|<details><summary>detail</summary>MICCAI 2025</details>|
|**2025-7-22**|**VRU-Accident: A Vision-Language Benchmark for Video Question Answering and Dense Captioning for Accident Scene Understanding**|Younggun Kim et.al|[paper](https://arxiv.org/abs/2507.09815)|-|-|
|**2025-7-22**|**Do large language vision models understand 3D shapes?**|Sagi Eppel et.al|[paper](https://arxiv.org/abs/2412.10908)|-|-|
|**2025-7-22**|**Zebra-CoT: A Dataset for Interleaved Vision Language Reasoning**|Ang Li et.al|[paper](https://arxiv.org/abs/2507.16746)|[code](https://huggingface.co/datasets/multimodal-reasoning-lab/Zebra-CoT)|<details><summary>detail</summary>dataset link: https://huggingface</details>|
|**2025-7-22**|**Enhancing Remote Sensing Vision-Language Models Through MLLM and LLM-Based High-Quality Image-Text Dataset Generation**|Yiguo He et.al|[paper](https://arxiv.org/abs/2507.16716)|[code](https://github.com/YiguoHe/HQRS-210K-and-HQRS-CLIP.)|<details><summary>detail</summary>SUBMIT TO IEEE TRANSACTIONS</details>|
|**2025-7-22**|**DOFA-CLIP: Multimodal Vision-Language Foundation Models for Earth Observation**|Zhitong Xiong et.al|[paper](https://arxiv.org/abs/2503.06312)|[code](https://github.com/xiong-zhitong/DOFA-CLIP)|<details><summary>detail</summary>code & weights: https://github</details>|
|**2025-7-22**|**Conformal Predictions for Human Action Recognition with Vision-Language Models**|Bary Tim et.al|[paper](https://arxiv.org/abs/2502.06631)|-|-|
|**2025-7-22**|**Spatial 3D-LLM: Exploring Spatial Awareness in 3D Vision-Language Models**|Xiaoyan Wang et.al|[paper](https://arxiv.org/abs/2507.16524)|[code](https://github.com/bjshuyuan/Spatial-3D-LLM.)|<details><summary>detail</summary>Accepted by ICME2025</details>|
|**2025-7-22**|**Hierarchical Safety Realignment: Lightweight Restoration of Safety in Pruned Large Vision-Language Models**|Yue Li et.al|[paper](https://arxiv.org/abs/2505.16104)|-|<details><summary>detail</summary>ACL 2025 Findings</details>|
|**2025-7-22**|**Multi-modal vision-language model for generalizable annotation-free pathology localization and clinical diagnosis**|Hao Yang et.al|[paper](https://arxiv.org/abs/2401.02044)|-|-|
|**2025-7-22**|**INTER: Mitigating Hallucination in Large Vision-Language Models by Interaction Guidance Sampling**|Xin Dong et.al|[paper](https://arxiv.org/abs/2507.05056)|-|<details><summary>detail</summary>Accepted by ICCV 2025</details>|
|**2025-7-22**|**Quality Text, Robust Vision: The Role of Language in Enhancing Visual Robustness of Vision-Language Models**|Futa Waseda et.al|[paper](https://arxiv.org/abs/2507.16257)|-|<details><summary>detail</summary>ACMMM 2025 Accepted</details>|
|**2025-7-21**|**Towards Vision-Language Geo-Foundation Model: A Survey**|Y Zhou et.al|[paper](https://www.researchgate.net/profile/Yue-Zhou-139/publication/381403816_Towards_Vision-Language_Geo-Foundation_Model_A_Survey/links/666ba71ea54c5f0b9464c544/Towards-Vision-Language-Geo-Foundation-Model-A-Survey.pdf)|[code](https://github.com/zytx121/awesome-vlgfm)|<details><summary>detail</summary>researchgate.net</details>|
|**2025-7-20**|**VLind-Bench: Measuring Language Priors in Large Vision-Language Models**|K Lee et.al|[paper](https://arxiv.org/abs/2406.08702)|[code](https://github.com/klee972/vlind-bench)|-|
|**2025-7-20**|**How structured are the representations in transformer-based vision encoders? An analysis of multi-object representations in vision-language models**|T Khajuria et.al|[paper](https://arxiv.org/abs/2406.09067)|-|-|
|**2025-7-20**|**AlignMMBench: Evaluating Chinese Multimodal Alignment in Large Vision-Language Models**|Y Wu et.al|[paper](https://arxiv.org/abs/2406.09295)|[code](https://paperswithcode.com/paper/alignmmbench-evaluating-chinese-multimodal)|-|
|**2025-7-20**|**MirrorCheck: Efficient Adversarial Defense for Vision-Language Models**|S Fares et.al|[paper](https://arxiv.org/abs/2406.09250)|[code](https://paperswithcode.com/paper/mirrorcheck-efficient-adversarial-defense-for)|-|
|**2025-7-20**|**LLAVIDAL: Benchmarking Large Language Vision Models for Daily Activities of Living**|R Chakraborty et.al|[paper](https://arxiv.org/abs/2406.09390)|-|-|
|**2025-7-20**|**OpenVLA: An Open-Source Vision-Language-Action Model**|MJ Kim et.al|[paper](https://arxiv.org/abs/2406.09246)|[code](https://github.com/openvla/openvla)|-|
|**2025-7-20**|**Generative AI-based Prompt Evolution Engineering Design Optimization With Vision-Language Model**|M Wong et.al|[paper](https://arxiv.org/abs/2406.09143)|[code](https://paperswithcode.com/paper/generative-ai-based-prompt-evolution)|-|
|**2025-7-19**|**VisionLLM v2: An End-to-End Generalist Multimodal Large Language Model for Hundreds of Vision-Language Tasks**|J Wu et.al|[paper](https://arxiv.org/abs/2406.08394)|[code](https://github.com/opengvlab/visionllm)|-|
|**2025-7-19**|**RWKV-CLIP: A Robust Vision-Language Representation Learner**|T Gu et.al|[paper](https://arxiv.org/abs/2406.06973)|[code](https://github.com/deepglint/rwkv-clip)|-|

