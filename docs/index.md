## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2025.07.10

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-4**|**Source-Free Domain Adaptation via Multi-view Contrastive Learning**|Amirfarhad Farhadi et.al|[paper](https://arxiv.org/abs/2507.03321)|-|-|
|**2025-6-26**|**Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework**|Ismail Nejjar et.al|[paper](https://arxiv.org/abs/2411.12558)|-|<details><summary>detail</summary>TMLR 2025</details>|
|**2025-6-26**|**Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation**|Yihong Cao et.al|[paper](https://arxiv.org/abs/2506.21198)|[code](https://github.com/yihong-97/UNLOCK.)|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-6-25**|**Context Aware Grounded Teacher for Source Free Object Detection**|Tajamul Ashraf et.al|[paper](https://arxiv.org/abs/2504.15404)|[code](https://github.com/Tajamul21/Grounded_Teacher.)|-|
|**2025-6-18**|**SFDLA: Source-Free Document Layout Analysis**|Sebastian Tewes et.al|[paper](https://arxiv.org/abs/2503.18742)|[code](https://github.com/s3setewe/sfdla-DLAdapter.)|<details><summary>detail</summary>Accepted by ICDAR 2025</details>|
|**2025-6-17**|**Unified Source-Free Domain Adaptation**|Song Tang et.al|[paper](https://arxiv.org/abs/2403.07601)|-|-|
|**2025-6-11**|**SRPL-SFDA: SAM-Guided Reliable Pseudo-Labels for Source-Free Domain Adaptation in Medical Image Segmentation**|Xinya Liu et.al|[paper](https://arxiv.org/abs/2506.09403)|[code](https://github.com/HiLab-git/SRPL-SFDA.)|-|
|**2025-6-5**|**DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization**|Geonyoung Lee et.al|[paper](https://arxiv.org/abs/2506.02858)|[code](https://wltschmrz.github.io/DGMO/)|<details><summary>detail</summary>Interspeech 2025</details>|
|**2025-5-30**|**Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2503.20771)|-|-|
|**2025-5-30**|**Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation**|Pascal Schlachter et.al|[paper](https://arxiv.org/abs/2504.11992)|[code](https://github.com/pascalschlachter/PLAnalysis.)|<details><summary>detail</summary>the 33rd European Signal Processing Conference (EUSIPCO 2025)</details>|
|**2025-5-30**|**Shuffle PatchMix Augmentation with Confidence-Margin Weighted Pseudo-Labels for Enhanced Source-Free Domain Adaptation**|Prasanna Reddy Pulakurthi et.al|[paper](https://arxiv.org/abs/2505.24216)|[code](https://github.com/PrasannaPulakurthi/SPM)|-|
|**2025-5-27**|**Multi-Granularity Class Prototype Topology Distillation for Class-Incremental Source-Free Unsupervised Domain Adaptation**|Peihua Deng et.al|[paper](https://arxiv.org/abs/2411.16064)|[code](https://github.com/dengpeihua/GROTO.)|<details><summary>detail</summary>Accepted by CVPR 2025</details>|
|**2025-5-26**|**Training-Free Multi-Step Audio Source Separation**|Yongyi Zang et.al|[paper](https://arxiv.org/abs/2505.19534)|-|-|
|**2025-5-23**|**Temporal Restoration and Spatial Rewiring for Source-Free Multivariate Time Series Domain Adaptation**|Peiliang Gong et.al|[paper](https://arxiv.org/abs/2505.21525)|-|-|
|**2025-5-20**|**Listen, Analyze, and Adapt to Learn New Attacks: An Exemplar-Free Class Incremental Learning Method for Audio Deepfake Source Tracing**|Yang Xiao et.al|[paper](https://arxiv.org/abs/2505.14601)|-|<details><summary>detail</summary>Accepted by Interspeech 2025</details>|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-9**|**DenoiseCP-Net: Efficient Collective Perception in Adverse Weather via Joint LiDAR-Based 3D Object Detection and Denoising**|Sven Teufel et.al|[paper](https://arxiv.org/abs/2507.06976)|-|-|
|**2025-7-9**|**PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection**|Xiao Li et.al|[paper](https://arxiv.org/abs/2506.23581)|-|<details><summary>detail</summary>Accepted by ICCV 2025</details>|
|**2025-7-9**|**From Blurry to Brilliant Detection: YOLO-Based Aerial Object Detection with Super Resolution**|Ragib Amin Nihal et.al|[paper](https://arxiv.org/abs/2401.14661)|-|-|
|**2025-7-9**|**StixelNExT: Toward Monocular Low-Weight Perception for Object Segmentation and Free Space Detection**|Marcel Vosshans et.al|[paper](https://arxiv.org/abs/2407.08277)|-|<details><summary>detail</summary>Accepted Conference Paper</details>|
|**2025-7-8**|**Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection**|Yupeng Hu et.al|[paper](https://arxiv.org/abs/2507.06510)|-|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-7-8**|**CFMW: Cross-modality Fusion Mamba for Robust Object Detection under Adverse Weather**|Haoyuan Li et.al|[paper](https://arxiv.org/abs/2404.16302)|[code](https://github.com/lhy-zjut/CFMW.)|<details><summary>detail</summary>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</details>|
|**2025-7-7**|**Rethinking Detecting Salient and Camouflaged Objects in Unconstrained Scenes**|Zhangjun Zhou et.al|[paper](https://arxiv.org/abs/2412.10943)|[code](https://github.com/ssecv/USCNet.)|-|
|**2025-7-6**|**CVFusion: Cross-View Fusion of 4D Radar and Camera for 3D Object Detection**|Hanzhi Zhong et.al|[paper](https://arxiv.org/abs/2507.04587)|-|-|
|**2025-7-6**|**MambaFusion: Height-Fidelity Dense Global Fusion for Multi-modal 3D Object Detection**|Hanshi Wang et.al|[paper](https://arxiv.org/abs/2507.04369)|-|-|
|**2025-7-6**|**DMAT: An End-to-End Framework for Joint Atmospheric Turbulence Mitigation and Object Detection**|Paul Hill et.al|[paper](https://arxiv.org/abs/2507.04323)|-|-|
|**2025-7-5**|**Towards Accurate and Efficient 3D Object Detection for Autonomous Driving: A Mixture of Experts Computing System on Edge**|Linshen Liu et.al|[paper](https://arxiv.org/abs/2507.04123)|-|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-7-4**|**Pillar-Voxel Fusion Network for 3D Object Detection in Airborne Hyperspectral Point Clouds**|Yanze Jiang et.al|[paper](https://arxiv.org/abs/2504.09506)|-|-|
|**2025-7-4**|**Hallucinatory Image Tokens: A Training-free EAZY Approach on Detecting and Mitigating Object Hallucinations in LVLMs**|Liwei Che et.al|[paper](https://arxiv.org/abs/2503.07772)|-|<details><summary>detail</summary>ICCV2025</details>|
|**2025-7-4**|**Cooperative Students: Navigating Unsupervised Domain Adaptation in Nighttime Object Detection**|Jicheng Yuan et.al|[paper](https://arxiv.org/abs/2404.01988)|[code](https://github.com/jichengyuan/Cooperitive_Students.)|<details><summary>detail</summary>Code is available at https://github</details>|
|**2025-7-4**|**2.5D Object Detection for Intelligent Roadside Infrastructure**|Nikolai Polley et.al|[paper](https://arxiv.org/abs/2507.03564)|[code](https://gitlab.kit.edu/kit/aifb/ATKS/public/digit4taf/2.5d-object-detection)|<details><summary>detail</summary>2025 IEEE 28th International Conference on Intelligent Transportation Systems (ITSC)</details>|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-9**|**Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining: Method, Evaluation and Applications**|Seonwu Kim et.al|[paper](https://arxiv.org/abs/2507.06795)|-|<details><summary>detail</summary>under review</details>|
|**2025-7-9**|**On the Hardness of Unsupervised Domain Adaptation: Optimal Learners and Information-Theoretic Perspective**|Zhiyi Dong et.al|[paper](https://arxiv.org/abs/2507.06552)|-|<details><summary>detail</summary>the 4th Conference on Lifelong Learning Agents (CoLLAs 2025)</details>|
|**2025-7-8**|**Mitigating Multi-Sequence 3D Prostate MRI Data Scarcity through Domain Adaptation using Locally-Trained Latent Diffusion Models for Prostate Cancer Detection**|Emerson P. Grabke et.al|[paper](https://arxiv.org/abs/2507.06384)|[code](https://github.com/grabkeem/CCELLA-plus-plus)|<details><summary>detail</summary>BT and MAH are co-senior authors on the work</details>|
|**2025-7-8**|**Safe Domain Randomization via Uncertainty-Aware Out-of-Distribution Detection and Policy Adaptation**|Mohamad H. Danesh et.al|[paper](https://arxiv.org/abs/2507.06111)|-|-|
|**2025-7-8**|**Optimal Transport for Domain Adaptation through Gaussian Mixture Models**|Eduardo Fernandes Montesuma et.al|[paper](https://arxiv.org/abs/2403.13847)|[code](https://github.com/eddardd/gmm-otda/)|-|
|**2025-7-8**|**Improving Robustness of Foundation Models in Domain Adaptation with Soup-Adapters**|Marco Roschkowski et.al|[paper](https://arxiv.org/abs/2507.05807)|-|-|
|**2025-7-8**|**Confidence sharing adaptation for out-of-domain human pose and shape estimation**|T Yue et.al|[paper](https://www.sciencedirect.com/science/article/pii/S1077314224001322)|-|<details><summary>detail</summary>Computer Vision and Image…, 2024 Elsevier</details>|
|**2025-7-7**|**Domain adaptation of large language models for geotechnical applications**|Lei Fan et.al|[paper](https://arxiv.org/abs/2507.05613)|-|-|
|**2025-7-7**|**Domain Adaptation of VLM for Soccer Video Understanding**|Tiancheng Jiang et.al|[paper](https://arxiv.org/abs/2505.13860)|-|-|
|**2025-7-6**|**Tackling Dimensional Collapse toward Comprehensive Universal Domain Adaptation**|Hung-Chieh Fang et.al|[paper](https://arxiv.org/abs/2410.11271)|[code](https://dc-unida.github.io/)|-|
|**2025-7-6**|**Domain Adaptation of Drag Reduction Policy to Partial Measurements**|Anton Plaksin et.al|[paper](https://arxiv.org/abs/2507.04309)|-|<details><summary>detail</summary>Journal ref:Machine Learning and the Physical Sciences Workshop</details>|
|**2025-7-5**|**Beyond Independent Passages: Adaptive Passage Combination Retrieval for Retrieval Augmented Open-Domain Question Answering**|Ting-Wen Ko et.al|[paper](https://arxiv.org/abs/2507.04069)|-|-|
|**2025-7-4**|**Cooperative Students: Navigating Unsupervised Domain Adaptation in Nighttime Object Detection**|Jicheng Yuan et.al|[paper](https://arxiv.org/abs/2404.01988)|[code](https://github.com/jichengyuan/Cooperitive_Students.)|<details><summary>detail</summary>Code is available at https://github</details>|
|**2025-7-4**|**Source-Free Domain Adaptation via Multi-view Contrastive Learning**|Amirfarhad Farhadi et.al|[paper](https://arxiv.org/abs/2507.03321)|-|-|
|**2025-7-4**|**Global Variational Inference Enhanced Robust Domain Adaptation**|Lingkun Luo et.al|[paper](https://arxiv.org/abs/2507.03291)|-|-|
|**2025-7-4**|**MORDA: A Synthetic Dataset to Facilitate Adaptation of Object Detectors to Unseen Real-target Domain While Preserving Performance on Real-source Domain**|Hojun Lim et.al|[paper](https://arxiv.org/abs/2501.04950)|-|-|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-9**|**Enhancing Food-Domain Question Answering with a Multimodal Knowledge Graph: Hybrid QA Generation and Diversity Analysis**|Srihari K B et.al|[paper](https://arxiv.org/abs/2507.06571)|-|-|
|**2025-7-8**|**Fair Domain Generalization: An Information-Theoretic View**|Tangzheng Lian et.al|[paper](https://arxiv.org/abs/2507.05823)|-|-|
|**2025-7-8**|**Entity-centric multi-domain transformer for improving generalization in fake news detection**|P Bazmi et.al|[paper](https://www.sciencedirect.com/science/article/pii/S0306457324001663)|-|<details><summary>detail</summary>Information Processing &…, 2024 Elsevier</details>|
|**2025-7-7**|**AdaptaGen: Domain-Specific Image Generation through Hierarchical Semantic Optimization Framework**|Suoxiang Zhang et.al|[paper](https://arxiv.org/abs/2507.05621)|-|-|
|**2025-7-7**|**LAID: Lightweight AI-Generated Image Detection in Spatial and Spectral Domains**|Nicholas Chivaran et.al|[paper](https://arxiv.org/abs/2507.05162)|[code](https://github.com/nchivar/LAID.)|<details><summary>detail</summary>To appear in the proceedings of PST2025</details>|
|**2025-7-7**|**Fine-Grained Domain Generalization with Feature Structuralization**|W Yu et.al|[paper](https://arxiv.org/abs/2406.09166)|[code](https://github.com/yuwlong666/fsdg)|-|
|**2025-7-6**|**Adversarial Data Augmentation for Single Domain Generalization via Lyapunov Exponent-Guided Optimization**|Zuyu Zhang et.al|[paper](https://arxiv.org/abs/2507.04302)|-|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-7-5**|**CLEP-DG: Contrastive Learning for Speech Emotion Domain Generalization via Soft Prompt Tuning**|Jiacheng Shi et.al|[paper](https://arxiv.org/abs/2507.04048)|-|<details><summary>detail</summary>Interspeech2025</details>|
|**2025-7-5**|**Leveraging Vision-Language Models for Improving Domain Generalization in Image Classification**|S Addepalli et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Addepalli_Leveraging_Vision-Language_Models_for_Improving_Domain_Generalization_in_Image_Classification_CVPR_2024_paper.html)|[code](https://github.com/val-iisc/VL2V-ADiP)|<details><summary>detail</summary>Proceedings of the…, 2024 openaccess.thecvf.com</details>|
|**2025-7-5**|**Disentangled Prompt Representation for Domain Generalization**|D Cheng et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_Disentangled_Prompt_Representation_for_Domain_Generalization_CVPR_2024_paper.html)|[code](https://github.com/henry123-boy/SpaTracker)|<details><summary>detail</summary>Proceedings of the…, 2024 openaccess.thecvf.com</details>|
|**2025-7-5**|**Supplementary Materials: Unknown Prompt, the only Lacuna: Unveiling CLIP's Potential in Open Domain Generalization**|M Singha et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/supplemental/Singha_Unknown_Prompt_the_CVPR_2024_supplemental.pdf)|-|<details><summary>detail</summary>openaccess.thecvf.com</details>|
|**2025-7-5**|**Supplementary Material for DiPrompT: Disentangled Prompt Tuning for Multiple Latent Domain Generalization in Federated Learning**|B Dataset - openaccess.thecvf.com et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/supplemental/Bai_DiPrompT_Disentangled_Prompt_CVPR_2024_supplemental.pdf)|-|<details><summary>detail</summary>openaccess.thecvf.com</details>|
|**2025-7-5**|**Supplementary Material for Efficiently Assemble Normalization Layers and Regularization for Federated Domain Generalization**|K Le et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024/supplemental/Le_Efficiently_Assemble_Normalization_CVPR_2024_supplemental.pdf)|-|<details><summary>detail</summary>Phuoc, KS Wong openaccess.thecvf.com</details>|
|**2025-7-5**|**Domain Generalization for Crop Segmentation with Standardized Ensemble Knowledge Distillation**|S Angarano et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Angarano_Domain_Generalization_for_Crop_Segmentation_with_Standardized_Ensemble_Knowledge_Distillation_CVPRW_2024_paper.html)|[code](https://github.com/pic4ser/agriseg)|<details><summary>detail</summary>Proceedings of the…, 2024 openaccess.thecvf.com</details>|
|**2025-7-5**|**MixStyle-Based Contrastive Test-Time Adaptation: Pathway to Domain Generalization**|K Yamashita et.al|[paper](https://openaccess.thecvf.com/content/CVPR2024W/MAT/html/Yamashita_MixStyle-Based_Contrastive_Test-Time_Adaptation_Pathway_to_Domain_Generalization_CVPRW_2024_paper.html)|-|<details><summary>detail</summary>…of the IEEE/CVF Conference on…, 2024 openaccess.thecvf.com</details>|
|**2025-7-5**|**Fault vibration model driven fault-aware domain generalization framework for bearing fault diagnosis**|B Pang et.al|[paper](https://www.sciencedirect.com/science/article/pii/S1474034624002684)|-|<details><summary>detail</summary>Advanced Engineering…, 2024 Elsevier</details>|
|**2025-7-4**|**Bridging Domain Generalization to Multimodal Domain Generalization via Unified Representations**|Hai Huang et.al|[paper](https://arxiv.org/abs/2507.03304)|-|<details><summary>detail</summary>Accepted by ICCV 2025</details>|
|**2025-7-3**|**Set Valued Predictions For Robust Domain Generalization**|Ron Tsibulsky et.al|[paper](https://arxiv.org/abs/2507.03146)|-|<details><summary>detail</summary>ICML 2025</details>|
|**2025-7-3**|**Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation**|Siyu Chen et.al|[paper](https://arxiv.org/abs/2504.12753)|[code](https://github.com/anonymouse-xzrptkvyqc/DepthForge.)|<details><summary>detail</summary>Accepted by ICCV 2025</details>|
|**2025-7-2**|**Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization**|De Cheng et.al|[paper](https://arxiv.org/abs/2507.02288)|-|-|
|**2025-7-2**|**Generalized Adaptive Transfer Network: Enhancing Transfer Learning in Reinforcement Learning Across Domains**|Abhishek Verma et.al|[paper](https://arxiv.org/abs/2507.03026)|-|-|
|**2025-7-2**|**NuSegDG: Integration of Heterogeneous Space and Gaussian Kernel for Domain-Generalized Nuclei Segmentation**|Zhenye Lou et.al|[paper](https://arxiv.org/abs/2408.11787)|[code](https://github.com/xq141839/NuSegDG.)|-|
|**2025-6-30**|**DGSAM: Domain Generalization via Individual Sharpness-Aware Minimization**|Youngjun Song et.al|[paper](https://arxiv.org/abs/2503.23430)|-|-|
|**2025-6-30**|**Calculation of Photocarrier Generation from Optical Absorption for Time-domain Simulation of Optoelectronic Devices**|Liang Chen et.al|[paper](https://arxiv.org/abs/2102.06702)|-|-|
|**2025-6-30**|**Generalizing vision-language models to novel domains: A comprehensive survey**|Xinyao Li et.al|[paper](https://arxiv.org/abs/2506.18504)|-|-|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-9**|**Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models**|Tiezheng Zhang et.al|[paper](https://arxiv.org/abs/2507.07104)|-|-|
|**2025-7-9**|**Finetuning Vision-Language Models as OCR Systems for Low-Resource Languages: A Case Study of Manchu**|Yan Hon Michael Chung et.al|[paper](https://arxiv.org/abs/2507.06761)|[code](https://github.com/mic7ch1/ManchuAI-OCR.)|-|
|**2025-7-9**|**DriveMRP: Enhancing Vision-Language Models with Synthetic Motion Data for Motion Risk Prediction**|Zhiyi Hou et.al|[paper](https://arxiv.org/abs/2507.02948)|[code](https://github.com/hzy138/DriveMRP)|-|
|**2025-7-9**|**SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments**|Tianshun Li et.al|[paper](https://arxiv.org/abs/2507.06564)|-|-|
|**2025-7-9**|**Integrated Structural Prompt Learning for Vision-Language Models**|Jiahui Wang et.al|[paper](https://arxiv.org/abs/2507.05677)|-|-|
|**2025-7-8**|**Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection**|Yupeng Hu et.al|[paper](https://arxiv.org/abs/2507.06510)|-|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-7-8**|**Refining Skewed Perceptions in Vision-Language Contrastive Models through Visual Representations**|Haocheng Dai et.al|[paper](https://arxiv.org/abs/2405.14030)|-|-|
|**2025-7-8**|**3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds**|Fan-Yun Sun et.al|[paper](https://arxiv.org/abs/2507.06484)|[code](https://ai.stanford.edu/)|<details><summary>detail</summary>project website: https://ai</details>|
|**2025-7-8**|**VisioPath: Vision-Language Enhanced Model Predictive Control for Safe Autonomous Navigation in Mixed Traffic**|Shanting Wang et.al|[paper](https://arxiv.org/abs/2507.06441)|-|-|
|**2025-7-8**|**Language-Unlocked ViT (LUViT): Empowering Self-Supervised Vision Transformers with LLMs**|Selim Kuzucu et.al|[paper](https://arxiv.org/abs/2507.00754)|-|-|
|**2025-7-8**|**On the Natural Robustness of Vision-Language Models Against Visual Perception Attacks in Autonomous Driving**|Pedram MohajerAnsari et.al|[paper](https://arxiv.org/abs/2506.11472)|-|-|
|**2025-7-8**|**LangMamba: A Language-driven Mamba Framework for Low-dose CT Denoising with Vision-language Models**|Zhihao Chen et.al|[paper](https://arxiv.org/abs/2507.06140)|[code](https://github.com/hao1635/LangMamba.)|-|
|**2025-7-8**|**Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation**|André Schakkal et.al|[paper](https://arxiv.org/abs/2506.22827)|[code](https://vlp-humanoid.github.io/)|<details><summary>detail</summary>the RSS 2025 Workshop on Robot Planning in the Era of Foundation Models</details>|
|**2025-7-8**|**FA: Forced Prompt Learning of Vision-Language Models for Out-of-Distribution Detection**|Xinhua Lu et.al|[paper](https://arxiv.org/abs/2507.04511)|[code](https://github.com/0xFAFA/FA.)|-|
|**2025-7-8**|**GeoMag: A Vision-Language Model for Pixel-level Fine-Grained Remote Sensing Image Parsing**|Xianzhi Ma et.al|[paper](https://arxiv.org/abs/2507.05887)|-|-|
|**2025-7-8**|**Towards Vision-Language Geo-Foundation Model: A Survey**|Y Zhou et.al|[paper](https://www.researchgate.net/profile/Yue-Zhou-139/publication/381403816_Towards_Vision-Language_Geo-Foundation_Model_A_Survey/links/666ba71ea54c5f0b9464c544/Towards-Vision-Language-Geo-Foundation-Model-A-Survey.pdf)|[code](https://github.com/zytx121/awesome-vlgfm)|<details><summary>detail</summary>researchgate.net</details>|
|**2025-7-7**|**VLind-Bench: Measuring Language Priors in Large Vision-Language Models**|K Lee et.al|[paper](https://arxiv.org/abs/2406.08702)|[code](https://github.com/klee972/vlind-bench)|-|
|**2025-7-7**|**How structured are the representations in transformer-based vision encoders? An analysis of multi-object representations in vision-language models**|T Khajuria et.al|[paper](https://arxiv.org/abs/2406.09067)|-|-|
|**2025-7-7**|**AlignMMBench: Evaluating Chinese Multimodal Alignment in Large Vision-Language Models**|Y Wu et.al|[paper](https://arxiv.org/abs/2406.09295)|[code](https://paperswithcode.com/paper/alignmmbench-evaluating-chinese-multimodal)|-|
|**2025-7-7**|**MirrorCheck: Efficient Adversarial Defense for Vision-Language Models**|S Fares et.al|[paper](https://arxiv.org/abs/2406.09250)|[code](https://paperswithcode.com/paper/mirrorcheck-efficient-adversarial-defense-for)|-|

