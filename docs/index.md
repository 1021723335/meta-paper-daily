## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2025.10.29

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-10-28**|**Training-free Source Attribution of AI-generated Images via Resynthesis**|Pietro Bongini et.al|[paper](https://arxiv.org/abs/2510.24278)|-|-|
|**2025-10-24**|**Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.22142)|-|-|
|**2025-10-22**|**Source-Free Domain Adaptation for SSVEP-based Brain-Computer Interfaces**|Osman Berke Guney et.al|[paper](https://arxiv.org/abs/2305.17403)|[code](https://github.com/osmanberke/SFDA-SSVEP-BCI)|-|
|**2025-10-13**|**Source-Free Object Detection with Detection Transformer**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2510.11090)|-|<details><summary>detail</summary>IEEE Transactions on Image Processing</details>|
|**2025-10-9**|**Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning**|Ziqi Zhang et.al|[paper](https://arxiv.org/abs/2510.08393)|-|-|
|**2025-10-7**|**ESS-Flow: Training-free guidance of flow-based models as inference in source space**|Adhithyan Kalaivanan et.al|[paper](https://arxiv.org/abs/2510.05849)|-|-|
|**2025-10-7**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|
|**2025-10-6**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu et.al|[paper](https://arxiv.org/abs/2509.22229)|-|-|
|**2025-10-6**|**Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection**|Mohamed Lamine Mekhalfi et.al|[paper](https://arxiv.org/abs/2501.10081)|-|-|
|**2025-10-3**|**Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation**|Yucheng Wang et.al|[paper](https://arxiv.org/abs/2409.19635)|-|-|
|**2025-10-2**|**OT Score: An OT based Confidence Score for Source Free Unsupervised Domain Adaptation**|Yiming Zhang et.al|[paper](https://arxiv.org/abs/2505.11669)|-|-|
|**2025-10-2**|**Source-Free Cross-Domain Continual Learning**|Muhammad Tanzil Furqon et.al|[paper](https://arxiv.org/abs/2510.01649)|-|-|
|**2025-10-1**|**Consistent Assistant Domains Transformer for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.01559)|[code](https://github.com/RoryShao/CADTrans.git.)|-|
|**2025-9-30**|**Source-Free Domain Adaptive Object Detection with Semantics Compensation**|Song Tang et.al|[paper](https://arxiv.org/abs/2410.05557)|-|-|
|**2025-9-29**|**DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation**|Xi Chen et.al|[paper](https://arxiv.org/abs/2509.24896)|-|-|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-10-28**|**MIC-BEV: Multi-Infrastructure Camera Bird's-Eye-View Transformer with Relation-Aware Fusion for 3D Object Detection**|Yun Zhang et.al|[paper](https://arxiv.org/abs/2510.24688)|[code](https://github.com/HandsomeYun/MIC-BEV.)|-|
|**2025-10-28**|**Multispectral State-Space Feature Fusion: Bridging Shared and Cross-Parametric Interactions for Object Detection**|Jifeng Shen et.al|[paper](https://arxiv.org/abs/2507.14643)|[code](https://github.com/61s61min/MS2Fusion.git.)|<details><summary>detail</summary>submitted on 30/4/2025</details>|
|**2025-10-28**|**Delving into Cascaded Instability: A Lipschitz Continuity View on Image Restoration and Object Detection Synergy**|Qing Zhao et.al|[paper](https://arxiv.org/abs/2510.24232)|-|<details><summary>detail</summary>NeurIPS 2025</details>|
|**2025-10-27**|**AG-Fusion: adaptive gated multimodal fusion for 3d object detection in complex scenes**|Sixian Liu et.al|[paper](https://arxiv.org/abs/2510.23151)|-|-|
|**2025-10-27**|**DQ3D: Depth-guided Query for Transformer-Based 3D Object Detection in Traffic Scenarios**|Ziyu Wang et.al|[paper](https://arxiv.org/abs/2510.23144)|-|-|
|**2025-10-25**|**3D Roadway Scene Object Detection with LIDARs in Snowfall Conditions**|Ghazal Farhani et.al|[paper](https://arxiv.org/abs/2510.22436)|-|<details><summary>detail</summary>2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC)</details>|
|**2025-10-24**|**S3OD: Towards Generalizable Salient Object Detection with Synthetic Data**|Orest Kupyn et.al|[paper](https://arxiv.org/abs/2510.21605)|-|-|
|**2025-10-24**|**LEGNet: A Lightweight Edge-Gaussian Network for Low-Quality Remote Sensing Image Object Detection**|Wei Lu et.al|[paper](https://arxiv.org/abs/2503.14012)|[code](https://github.com/AeroVILab-AHU/LEGNet.)|-|
|**2025-10-23**|**BioDet: Boosting Industrial Object Detection with Image Preprocessing Strategies**|Jiaqi Hu et.al|[paper](https://arxiv.org/abs/2510.21000)|-|-|
|**2025-10-23**|**Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection**|Talha Ilyas et.al|[paper](https://arxiv.org/abs/2510.20214)|-|<details><summary>detail</summary>This is the preprint version of the manuscript submitted to IEEE Journal of Biomedical and Health Informatics (JBHI) for review</details>|
|**2025-10-22**|**Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models**|Peter Robicheaux et.al|[paper](https://arxiv.org/abs/2505.20612)|[code](https://github.com/roboflow/rf100-vl)|<details><summary>detail</summary>The first two authors contributed equally</details>|
|**2025-10-22**|**A Unified Detection Pipeline for Robust Object Detection in Fisheye-Based Traffic Surveillance**|Neema Jakisa Owor et.al|[paper](https://arxiv.org/abs/2510.20016)|-|<details><summary>detail</summary>The paper was accepted at ICCV 2025 and published in CVF database</details>|
|**2025-10-22**|**Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR**|Adwait Chandorkar et.al|[paper](https://arxiv.org/abs/2508.00744)|-|<details><summary>detail</summary>Best Paper Award at the Embedded Vision Workshop ICCV 2025</details>|
|**2025-10-22**|**Can You Trust What You See? Alpha Channel No-Box Attacks on Video Object Detection**|Ariana Yi et.al|[paper](https://arxiv.org/abs/2510.19574)|-|-|
|**2025-10-22**|**Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts**|Chen Li et.al|[paper](https://arxiv.org/abs/2510.19487)|-|-|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-10-28**|**BEST-RQ-Based Self-Supervised Learning for Whisper Domain Adaptation**|Raphaël Bagat et.al|[paper](https://arxiv.org/abs/2510.24570)|-|<details><summary>detail</summary>Submitted to ICASSP 2026</details>|
|**2025-10-27**|**DPGLA: Bridging the Gap between Synthetic and Real Data for Unsupervised Domain Adaptation in 3D LiDAR Semantic Segmentation**|Wanmeng Li et.al|[paper](https://arxiv.org/abs/2510.23525)|-|<details><summary>detail</summary>This paper has been accepted for publication at the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</details>|
|**2025-10-27**|**PTPP-Aware Adaptation Scaling Laws: Predicting Domain-Adaptation Performance at Unseen Pre-Training Budgets**|Etienne Goffinet et.al|[paper](https://arxiv.org/abs/2510.23198)|-|-|
|**2025-10-27**|**DeepSalt: Bridging Laboratory and Satellite Spectra through Domain Adaptation and Knowledge Distillation for Large-Scale Soil Salinity Estimation**|Rupasree Dey et.al|[paper](https://arxiv.org/abs/2510.23124)|-|-|
|**2025-10-26**|**Progressive Multi-Source Domain Adaptation for Personalized Facial Expression Recognition**|Muhammad Osama Zeeshan et.al|[paper](https://arxiv.org/abs/2504.04252)|-|<details><summary>detail</summary>Transactions on Affective Computing 2025</details>|
|**2025-10-25**|**GALA: A GlobAl-LocAl Approach for Multi-Source Active Domain Adaptation**|Juepeng Zheng et.al|[paper](https://arxiv.org/abs/2510.22214)|-|-|
|**2025-10-24**|**Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.22142)|-|-|
|**2025-10-24**|**DAP-MAE: Domain-Adaptive Point Cloud Masked Autoencoder for Effective Cross-Domain Learning**|Ziqi Gao et.al|[paper](https://arxiv.org/abs/2510.21635)|-|-|
|**2025-10-24**|**Video-Skill-CoT: Skill-based Chain-of-Thoughts for Domain-Adaptive Video Reasoning**|Daeun Lee et.al|[paper](https://arxiv.org/abs/2506.03525)|[code](https://video-skill-cot.github.io/)|<details><summary>detail</summary>Project website: https://video-skill-cot</details>|
|**2025-10-24**|**Domain Adaptation-based Edge Computing for Cross-Conditions Fault Diagnosis**|Yanzhi Wang et.al|[paper](https://arxiv.org/abs/2411.10340)|-|-|
|**2025-10-24**|**PINN Balls: Scaling Second-Order Methods for PINNs with Domain Decomposition and Adaptive Sampling**|Andrea Bonfanti et.al|[paper](https://arxiv.org/abs/2510.21262)|-|<details><summary>detail</summary>Accepted Conference Paper</details>|
|**2025-10-24**|**RT-DATR: Real-time Unsupervised Domain Adaptive Detection Transformer with Adversarial Feature Alignment**|Feng Lv et.al|[paper](https://arxiv.org/abs/2504.09196)|[code](https://github.com/Jeremy-lf/RT-DATR.)|-|
|**2025-10-24**|**How to Auto-optimize Prompts for Domain Tasks? Adaptive Prompting and Reasoning through Evolutionary Domain Knowledge Adaptation**|Yang Zhao et.al|[paper](https://arxiv.org/abs/2510.21148)|-|-|
|**2025-10-23**|**Graph Data Selection for Domain Adaptation: A Model-Free Approach**|Ting-Wei Li et.al|[paper](https://arxiv.org/abs/2505.17293)|-|-|
|**2025-10-23**|**Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation**|Ziyu Ye et.al|[paper](https://arxiv.org/abs/2510.20596)|-|<details><summary>detail</summary>MICCAI 2021</details>|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-10-28**|**A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation**|Hao-Ran Yang et.al|[paper](https://arxiv.org/abs/2505.13043)|-|<details><summary>detail</summary>NeurIPS 2025</details>|
|**2025-10-28**|**Model-Guided Dual-Role Alignment for High-Fidelity Open-Domain Video-to-Audio Generation**|Kang Zhang et.al|[paper](https://arxiv.org/abs/2510.24103)|[code](https://github.com/pantheon5100/mgaudio)|<details><summary>detail</summary>accepted by NeurIPS 2025</details>|
|**2025-10-27**|**OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting**|Tingyue Pan et.al|[paper](https://arxiv.org/abs/2510.24028)|-|-|
|**2025-10-27**|**AdvBlur: Adversarial Blur for Robust Diabetic Retinopathy Classification and Cross-Domain Generalization**|Heethanjan Kanagalingam et.al|[paper](https://arxiv.org/abs/2510.24000)|-|-|
|**2025-10-27**|**Local Density-Based Anomaly Score Normalization for Domain Generalization**|Kevin Wilkinghoff et.al|[paper](https://arxiv.org/abs/2509.10951)|-|-|
|**2025-10-26**|**Robust Atypical Mitosis Classification with DenseNet121: Stain-Aware Augmentation and Hybrid Loss for Domain Generalization**|Adinath Dukre et.al|[paper](https://arxiv.org/abs/2510.22630)|-|<details><summary>detail</summary>MIDOG 2025 MICCAI Workshop accepted</details>|
|**2025-10-25**|**Emotion Recognition with Minimal Wearable Sensing: Multi-domain Feature, Hybrid Feature Selection, and Personalized vs. Generalized Ensemble Model Analysis**|Muhammad Irfan et.al|[paper](https://arxiv.org/abs/2510.22498)|-|-|
|**2025-10-24**|**Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering**|Elman Ghazaei et.al|[paper](https://arxiv.org/abs/2508.08974)|[code](https://github.com/Elman295/TCSSM.)|-|
|**2025-10-23**|**How Many Domains Suffice for Domain Generalization? A Tight Characterization via the Domain Shattering Dimension**|Cynthia Dwork et.al|[paper](https://arxiv.org/abs/2506.16704)|-|<details><summary>detail</summary>NeurIPS 2025</details>|
|**2025-10-22**|**Towards Context-Aware Domain Generalization: Understanding the Benefits and Limits of Marginal Transfer Learning**|Jens Müller et.al|[paper](https://arxiv.org/abs/2312.10107)|-|-|
|**2025-10-22**|**Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts**|Chen Li et.al|[paper](https://arxiv.org/abs/2510.19487)|-|-|
|**2025-10-22**|**Exploring Scale Shift in Crowd Localization under the Context of Domain Generalization**|Juncheng Wang et.al|[paper](https://arxiv.org/abs/2510.19330)|-|-|
|**2025-10-21**|**FlexiDataGen: An Adaptive LLM Framework for Dynamic Semantic Dataset Generation in Sensitive Domains**|Hamed Jelodar et.al|[paper](https://arxiv.org/abs/2510.19025)|-|-|
|**2025-10-21**|**XGen-Q: An Explainable Domain-Adaptive LLM Framework with Retrieval-Augmented Generation for Software Security**|Hamed Jelodar et.al|[paper](https://arxiv.org/abs/2510.19006)|-|-|
|**2025-10-20**|**TreeFedDG: Alleviating Global Drift in Federated Domain Generalization for Medical Image Segmentation**|Yucheng Song et.al|[paper](https://arxiv.org/abs/2510.18268)|-|-|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-10-28**|**Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies**|Zhixuan Liang et.al|[paper](https://arxiv.org/abs/2508.20072)|[code](https://github.com/Liang-ZX/DiscreteDiffusionVLA)|-|
|**2025-10-28**|**What do vision-language models see in the context? Investigating multimodal in-context learning**|Gabriel O. dos Santos et.al|[paper](https://arxiv.org/abs/2510.24331)|-|-|
|**2025-10-28**|**VOLD: Reasoning Transfer from LLMs to Vision-Language Models via On-Policy Distillation**|Walid Bousselham et.al|[paper](https://arxiv.org/abs/2510.23497)|-|<details><summary>detail</summary>www</details>|
|**2025-10-28**|**ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model**|Juntian Zhang et.al|[paper](https://arxiv.org/abs/2510.24285)|-|-|
|**2025-10-28**|**On Robustness of Vision-Language-Action Model against Multi-Modal Perturbations**|Jianing Guo et.al|[paper](https://arxiv.org/abs/2510.00037)|-|-|
|**2025-10-28**|**Enabling Near-realtime Remote Sensing via Satellite-Ground Collaboration of Large Vision-Language Models**|Zihan Li et.al|[paper](https://arxiv.org/abs/2510.24242)|-|-|
|**2025-10-28**|**Normal and Abnormal Pathology Knowledge-Augmented Vision-Language Model for Anomaly Detection in Pathology Images**|Jinsol Song et.al|[paper](https://arxiv.org/abs/2508.15256)|[code](https://github.com/QuIIL/ICCV2025_Ano-NAViLa)|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-10-28**|**Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning**|Aodi Wu et.al|[paper](https://arxiv.org/abs/2510.24152)|[code](https://github.com/wuaodi/UCAS-CSU-phase2.)|<details><summary>detail</summary>RoboSense Challenge with IROS 2025</details>|
|**2025-10-28**|**HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology**|Sandeep Vissapragada et.al|[paper](https://arxiv.org/abs/2510.24115)|-|-|
|**2025-10-27**|**PlanarGS: High-Fidelity Indoor 3D Gaussian Splatting Guided by Vision-Language Planar Priors**|Xirui Jin et.al|[paper](https://arxiv.org/abs/2510.23930)|[code](https://planargs.github.io)|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|
|**2025-10-27**|**Seeing Symbols, Missing Cultures: Probing Vision-Language Models' Reasoning on Fire Imagery and Cultural Meaning**|Haorui Yu et.al|[paper](https://arxiv.org/abs/2509.23311)|-|-|
|**2025-10-27**|**Explainable Detection of AI-Generated Images with Artifact Localization Using Faster-Than-Lies and Vision-Language Models for Edge Devices**|Aryan Mathur et.al|[paper](https://arxiv.org/abs/2510.23775)|-|-|
|**2025-10-27**|**UrbanVLA: A Vision-Language-Action Model for Urban Micromobility**|Anqi Li et.al|[paper](https://arxiv.org/abs/2510.23576)|-|-|
|**2025-10-27**|**Dexbotic: Open-Source Vision-Language-Action Toolbox**|Bin Xie et.al|[paper](https://arxiv.org/abs/2510.23511)|[code](https://dexbotic.com/.)|<details><summary>detail</summary>Authors are listed in alphabetical order</details>|
|**2025-10-27**|**Med-R1: Reinforcement Learning for Generalizable Medical Reasoning in Vision-Language Models**|Yuxiang Lai et.al|[paper](https://arxiv.org/abs/2503.13939)|-|-|

