## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2025.07.20

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-14**|**Text-Driven Causal Representation Learning for Source-Free Domain Generalization**|Lihua Zhou et.al|[paper](https://arxiv.org/abs/2507.09961)|-|<details><summary>detail</summary>Under Review</details>|
|**2025-7-12**|**Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting**|Zheang Huai et.al|[paper](https://arxiv.org/abs/2505.08527)|[code](https://github.com/xmed-lab/DFG.)|<details><summary>detail</summary>Accepted in TMI 2025</details>|
|**2025-7-4**|**Source-Free Domain Adaptation via Multi-view Contrastive Learning**|Amirfarhad Farhadi et.al|[paper](https://arxiv.org/abs/2507.03321)|-|-|
|**2025-6-26**|**Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework**|Ismail Nejjar et.al|[paper](https://arxiv.org/abs/2411.12558)|-|<details><summary>detail</summary>TMLR 2025</details>|
|**2025-6-26**|**Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation**|Yihong Cao et.al|[paper](https://arxiv.org/abs/2506.21198)|[code](https://github.com/yihong-97/UNLOCK.)|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-6-25**|**Context Aware Grounded Teacher for Source Free Object Detection**|Tajamul Ashraf et.al|[paper](https://arxiv.org/abs/2504.15404)|[code](https://github.com/Tajamul21/Grounded_Teacher.)|-|
|**2025-6-18**|**SFDLA: Source-Free Document Layout Analysis**|Sebastian Tewes et.al|[paper](https://arxiv.org/abs/2503.18742)|[code](https://github.com/s3setewe/sfdla-DLAdapter.)|<details><summary>detail</summary>Accepted by ICDAR 2025</details>|
|**2025-6-17**|**Unified Source-Free Domain Adaptation**|Song Tang et.al|[paper](https://arxiv.org/abs/2403.07601)|-|-|
|**2025-6-11**|**SRPL-SFDA: SAM-Guided Reliable Pseudo-Labels for Source-Free Domain Adaptation in Medical Image Segmentation**|Xinya Liu et.al|[paper](https://arxiv.org/abs/2506.09403)|[code](https://github.com/HiLab-git/SRPL-SFDA.)|-|
|**2025-6-5**|**DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization**|Geonyoung Lee et.al|[paper](https://arxiv.org/abs/2506.02858)|[code](https://wltschmrz.github.io/DGMO/)|<details><summary>detail</summary>Interspeech 2025</details>|
|**2025-5-30**|**Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2503.20771)|-|-|
|**2025-5-30**|**Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation**|Pascal Schlachter et.al|[paper](https://arxiv.org/abs/2504.11992)|[code](https://github.com/pascalschlachter/PLAnalysis.)|<details><summary>detail</summary>the 33rd European Signal Processing Conference (EUSIPCO 2025)</details>|
|**2025-5-30**|**Shuffle PatchMix Augmentation with Confidence-Margin Weighted Pseudo-Labels for Enhanced Source-Free Domain Adaptation**|Prasanna Reddy Pulakurthi et.al|[paper](https://arxiv.org/abs/2505.24216)|[code](https://github.com/PrasannaPulakurthi/SPM)|-|
|**2025-5-27**|**Multi-Granularity Class Prototype Topology Distillation for Class-Incremental Source-Free Unsupervised Domain Adaptation**|Peihua Deng et.al|[paper](https://arxiv.org/abs/2411.16064)|[code](https://github.com/dengpeihua/GROTO.)|<details><summary>detail</summary>Accepted by CVPR 2025</details>|
|**2025-5-26**|**Training-Free Multi-Step Audio Source Separation**|Yongyi Zang et.al|[paper](https://arxiv.org/abs/2505.19534)|-|-|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-17**|**A Real-Time System for Egocentric Hand-Object Interaction Detection in Industrial Domains**|Antonio Finocchiaro et.al|[paper](https://arxiv.org/abs/2507.13326)|-|-|
|**2025-7-17**|**RS-TinyNet: Stage-wise Feature Fusion Network for Detecting Tiny Objects in Remote Sensing Images**|Xiaozheng Jiang et.al|[paper](https://arxiv.org/abs/2507.13120)|-|-|
|**2025-7-17**|**Decoupled PROB: Decoupled Query Initialization Tasks and Objectness-Class Learning for Open World Object Detection**|Riku Inoue et.al|[paper](https://arxiv.org/abs/2507.13085)|-|<details><summary>detail</summary>This paper has been accepted to WACV 2025 (Tucson</details>|
|**2025-7-16**|**SOD-YOLO: Enhancing YOLO-Based Detection of Small Objects in UAV Imagery**|Peijun Wang et.al|[paper](https://arxiv.org/abs/2507.12727)|[code](https://github.com/iamwangxiaobai/SOD-YOLO.)|<details><summary>detail</summary>ACM Class:I</details>|
|**2025-7-16**|**OD-VIRAT: A Large-Scale Benchmark for Object Detection in Realistic Surveillance Environments**|Hayat Ullah et.al|[paper](https://arxiv.org/abs/2507.12396)|-|-|
|**2025-7-16**|**2.5D Object Detection for Intelligent Roadside Infrastructure**|Nikolai Polley et.al|[paper](https://arxiv.org/abs/2507.03564)|[code](https://gitlab.kit.edu/kit/aifb/ATKS/public/digit4taf/2.5d-object-detection)|<details><summary>detail</summary>2025 IEEE 28th International Conference on Intelligent Transportation Systems (ITSC)</details>|
|**2025-7-16**|**SpikeDet: Better Firing Patterns for Accurate and Energy-Efficient Object Detection with Spiking Neuron Networks**|Yimeng Fan et.al|[paper](https://arxiv.org/abs/2501.15151)|-|-|
|**2025-7-16**|**SS-DC: Spatial-Spectral Decoupling and Coupling Across Visible-Infrared Gap for Domain Adaptive Object Detection**|Xiwei Zhang et.al|[paper](https://arxiv.org/abs/2507.12017)|-|-|
|**2025-7-15**|**Combining Transformers and CNNs for Efficient Object Detection in High-Resolution Satellite Imagery**|Nicolas Drapier et.al|[paper](https://arxiv.org/abs/2507.11040)|-|-|
|**2025-7-15**|**Conceptualizing Multi-scale Wavelet Attention and Ray-based Encoding for Human-Object Interaction Detection**|Quan Bi Pay et.al|[paper](https://arxiv.org/abs/2507.10977)|[code](https://github.com/henry-pay/RayEncoder].)|<details><summary>detail</summary>International Joint Conference on Neural Networks (IJCNN 2025)</details>|
|**2025-7-14**|**LLM-Guided Agentic Object Detection for Open-World Understanding**|Furkan Mumcu et.al|[paper](https://arxiv.org/abs/2507.10844)|-|-|
|**2025-7-14**|**Versatile and Generalizable Manipulation via Goal-Conditioned Reinforcement Learning with Grounded Object Detection**|Huiyi Wang et.al|[paper](https://arxiv.org/abs/2507.10814)|-|-|
|**2025-7-14**|**Fine-Grained Zero-Shot Object Detection**|Hongxu Ma et.al|[paper](https://arxiv.org/abs/2507.10358)|-|<details><summary>detail</summary>Accepted by ACM MM'25</details>|
|**2025-7-14**|**Class-Aware PillarMix: Can Mixed Sample Data Augmentation Enhance 3D Object Detection with Radar Point Clouds?**|Miao Zhang et.al|[paper](https://arxiv.org/abs/2503.02687)|-|-|
|**2025-7-14**|**Measuring the Impact of Rotation Equivariance on Aerial Object Detection**|Xiuyu Wu et.al|[paper](https://arxiv.org/abs/2507.09896)|-|<details><summary>detail</summary>Accepted by ICCV 2025</details>|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-17**|**SIDDA: SInkhorn Dynamic Domain Adaptation for Image Classification with Equivariant Neural Networks**|Sneh Pandya et.al|[paper](https://arxiv.org/abs/2501.14048)|[code](https://github.com/deepskies/SIDDA)|-|
|**2025-7-16**|**A Privacy-Preserving Semantic-Segmentation Method Using Domain-Adaptation Technique**|Homare Sueyoshi et.al|[paper](https://arxiv.org/abs/2507.12730)|-|-|
|**2025-7-16**|**Prominent Roles of Conditionally Invariant Components in Domain Adaptation: Theory and Algorithms**|Keru Wu et.al|[paper](https://arxiv.org/abs/2309.10301)|-|-|
|**2025-7-16**|**SS-DC: Spatial-Spectral Decoupling and Coupling Across Visible-Infrared Gap for Domain Adaptive Object Detection**|Xiwei Zhang et.al|[paper](https://arxiv.org/abs/2507.12017)|-|-|
|**2025-7-16**|**Dual form Complementary Masking for Domain-Adaptive Image Segmentation**|Jiawen Wang et.al|[paper](https://arxiv.org/abs/2507.12008)|-|<details><summary>detail</summary>Accepted by ICML 2025</details>|
|**2025-7-15**|**Few-Shot Radar Signal Recognition through Self-Supervised Learning and Radio Frequency Domain Adaptation**|Zi Huang et.al|[paper](https://arxiv.org/abs/2501.03461)|-|-|
|**2025-7-15**|**Sim2Real Diffusion: Learning Cross-Domain Adaptive Representations for Transferable Autonomous Driving**|Chinmay Vilas Samak et.al|[paper](https://arxiv.org/abs/2507.00236)|-|-|
|**2025-7-14**|**SA-GDA: Spectral Augmentation for Graph Domain Adaptation**|Jinhui Pang et.al|[paper](https://arxiv.org/abs/2408.09189)|-|-|
|**2025-7-14**|**Domain-Adaptive Small Language Models for Structured Tax Code Prediction**|Souvik Nath et.al|[paper](https://arxiv.org/abs/2507.10880)|-|-|
|**2025-7-14**|**DQLoRA: A Lightweight Domain-Aware Denoising ASR via Adapter-guided Distillation**|Yiru Yang et.al|[paper](https://arxiv.org/abs/2507.10313)|-|-|
|**2025-7-14**|**Domain Borders Are There to Be Crossed With Federated Few-Shot Adaptation**|Manuel RÃ¶der et.al|[paper](https://arxiv.org/abs/2507.10160)|[code](http://dx.doi.org/10.5220/0012351900003654)|<details><summary>detail</summary>Extension of http://dx</details>|
|**2025-7-13**|**NMIXX: Domain-Adapted Neural Embeddings for Cross-Lingual eXploration of Finance**|Hanwool Lee et.al|[paper](https://arxiv.org/abs/2507.09601)|-|<details><summary>detail</summary>Under Review</details>|
|**2025-7-12**|**Domain Adaptation and Multi-view Attention for Learnable Landmark Tracking with Sparse Data**|Timothy Chase Jr et.al|[paper](https://arxiv.org/abs/2507.09420)|[code](https://tjchase34.github.io/assets/pdfs/rss_poster.pdf)|<details><summary>detail</summary>Presented at the RSS Space Robotics Workshop 2025</details>|
|**2025-7-12**|**Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting**|Zheang Huai et.al|[paper](https://arxiv.org/abs/2505.08527)|[code](https://github.com/xmed-lab/DFG.)|<details><summary>detail</summary>Accepted in TMI 2025</details>|
|**2025-7-12**|**CoCo: A Coupled Contrastive Framework for Unsupervised Domain Adaptive Graph Classification**|Nan Yin et.al|[paper](https://arxiv.org/abs/2306.04979)|-|-|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-17**|**CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings**|Daniil Orel et.al|[paper](https://arxiv.org/abs/2503.13733)|-|-|
|**2025-7-17**|**A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints**|Youssef Tawfilis et.al|[paper](https://arxiv.org/abs/2507.12979)|[code](https://github.com/youssefga28/HuSCF-GAN.)|-|
|**2025-7-17**|**Generative Multi-Target Cross-Domain Recommendation**|Jinqiu Jin et.al|[paper](https://arxiv.org/abs/2507.12871)|-|-|
|**2025-7-17**|**Simulate, Refocus and Ensemble: An Attention-Refocusing Scheme for Domain Generalization**|Ziyi Wang et.al|[paper](https://arxiv.org/abs/2507.12851)|[code](https://github.com/bitPrincy/SRE-DG.)|<details><summary>detail</summary>\c{opyright} 20XX IEEE</details>|
|**2025-7-15**|**Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation**|Siyu Chen et.al|[paper](https://arxiv.org/abs/2504.12753)|[code](https://github.com/anonymouse-xzrptkvyqc/DepthForge.)|<details><summary>detail</summary>Accepted by ICCV 2025</details>|
|**2025-7-14**|**Text-Driven Causal Representation Learning for Source-Free Domain Generalization**|Lihua Zhou et.al|[paper](https://arxiv.org/abs/2507.09961)|-|<details><summary>detail</summary>Under Review</details>|
|**2025-7-13**|**Fair Domain Generalization: An Information-Theoretic View**|Tangzheng Lian et.al|[paper](https://arxiv.org/abs/2507.05823)|-|-|
|**2025-7-11**|**RadEyeVideo: Enhancing general-domain Large Vision Language Model for chest X-ray analysis with video representations of eye gaze**|Yunsoo Kim et.al|[paper](https://arxiv.org/abs/2507.09097)|-|-|
|**2025-7-11**|**Single-Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement**|Jia-Xuan Jiang et.al|[paper](https://arxiv.org/abs/2507.08340)|[code](https://github.com/HopkinsKwong/MCCSDG)|<details><summary>detail</summary>Accepted by ACMMM 25</details>|
|**2025-7-10**|**From Domain Documents to Requirements: Retrieval-Augmented Generation in the Space Industry**|Chetan Arora et.al|[paper](https://arxiv.org/abs/2507.07689)|-|-|
|**2025-7-10**|**Sparse Causal Discovery with Generative Intervention for Unsupervised Graph Domain Adaptation**|Junyu Luo et.al|[paper](https://arxiv.org/abs/2507.07621)|-|<details><summary>detail</summary>ICML 2025</details>|
|**2025-7-9**|**SynthTextEval: Synthetic Text Data Generation and Evaluation for High-Stakes Domains**|Krithika Ramesh et.al|[paper](https://arxiv.org/abs/2507.07229)|-|-|
|**2025-7-9**|**Enhancing Food-Domain Question Answering with a Multimodal Knowledge Graph: Hybrid QA Generation and Diversity Analysis**|Srihari K B et.al|[paper](https://arxiv.org/abs/2507.06571)|-|-|
|**2025-7-7**|**AdaptaGen: Domain-Specific Image Generation through Hierarchical Semantic Optimization Framework**|Suoxiang Zhang et.al|[paper](https://arxiv.org/abs/2507.05621)|-|-|
|**2025-7-7**|**LAID: Lightweight AI-Generated Image Detection in Spatial and Spectral Domains**|Nicholas Chivaran et.al|[paper](https://arxiv.org/abs/2507.05162)|[code](https://github.com/nchivar/LAID.)|<details><summary>detail</summary>To appear in the proceedings of PST2025</details>|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-17**|**VisionThink: Smart and Efficient Vision Language Model via Reinforcement Learning**|Senqiao Yang et.al|[paper](https://arxiv.org/abs/2507.13348)|[code](https://github.com/dvlab-research/VisionThink.)|<details><summary>detail</summary>Code and models are available at https://github</details>|
|**2025-7-17**|**Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It**|Yulu Qin et.al|[paper](https://arxiv.org/abs/2507.13328)|-|-|
|**2025-7-17**|**EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos**|Ruihan Yang et.al|[paper](https://arxiv.org/abs/2507.12440)|[code](https://rchalyang.github.io/EgoVLA)|<details><summary>detail</summary>More videos can be found on our website: https://rchalyang</details>|
|**2025-7-17**|**SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models**|Xiangyu Dong et.al|[paper](https://arxiv.org/abs/2507.13152)|-|-|
|**2025-7-17**|**Aligning Information Capacity Between Vision and Language via Dense-to-Sparse Feature Distillation for Image-Text Matching**|Yang Liu et.al|[paper](https://arxiv.org/abs/2503.14953)|-|-|
|**2025-7-17**|**Unified Triplet-Level Hallucination Evaluation for Large Vision-Language Models**|Junjie Wu et.al|[paper](https://arxiv.org/abs/2410.23114)|[code](https://github.com/wujunjie1998/Tri-HE.)|<details><summary>detail</summary>Accepted by TMLR 2025</details>|
|**2025-7-17**|**GLAD: Generalizable Tuning for Vision-Language Models**|Yuqi Peng et.al|[paper](https://arxiv.org/abs/2507.13089)|-|<details><summary>detail</summary>ICCV 2025 workshop</details>|
|**2025-7-17**|**Rethinking the Embodied Gap in Vision-and-Language Navigation: A Holistic Study of Physical and Visual Disparities**|Liuyi Wang et.al|[paper](https://arxiv.org/abs/2507.13019)|[code](https://crystalsixone.github.io/vln_pe.github.io/.)|<details><summary>detail</summary>Accepted by ICCV 2025</details>|
|**2025-7-17**|**DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge**|Wenyao Zhang et.al|[paper](https://arxiv.org/abs/2507.04447)|-|-|
|**2025-7-16**|**Pixel Perfect MegaMed: A Megapixel-Scale Vision-Language Foundation Model for Generating High Resolution Medical Images**|Zahra TehraniNasab et.al|[paper](https://arxiv.org/abs/2507.12698)|[code](https://tehraninasab.github.io/pixelperfect-megamed.)|-|
|**2025-7-16**|**JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language Model**|Yi Nian et.al|[paper](https://arxiv.org/abs/2504.03770)|-|-|
|**2025-7-16**|**VLMgineer: Vision Language Models as Robotic Toolsmiths**|George Jiayuan Gao et.al|[paper](https://arxiv.org/abs/2507.12644)|[code](https://vlmgineer.github.io/release)|<details><summary>detail</summary>Project Website: https://vlmgineer</details>|
|**2025-7-16**|**Escaping Plato's Cave: JAM for Aligning Independently Trained Vision and Language Models**|Lauren Hyoseo Yoon et.al|[paper](https://arxiv.org/abs/2507.01201)|-|-|
|**2025-7-16**|**AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models**|Santosh Vasa et.al|[paper](https://arxiv.org/abs/2507.12414)|-|-|
|**2025-7-16**|**Generate to Ground: Multimodal Text Conditioning Boosts Phrase Grounding in Medical Vision-Language Models**|Felix NÃ¼tzel et.al|[paper](https://arxiv.org/abs/2507.12236)|[code](https://github.com/Felix-012/generate_to_ground.)|-|

