## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2025.12.02

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-28**|**Source-free Video Domain Adaptation by Learning from Noisy Labels**|Avijit Dasgupta et.al|[paper](https://arxiv.org/abs/2311.18572)|[code](https://avijit9.github.io/CleanAdapt.)|<details><summary>detail</summary>Our extended ICVGIP paper is now accepted in Pattern Recognition</details>|
|**2025-11-24**|**Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation**|Huisoo Lee et.al|[paper](https://arxiv.org/abs/2511.19147)|-|-|
|**2025-11-24**|**Unsupervised and Source-Free Ranking of Biomedical Segmentation Models**|Joshua Talks et.al|[paper](https://arxiv.org/abs/2503.00450)|-|-|
|**2025-11-23**|**SloMo-Fast: Slow-Momentum and Fast-Adaptive Teachers for Source-Free Continual Test-Time Adaptation**|Md Akil Raihan Iftee et.al|[paper](https://arxiv.org/abs/2511.18468)|-|-|
|**2025-11-23**|**ViMix-14M: A Curated Multi-Source Video-Text Dataset with Long-Form, High-Quality Captions and Crawl-Free Access**|Timing Yang et.al|[paper](https://arxiv.org/abs/2511.18382)|-|-|
|**2025-11-22**|**HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for Cross-Modality Medical Image Segmentation**|Yulong Shi et.al|[paper](https://arxiv.org/abs/2511.17958)|[code](https://github.com/derekshiii/HEAL.)|<details><summary>detail</summary>Accepted by The 36th British Machine Vision Conference (BMVC 2025)</details>|
|**2025-11-19**|**Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation**|Yaxuan Song et.al|[paper](https://arxiv.org/abs/2402.06213)|[code](https://github.com/YXSong000/UAD.)|<details><summary>detail</summary>Accepted by ISBI 2024</details>|
|**2025-11-10**|**Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection**|Huizai Yao et.al|[paper](https://arxiv.org/abs/2511.07301)|-|<details><summary>detail</summary>AAAI 2026</details>|
|**2025-11-5**|**Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping**|Zhihang Qin et.al|[paper](https://arxiv.org/abs/2511.03691)|-|-|
|**2025-11-1**|**Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results**|Rohan Palanikumar et.al|[paper](https://arxiv.org/abs/2511.00752)|-|-|
|**2025-10-31**|**Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising**|Kangjia Yan et.al|[paper](https://arxiv.org/abs/2510.05589)|-|-|
|**2025-10-29**|**Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation**|Yuyang Huang et.al|[paper](https://arxiv.org/abs/2510.25279)|-|<details><summary>detail</summary>Accepted by NeurIPS 2025</details>|
|**2025-10-29**|**Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation**|Quang-Khai Bui-Tran et.al|[paper](https://arxiv.org/abs/2510.25227)|-|-|
|**2025-10-28**|**Training-free Source Attribution of AI-generated Images via Resynthesis**|Pietro Bongini et.al|[paper](https://arxiv.org/abs/2510.24278)|-|-|
|**2025-10-24**|**Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation**|Renrong Shao et.al|[paper](https://arxiv.org/abs/2510.22142)|-|-|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-29**|**AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection**|Qihang Zhou et.al|[paper](https://arxiv.org/abs/2310.18961)|[code](https://github.com/zqhang/AnomalyCLIP.)|<details><summary>detail</summary>Accepted by ICLR 2024</details>|
|**2025-11-28**|**Object-Centric Data Synthesis for Category-level Object Detection**|Vikhyat Agarwal et.al|[paper](https://arxiv.org/abs/2511.23450)|-|-|
|**2025-11-28**|**Synthetic Industrial Object Detection: GenAI vs. Feature-Based Methods**|Jose Moises Araya-Martinez et.al|[paper](https://arxiv.org/abs/2511.23241)|-|<details><summary>detail</summary>MSC Class:68T45ACM Class:I</details>|
|**2025-11-28**|**Barcode and QR Code Object Detection: An Experimental Study on YOLOv8 Models**|Kushagra Pandya et.al|[paper](https://arxiv.org/abs/2511.22937)|-|<details><summary>detail</summary>7 Pages</details>|
|**2025-11-27**|**Small Object Detection for Birds with Swin Transformer**|Da Huo et.al|[paper](https://arxiv.org/abs/2511.22310)|[code](https://www.mva-org.jp/mva2023/challenge/index))|<details><summary>detail</summary>This paper is included in the proceedings of the 18th International Conference on Machine Vision Applications (MVA2023) (https://www</details>|
|**2025-11-27**|**Wavefront-Constrained Passive Obscured Object Detection**|Zhiwen Zheng et.al|[paper](https://arxiv.org/abs/2511.20991)|-|-|
|**2025-11-27**|**SemOD: Semantic Enabled Object Detection Network under Various Weather Conditions**|Aiyinsi Zuo et.al|[paper](https://arxiv.org/abs/2511.22142)|[code](https://github.com/EnisZuo/SemOD.)|-|
|**2025-11-26**|**PAGen: Phase-guided Amplitude Generation for Domain-adaptive Object Detection**|Shuchen Du et.al|[paper](https://arxiv.org/abs/2511.22029)|-|-|
|**2025-11-26**|**Adaptive Object Detection for Indoor Navigation Assistance: A Performance Evaluation of Real-Time Algorithms**|Abhinav Pratap et.al|[paper](https://arxiv.org/abs/2501.18444)|-|-|
|**2025-11-25**|**RefOnce: Distilling References into a Prototype Memory for Referring Camouflaged Object Detection**|Yu-Huan Wu et.al|[paper](https://arxiv.org/abs/2511.20989)|[code](https://github.com/yuhuan-wu/RefOnce.)|-|
|**2025-11-25**|**Open Vocabulary Monocular 3D Object Detection**|Jin Yao et.al|[paper](https://arxiv.org/abs/2411.16833)|[code](https://cvlab.cs.virginia.edu/ovmono3d)|<details><summary>detail</summary>3DV 2026</details>|
|**2025-11-25**|**StableTrack: Stabilizing Multi-Object Tracking on Low-Frequency Detections**|Matvei Shelukhan et.al|[paper](https://arxiv.org/abs/2511.20418)|-|-|
|**2025-11-25**|**Zoo3D: Zero-Shot 3D Object Detection at Scene Level**|Andrey Lemeshko et.al|[paper](https://arxiv.org/abs/2511.20253)|[code](https://github.com/col14m/zoo3d)|-|
|**2025-11-25**|**Unleashing the Power of Chain-of-Prediction for Monocular 3D Object Detection**|Zhihao Zhang et.al|[paper](https://arxiv.org/abs/2505.04594)|-|-|
|**2025-11-24**|**Video Object Recognition in Mobile Edge Networks: Local Tracking or Edge Detection?**|Kun Guo et.al|[paper](https://arxiv.org/abs/2511.20716)|-|-|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-28**|**ParaGate: Parasitic-Driven Domain Adaptation Transfer Learning for Netlist Performance Prediction**|Bin Sun et.al|[paper](https://arxiv.org/abs/2511.23340)|-|-|
|**2025-11-28**|**Tourism Question Answer System in Indian Language using Domain-Adapted Foundation Models**|Praveen Gatla et.al|[paper](https://arxiv.org/abs/2511.23235)|-|-|
|**2025-11-28**|**Source-free Video Domain Adaptation by Learning from Noisy Labels**|Avijit Dasgupta et.al|[paper](https://arxiv.org/abs/2311.18572)|[code](https://avijit9.github.io/CleanAdapt.)|<details><summary>detail</summary>Our extended ICVGIP paper is now accepted in Pattern Recognition</details>|
|**2025-11-28**|**Analysis of Incursive Breast Cancer in Mammograms Using YOLO, Explainability, and Domain Adaptation**|Jayan Adhikari et.al|[paper](https://arxiv.org/abs/2512.00129)|-|-|
|**2025-11-27**|**Domain adaptation of large language models for geotechnical applications**|Lei Fan et.al|[paper](https://arxiv.org/abs/2507.05613)|-|-|
|**2025-11-26**|**PAGen: Phase-guided Amplitude Generation for Domain-adaptive Object Detection**|Shuchen Du et.al|[paper](https://arxiv.org/abs/2511.22029)|-|-|
|**2025-11-26**|**HarmonicAttack: An Adaptive Cross-Domain Audio Watermark Removal**|Kexin Li et.al|[paper](https://arxiv.org/abs/2511.21577)|-|-|
|**2025-11-26**|**CrossEarth-Gate: Fisher-Guided Adaptive Tuning Engine for Efficient Adaptation of Cross-Domain Remote Sensing Semantic Segmentation**|Shilei Cao et.al|[paper](https://arxiv.org/abs/2511.20302)|-|-|
|**2025-11-26**|**Earth-Adapter: Bridge the Geospatial Domain Gaps with Mixture of Frequency Adaptation**|Xiaoxing Hu et.al|[paper](https://arxiv.org/abs/2504.06220)|[code](https://github.com/VisionXLab/Earth-Adapter.)|<details><summary>detail</summary>AAAI 2026 camera ready</details>|
|**2025-11-26**|**Disentangled Geometric Alignment with Adaptive Contrastive Perturbation for Reliable Domain Transfer**|Emma Collins et.al|[paper](https://arxiv.org/abs/2505.15241)|-|-|
|**2025-11-26**|**MortgageLLM: Domain-Adaptive Pretraining with Residual Instruction Transfer, Alignment Tuning, and Task-Specific Routing**|Manish Jain et.al|[paper](https://arxiv.org/abs/2511.21101)|-|-|
|**2025-11-25**|**DAPointMamba: Domain Adaptive Point Mamba for Point Cloud Completion**|Yinghui Li et.al|[paper](https://arxiv.org/abs/2511.20278)|-|<details><summary>detail</summary>AAAI 2026</details>|
|**2025-11-25**|**EfficientXpert: Efficient Domain Adaptation for Large Language Models via Propagation-Aware Pruning**|Songlin Zhao et.al|[paper](https://arxiv.org/abs/2511.19935)|-|-|
|**2025-11-24**|**AraFinNews: Arabic Financial Summarisation with Domain-Adapted LLMs**|Mo El-Haj et.al|[paper](https://arxiv.org/abs/2511.01265)|[code](https://github.com/ArabicNLP-uk/AraFinNews.)|-|
|**2025-11-24**|**Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation**|Huisoo Lee et.al|[paper](https://arxiv.org/abs/2511.19147)|-|-|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-29**|**Breaking It Down: Domain-Aware Semantic Segmentation for Retrieval Augmented Generation**|Aparajitha Allamraju et.al|[paper](https://arxiv.org/abs/2512.00367)|-|-|
|**2025-11-28**|**Do We Need Perfect Data? Leveraging Noise for Domain Generalized Segmentation**|Taeyeong Kim et.al|[paper](https://arxiv.org/abs/2511.22948)|[code](https://github.com/VisualScienceLab-KHU/FLEX-Seg.)|<details><summary>detail</summary>Accepted by AAAI 2026</details>|
|**2025-11-28**|**Hybrid Synthetic Data Generation with Domain Randomization Enables Zero-Shot Vision-Based Part Inspection Under Extreme Class Imbalance**|Ruo-Syuan Mei et.al|[paper](https://arxiv.org/abs/2512.00125)|-|<details><summary>detail</summary>Submitted to the NAMRC 54</details>|
|**2025-11-27**|**A Sampling-Based Domain Generalization Study with Diffusion Generative Models**|Ye Zhu et.al|[paper](https://arxiv.org/abs/2310.09213)|[code](https://github.com/L-YeZhu/DiscoveryDiff)|<details><summary>detail</summary>NeurIPS 2025 Workshop on Frontiers in Probabilistic Inference: Learning meets Sampling</details>|
|**2025-11-27**|**Generalizing Analogical Inference from Boolean to Continuous Domains**|Francisco Cunha et.al|[paper](https://arxiv.org/abs/2511.10416)|-|-|
|**2025-11-26**|**PAGen: Phase-guided Amplitude Generation for Domain-adaptive Object Detection**|Shuchen Du et.al|[paper](https://arxiv.org/abs/2511.22029)|-|-|
|**2025-11-25**|**Modality-Balanced Collaborative Distillation for Multi-Modal Domain Generalization**|Xiaohan Wang et.al|[paper](https://arxiv.org/abs/2511.20258)|-|-|
|**2025-11-25**|**Domain Fusion Controllable Generalization for Cross-Domain Time Series Forecasting from Multi-Domain Integrated Distribution**|Xiangkai Ma et.al|[paper](https://arxiv.org/abs/2412.03068)|-|<details><summary>detail</summary>We have updated the abstract</details>|
|**2025-11-24**|**Enhancing Domain-Specific Encoder Models with LLM-Generated Data: How to Leverage Ontologies, and How to Do Without Them**|Marc Brinner et.al|[paper](https://arxiv.org/abs/2503.22006)|-|<details><summary>detail</summary>Published in the Findings of the Association for Computational Linguistics: EMNLP 2025</details>|
|**2025-11-24**|**Cross-Domain Generalization of Multimodal LLMs for Global Photovoltaic Assessment**|Muhao Guo et.al|[paper](https://arxiv.org/abs/2511.19537)|-|-|
|**2025-11-23**|**When Generative Replay Meets Evolving Deepfakes: Domain-Aware Relative Weighting for Incremental Face Forgery Detection**|Hao Shen et.al|[paper](https://arxiv.org/abs/2511.18436)|-|-|
|**2025-11-23**|**General vs Domain-Specific CNNs: Understanding Pretraining Effects on Brain MRI Tumor Classification**|Helia Abedini et.al|[paper](https://arxiv.org/abs/2511.18326)|-|-|
|**2025-11-23**|**Building Domain-Specific Small Language Models via Guided Data Generation**|Aman Kumar et.al|[paper](https://arxiv.org/abs/2511.21748)|-|<details><summary>detail</summary>Thirty-Eighth Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-26)</details>|
|**2025-11-22**|**UniFlow: Towards Zero-Shot LiDAR Scene Flow for Autonomous Vehicles via Cross-Domain Generalization**|Siyi Li et.al|[paper](https://arxiv.org/abs/2511.18254)|[code](https://lisiyi777.github.io/UniFlow/)|<details><summary>detail</summary>Project Page: https://lisiyi777</details>|
|**2025-11-22**|**Rethinking Retrieval: From Traditional Retrieval Augmented Generation to Agentic and Non-Vector Reasoning Systems in the Financial Domain for Large Language Models**|Elias Lumer et.al|[paper](https://arxiv.org/abs/2511.18177)|-|-|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-11-30**|**TRoVe: Discovering Error-Inducing Static Feature Biases in Temporal Vision-Language Models**|Maya Varma et.al|[paper](https://arxiv.org/abs/2512.01048)|[code](https://github.com/Stanford-AIMI/TRoVe.)|<details><summary>detail</summary>NeurIPS 2025</details>|
|**2025-11-30**|**Minimal neuron ablation triggers catastrophic collapse in the language core of Large Vision-Language Models**|Cen Lu et.al|[paper](https://arxiv.org/abs/2512.00918)|-|-|
|**2025-11-30**|**SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models**|Senyu Fei et.al|[paper](https://arxiv.org/abs/2511.15605)|-|-|
|**2025-11-30**|**Vision Language Models are Biased**|An Vo et.al|[paper](https://arxiv.org/abs/2505.23941)|-|<details><summary>detail</summary>Code and qualitative examples are available at: vlmsarebiased</details>|
|**2025-11-30**|**Dynamic Multimodal Prototype Learning in Vision-Language Models**|Xingyu Zhu et.al|[paper](https://arxiv.org/abs/2507.03657)|-|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-11-30**|**BioPro: On Difference-Aware Gender Fairness for Vision-Language Models**|Yujie Lin et.al|[paper](https://arxiv.org/abs/2512.00807)|-|-|
|**2025-11-30**|**Sigma: The Key for Vision-Language-Action Models toward Telepathic Alignment**|Libo Wang et.al|[paper](https://arxiv.org/abs/2512.00783)|[code](https://huggingface.co/Veltraxor/Sigma)|<details><summary>detail</summary>The Sigma model has been open-sourced on Hugging Face</details>|
|**2025-11-30**|**When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models**|Hui Lu et.al|[paper](https://arxiv.org/abs/2511.21192)|-|-|
|**2025-11-29**|**Concept-Guided Backdoor Attack on Vision Language Models**|Haoyu Shen et.al|[paper](https://arxiv.org/abs/2512.00713)|-|-|
|**2025-11-29**|**Scaling Down to Scale Up: Towards Operationally-Efficient and Deployable Clinical Models via Cross-Modal Low-Rank Adaptation for Medical Vision-Language Models**|Thuraya Alzubaidi et.al|[paper](https://arxiv.org/abs/2512.00597)|-|-|
|**2025-11-29**|**Learning to Hear by Seeing: It's Time for Vision Language Models to Understand Artistic Emotion from Sight and Sound**|Dengming Zhang et.al|[paper](https://arxiv.org/abs/2511.12077)|-|-|
|**2025-11-29**|**Prompt-OT: An Optimal Transport Regularization Paradigm for Knowledge Preservation in Vision-Language Model Adaptation**|Xiwen Chen et.al|[paper](https://arxiv.org/abs/2503.08906)|[code](https://github.com/ChongQingNoSubway/Prompt-OT)|<details><summary>detail</summary>WACV 2026</details>|
|**2025-11-29**|**Assimilation Matters: Model-level Backdoor Detection in Vision-Language Pretrained Models**|Zhongqi Wang et.al|[paper](https://arxiv.org/abs/2512.00343)|[code](https://github.com/Robin-WZQ/AMDET)|-|
|**2025-11-28**|**A Comprehensive Survey and Guide to Multimodal Large Language Models in Vision-Language Tasks**|Chia Xin Liang et.al|[paper](https://arxiv.org/abs/2411.06284)|-|-|
|**2025-11-28**|**AutocleanEEG ICVision: Automated ICA Artifact Classification Using Vision-Language AI**|Zag ElSayed et.al|[paper](https://arxiv.org/abs/2512.00194)|-|-|

