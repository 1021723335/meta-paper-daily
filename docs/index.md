## CV Papers Daily
- [source-free](#source-free)
- [object detection](#object-detection)
- [domain adaptation](#domain-adaptation)
- [domain generalization](#domain-generalization)
- [vision language](#vision-language)


## Updated on 2025.07.30

## source-free

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-28**|**Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation**|Yihong Cao et.al|[paper](https://arxiv.org/abs/2506.21198)|[code](https://github.com/yihong-97/UNLOCK.)|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-7-26**|**GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning**|Sanqing Qu et.al|[paper](https://arxiv.org/abs/2403.14410)|[code](https://github.com/ispc-lab/GLC-plus.)|<details><summary>detail</summary>A substantial extension of the CVPR paper "Upcycling Models under Domain and Category Shift"</details>|
|**2025-7-23**|**SFUOD: Source-Free Unknown Object Detection**|Keon-Hee Park et.al|[paper](https://arxiv.org/abs/2507.17373)|-|<details><summary>detail</summary>This paper has been accepted by ICCV 2025</details>|
|**2025-7-21**|**Model-Free and Real-Time Bioinspired Unicycle-Based Source Seeking: Differential Wheeled Robotic Experiments**|Ahmed A. Elgohary et.al|[paper](https://arxiv.org/abs/2501.02184)|-|-|
|**2025-7-14**|**Text-Driven Causal Representation Learning for Source-Free Domain Generalization**|Lihua Zhou et.al|[paper](https://arxiv.org/abs/2507.09961)|-|<details><summary>detail</summary>Under Review</details>|
|**2025-7-12**|**Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting**|Zheang Huai et.al|[paper](https://arxiv.org/abs/2505.08527)|[code](https://github.com/xmed-lab/DFG.)|<details><summary>detail</summary>Accepted in TMI 2025</details>|
|**2025-7-4**|**Source-Free Domain Adaptation via Multi-view Contrastive Learning**|Amirfarhad Farhadi et.al|[paper](https://arxiv.org/abs/2507.03321)|-|-|
|**2025-6-26**|**Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework**|Ismail Nejjar et.al|[paper](https://arxiv.org/abs/2411.12558)|-|<details><summary>detail</summary>TMLR 2025</details>|
|**2025-6-25**|**Context Aware Grounded Teacher for Source Free Object Detection**|Tajamul Ashraf et.al|[paper](https://arxiv.org/abs/2504.15404)|[code](https://github.com/Tajamul21/Grounded_Teacher.)|-|
|**2025-6-18**|**SFDLA: Source-Free Document Layout Analysis**|Sebastian Tewes et.al|[paper](https://arxiv.org/abs/2503.18742)|[code](https://github.com/s3setewe/sfdla-DLAdapter.)|<details><summary>detail</summary>Accepted by ICDAR 2025</details>|
|**2025-6-17**|**Unified Source-Free Domain Adaptation**|Song Tang et.al|[paper](https://arxiv.org/abs/2403.07601)|-|-|
|**2025-6-11**|**SRPL-SFDA: SAM-Guided Reliable Pseudo-Labels for Source-Free Domain Adaptation in Medical Image Segmentation**|Xinya Liu et.al|[paper](https://arxiv.org/abs/2506.09403)|[code](https://github.com/HiLab-git/SRPL-SFDA.)|-|
|**2025-6-5**|**DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization**|Geonyoung Lee et.al|[paper](https://arxiv.org/abs/2506.02858)|[code](https://wltschmrz.github.io/DGMO/)|<details><summary>detail</summary>Interspeech 2025</details>|
|**2025-5-30**|**Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data**|Masoumeh Sharafi et.al|[paper](https://arxiv.org/abs/2503.20771)|-|-|
|**2025-5-30**|**Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation**|Pascal Schlachter et.al|[paper](https://arxiv.org/abs/2504.11992)|[code](https://github.com/pascalschlachter/PLAnalysis.)|<details><summary>detail</summary>the 33rd European Signal Processing Conference (EUSIPCO 2025)</details>|

## object detection

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-29**|**Unleashing the Power of Motion and Depth: A Selective Fusion Strategy for RGB-D Video Salient Object Detection**|Jiahao He et.al|[paper](https://arxiv.org/abs/2507.21857)|[code](https://github.com/Jia-hao999/SMFNet.)|<details><summary>detail</summary>submitted to TMM on 11-Jun-2024</details>|
|**2025-7-29**|**YOLO-PRO: Enhancing Instance-Specific Object Detection with Full-Channel Global Self-Attention**|Lin Huang et.al|[paper](https://arxiv.org/abs/2503.02348)|-|-|
|**2025-7-28**|**Collaborative Perceiver: Elevating Vision-based 3D Object Detection via Local Density-Aware Spatial Occupancy**|Jicheng Yuan et.al|[paper](https://arxiv.org/abs/2507.21358)|[code](https://github.com/jichengyuan/Collaborative-Perceiver.)|-|
|**2025-7-28**|**Tracking Moose using Aerial Object Detection**|Christopher Indris et.al|[paper](https://arxiv.org/abs/2507.21256)|[code](https://github.com/chrisindris/Moose.)|-|
|**2025-7-28**|**Rethinking Multi-Modal Object Detection from the Perspective of Mono-Modality Feature Learning**|Tianyi Zhao et.al|[paper](https://arxiv.org/abs/2503.11780)|[code](https://github.com/Zhao-Tian-yi/M2D-LIF.)|-|
|**2025-7-28**|**Hoi2Threat: An Interpretable Threat Detection Method for Human Violence Scenarios Guided by Human-Object Interaction**|Yuhan Wang et.al|[paper](https://arxiv.org/abs/2503.10508)|-|-|
|**2025-7-28**|**Synthetic-to-Real Camouflaged Object Detection**|Zhihao Luo et.al|[paper](https://arxiv.org/abs/2507.18911)|[code](https://github.com/Muscape/S2R-COD.)|-|
|**2025-7-27**|**Wavelet-guided Misalignment-aware Network for Visible-Infrared Object Detection**|Haote Zhang et.al|[paper](https://arxiv.org/abs/2507.20146)|-|-|
|**2025-7-26**|**DriveIndia: An Object Detection Dataset for Diverse Indian Traffic Scenes**|Rishav Kumar et.al|[paper](https://arxiv.org/abs/2507.19912)|[code](https://tihan.iith.ac.in/tiand-datasets/).)|<details><summary>detail</summary>ITSC 2025 Conference</details>|
|**2025-7-26**|**Interpretable Open-Vocabulary Referring Object Detection with Reverse Contrast Attention**|Drandreb Earl O. Juanico et.al|[paper](https://arxiv.org/abs/2507.19891)|-|-|
|**2025-7-26**|**OW-CLIP: Data-Efficient Visual Supervision for Open-World Object Detection via Human-AI Collaboration**|Junwen Duan et.al|[paper](https://arxiv.org/abs/2507.19870)|-|-|
|**2025-7-26**|**RaGS: Unleashing 3D Gaussian Splatting from 4D Radar and Monocular Cues for 3D Object Detection**|Xiaokai Bai et.al|[paper](https://arxiv.org/abs/2507.19856)|-|-|
|**2025-7-26**|**DS-Det: Single-Query Paradigm and Attention Disentangled Learning for Flexible Object Detection**|Guiping Cao et.al|[paper](https://arxiv.org/abs/2507.19807)|[code](https://github.com/Med-Process/DS-Det/.)|<details><summary>detail</summary>Journal ref:The 33rd ACM International Conference on Multimedia 2025</details>|
|**2025-7-26**|**TransFlow: Motion Knowledge Transfer from Video Diffusion Models to Video Salient Object Detection**|Suhwan Cho et.al|[paper](https://arxiv.org/abs/2507.19789)|-|<details><summary>detail</summary>ICCVW 2025</details>|
|**2025-7-25**|**Co-Win: Joint Object Detection and Instance Segmentation in LiDAR Point Clouds via Collaborative Window Processing**|Haichuan Li et.al|[paper](https://arxiv.org/abs/2507.19691)|-|-|

## domain adaptation

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-29**|**Domain Generalization and Adaptation in Intensive Care with Anchor Regression**|Malte Londschien et.al|[paper](https://arxiv.org/abs/2507.21783)|-|-|
|**2025-7-29**|**GDAIP: A Graph-Based Domain Adaptive Framework for Individual Brain Parcellation**|Jianfei Zhu et.al|[paper](https://arxiv.org/abs/2507.21727)|-|-|
|**2025-7-29**|**ST-DAI: Single-shot 2.5D Spatial Transcriptomics with Intra-Sample Domain Adaptive Imputation for Cost-efficient 3D Reconstruction**|Jiahe Qian et.al|[paper](https://arxiv.org/abs/2507.21516)|-|-|
|**2025-7-28**|**Adapting Vehicle Detectors for Aerial Imagery to Unseen Domains with Weak Supervision**|Xiao Fang et.al|[paper](https://arxiv.org/abs/2507.20976)|[code](https://humansensinglab.github.io/AGenDA)|<details><summary>detail</summary>ICCV 2025</details>|
|**2025-7-28**|**From Entanglement to Alignment: Representation Space Decomposition for Unsupervised Time Series Domain Adaptation**|Rongyao Cai et.al|[paper](https://arxiv.org/abs/2507.20968)|-|-|
|**2025-7-27**|**Partial Domain Adaptation via Importance Sampling-based Shift Correction**|Cheng-Jun Guo et.al|[paper](https://arxiv.org/abs/2507.20191)|-|-|
|**2025-7-26**|**GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning**|Sanqing Qu et.al|[paper](https://arxiv.org/abs/2403.14410)|[code](https://github.com/ispc-lab/GLC-plus.)|<details><summary>detail</summary>A substantial extension of the CVPR paper "Upcycling Models under Domain and Category Shift"</details>|
|**2025-7-25**|**Deep Unsupervised Domain Adaptation for Time Series Classification: a Benchmark**|Hassan Ismail Fawaz et.al|[paper](https://arxiv.org/abs/2312.09857)|[code](https://github.com/EricssonResearch/UDA-4-TSC.)|<details><summary>detail</summary>Published in Data Mining and Knowledge Discovery</details>|
|**2025-7-25**|**Style-Adaptive Detection Transformer for Single-Source Domain Generalized Object Detection**|Jianhong Han et.al|[paper](https://arxiv.org/abs/2504.20498)|-|<details><summary>detail</summary>Manuscript submitted to IEEE Transactions on Circuits and Systems for Video Technology</details>|
|**2025-7-24**|**SIDA: Synthetic Image Driven Zero-shot Domain Adaptation**|Ye-Chan Kim et.al|[paper](https://arxiv.org/abs/2507.18632)|-|<details><summary>detail</summary>ACM MM 2025</details>|
|**2025-7-24**|**crossMoDA Challenge: Evolution of Cross-Modality Domain Adaptation Techniques for Vestibular Schwannoma and Cochlea Segmentation from 2021 to 2023**|Navodini Wijethilake et.al|[paper](https://arxiv.org/abs/2506.12006)|-|-|
|**2025-7-24**|**Att-Adapter: A Robust and Precise Domain-Specific Multi-Attributes T2I Diffusion Adapter via Conditional Variational Autoencoder**|Wonwoong Cho et.al|[paper](https://arxiv.org/abs/2503.11937)|[code](https://tri-mac.github.io/att-adapter/)|<details><summary>detail</summary>ICCV'25 (Highlight)</details>|
|**2025-7-24**|**Unsupervised Domain Adaptation for 3D LiDAR Semantic Segmentation Using Contrastive Learning and Multi-Model Pseudo Labeling**|Abhishek Kaushik et.al|[paper](https://arxiv.org/abs/2507.18176)|-|-|
|**2025-7-23**|**AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation**|Md. Al-Masrur Khan et.al|[paper](https://arxiv.org/abs/2507.17957)|[code](https://github.com/Masrur02/AFRDA)|-|
|**2025-7-23**|**ODES: Domain Adaptation with Expert Guidance for Online Medical Image Segmentation**|Md Shazid Islam et.al|[paper](https://arxiv.org/abs/2312.05407)|-|-|

## domain generalization

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-29**|**Domain Generalization and Adaptation in Intensive Care with Anchor Regression**|Malte Londschien et.al|[paper](https://arxiv.org/abs/2507.21783)|-|-|
|**2025-7-28**|**Exploring Probabilistic Modeling Beyond Domain Generalization for Semantic Segmentation**|I-Hsiang Chen et.al|[paper](https://arxiv.org/abs/2507.21367)|-|<details><summary>detail</summary>Accepted by ICCV2025</details>|
|**2025-7-26**|**FedS2R: One-Shot Federated Domain Generalization for Synthetic-to-Real Semantic Segmentation in Autonomous Driving**|Tao Lian et.al|[paper](https://arxiv.org/abs/2507.19881)|-|-|
|**2025-7-25**|**PennyCoder: Efficient Domain-Specific LLMs for PennyLane-Based Quantum Code Generation**|Abdul Basit et.al|[paper](https://arxiv.org/abs/2507.19562)|-|-|
|**2025-7-25**|**From Continuous to Discrete: Cross-Domain Collaborative General Speech Enhancement via Hierarchical Language Models**|Zhaoxi Mu et.al|[paper](https://arxiv.org/abs/2507.19062)|-|<details><summary>detail</summary>ACMMM 2025</details>|
|**2025-7-25**|**Style-Adaptive Detection Transformer for Single-Source Domain Generalized Object Detection**|Jianhong Han et.al|[paper](https://arxiv.org/abs/2504.20498)|-|<details><summary>detail</summary>Manuscript submitted to IEEE Transactions on Circuits and Systems for Video Technology</details>|
|**2025-7-24**|**Omni-Thinker: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards**|Derek Li et.al|[paper](https://arxiv.org/abs/2507.14783)|-|-|
|**2025-7-24**|**VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks**|Juhwan Choi et.al|[paper](https://arxiv.org/abs/2407.19795)|-|<details><summary>detail</summary>ICCV 2025 Workshop on Curated Data for Efficient Learning (CDEL)</details>|
|**2025-7-23**|**Fully Automated SAM for Single-source Domain Generalization in Medical Image Segmentation**|Huanli Zhuo et.al|[paper](https://arxiv.org/abs/2507.17281)|-|<details><summary>detail</summary>This manuscript has been accepted for presentation at the IEEE International Conference on Systems</details>|
|**2025-7-21**|**Gradient-Guided Annealing for Domain Generalization**|Aristotelis Ballas et.al|[paper](https://arxiv.org/abs/2502.20162)|-|<details><summary>detail</summary>Paper accepted in CVPR2025</details>|
|**2025-7-20**|**DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation**|Bo Liu et.al|[paper](https://arxiv.org/abs/2501.03466)|-|-|
|**2025-7-19**|**Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification**|Subhendu Khatuya et.al|[paper](https://arxiv.org/abs/2506.06806)|-|<details><summary>detail</summary>This work has been accepted to appear at the Association for Computational Linguistics (ACL)</details>|
|**2025-7-18**|**VizGenie: Toward Self-Refining, Domain-Aware Workflows for Next-Generation Scientific Visualization**|Ayan Biswas et.al|[paper](https://arxiv.org/abs/2507.21124)|-|-|
|**2025-7-17**|**Generative Multi-Target Cross-Domain Recommendation**|Jinqiu Jin et.al|[paper](https://arxiv.org/abs/2507.12871)|-|<details><summary>detail</summary>fix author information</details>|
|**2025-7-17**|**Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning**|Simon Ouellette et.al|[paper](https://arxiv.org/abs/2507.15877)|-|-|

## vision language

|Date|Title|Authors|PDF|Code|Comments|
|:------|:---------------------|:---|:-|:-|:---|
|**2025-7-29**|**GLIMPSE: Holistic Cross-Modal Explainability for Large Vision-Language Models**|Guanxi Shen et.al|[paper](https://arxiv.org/abs/2506.18985)|-|<details><summary>detail</summary>Keywords: Explainable Computer Vision</details>|
|**2025-7-29**|**Cardiac-CLIP: A Vision-Language Foundation Model for 3D Cardiac CT Images**|Yutao Hu et.al|[paper](https://arxiv.org/abs/2507.22024)|-|-|
|**2025-7-29**|**Representations in vision and language converge in a shared, multidimensional space of perceived similarities**|Katerina Marie Simkova et.al|[paper](https://arxiv.org/abs/2507.21871)|-|-|
|**2025-7-29**|**Knowledge Regularized Negative Feature Tuning of Vision-Language Models for Out-of-Distribution Detection**|Wenjie Zhu et.al|[paper](https://arxiv.org/abs/2507.19847)|[code](https://github.com/ZhuWenjie98/KRNFT)|<details><summary>detail</summary>accepted by ACMMM 2025</details>|
|**2025-7-29**|**Distribution-Based Masked Medical Vision-Language Model Using Structured Reports**|Shreyank N Gowda et.al|[paper](https://arxiv.org/abs/2507.21794)|-|<details><summary>detail</summary>Accepted in MICCAI-W 2025</details>|
|**2025-7-29**|**VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback**|Jianxin Bi et.al|[paper](https://arxiv.org/abs/2507.17294)|[code](https://github.com/jxbi1010/VLA-Touch)|-|
|**2025-7-29**|**Few-Shot Vision-Language Reasoning for Satellite Imagery via Verifiable Rewards**|Aybora Koksal et.al|[paper](https://arxiv.org/abs/2507.21745)|[code](https://github.com/aybora/FewShotReasoning)|<details><summary>detail</summary>ICCV 2025 Workshop on Curated Data for Efficient Learning (CDEL)</details>|
|**2025-7-29**|**Self-Aware Safety Augmentation: Leveraging Internal Semantic Understanding to Enhance Safety in Vision-Language Models**|Wanying Wang et.al|[paper](https://arxiv.org/abs/2507.21637)|-|<details><summary>detail</summary>Accepted by ACM Multimedia 2025</details>|
|**2025-7-29**|**PEVLM: Parallel Encoding for Vision-Language Models**|Letian Kang et.al|[paper](https://arxiv.org/abs/2506.19651)|-|-|
|**2025-7-29**|**Optimizing Active Learning in Vision-Language Models via Parameter-Efficient Uncertainty Calibration**|Athmanarayanan Lakshmi Narayanan et.al|[paper](https://arxiv.org/abs/2507.21521)|-|<details><summary>detail</summary>International Joint Conference on Neural Networks 2025 (Accepted)</details>|
|**2025-7-29**|**Latte: Collaborative Test-Time Adaptation of Vision-Language Models in Federated Learning**|Wenxuan Bao et.al|[paper](https://arxiv.org/abs/2507.21494)|[code](https://github.com/baowenxuan/Latte)|<details><summary>detail</summary>Accepted by ICCV 2025</details>|
|**2025-7-28**|**ManiTaskGen: A Comprehensive Task Generator for Benchmarking and Improving Vision-Language Agents on Embodied Decision-Making**|Liu Dai et.al|[paper](https://arxiv.org/abs/2505.20726)|[code](https://manitaskgen.github.io/)|<details><summary>detail</summary>Project Website: https://manitaskgen</details>|
|**2025-7-28**|**Recursive Visual Imagination and Adaptive Linguistic Grounding for Vision Language Navigation**|Bolei Chen et.al|[paper](https://arxiv.org/abs/2507.21450)|-|<details><summary>detail</summary>Submitted to AAAI 2026</details>|
|**2025-7-28**|**VLM-CPL: Consensus Pseudo Labels from Vision-Language Models for Annotation-Free Pathological Image Classification**|Lanfeng Zhong et.al|[paper](https://arxiv.org/abs/2403.15836)|[code](https://github.com/HiLab-git/VLM-CPL.)|<details><summary>detail</summary>TMI</details>|
|**2025-7-28**|**Analyzing the Sensitivity of Vision Language Models in Visual Question Answering**|Monika Shah et.al|[paper](https://arxiv.org/abs/2507.21335)|-|-|

